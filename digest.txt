Directory structure:
‚îî‚îÄ‚îÄ sync-genai-poc/
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ AGENT_ARCHITECTURE.md
    ‚îú‚îÄ‚îÄ CLAUDE.md
    ‚îú‚îÄ‚îÄ index.html
    ‚îú‚îÄ‚îÄ main.py
    ‚îú‚îÄ‚îÄ package.json
    ‚îú‚îÄ‚îÄ postcss.config.js
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ tailwind.config.js
    ‚îú‚îÄ‚îÄ test_gemini.py
    ‚îú‚îÄ‚îÄ tsconfig.json
    ‚îú‚îÄ‚îÄ tsconfig.node.json
    ‚îú‚îÄ‚îÄ vite.config.ts
    ‚îú‚îÄ‚îÄ app/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ router.py
    ‚îÇ   ‚îú‚îÄ‚îÄ agents/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ carecredit.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_agent.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collections.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contracts.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contracts_enhanced.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ devcopilot.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dispute.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dispute_reg_e.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ imagegen.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ narrator.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ offerpilot.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trustshield.py
    ‚îÇ   ‚îú‚îÄ‚îÄ config/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rules_loader.py
    ‚îÇ   ‚îú‚îÄ‚îÄ contracts/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ merchant_agreement.md
    ‚îÇ   ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ financing_offers.json
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hardship_policies.json
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ marketplace_catalog.json
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics_schema.json
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ provider_catalog.json
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ providers.json
    ‚îÇ   ‚îú‚îÄ‚îÄ kb/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contract_ontology.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_privacy_policy.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ disputes_policy.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ promotional_terms.md
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ security_guidelines.md
    ‚îÇ   ‚îú‚îÄ‚îÄ llm/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini.py
    ‚îÇ   ‚îú‚îÄ‚îÄ multi_agent/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ supervisor.py
    ‚îÇ   ‚îú‚îÄ‚îÄ openapi/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ payments.json
    ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ multi_agent.py
    ‚îÇ   ‚îú‚îÄ‚îÄ rag/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py
    ‚îÇ   ‚îú‚îÄ‚îÄ services/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pdf_processor.py
    ‚îÇ   ‚îú‚îÄ‚îÄ tools/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini_chat.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tavily_search.py
    ‚îÇ   ‚îú‚îÄ‚îÄ ui/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.html
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modern.html
    ‚îÇ   ‚îî‚îÄ‚îÄ utils/
    ‚îÇ       ‚îî‚îÄ‚îÄ tracer.py
    ‚îú‚îÄ‚îÄ metrics/
    ‚îÇ   ‚îú‚îÄ‚îÄ credit_metrics.csv
    ‚îÇ   ‚îú‚îÄ‚îÄ delinquency_rates.csv
    ‚îÇ   ‚îú‚îÄ‚îÄ portfolio_spend.csv
    ‚îÇ   ‚îî‚îÄ‚îÄ promo_performance.csv
    ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx
    ‚îÇ   ‚îú‚îÄ‚îÄ index.css
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tsx
    ‚îÇ   ‚îú‚îÄ‚îÄ types.ts
    ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AgentTheater.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatMessage.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatPane.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Header.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LandingPage.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LeftRail.tsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MarkdownRenderer.tsx
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ RightInspector.tsx
    ‚îÇ   ‚îî‚îÄ‚îÄ config/
    ‚îÇ       ‚îî‚îÄ‚îÄ agents.ts
    ‚îî‚îÄ‚îÄ synchrony-demo-rules-repo/
        ‚îú‚îÄ‚îÄ README.md
        ‚îú‚îÄ‚îÄ flags.json
        ‚îú‚îÄ‚îÄ VERSION.txt
        ‚îú‚îÄ‚îÄ fixtures/
        ‚îÇ   ‚îú‚îÄ‚îÄ merchants.json
        ‚îÇ   ‚îú‚îÄ‚îÄ products.json
        ‚îÇ   ‚îú‚îÄ‚îÄ providers.json
        ‚îÇ   ‚îú‚îÄ‚îÄ transactions.json
        ‚îÇ   ‚îú‚îÄ‚îÄ users.json
        ‚îÇ   ‚îú‚îÄ‚îÄ contracts/
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ card_terms_urbanliving_v1.md
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ carecredit_terms_v1.md
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ partner_agreement_lifestyle_v1.md
        ‚îÇ   ‚îú‚îÄ‚îÄ dev_docs/
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dispute_status.md
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ error_handling.md
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging.md
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ onboarding.md
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ webhooks.md
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ widget_embed.md
        ‚îÇ   ‚îú‚îÄ‚îÄ disputes/
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample_intake_duplicate.md
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample_intake_not_received.md
        ‚îÇ   ‚îú‚îÄ‚îÄ estimates/
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dental_implant_estimate_01.txt
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dermatology_laser_01.txt
        ‚îÇ   ‚îú‚îÄ‚îÄ marketing/
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ email_templates/
        ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ header_equal_payment.md
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ signage_templates/
        ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ a4_deferred_interest.md
        ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ a4_equal_payment.md
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ social_templates/
        ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ square_equal_payment.md
        ‚îÇ   ‚îî‚îÄ‚îÄ narrator/
        ‚îÇ       ‚îú‚îÄ‚îÄ kpi_definitions.md
        ‚îÇ       ‚îî‚îÄ‚îÄ mock_portfolio_metrics.json
        ‚îú‚îÄ‚îÄ golden_tests/
        ‚îÇ   ‚îú‚îÄ‚îÄ collections_plan_demo.json
        ‚îÇ   ‚îú‚îÄ‚îÄ contracts_detection_demo.json
        ‚îÇ   ‚îú‚îÄ‚îÄ devcopilot_widget_embed_demo.json
        ‚îÇ   ‚îú‚îÄ‚îÄ dispute_duplicate_charge_demo.json
        ‚îÇ   ‚îú‚îÄ‚îÄ imagegen_marketing_flyer_demo.json
        ‚îÇ   ‚îî‚îÄ‚îÄ offerpilot_carecredit_demo.json
        ‚îî‚îÄ‚îÄ rules/
            ‚îú‚îÄ‚îÄ carecredit.yml
            ‚îú‚îÄ‚îÄ collections.yml
            ‚îú‚îÄ‚îÄ contracts_lexicon.yml
            ‚îú‚îÄ‚îÄ disclosures.yml
            ‚îú‚îÄ‚îÄ dispute.yml
            ‚îú‚îÄ‚îÄ imagegen.yml
            ‚îú‚îÄ‚îÄ narrator.yml
            ‚îú‚îÄ‚îÄ prequalification.yml
            ‚îú‚îÄ‚îÄ promotions.yml
            ‚îú‚îÄ‚îÄ routing.yml
            ‚îú‚îÄ‚îÄ run_ledger_schema.json
            ‚îî‚îÄ‚îÄ trustshield.yml

================================================
FILE: README.md
================================================
# Synch GenAI PoC

A complete GenAI-powered financial services platform with 8 specialized AI agents, intelligent document processing, and enhanced markdown rendering.

## Quick Start

### Install Dependencies
```bash
# Install Node.js dependencies
npm install

# Install Python dependencies (if not already done)
pip install -r requirements.txt
```

### Development
```bash
# Start backend server (Terminal 1)
python main.py

# Start frontend development server (Terminal 2)
npm run dev
```

### Production
```bash
# Build frontend
npm run build

# Start production server
python main.py
```

## Features

### üß† Intelligent Fallback System
- **LLM Knowledge Fallback**: Uses the LLM's training knowledge when documents are insufficient
- **Web Search Integration**: Tavily search for current information
- **Smart Document Assessment**: AI-powered evaluation of document relevance and coverage

### üé® Enhanced UI
- **React + TypeScript**: Modern, type-safe frontend with proper markdown rendering
- **Syntax Highlighting**: Beautiful code blocks with language detection
- **Drag & Drop PDF**: Upload documents directly in chat
- **Fallback Indicators**: Visual feedback for knowledge sources used

### ü§ñ 8 Specialized AI Agents
- **Smart Chat**: AI router with intelligent fallbacks
- **OfferPilot**: Product search with financing
- **Dispute Copilot**: Credit card dispute assistance
- **Collections**: Hardship and payment plans
- **DevCopilot**: Code generation and API docs
- **CareCredit**: Medical expense analysis
- **Narrator**: Portfolio analytics
- **ImageGen**: AI image generation

## Environment Variables

Create `.env` file with:
```bash
GOOGLE_API_KEY=your_gemini_api_key
VISION_AGENT_API_KEY=your_landing_ai_key
TAVILY_API_KEY=your_tavily_key  # Optional
ALLOW_TAVILY=true  # Optional
```

## Architecture

- **Backend**: FastAPI with intelligent RAG and fallback systems
- **Frontend**: React + TypeScript with proper markdown rendering
- **AI**: Google Gemini with document assessment and knowledge fallbacks
- **PDF Processing**: Landing AI with bounding box extraction
- **Security**: PII redaction and TrustShield content filtering


================================================
FILE: AGENT_ARCHITECTURE.md
================================================
# Synch GenAI PoC - Agent Architecture Documentation

## System Overview

The Synch GenAI PoC is a comprehensive financial services chatbot platform with 8 specialized AI agents, intelligent routing, and PDF processing capabilities. The system is designed for defensive security applications with built-in PII protection and fraud detection.

## Agent Architecture Flow

```mermaid
flowchart TD
    %% User Input Layer
    User[üë§ User Input] --> UI[üñ•Ô∏è React Frontend]
    
    %% Routing Layer
    UI --> Router{üß≠ Smart Router}
    Router --> |"Gemini Classification"| GeminiClass[ü§ñ Gemini Classifier]
    GeminiClass --> |"confidence < 0.6"| KeywordFallback[üìù Keyword Analysis]
    KeywordFallback --> RouterDecision[üìä Final Route Decision]
    GeminiClass --> |"confidence >= 0.6"| RouterDecision
    
    %% Smart Chat Special Flow
    Router --> |"smart agent"| SmartChat[üß† Smart Chat Agent]
    SmartChat --> |"Route to best agent"| AutoRoute[üîÑ Auto-route to specialist]
    AutoRoute --> Agent1[Agent Selection]
    
    %% Agent Layer
    RouterDecision --> Agent1
    Agent1 --> |"offer"| OfferPilot[üè∑Ô∏è OfferPilot]
    Agent1 --> |"trust"| TrustShield[üõ°Ô∏è TrustShield]
    Agent1 --> |"dispute"| DisputeCopilot[‚öñÔ∏è Dispute Copilot]
    Agent1 --> |"collections"| Collections[üí≥ Collections Agent]
    Agent1 --> |"devcopilot"| DevCopilot[üíª DevCopilot]
    Agent1 --> |"carecredit"| CareCredit[‚ù§Ô∏è CareCredit]
    Agent1 --> |"narrator"| Narrator[üìä Portfolio Narrator]
    Agent1 --> |"imagegen"| ImageGen[üé® Image Generator]
    
    %% RAG System
    subgraph RAG["üóÑÔ∏è RAG Knowledge Base"]
        DocStore[(üìö Document Store)]
        Embedder[üî¢ Gemini Embeddings]
        Retriever[üîç Vector Retriever]
        MarkdownDocs[üìÑ Markdown Documents]
        PDFDocs[üìÑ PDF Documents]
    end
    
    %% PDF Processing Pipeline
    PDFUpload[üì§ PDF Upload] --> PDFProcessor[üîÑ LandingAI PDF Processor]
    PDFProcessor --> PDFChunks[üìë Text Chunks + Bounding Boxes]
    PDFChunks --> DocStore
    
    %% Agent Processing
    OfferPilot --> RAG
    TrustShield --> RAG
    TrustShield --> PII[üîê PII Detection/Redaction]
    DisputeCopilot --> RAG
    Collections --> RAG
    DevCopilot --> APIRef[üìñ API Reference]
    CareCredit --> RAG
    Narrator --> RAG
    ImageGen --> StableDiffusion[üé® Stable Diffusion API]
    
    %% Fallback System
    subgraph Fallbacks["üîÑ Intelligent Fallbacks"]
        LLMFallback[üß† LLM Knowledge Fallback]
        WebSearch[üåê Web Search Fallback]
        TavilyLegacy[üîç Tavily Search Legacy]
    end
    
    SmartChat --> |"insufficient docs"| Fallbacks
    
    %% Response Processing
    OfferPilot --> ResponseProc[üì§ Response Processing]
    TrustShield --> ResponseProc
    DisputeCopilot --> ResponseProc
    Collections --> ResponseProc
    DevCopilot --> ResponseProc
    CareCredit --> ResponseProc
    Narrator --> ResponseProc
    ImageGen --> ResponseProc
    
    ResponseProc --> |"with citations"| UI
    ResponseProc --> |"confidence score"| UI
    ResponseProc --> |"source tracking"| UI
    
    %% UI Components
    UI --> ChatPane[üí¨ Chat Interface]
    UI --> AgentSelector[üéõÔ∏è Agent Selector]
    UI --> PDFViewer[üìÑ PDF Viewer]
    UI --> CitationsPanel[üìù Citations Panel]
    UI --> ToolTrace[üîß Tool Trace Panel]
    
    %% Styling
    classDef userLayer fill:#e1f5fe
    classDef routingLayer fill:#f3e5f5
    classDef agentLayer fill:#e8f5e8
    classDef ragLayer fill:#fff3e0
    classDef uiLayer fill:#fce4ec
    
    class User,UI userLayer
    class Router,GeminiClass,KeywordFallback,RouterDecision,SmartChat,AutoRoute routingLayer
    class OfferPilot,TrustShield,DisputeCopilot,Collections,DevCopilot,CareCredit,Narrator,ImageGen agentLayer
    class RAG,DocStore,Embedder,Retriever,MarkdownDocs,PDFDocs ragLayer
    class ChatPane,AgentSelector,PDFViewer,CitationsPanel,ToolTrace uiLayer
```

## Agent Detailed Specifications

### üß† Smart Chat Agent
- **Purpose**: Intelligent routing hub that analyzes queries and routes to the most appropriate specialist agent
- **Key Features**:
  - Uses Gemini LLM for intent classification
  - Confidence-based routing with fallback mechanisms
  - Supports LLM knowledge and web search fallbacks when RAG documents are insufficient
  - Real-time document assessment for relevance
- **Fallback Options**: LLM Knowledge, Web Search, Legacy Tavily
- **Example Query**: *"Find a standing desk under ‚Çπ50k with 12-mo 0% APR"*

### üè∑Ô∏è OfferPilot
- **Purpose**: Product search and financing options specialist
- **Core Functions**:
  - Product discovery with budget constraints
  - Financing option analysis (APR, payment plans)
  - Promotional offer matching
  - Cross-sell opportunity identification
- **Integration**: Connected to RAG system for product knowledge
- **Example Query**: *"Show me wireless headphones under $200"*

### üõ°Ô∏è TrustShield
- **Purpose**: Real-time fraud detection and PII protection system
- **Advanced Capabilities**:
  - Multi-layer scam pattern recognition
  - PII detection and automatic redaction using Microsoft Presidio
  - Risk scoring with confidence metrics
  - Safety guidance recommendations
  - Threat evidence compilation
- **Security Features**: Built-in defensive measures, no malicious code generation
- **Example Query**: *"Someone called asking for my SSN to verify my account"*

### ‚öñÔ∏è Dispute Copilot
- **Purpose**: Credit card and transaction dispute assistance
- **Specialized Functions**:
  - Dispute classification and merit analysis
  - Evidence collection guidance
  - Chargeback process navigation
  - Documentation requirement checklists
- **Integration**: RAG-powered with dispute resolution knowledge base
- **Example Query**: *"I was charged twice for the same purchase"*

### üí≥ Collections Agent
- **Purpose**: Payment assistance and hardship support
- **Customer-Focused Features**:
  - Payment plan options analysis
  - Hardship assessment and solutions
  - Customer state tracking (balance, APR, bucket status)
  - Empathetic communication patterns
- **Data Integration**: Customer account state analysis
- **Example Query**: *"I need help with payment plan options"*

### üíª DevCopilot
- **Purpose**: Technical support and API documentation assistant
- **Developer Tools**:
  - Code generation for payment processing
  - API endpoint documentation
  - Integration guidance and troubleshooting
  - SDK usage examples
  - Multi-language support (Python, JavaScript, Java, etc.)
- **Knowledge Base**: Technical documentation and best practices
- **Example Query**: *"Generate Python code for payment processing"*

### ‚ù§Ô∏è CareCredit
- **Purpose**: Healthcare and medical expense analysis specialist
- **Healthcare Focus**:
  - Medical treatment estimate analysis
  - Dental procedure cost breakdowns
  - Healthcare financing option evaluation
  - Insurance coverage assessment
- **Specialized Knowledge**: Medical billing and healthcare financing
- **Example Query**: *"Analyze this dental treatment estimate"*

### üìä Portfolio Narrator
- **Purpose**: Business intelligence and portfolio analytics
- **Analytics Capabilities**:
  - Spending pattern analysis
  - Portfolio performance insights
  - Trend identification and explanation
  - Business metrics interpretation
- **Data Sources**: Financial data and portfolio information
- **Example Query**: *"Why did spend drop after 2025-07-31?"*

### üé® ImageGen Agent
- **Purpose**: AI-powered visual content generation
- **Creative Features**:
  - Text-to-image generation using Stable Diffusion
  - Style customization options
  - Marketing visual creation
  - Concept visualization
- **API Integration**: Stable Diffusion API
- **Example Query**: *"Create a futuristic city with flying cars and neon lights"*

## System Architecture Components

### üß≠ Intelligent Routing System
- **Primary**: Gemini-powered intent classification
- **Fallback**: Keyword-based pattern matching
- **Confidence Thresholds**: Dynamic routing based on confidence scores
- **Default Routing**: TrustShield for security when confidence is low

### üóÑÔ∏è RAG (Retrieval-Augmented Generation) System
- **Document Store**: ChromaDB for vector storage
- **Embeddings**: Google Gemini embedding model
- **Retriever**: Semantic similarity search
- **Content Types**: Markdown documents, PDF processing with bounding boxes

### üìÑ PDF Processing Pipeline
- **Processor**: LandingAI PDF processing service
- **Features**: Text extraction, bounding box detection, chunk segmentation
- **Integration**: Automatic indexing into RAG system
- **UI**: Interactive PDF viewer with clickable text chunks

### üîÑ Fallback Mechanisms
1. **Document Assessment**: LLM evaluates if retrieved documents contain sufficient information
2. **LLM Knowledge**: Falls back to pre-trained model knowledge when documents insufficient
3. **Web Search**: Real-time web search for current information
4. **Legacy Tavily**: Backup search integration

### üîê Security & Privacy Features
- **PII Detection**: Automatic detection using Microsoft Presidio
- **PII Redaction**: Real-time anonymization of sensitive data
- **Defensive Design**: All agents designed for defensive security use only
- **Fraud Detection**: Multi-pattern scam and threat detection

## API Endpoints

### Smart Chat Endpoints
- `POST /chat` - Main chat interface with fallback options
- `POST /agent/{agent_name}` - Direct agent invocation

### PDF Management
- `POST /upload/pdf` - PDF upload and processing
- `GET /pdf/{pdf_id}/page/{page_num}` - Get PDF page with annotations
- `GET /pdf/{pdf_id}/info` - Get PDF metadata and chunks

### Agent-Specific Endpoints
- `POST /agent/offerpilot` - Product search queries
- `POST /agent/dispute` - Dispute assistance
- `POST /agent/collections` - Payment assistance  
- `POST /agent/devcopilot` - Technical support
- `POST /agent/carecredit` - Healthcare analysis
- `POST /agent/narrator` - Business analytics
- `POST /agent/imagegen` - Image generation
- `POST /agent/trustshield` - Fraud detection

## Frontend Architecture

### React Components
- **ChatPane**: Main conversation interface with PDF drag-and-drop
- **LeftRail**: Agent selection sidebar with examples
- **RightInspector**: Tabbed panel for citations, tool traces, and PDF viewer
- **Header**: Settings controls with elegant toggle switches

### Key Features
- **Real-time Chat**: WebSocket-style communication with loading states
- **PDF Integration**: Drag-and-drop upload with interactive viewer
- **Agent Switching**: Seamless switching between specialized agents
- **Citation Tracking**: Source attribution for all responses
- **Tool Tracing**: Visibility into agent decision-making process

## Deployment & Configuration

### Environment Requirements
- Python 3.8+ with FastAPI
- Node.js 16+ with React/TypeScript
- Google Gemini API access
- LandingAI API for PDF processing
- Optional: Tavily API for web search

### Development Workflow
```bash
# Backend
python main.py

# Frontend
npm run dev
```

### Production Considerations
- CORS configuration for cross-origin requests
- Environment variable management
- API key security
- Rate limiting and usage monitoring

## Security & Compliance

### Defensive Security Focus
- **PII Protection**: Automatic detection and redaction
- **Fraud Prevention**: Real-time threat analysis
- **No Malicious Code**: Designed exclusively for defensive use
- **Source Tracking**: Full audit trail of information sources

### Privacy Features
- **Local Processing**: No persistent user data storage
- **Redaction**: Sensitive information automatically masked
- **Citations**: Transparent source attribution
- **User Control**: Fallback options user-configurable

This architecture provides a robust, scalable, and secure foundation for financial services AI assistance with specialized expertise across multiple domains.


================================================
FILE: CLAUDE.md
================================================
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Development Commands

### Frontend Development
- `npm install` - Install Node.js dependencies
- `npm run dev` - Start Vite development server on port 3000
- `npm run build` - Build frontend for production (TypeScript compilation + Vite build)
- `npm run preview` - Preview production build

### Backend Development  
- `pip install -r requirements.txt` - Install Python dependencies
- `python main.py` - Start FastAPI backend server on port 8000

### Testing and Quality
- No lint/test commands configured - check with user before running any quality checks
- TypeScript compilation is included in `npm run build`

### Full Development Environment
```bash
# Terminal 1 - Backend
python main.py

# Terminal 2 - Frontend  
npm run dev
```

## Architecture Overview

This is a financial services AI platform with 8 specialized agents built on FastAPI (backend) and React/TypeScript (frontend). The system uses a defensive security approach with built-in PII protection and fraud detection.

### Key Components

**Multi-Agent System**: 8 specialized AI agents handle different financial domains:
- Smart Chat Agent (intelligent routing hub)
- OfferPilot (product search & financing)  
- TrustShield (fraud detection & PII protection)
- Dispute Copilot (credit card disputes)
- Collections Agent (payment assistance)
- DevCopilot (technical support & API docs)
- CareCredit (medical expense analysis)
- Narrator (portfolio analytics)
- ImageGen (AI image generation)

**Intelligent Routing**: Uses Gemini LLM for intent classification with keyword fallback. Routes queries to the most appropriate specialist agent based on confidence scores.

**RAG System**: ChromaDB vector store with Gemini embeddings for document retrieval. Supports markdown documents and PDF processing with bounding box extraction via LandingAI.

**Fallback Mechanisms**: Multi-tiered fallbacks when documents are insufficient:
1. Document assessment via LLM
2. LLM knowledge fallback  
3. Web search (Tavily integration)

**Security Features**: Microsoft Presidio for PII detection/redaction, defensive design principles, fraud pattern recognition.

### File Structure
- `main.py` - FastAPI application entry point with all agent endpoints
- `app/agents/` - Individual agent implementations (8 specialized agents)
  - `chat_agent.py` - Smart Chat routing agent
  - `offerpilot.py` - Product search and financing
  - `trustshield.py` - Fraud detection and PII protection  
  - `dispute_reg_e.py` - Dispute assistance
  - `collections.py` - Payment plans and hardship support
  - `devcopilot.py` - Technical support and API docs
  - `carecredit.py` - Healthcare financing specialist
  - `narrator.py` - Portfolio analytics
  - `imagegen.py` - AI image generation
- `app/rag/` - RAG system (embeddings, retrieval, document store)
  - `core.py` - ChromaDB integration and retrieval logic
  - `pipeline.py` - Document processing pipeline
- `app/llm/gemini.py` - Gemini LLM integration with fallback logic
- `app/router.py` - Intelligent query routing system (confidence-based)
- `app/services/pdf_processor.py` - LandingAI PDF processing pipeline
- `app/config/rules_loader.py` - YAML rules configuration loader
- `src/` - React/TypeScript frontend components
- `synchrony-demo-rules-repo/` - Business rules and knowledge base files

### Frontend Components
- `ChatPane.tsx` - Main chat interface with PDF drag-and-drop
- `LeftRail.tsx` - Agent selector sidebar
- `RightInspector.tsx` - Citations, tool traces, PDF viewer
- `src/config/agents.ts` - Agent configuration and examples

### Environment Variables Required
```bash
GOOGLE_API_KEY=your_gemini_api_key
VISION_AGENT_API_KEY=your_landing_ai_key  
TAVILY_API_KEY=your_tavily_key  # Optional
ALLOW_TAVILY=true  # Optional
```

## Key Development Patterns

**Agent Structure**: Each agent follows a consistent pattern with RAG integration, confidence scoring, and citation tracking.

**Intelligent Routing**: Uses Gemini LLM for intent classification with keyword fallback. Confidence threshold of 0.6 determines routing method.

**RAG Integration**: Documents are indexed as markdown chunks with semantic search. PDF processing extracts text with bounding boxes for interactive viewing.

**Fallback System**: Multi-tiered approach - RAG ‚Üí LLM Knowledge ‚Üí Web Search ‚Üí Legacy Tavily when documents are insufficient.

**Error Handling**: Comprehensive fallback systems ensure graceful degradation when primary knowledge sources fail.

**Security First**: All agents designed for defensive security use only. PII is automatically detected and redacted using Microsoft Presidio.

**TypeScript Frontend**: Strict TypeScript configuration with React, Tailwind CSS, and proper markdown rendering with syntax highlighting.

**Rules-Based Configuration**: YAML files in `synchrony-demo-rules-repo/rules/` define agent behaviors and business logic.

## API Endpoints

### Core Chat
- `POST /chat` - Main chat interface with fallback options
- `POST /agent/{agent_name}` - Direct agent invocation

### PDF Management
- `POST /upload/pdf` - PDF upload and processing  
- `GET /pdf/{pdf_id}/page/{page_num}` - Get PDF page with annotations
- `GET /pdf/{pdf_id}/info` - Get PDF metadata and chunks

### Health Check
- `GET /healthz` - Application health status

The system uses CORS middleware for cross-origin requests and serves static files from the built frontend.

## Important Implementation Notes

**Agent Routing**: The system first attempts Gemini-based classification. If confidence < 0.6, falls back to keyword matching. Default route is TrustShield for security.

**PDF Processing**: Uses LandingAI for text extraction with bounding box coordinates. Processed chunks are automatically indexed into the RAG system.

**PII Protection**: Microsoft Presidio automatically detects and redacts sensitive information (SSN, phone numbers, addresses, etc.) in real-time.

**Document Assessment**: Before falling back to LLM knowledge or web search, the system uses AI to assess whether retrieved documents contain sufficient information to answer the query.

**Business Rules**: The `synchrony-demo-rules-repo/` contains fixtures, golden tests, and YAML configuration files that define agent behaviors and example interactions.


================================================
FILE: index.html
================================================
<!doctype html>
<html lang="en" class="h-full">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GenAI Studio (Hackathon PoC)</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  </head>
  <body class="h-full bg-slate-50">
    <div id="root" class="h-full"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>


================================================
FILE: main.py
================================================
"""
Synch GenAI PoC - Main FastAPI Application
Complete app wiring with middleware, agent endpoints, and UI
"""

import os
import re
import logging
import time
from pathlib import Path
from typing import Optional, Dict, Any, Union

from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request, Response, UploadFile, File
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
from pydantic import BaseModel, Field
from dotenv import load_dotenv
import json

from app.rag.core import init_docstore, GeminiEmbedder, index_markdown, build_retriever, retrieve
from app.llm.gemini import chat_with_context, chat_with_context_and_fallback
from app.tools.tavily_search import web_search_into_docstore, WebDisabled
from app.router import route
from app.agents.trustshield import TrustShield
from app.agents.offerpilot import OfferPilot
from app.agents.dispute_reg_e import DisputeCopilot
from app.agents.collections import CollectionsAdvisor, CustomerState
from app.agents.contracts_enhanced import ContractIntelligence
from app.agents.devcopilot import DevCopilot
from app.agents.carecredit import CareCredit
from app.agents.narrator import PortfolioIntelNarrator
from app.services.pdf_processor import LandingAIPDFProcessor, ProcessedPDF
from app.config.rules_loader import get_rules_loader

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=getattr(logging, os.getenv("LOG_LEVEL", "INFO")),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Global components
docstore = None
embedder = None
retriever = None
agents = {}  # Agent registry
pdf_processor = None
uploaded_pdfs = {}  # Store processed PDFs
multi_agent_supervisor = None  # LangGraph multi-agent orchestrator

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Initialize components on startup and cleanup on shutdown"""
    global docstore, embedder, retriever, agents, pdf_processor, multi_agent_supervisor
    
    try:
        logger.info("Loading all rules from synchrony-demo-rules-repo...")
        rules_loader = get_rules_loader()
        
        logger.info("Initializing document store...")
        docstore = init_docstore()
        
        logger.info("Initializing Gemini embedder...")
        embedder = GeminiEmbedder()
        
        logger.info("Indexing markdown documents...")
        doc_count = index_markdown(docstore, embedder)
        logger.info(f"Indexed {doc_count} document chunks")
        
        logger.info("Building retriever...")
        retriever = build_retriever(docstore)
        
        logger.info("Initializing PDF processor...")
        pdf_processor = LandingAIPDFProcessor()
        
        logger.info("Initializing agents with centralized rules...")
        agents = {
            'trustshield': TrustShield(docstore=docstore, embedder=embedder, retriever=retriever, rules_loader=rules_loader),
            'offerpilot': OfferPilot(docstore=docstore, embedder=embedder, retriever=retriever, rules_loader=rules_loader),
            'dispute': DisputeCopilot(docstore=docstore, embedder=embedder, retriever=retriever, rules_loader=rules_loader),
            'collections': CollectionsAdvisor(docstore=docstore, embedder=embedder, retriever=retriever, rules_loader=rules_loader),
            'contracts': ContractIntelligence(docstore=docstore, embedder=embedder, retriever=retriever, rules_loader=rules_loader),
            'devcopilot': DevCopilot(docstore=docstore, embedder=embedder, retriever=retriever, rules_loader=rules_loader),
            'carecredit': CareCredit(docstore=docstore, embedder=embedder, retriever=retriever, rules_loader=rules_loader),
            'narrator': PortfolioIntelNarrator(docstore=docstore, embedder=embedder, retriever=retriever, rules_loader=rules_loader),
        }
        
        logger.info("Initializing LangGraph multi-agent supervisor...")
        from app.multi_agent.supervisor import FinancialServicesSupervisor
        multi_agent_supervisor = FinancialServicesSupervisor(
            agents=agents,
            google_api_key=os.getenv("GOOGLE_API_KEY")
        )
        
        logger.info(f"Application startup complete - {len(agents)} agents + multi-agent supervisor initialized")
    except Exception as e:
        logger.error(f"Failed to initialize application: {e}")
        raise
    
    yield
    
    # Cleanup on shutdown
    logger.info("Application shutdown complete")

# Initialize FastAPI app with lifespan
app = FastAPI(
    title="Synch GenAI PoC",
    description="Complete GenAI-powered financial services platform",
    version="2.0.0",
    lifespan=lifespan
)

# PII Redactor Middleware
class PIIRedactorMiddleware(BaseHTTPMiddleware):
    """Redacts PAN, SSN, CVV from request bodies"""
    
    def __init__(self, app):
        super().__init__(app)
        # PII patterns
        self.patterns = {
            'PAN': re.compile(r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b'),
            'SSN': re.compile(r'\b\d{3}-?\d{2}-?\d{4}\b'),
            'CVV': re.compile(r'\b\d{3,4}\b(?=.*(?:cvv|cvc|security|code))', re.IGNORECASE),
        }
    
    async def dispatch(self, request: Request, call_next):
        # Only process POST requests with JSON bodies
        if request.method == "POST" and request.headers.get("content-type", "").startswith("application/json"):
            body = await request.body()
            if body:
                try:
                    body_str = body.decode('utf-8')
                    original_str = body_str
                    
                    # Redact PII patterns
                    for pii_type, pattern in self.patterns.items():
                        body_str = pattern.sub(f'[REDACTED_{pii_type}]', body_str)
                    
                    # Log if redaction occurred
                    if body_str != original_str:
                        logger.warning(f"PII redaction performed on request to {request.url.path}")
                    
                    # Create new request with redacted body
                    from fastapi.requests import Request as FastAPIRequest
                    async def receive():
                        return {"type": "http.request", "body": body_str.encode('utf-8')}
                    
                    # Modify the request
                    request._body = body_str.encode('utf-8')
                    
                except Exception as e:
                    logger.error(f"Error in PII redaction: {e}")
        
        response = await call_next(request)
        return response

# TrustShield Blocking Middleware
class TrustShieldMiddleware(BaseHTTPMiddleware):
    """TrustShield security scanning and blocking"""
    
    def __init__(self, app):
        super().__init__(app)
        self.protected_endpoints = ['/chat', '/agent/', '/api/']
    
    async def dispatch(self, request: Request, call_next):
        # Check if endpoint needs protection
        needs_protection = any(request.url.path.startswith(endpoint) 
                             for endpoint in self.protected_endpoints)
        
        if needs_protection and request.method == "POST":
            # Get request body for TrustShield scan
            body = await request.body()
            if body and agents.get('trustshield'):
                try:
                    body_data = json.loads(body.decode('utf-8'))
                    
                    # Extract text to scan (look for common field names)
                    text_to_scan = ""
                    for field in ['message', 'query', 'narrative', 'question', 'estimate_text']:
                        if field in body_data:
                            text_to_scan = body_data[field]
                            break
                    
                    if text_to_scan:
                        # Get user_type from request
                        user_type = body_data.get('user_type', 'consumer')
                        
                        # Run TrustShield scan with persona context
                        shield_result = agents['trustshield'].scan(text_to_scan, user_type)
                        
                        if shield_result["decision"] == "block":
                            logger.warning(f"TrustShield BLOCKED request to {request.url.path}")
                            return JSONResponse(
                                status_code=403,
                                content={
                                    "error": "Request blocked by security policy",
                                    "reason": shield_result.get('next_step', {}).get('label', 'Security violation detected'),
                                    "blocked": True
                                }
                            )
                        
                        # Replace original text with redacted version
                        for field in ['message', 'query', 'narrative', 'question', 'estimate_text']:
                            if field in body_data:
                                body_data[field] = shield_result["redacted_text"]
                        
                        # Update request body
                        new_body = json.dumps(body_data).encode('utf-8')
                        request._body = new_body
                    
                except Exception as e:
                    logger.error(f"Error in TrustShield middleware: {e}")
        
        response = await call_next(request)
        return response

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:8000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Add middleware (order matters - CORS first, then PII redaction, then TrustShield)
app.add_middleware(TrustShieldMiddleware)
app.add_middleware(PIIRedactorMiddleware)

# Startup event handler has been moved to lifespan function above

# Request/Response models
class ChatRequest(BaseModel):
    message: str
    allow_tavily: Optional[bool] = False
    allow_llm_knowledge: Optional[bool] = True
    allow_web_search: Optional[bool] = False
    user_type: Optional[str] = "consumer"

class ChatResponse(BaseModel):
    response: str
    agent: str
    confidence: float
    sources: list[str] = []
    used_tavily: bool = False
    fallback_used: Optional[str] = None
    document_assessment: Optional[dict] = None
    image_data: Optional[str] = None
    image_format: Optional[str] = None
    agent_trace: Optional[dict] = None

class OfferRequest(BaseModel):
    query: str
    budget: Optional[float] = None
    user_type: Optional[str] = "consumer"

class DisputeRequest(BaseModel):
    narrative: str
    merchant: Optional[str] = None
    amount: Optional[float] = None
    uploaded_text: Optional[str] = None
    user_type: Optional[str] = "consumer"

class CollectionsRequest(BaseModel):
    balance: float
    apr: float
    bucket: str
    income_monthly: Optional[float] = None
    expenses_monthly: Optional[float] = None
    preferences: Optional[dict] = None
    user_type: Optional[str] = "consumer"

class DevCopilotRequest(BaseModel):
    query: str
    context: Optional[Dict[str, Any]] = None

class CareCreditRequest(BaseModel):
    estimate_text: str
    location: Optional[str] = None
    insurance: Optional[dict] = None
    user_type: Optional[str] = "consumer"

class NarratorRequest(BaseModel):
    question: str
    user_type: Optional[str] = "consumer"


class ContractRequest(BaseModel):
    contract_text: str
    question: Optional[str] = None

# Serve static files from React build (only if directory exists)
if Path("dist/assets").exists():
    app.mount("/assets", StaticFiles(directory="dist/assets"), name="assets")

# UI Routes
@app.get("/", response_class=HTMLResponse)
async def root():
    """Serve the React UI"""
    try:
        # Try to serve the built React app first
        ui_path = Path("dist/index.html")
        if ui_path.exists():
            return HTMLResponse(content=ui_path.read_text(encoding='utf-8'), status_code=200)
        
        # Fallback to the old HTML version
        fallback_path = Path("app/ui/modern.html")
        if fallback_path.exists():
            return HTMLResponse(content=fallback_path.read_text(encoding='utf-8'), status_code=200)
        
        return HTMLResponse(content="<h1>UI not found</h1><p>Please run 'npm run build' to build the React app</p>", status_code=404)
    except Exception as e:
        return HTMLResponse(content=f"<h1>Error loading UI</h1><p>{str(e)}</p>", status_code=500)

@app.get("/classic", response_class=HTMLResponse)
async def classic_ui():
    """Serve the classic UI as backup"""
    return HTMLResponse(content=UI_HTML, status_code=200)

# Enhanced Smart Chat Endpoint with Multi-Agent Orchestration
@app.post("/chat", response_model=ChatResponse)
async def smart_chat(request: ChatRequest):
    """Enhanced Smart Chat with LangGraph multi-agent orchestration and intelligent fallbacks"""
    if not all([docstore, embedder, retriever]) or not agents or not multi_agent_supervisor:
        raise HTTPException(status_code=500, detail="System components not initialized")
    
    try:
        logger.info(f"Processing chat message with enhanced Smart Chat: {request.message}")
        
        # Use LangGraph multi-agent supervisor for orchestration
        result = await multi_agent_supervisor.process_query(
            query=request.message,
            allow_tavily=request.allow_tavily,
            allow_llm_knowledge=request.allow_llm_knowledge,
            allow_web_search=request.allow_web_search,
            user_context={
                "timestamp": time.time(),
                "session_id": "default",  # Could be enhanced with actual session management
                "user_type": request.user_type
            }
        )
        
        # Debug: Print raw API response
        logger.info(f"üîç Raw API response from supervisor: {result}")
        logger.info(f"üîç Response type check - response: {type(result.get('response'))}, value: '{result.get('response')}'")
        
        # Return the formatted response from supervisor
        return ChatResponse(**result)
        
    except Exception as e:
        logger.error(f"Error processing chat with multi-agent system: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Agent-specific endpoints for tabbed UI testing
@app.post("/agent/offerpilot")
async def agent_offerpilot(request: OfferRequest):
    """OfferPilot direct endpoint"""
    if "offerpilot" not in agents:
        raise HTTPException(status_code=500, detail="OfferPilot not initialized")
    
    try:
        result = agents["offerpilot"].process_query(request.query, request.budget, request.user_type)
        return result.dict()
    except Exception as e:
        logger.error(f"OfferPilot error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/dispute")
async def agent_dispute(request: DisputeRequest):
    """Dispute Copilot direct endpoint"""
    if "dispute" not in agents:
        raise HTTPException(status_code=500, detail="DisputeCopilot not initialized")
    
    try:
        result = agents["dispute"].process_dispute(
            narrative=request.narrative,
            merchant=request.merchant,
            amount=request.amount,
            uploaded_text=request.uploaded_text
        )
        return result.dict()
    except Exception as e:
        logger.error(f"DisputeCopilot error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/collections")
async def agent_collections(request: CollectionsRequest):
    """Collections Advisor direct endpoint"""
    if "collections" not in agents:
        raise HTTPException(status_code=500, detail="CollectionsAdvisor not initialized")
    
    try:
        customer_state = CustomerState(
            balance=request.balance,
            apr=request.apr,
            bucket=request.bucket,
            income_monthly=request.income_monthly,
            expenses_monthly=request.expenses_monthly,
            preferences=request.preferences
        )
        result = agents["collections"].process_hardship_request(customer_state)
        return result.dict()
    except Exception as e:
        logger.error(f"CollectionsAdvisor error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/devcopilot")
async def agent_devcopilot(request: DevCopilotRequest):
    """DevCopilot direct endpoint for partner enablement"""
    if "devcopilot" not in agents:
        raise HTTPException(status_code=500, detail="DevCopilot not initialized")
    
    try:
        result = agents["devcopilot"].process_request(
            query=request.query,
            context=request.context
        )
        return result.model_dump()
    except Exception as e:
        logger.error(f"DevCopilot error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/carecredit")
async def agent_carecredit(request: CareCreditRequest):
    """CareCredit direct endpoint"""
    if "carecredit" not in agents:
        raise HTTPException(status_code=500, detail="CareCredit not initialized")
    
    try:
        result = agents["carecredit"].process_estimate(
            estimate_text=request.estimate_text,
            location=request.location,
            insurance=request.insurance
        )
        return result.dict()
    except Exception as e:
        logger.error(f"CareCredit error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/narrator")
async def agent_narrator(request: NarratorRequest):
    """Portfolio Intel Narrator direct endpoint"""
    if "narrator" not in agents:
        raise HTTPException(status_code=500, detail="PortfolioIntelNarrator not initialized")
    
    try:
        result = agents["narrator"].process_question(request.question)
        return result.dict()
    except Exception as e:
        logger.error(f"PortfolioIntelNarrator error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/agent/contracts")
async def agent_contracts(request: ContractRequest):
    """Contract Intelligence direct endpoint"""
    if "contracts" not in agents:
        raise HTTPException(status_code=500, detail="ContractIntelligence not initialized")
    
    try:
        result = agents["contracts"].analyze_contract(request.contract_text, request.question)
        return result.dict()
    except Exception as e:
        logger.error(f"ContractIntelligence error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/trustshield")
async def agent_trustshield(request: dict):
    """TrustShield direct endpoint"""
    if "trustshield" not in agents:
        raise HTTPException(status_code=500, detail="TrustShield not initialized")
    
    try:
        text = request.get("text", "")
        result = agents["trustshield"].scan(text)
        return result
    except Exception as e:
        logger.error(f"TrustShield error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload/pdf")
async def upload_pdf(file: UploadFile = File(...)):
    """Upload and process PDF document"""
    if not pdf_processor:
        raise HTTPException(status_code=500, detail="PDF processor not initialized")
    
    # Validate file type
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Only PDF files are supported")
    
    # Limit file size (10MB)
    max_size = 10 * 1024 * 1024
    
    try:
        # Save uploaded file temporarily
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            content = await file.read()
            
            if len(content) > max_size:
                raise HTTPException(status_code=400, detail="File too large (max 10MB)")
            
            tmp_file.write(content)
            tmp_path = tmp_file.name
        
        # Process PDF
        logger.info(f"Processing uploaded PDF: {file.filename}")
        processed_pdf = pdf_processor.process_pdf(tmp_path, chunk_strategy="semantic")
        
        # Store processed PDF
        pdf_id = f"pdf_{int(time.time())}_{len(uploaded_pdfs)}"
        uploaded_pdfs[pdf_id] = processed_pdf
        
        # Add chunks to document store for RAG
        documents = []
        for chunk in processed_pdf.chunks:
            doc = chunk.to_document(file.filename)
            doc.meta["pdf_id"] = pdf_id
            documents.append(doc)
        
        # Generate embeddings and add to docstore
        if documents:
            texts = [doc.content for doc in documents]
            embeddings = embedder.embed_texts(texts)
            
            for doc, embedding in zip(documents, embeddings):
                doc.embedding = embedding
            
            docstore.write_documents(documents)
            logger.info(f"Added {len(documents)} PDF chunks to docstore")
        
        # Clean up temporary file
        os.unlink(tmp_path)
        
        return {
            "success": True,
            "pdf_id": pdf_id,
            "filename": file.filename,
            "total_pages": processed_pdf.total_pages,
            "chunks_extracted": len(processed_pdf.chunks),
            "processing_time": processed_pdf.processing_time,
            "file_size": processed_pdf.file_size
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error processing PDF upload: {e}")
        # Clean up temp file if it exists
        if 'tmp_path' in locals():
            try:
                os.unlink(tmp_path)
            except:
                pass
        raise HTTPException(status_code=500, detail=f"PDF processing failed: {str(e)}")

@app.get("/pdf/{pdf_id}/info")
async def get_pdf_info(pdf_id: str):
    """Get detailed information about a processed PDF including chunks"""
    if pdf_id not in uploaded_pdfs:
        raise HTTPException(status_code=404, detail="PDF not found")
    
    pdf = uploaded_pdfs[pdf_id]
    return {
        "pdf_id": pdf_id,
        "filename": pdf.filename,
        "total_pages": pdf.total_pages,
        "chunks": [
            {
                "chunk_id": chunk.chunk_id,
                "text": chunk.text[:100] + "..." if len(chunk.text) > 100 else chunk.text,
                "page_number": chunk.page_number,
                "bbox": chunk.bbox.to_dict(),
                "confidence": chunk.confidence
            }
            for chunk in pdf.chunks
        ],
        "processing_time": pdf.processing_time
    }

@app.get("/pdf/{pdf_id}")
async def get_pdf_summary(pdf_id: str):
    """Get summary information about a processed PDF"""
    if pdf_id not in uploaded_pdfs:
        raise HTTPException(status_code=404, detail="PDF not found")
    
    pdf = uploaded_pdfs[pdf_id]
    return {
        "pdf_id": pdf_id,
        "filename": pdf.filename,
        "total_pages": pdf.total_pages,
        "chunks": len(pdf.chunks),
        "processing_time": pdf.processing_time
    }

@app.get("/pdf/{pdf_id}/page/{page_num}")
async def get_pdf_page(pdf_id: str, page_num: int):
    """Get a specific page image with optional bounding box overlays"""
    if pdf_id not in uploaded_pdfs:
        raise HTTPException(status_code=404, detail="PDF not found")
    
    pdf = uploaded_pdfs[pdf_id]
    
    if page_num >= len(pdf.page_images) or page_num < 0:
        raise HTTPException(status_code=404, detail="Page not found")
    
    # Get chunks for this page
    page_chunks = [chunk for chunk in pdf.chunks if chunk.page_number == page_num]
    
    return {
        "pdf_id": pdf_id,
        "page_number": page_num,
        "image_base64": pdf.page_images[page_num],
        "chunks": [
            {
                "chunk_id": chunk.chunk_id,
                "text": chunk.text[:200] + "..." if len(chunk.text) > 200 else chunk.text,
                "bbox": chunk.bbox.to_dict(),
                "confidence": chunk.confidence
            }
            for chunk in page_chunks
        ]
    }

# Chat Title Generation endpoint
@app.post("/generate-chat-title")
async def generate_chat_title(request: dict):
    """Generate a meaningful chat title from the first message using LLM"""
    try:
        message = request.get('message', '')
        if not message:
            return {"title": "New Chat"}
        
        from app.llm.gemini import chat
        
        system_prompt = """You are a chat title generator. Create a concise, meaningful title (2-6 words) that captures the essence of the user's message.

Guidelines:
- Keep it short and descriptive
- Use title case
- Focus on the main topic or intent
- Avoid generic words like "Question", "Help", "Chat"
- Make it specific to the user's need

Examples:
"I need help financing a dental procedure" ‚Üí "Dental Financing Options"
"What are the current KPIs for our portfolio?" ‚Üí "Portfolio KPI Analysis" 
"How do I integrate the payment API?" ‚Üí "Payment API Integration"
"Tell me about CareCredit" ‚Üí "CareCredit Information"
"Show me business metrics" ‚Üí "Business Metrics Dashboard"

Respond with ONLY the title, nothing else."""

        messages = [{"role": "user", "content": f"Generate a title for this message: {message}"}]
        title = chat(messages, system=system_prompt)
        
        # Clean up the response
        title = title.strip().strip('"').strip("'")
        
        # Fallback if title is too long or empty
        if len(title) > 50 or len(title) < 2:
            title = message[:30] + "..." if len(message) > 30 else message
            
        return {"title": title}
        
    except Exception as e:
        logger.error(f"Chat title generation failed: {e}")
        # Fallback to truncated message
        message = request.get('message', 'New Chat')
        fallback_title = message[:30] + "..." if len(message) > 30 else message
        return {"title": fallback_title}

# Persona and Available Agents endpoint
@app.post("/detect-persona-and-agents")
async def detect_persona_and_get_agents(request: ChatRequest):
    """Detect user persona and return available agents"""
    if not multi_agent_supervisor:
        raise HTTPException(status_code=500, detail="Supervisor not initialized")
    
    try:
        # Create initial state for persona detection
        from app.multi_agent.state import create_initial_state
        initial_state = create_initial_state(
            original_query=request.message,
            allow_tavily=request.allow_tavily,
            allow_llm_knowledge=request.allow_llm_knowledge,
            allow_web_search=request.allow_web_search,
            user_context={"user_type": request.user_type}
        )
        
        # Run only the master node for persona detection
        master_result = await multi_agent_supervisor._master_node(initial_state)
        
        detected_persona = master_result.get("detected_persona", "consumer")
        confidence = master_result.get("persona_confidence", 0.5)
        reasoning = master_result.get("persona_reasoning", "")
        
        # Get available agents based on detected persona
        if detected_persona == "consumer":
            available_agents = ['offerpilot', 'dispute', 'collections', 'contracts', 'carecredit', 'narrator', 'trustshield']
        elif detected_persona == "partner":
            available_agents = ['devcopilot', 'narrator', 'contracts', 'offerpilot', 'carecredit', 'trustshield']
        else:
            available_agents = ['offerpilot', 'dispute', 'collections', 'contracts', 'carecredit', 'narrator', 'trustshield']
        
        # Always include smart chat
        if 'smart' not in available_agents:
            available_agents.insert(0, 'smart')
            
        return {
            "persona": detected_persona,
            "confidence": confidence,
            "reasoning": reasoning,
            "available_agents": available_agents,
            "is_confident": confidence >= 0.7
        }
        
    except Exception as e:
        logger.error(f"Persona detection failed: {e}")
        # Fallback to consumer persona
        return {
            "persona": "consumer", 
            "confidence": 0.3,
            "reasoning": "Fallback due to detection error",
            "available_agents": ['smart', 'offerpilot', 'dispute', 'collections', 'contracts', 'carecredit', 'narrator', 'trustshield'],
            "is_confident": False,
            "error": str(e)
        }

# Health endpoint
@app.get("/healthz")
async def health_check():
    """Enhanced health check with docstore size and env flags"""
    try:
        docstore_size = docstore.count_documents() if docstore else 0
        
        env_flags = {
            "ALLOW_TAVILY": os.getenv("ALLOW_TAVILY", "false").lower() == "true",
            "LOG_LEVEL": os.getenv("LOG_LEVEL", "INFO"),
            "DEBUG": os.getenv("DEBUG", "false").lower() == "true",
        }
        
        agent_status = {name: agent is not None for name, agent in agents.items()}
        
        return {
            "status": "healthy" if docstore and len(agents) > 0 else "degraded",
            "docstore_size": docstore_size,
            "agents_initialized": len(agents),
            "agent_status": agent_status,
            "env_flags": env_flags,
            "components": {
                "docstore": docstore is not None,
                "embedder": embedder is not None, 
                "retriever": retriever is not None,
            }
        }
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}

# Minimal SPA UI
UI_HTML = """
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Synch GenAI PoC</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif; background: #f8fafc; }
        .container { max-width: 1200px; margin: 0 auto; padding: 20px; }
        .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px 0; margin-bottom: 30px; border-radius: 12px; }
        .header h1 { text-align: center; font-size: 2.5rem; font-weight: 700; margin-bottom: 10px; }
        .header p { text-align: center; font-size: 1.1rem; opacity: 0.9; }
        
        .tabs { display: flex; flex-wrap: wrap; gap: 8px; margin-bottom: 30px; background: white; padding: 20px; border-radius: 12px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
        .tab { padding: 12px 20px; background: #f1f5f9; border: none; border-radius: 8px; cursor: pointer; font-weight: 500; transition: all 0.2s; color: #64748b; }
        .tab:hover { background: #e2e8f0; }
        .tab.active { background: #3b82f6; color: white; }
        
        .tab-content { display: none; background: white; padding: 30px; border-radius: 12px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
        .tab-content.active { display: block; }
        
        .form-group { margin-bottom: 20px; }
        .form-group label { display: block; font-weight: 600; margin-bottom: 8px; color: #374151; }
        .form-group input, .form-group textarea, .form-group select { width: 100%; padding: 12px 16px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 14px; transition: border-color 0.2s; }
        .form-group input:focus, .form-group textarea:focus, .form-group select:focus { outline: none; border-color: #3b82f6; }
        .form-group textarea { min-height: 100px; resize: vertical; }
        
        .btn { background: #3b82f6; color: white; border: none; padding: 14px 28px; border-radius: 8px; font-weight: 600; cursor: pointer; font-size: 14px; transition: background 0.2s; }
        .btn:hover { background: #2563eb; }
        .btn:disabled { background: #9ca3af; cursor: not-allowed; }
        
        .result { margin-top: 30px; padding: 20px; background: #f8fafc; border-radius: 8px; border-left: 4px solid #3b82f6; }
        .result-json { background: #1f2937; color: #f9fafb; padding: 20px; border-radius: 8px; font-family: 'SF Mono', Monaco, monospace; font-size: 13px; overflow-x: auto; white-space: pre; }
        
        .loading { display: none; text-align: center; padding: 20px; color: #6b7280; }
        .loading.show { display: block; }
        
        .error { background: #fef2f2; border: 1px solid #fecaca; color: #dc2626; padding: 16px; border-radius: 8px; margin-top: 20px; }
        
        .example { background: #f0f9ff; border: 1px solid #bae6fd; padding: 16px; border-radius: 8px; margin-bottom: 20px; font-size: 14px; }
        .example-title { font-weight: 600; color: #0369a1; margin-bottom: 8px; }
        
        .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-top: 20px; }
        .card { background: white; padding: 20px; border-radius: 8px; border: 1px solid #e5e7eb; }
        .card h3 { margin-bottom: 12px; color: #374151; }
        .card-content { color: #6b7280; font-size: 14px; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ü§ñ Synch GenAI PoC</h1>
            <p>Complete AI-powered financial services platform with 8 specialized agents</p>
        </div>
        
        <div class="tabs">
            <button class="tab active" onclick="showTab('chat')">üí¨ Smart Chat</button>
            <button class="tab" onclick="showTab('offerpilot')">üõçÔ∏è OfferPilot</button>
            <button class="tab" onclick="showTab('dispute')">‚öñÔ∏è Dispute Copilot</button>
            <button class="tab" onclick="showTab('collections')">üí≥ Collections</button>
            <button class="tab" onclick="showTab('devcopilot')">üë®‚Äçüíª DevCopilot</button>
            <button class="tab" onclick="showTab('carecredit')">üè• CareCredit</button>
            <button class="tab" onclick="showTab('narrator')">üìä Portfolio Intel</button>
            <button class="tab" onclick="showTab('trustshield')">üõ°Ô∏è TrustShield</button>
            <button class="tab" onclick="showTab('contracts')">üìã Contracts</button>
        </div>
        
        <!-- Smart Chat Tab -->
        <div id="chat" class="tab-content active">
            <div class="example">
                <div class="example-title">üí° Smart Chat Example:</div>
                "I want to buy a laptop under $1000 with 0% financing"
            </div>
            <div class="form-group">
                <label>Message:</label>
                <textarea id="chat-message" placeholder="Ask anything - the router will send you to the right agent..."></textarea>
            </div>
            <div class="form-group">
                <label><input type="checkbox" id="chat-tavily"> Allow web search (Tavily)</label>
            </div>
            <button class="btn" onclick="runChat()">üí¨ Send Message</button>
            <div class="loading" id="chat-loading">Processing your message...</div>
            <div id="chat-result"></div>
        </div>
        
        <!-- OfferPilot Tab -->
        <div id="offerpilot" class="tab-content">
            <div class="example">
                <div class="example-title">üõçÔ∏è OfferPilot Example:</div>
                Query: "office desk" | Budget: 600
            </div>
            <div class="form-group">
                <label>Search Query:</label>
                <input type="text" id="offer-query" placeholder="office desk" value="office desk">
            </div>
            <div class="form-group">
                <label>Budget (optional):</label>
                <input type="number" id="offer-budget" placeholder="600" value="600">
            </div>
            <button class="btn" onclick="runOfferPilot()">üõçÔ∏è Search Products</button>
            <div class="loading" id="offerpilot-loading">Searching products...</div>
            <div id="offerpilot-result"></div>
        </div>
        
        <!-- Dispute Copilot Tab -->
        <div id="dispute" class="tab-content">
            <div class="example">
                <div class="example-title">‚öñÔ∏è Dispute Example:</div>
                "I was charged twice for the same Amazon purchase on my Synchrony card"
            </div>
            <div class="form-group">
                <label>Dispute Narrative:</label>
                <textarea id="dispute-narrative" placeholder="Describe your dispute..." value="I was charged twice for the same Amazon purchase on my Synchrony card"></textarea>
            </div>
            <div class="form-group">
                <label>Merchant (optional):</label>
                <input type="text" id="dispute-merchant" placeholder="Amazon" value="Amazon">
            </div>
            <div class="form-group">
                <label>Amount (optional):</label>
                <input type="number" id="dispute-amount" placeholder="150.00" value="150.00">
            </div>
            <button class="btn" onclick="runDispute()">‚öñÔ∏è Process Dispute</button>
            <div class="loading" id="dispute-loading">Processing dispute...</div>
            <div id="dispute-result"></div>
        </div>
        
        <!-- Collections Tab -->
        <div id="collections" class="tab-content">
            <div class="example">
                <div class="example-title">üí≥ Collections Example:</div>
                Balance: 5000 | APR: 24.99% | Bucket: "90-120"
            </div>
            <div class="form-group">
                <label>Balance:</label>
                <input type="number" id="collections-balance" placeholder="5000" value="5000">
            </div>
            <div class="form-group">
                <label>APR (%):</label>
                <input type="number" id="collections-apr" placeholder="24.99" value="24.99" step="0.01">
            </div>
            <div class="form-group">
                <label>Delinquency Bucket:</label>
                <select id="collections-bucket">
                    <option value="30-60">30-60 days</option>
                    <option value="60-90">60-90 days</option>
                    <option value="90-120" selected>90-120 days</option>
                    <option value="120+">120+ days</option>
                </select>
            </div>
            <div class="form-group">
                <label>Monthly Income (optional):</label>
                <input type="number" id="collections-income" placeholder="4000">
            </div>
            <button class="btn" onclick="runCollections()">üí≥ Generate Hardship Plans</button>
            <div class="loading" id="collections-loading">Generating plans...</div>
            <div id="collections-result"></div>
        </div>
        
        <!-- DevCopilot Tab -->
        <div id="devcopilot" class="tab-content">
            <div class="example">
                <div class="example-title">üë®‚Äçüíª DevCopilot Example:</div>
                Service: "payments" | Language: "python"
            </div>
            <div class="form-group">
                <label>Service:</label>
                <input type="text" id="dev-service" placeholder="payments" value="payments">
            </div>
            <div class="form-group">
                <label>Endpoint (optional):</label>
                <input type="text" id="dev-endpoint" placeholder="/payments">
            </div>
            <div class="form-group">
                <label>Language:</label>
                <select id="dev-language">
                    <option value="python" selected>Python</option>
                    <option value="javascript">JavaScript</option>
                    <option value="java">Java</option>
                    <option value="curl">cURL</option>
                </select>
            </div>
            <button class="btn" onclick="runDevCopilot()">üë®‚Äçüíª Generate Code</button>
            <div class="loading" id="devcopilot-loading">Generating code...</div>
            <div id="devcopilot-result"></div>
        </div>
        
        <!-- CareCredit Tab -->
        <div id="carecredit" class="tab-content">
            <div class="example">
                <div class="example-title">üè• CareCredit Example:</div>
                Medical estimate with procedure codes and costs
            </div>
            <div class="form-group">
                <label>Medical Estimate:</label>
                <textarea id="care-estimate" placeholder="Paste your medical estimate..." value="Dental Estimate - City Dental Care

D0120 | Periodic oral evaluation | $85.00
D1110 | Prophylaxis - adult cleaning | $120.00
D0274 | Bitewing X-rays (4 films) | $65.00

Total: $270.00"></textarea>
            </div>
            <div class="form-group">
                <label>Location (optional):</label>
                <input type="text" id="care-location" placeholder="New York, NY" value="New York, NY">
            </div>
            <button class="btn" onclick="runCareCredit()">üè• Analyze Treatment</button>
            <div class="loading" id="carecredit-loading">Analyzing treatment...</div>
            <div id="carecredit-result"></div>
        </div>
        
        <!-- Portfolio Intel Narrator Tab -->
        <div id="narrator" class="tab-content">
            <div class="example">
                <div class="example-title">üìä Portfolio Intel Example:</div>
                "Why did spend drop after 2025-07-31?"
            </div>
            <div class="form-group">
                <label>Business Question:</label>
                <textarea id="narrator-question" placeholder="Ask about portfolio metrics..." value="Why did spend drop after 2025-07-31?"></textarea>
            </div>
            <button class="btn" onclick="runNarrator()">üìä Analyze Metrics</button>
            <div class="loading" id="narrator-loading">Analyzing portfolio data...</div>
            <div id="narrator-result"></div>
        </div>
        
        <!-- TrustShield Tab -->
        <div id="trustshield" class="tab-content">
            <div class="example">
                <div class="example-title">üõ°Ô∏è TrustShield Example:</div>
                "My SSN is 123-45-6789 and my credit card is 4111-1111-1111-1111"
            </div>
            <div class="form-group">
                <label>Text to Scan:</label>
                <textarea id="trust-text" placeholder="Enter text to scan for security issues..." value="My SSN is 123-45-6789 and my credit card is 4111-1111-1111-1111"></textarea>
            </div>
            <button class="btn" onclick="runTrustShield()">üõ°Ô∏è Security Scan</button>
            <div class="loading" id="trustshield-loading">Scanning for security issues...</div>
            <div id="trustshield-result"></div>
        </div>
        
        <!-- Contracts Tab -->
        <div id="contracts" class="tab-content">
            <div class="example">
                <div class="example-title">üìã Contract Analysis Example:</div>
                "What are the late fees?" or "Analyze this contract for promotional terms"
            </div>
            <div class="form-group">
                <label>Contract Text:</label>
                <textarea id="contracts-text" placeholder="Paste contract text here..." value="MERCHANT AGREEMENT - The APR for purchases is 24.99%. Equal payment promotional financing available for 12 months with no interest if paid in full during the promotional period. Late payment fee is $25. All disputes must be resolved through binding arbitration."></textarea>
            </div>
            <div class="form-group">
                <label>Question (optional):</label>
                <input type="text" id="contracts-question" placeholder="What are the late fees?" value="What are the promotional terms?">
            </div>
            <button class="btn" onclick="runContracts()">üìã Analyze Contract</button>
            <div class="loading" id="contracts-loading">Analyzing contract clauses...</div>
            <div id="contracts-result"></div>
        </div>
    </div>

    <script>
        function showTab(tabName) {
            // Hide all tab contents
            document.querySelectorAll('.tab-content').forEach(content => {
                content.classList.remove('active');
            });
            
            // Remove active class from all tabs
            document.querySelectorAll('.tab').forEach(tab => {
                tab.classList.remove('active');
            });
            
            // Show selected tab content
            document.getElementById(tabName).classList.add('active');
            
            // Add active class to clicked tab
            event.target.classList.add('active');
        }
        
        function showLoading(agentName, show = true) {
            const loading = document.getElementById(`${agentName}-loading`);
            if (loading) {
                loading.classList.toggle('show', show);
            }
        }
        
        function showResult(agentName, result) {
            const resultDiv = document.getElementById(`${agentName}-result`);
            if (!resultDiv) return;
            
            // Create human-readable and JSON views
            const humanReadable = createHumanReadableView(result);
            const jsonView = JSON.stringify(result, null, 2);
            
            resultDiv.innerHTML = `
                <div class="result">
                    <h3>üìã Summary</h3>
                    ${humanReadable}
                    <h3 style="margin-top: 25px;">üìÑ Raw JSON Response</h3>
                    <div class="result-json">${jsonView}</div>
                </div>
            `;
        }
        
        function createHumanReadableView(result) {
            // Create cards/tiles based on result type
            if (result.items && Array.isArray(result.items)) {
                // OfferPilot results
                return `
                    <div class="grid">
                        ${result.items.map(item => `
                            <div class="card">
                                <h3>${item.title}</h3>
                                <div class="card-content">
                                    <p><strong>Price:</strong> $${item.price}</p>
                                    <p><strong>Merchant:</strong> ${item.merchant}</p>
                                    <p><strong>Offers:</strong> ${item.offers.length} financing options</p>
                                </div>
                            </div>
                        `).join('')}
                    </div>
                `;
            } else if (result.findings && Array.isArray(result.findings)) {
                // Narrator results
                return `
                    <div class="grid">
                        ${result.findings.map(finding => `
                            <div class="card">
                                <h3>${finding.title}</h3>
                                <div class="card-content">
                                    <pre>${JSON.stringify(finding.evidence, null, 2)}</pre>
                                </div>
                            </div>
                        `).join('')}
                    </div>
                `;
            } else if (result.line_items && Array.isArray(result.line_items)) {
                // CareCredit results
                return `
                    <div class="card">
                        <h3>üí∞ Treatment Costs</h3>
                        <div class="card-content">
                            ${result.line_items.map(item => `
                                <p><strong>${item.name}:</strong> $${item.subtotal} (${item.qty}x $${item.unit_cost})</p>
                            `).join('')}
                            <hr>
                            <p><strong>Total:</strong> $${result.oopp.estimated_total}</p>
                        </div>
                    </div>
                    <div class="card">
                        <h3>üè• Providers Found</h3>
                        <div class="card-content">
                            ${result.providers.map(provider => `
                                <p><strong>${provider.name}</strong><br>
                                Next appointment: ${provider.next_appt_days} days</p>
                            `).join('')}
                        </div>
                    </div>
                `;
            } else if (result.snippet && result.code) {
                // DevCopilot results
                return `
                    <div class="card">
                        <h3>üíª Generated Code</h3>
                        <div class="result-json">${result.snippet.code}</div>
                    </div>
                `;
            } else if (result.response) {
                // Chat results
                return `
                    <div class="card">
                        <h3>üí¨ Response</h3>
                        <div class="card-content">
                            <p>${result.response}</p>
                            <p><strong>Agent:</strong> ${result.agent} (${(result.confidence * 100).toFixed(1)}% confidence)</p>
                        </div>
                    </div>
                `;
            }
            
            return '<p>Response received successfully.</p>';
        }
        
        function showError(agentName, error) {
            const resultDiv = document.getElementById(`${agentName}-result`);
            if (!resultDiv) return;
            
            resultDiv.innerHTML = `<div class="error">‚ùå Error: ${error}</div>`;
        }
        
        async function apiCall(endpoint, data) {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(data)
            });
            
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }
            
            return response.json();
        }
        
        async function runChat() {
            const message = document.getElementById('chat-message').value;
            const allowTavily = document.getElementById('chat-tavily').checked;
            
            if (!message.trim()) return;
            
            showLoading('chat', true);
            try {
                const result = await apiCall('/chat', { message, allow_tavily: allowTavily });
                showResult('chat', result);
            } catch (error) {
                showError('chat', error.message);
            } finally {
                showLoading('chat', false);
            }
        }
        
        async function runOfferPilot() {
            const query = document.getElementById('offer-query').value;
            const budget = parseFloat(document.getElementById('offer-budget').value) || null;
            
            if (!query.trim()) return;
            
            showLoading('offerpilot', true);
            try {
                const result = await apiCall('/agent/offerpilot', { query, budget });
                showResult('offerpilot', result);
            } catch (error) {
                showError('offerpilot', error.message);
            } finally {
                showLoading('offerpilot', false);
            }
        }
        
        async function runDispute() {
            const narrative = document.getElementById('dispute-narrative').value;
            const merchant = document.getElementById('dispute-merchant').value || null;
            const amount = parseFloat(document.getElementById('dispute-amount').value) || null;
            
            if (!narrative.trim()) return;
            
            showLoading('dispute', true);
            try {
                const result = await apiCall('/agent/dispute', { narrative, merchant, amount });
                showResult('dispute', result);
            } catch (error) {
                showError('dispute', error.message);
            } finally {
                showLoading('dispute', false);
            }
        }
        
        async function runCollections() {
            const balance = parseFloat(document.getElementById('collections-balance').value);
            const apr = parseFloat(document.getElementById('collections-apr').value);
            const bucket = document.getElementById('collections-bucket').value;
            const income = parseFloat(document.getElementById('collections-income').value) || null;
            
            if (!balance || !apr) return;
            
            showLoading('collections', true);
            try {
                const result = await apiCall('/agent/collections', { balance, apr, bucket, income_monthly: income });
                showResult('collections', result);
            } catch (error) {
                showError('collections', error.message);
            } finally {
                showLoading('collections', false);
            }
        }
        
        async function runDevCopilot() {
            const service = document.getElementById('dev-service').value;
            const endpoint = document.getElementById('dev-endpoint').value || null;
            const lang = document.getElementById('dev-language').value;
            
            if (!service.trim()) return;
            
            showLoading('devcopilot', true);
            try {
                const result = await apiCall('/agent/devcopilot', { service, endpoint, lang });
                showResult('devcopilot', result);
            } catch (error) {
                showError('devcopilot', error.message);
            } finally {
                showLoading('devcopilot', false);
            }
        }
        
        async function runCareCredit() {
            const estimate_text = document.getElementById('care-estimate').value;
            const location = document.getElementById('care-location').value || null;
            
            if (!estimate_text.trim()) return;
            
            showLoading('carecredit', true);
            try {
                const result = await apiCall('/agent/carecredit', { estimate_text, location });
                showResult('carecredit', result);
            } catch (error) {
                showError('carecredit', error.message);
            } finally {
                showLoading('carecredit', false);
            }
        }
        
        async function runNarrator() {
            const question = document.getElementById('narrator-question').value;
            
            if (!question.trim()) return;
            
            showLoading('narrator', true);
            try {
                const result = await apiCall('/agent/narrator', { question });
                showResult('narrator', result);
            } catch (error) {
                showError('narrator', error.message);
            } finally {
                showLoading('narrator', false);
            }
        }
        
        async function runTrustShield() {
            const text = document.getElementById('trust-text').value;
            
            if (!text.trim()) return;
            
            showLoading('trustshield', true);
            try {
                const result = await apiCall('/agent/trustshield', { text });
                showResult('trustshield', result);
            } catch (error) {
                showError('trustshield', error.message);
            } finally {
                showLoading('trustshield', false);
            }
        }
        
        async function runContracts() {
            const contract_text = document.getElementById('contracts-text').value;
            const question = document.getElementById('contracts-question').value || null;
            
            if (!contract_text.trim()) return;
            
            showLoading('contracts', true);
            try {
                const result = await apiCall('/agent/contracts', { contract_text, question });
                showResult('contracts', result);
            } catch (error) {
                showError('contracts', error.message);
            } finally {
                showLoading('contracts', false);
            }
        }
    </script>
</body>
</html>
"""

if __name__ == "__main__":
    import uvicorn
    
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", 8000))
    debug = os.getenv("DEBUG", "false").lower() == "true"
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=debug,
        log_level=os.getenv("LOG_LEVEL", "info").lower()
    )


================================================
FILE: package.json
================================================
{
  "name": "synch-genai-poc",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-markdown": "^9.0.1",
    "rehype-highlight": "^7.0.0",
    "remark-gfm": "^4.0.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.66",
    "@types/react-dom": "^18.2.22",
    "@vitejs/plugin-react": "^4.2.1",
    "autoprefixer": "^10.4.19",
    "postcss": "^8.4.38",
    "tailwindcss": "^3.4.1",
    "typescript": "^5.2.2",
    "vite": "^5.2.0"
  }
}


================================================
FILE: postcss.config.js
================================================
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}


================================================
FILE: requirements.txt
================================================
# Core FastAPI dependencies
fastapi==0.116.1
uvicorn[standard]==0.32.1
pydantic==2.10.3

# AI/ML dependencies
haystack-ai==2.10.0
google-generativeai==0.8.3
tavily-python==0.5.0
sentence-transformers==3.3.1

# Data processing
numpy==2.1.3
pandas==2.2.3

# Template engine
jinja2==3.1.4

# Environment management
python-dotenv==1.0.1

# PII Detection and Security
presidio-analyzer==2.2.359
presidio-anonymizer==2.2.359
spacy==3.8.2

# PDF Processing
PyMuPDF==1.24.14

# LangGraph Multi-Agent Orchestration
langgraph==0.2.53
langchain-core>=0.3.19
langchain-google-genai>=2.0.4



================================================
FILE: tailwind.config.js
================================================
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      fontFamily: {
        sans: ['Inter', 'system-ui', 'sans-serif'],
      },
      animation: {
        'fade-in': 'fadeIn 0.3s ease-in-out',
        'slide-up': 'slideUp 0.3s ease-out',
      },
      keyframes: {
        fadeIn: {
          '0%': { opacity: '0' },
          '100%': { opacity: '1' },
        },
        slideUp: {
          '0%': { opacity: '0', transform: 'translateY(20px)' },
          '100%': { opacity: '1', transform: 'translateY(0)' },
        }
      }
    },
  },
  plugins: [],
}


================================================
FILE: test_gemini.py
================================================
#!/usr/bin/env python3
"""
Simple test script to check Gemini API connectivity
"""

import os
from dotenv import load_dotenv
from app.llm.gemini import chat

def test_gemini_api():
    """Test basic Gemini API functionality"""
    
    # Load environment variables
    load_dotenv()
    
    api_key = os.getenv('GOOGLE_API_KEY')
    if not api_key:
        print("‚ùå GOOGLE_API_KEY not found in environment")
        return False
        
    print(f"üîë Using API key: {api_key[:10]}...")
    
    try:
        # Test basic chat functionality
        print("üß™ Testing basic chat...")
        messages = [{"role": "user", "content": "Say 'Hello, API test successful!'"}]
        response = chat(messages)
        
        print(f"‚úÖ Basic chat response: {response}")
        
        # Test JSON response parsing
        print("\nüß™ Testing JSON response...")
        json_messages = [{"role": "user", "content": "Return this as JSON: {'test': 'success', 'status': 'working'}"}]
        json_response = chat(json_messages, system="You must return valid JSON only, no other text.")
        
        print(f"‚úÖ JSON response: {json_response}")
        
        # Test persona detection format
        print("\nüß™ Testing persona detection format...")
        persona_messages = [{"role": "user", "content": "I need help with my credit card payment plan"}]
        persona_system = """You are a persona detection system. Respond with ONLY a JSON object:
{"persona": "consumer", "confidence": 0.85, "reasoning": "mentions personal credit card"}"""
        
        persona_response = chat(persona_messages, system=persona_system)
        print(f"‚úÖ Persona detection response: {persona_response}")
        
        # Try to parse as JSON
        import json
        import re
        
        def extract_json(text: str) -> str:
            """Extract JSON from LLM response that may contain markdown formatting"""
            if not text or not text.strip():
                return "{}"
            
            # Try to find JSON in code blocks (more flexible pattern)
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL | re.IGNORECASE)
            if json_match:
                return json_match.group(1).strip()
            
            # Try to find JSON directly (non-greedy)
            json_match = re.search(r'\{.*?\}', text, re.DOTALL)
            if json_match:
                return json_match.group(0).strip()
            
            # Try to extract everything between first { and last }
            first_brace = text.find('{')
            last_brace = text.rfind('}')
            if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
                return text[first_brace:last_brace+1].strip()
            
            # Fallback - return empty JSON
            return '{"persona": "consumer", "confidence": 0.3, "reasoning": "Failed to parse response"}'
        
        try:
            extracted = extract_json(persona_response)
            print(f"üîß Extracted JSON: {extracted}")
            
            parsed = json.loads(extracted)
            print(f"‚úÖ JSON parsing successful: {parsed}")
        except json.JSONDecodeError as e:
            print(f"‚ùå JSON parsing failed: {e}")
            print(f"Raw response: {repr(persona_response)}")
            
        return True
        
    except Exception as e:
        print(f"‚ùå API test failed: {e}")
        return False

if __name__ == "__main__":
    print("üöÄ Testing Gemini API connectivity...\n")
    success = test_gemini_api()
    
    if success:
        print("\nüéâ All tests passed!")
    else:
        print("\nüí• Tests failed!")


================================================
FILE: tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": false,
    "noUnusedParameters": false,
    "noFallthroughCasesInSwitch": true
  },
  "include": ["src"],
  "references": [{ "path": "./tsconfig.node.json" }]
}


================================================
FILE: tsconfig.node.json
================================================
{
  "compilerOptions": {
    "composite": true,
    "skipLibCheck": true,
    "module": "ESNext",
    "moduleResolution": "bundler",
    "allowSyntheticDefaultImports": true
  },
  "include": ["vite.config.ts"]
}


================================================
FILE: vite.config.ts
================================================
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

export default defineConfig({
  plugins: [react()],
  server: {
    port: 3000,
    proxy: {
      '/chat': 'http://localhost:8000',
      '/agent': 'http://localhost:8000',
      '/upload': 'http://localhost:8000',
      '/pdf': 'http://localhost:8000',
      '/healthz': 'http://localhost:8000',
    }
  },
  build: {
    outDir: 'dist',
  },
})


================================================
FILE: app/__init__.py
================================================
# Synch GenAI PoC Application Package



================================================
FILE: app/router.py
================================================
"""
Message routing system using Gemini classifier
"""

import logging
from typing import Dict, List
from app.llm.gemini import chat

logger = logging.getLogger(__name__)

# Supported agent types
AGENT_TYPES = [
    "offer",
    "trust", 
    "dispute",
    "collections",
    "contracts",
    "devcopilot",
    "carecredit",
    "narrator",
]

def route(message: str) -> Dict[str, any]:
    """
    Route a message to the appropriate agent using Gemini classifier
    
    Args:
        message: User message to classify
        
    Returns:
        Dictionary with agent type and confidence score
    """
    try:
        # Create classification prompt
        system_prompt = """You are a message routing classifier for a financial services platform. 
Your job is to classify user messages into one of these agent categories based on intent and content.

Agent Categories:
- offer: Product offers, promotions, deals, discounts, marketing content
- trust: Security concerns, fraud detection, suspicious activity, safety issues
- dispute: Transaction disputes, chargebacks, billing issues, payment problems
- collections: Debt collection, overdue payments, payment reminders
- contracts: Contract terms, agreements, legal documents, merchant agreements
- devcopilot: Technical support, API questions, integration help, developer tools
- carecredit: Healthcare financing, medical payments, care credit specific queries
- narrator: General conversation, greetings, small talk, unclear intent

Respond with ONLY a JSON object in this exact format:
{"agent": "category_name", "confidence": 0.85}

The confidence should be a float between 0.0 and 1.0 representing how certain you are about the classification."""

        user_message = f"Classify this message: '{message}'"
        
        messages = [{"role": "user", "content": user_message}]
        
        # Get classification from Gemini
        response = chat(messages, system=system_prompt)
        
        # Parse JSON response
        import json
        try:
            # Handle markdown-wrapped JSON responses
            response_text = response.strip()
            if response_text.startswith('```json'):
                # Extract JSON from markdown code block
                response_text = response_text.replace('```json', '').replace('```', '').strip()
            elif response_text.startswith('```'):
                # Handle generic code blocks
                lines = response_text.split('\n')
                response_text = '\n'.join(lines[1:-1]).strip()
            
            result = json.loads(response_text)
            
            # Validate response format
            if not isinstance(result, dict) or "agent" not in result or "confidence" not in result:
                raise ValueError("Invalid response format")
            
            agent = result["agent"]
            confidence = float(result["confidence"])
            
            # Validate agent type
            if agent not in AGENT_TYPES:
                logger.warning(f"Unknown agent type '{agent}', defaulting to 'trust'")
                agent = "trust"
                confidence = 0.3
            
            # Validate confidence range
            confidence = max(0.0, min(1.0, confidence))
            
            # Apply default routing rule: if confidence < 0.5, default to "trust"
            if confidence < 0.5:
                logger.info(f"Low confidence ({confidence:.3f}) for agent '{agent}', defaulting to 'trust'")
                agent = "trust"
                confidence = 0.5
            
            logger.info(f"Routed message to '{agent}' with confidence {confidence:.3f}")
            
            return {
                "agent": agent,
                "confidence": confidence
            }
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            logger.error(f"Failed to parse classification response: {e}")
            logger.debug(f"Raw response: {response}")
            
            # Fallback classification
            return {
                "agent": "trust",
                "confidence": 0.3
            }
            
    except Exception as e:
        logger.error(f"Error in message routing: {e}")
        
        # Default fallback
        return {
            "agent": "trust", 
            "confidence": 0.3
        }

def get_agent_description(agent_type: str) -> str:
    """
    Get description of what each agent handles
    
    Args:
        agent_type: The agent type
        
    Returns:
        Description string
    """
    descriptions = {
        "offer": "Handles product offers, promotions, deals, and marketing content",
        "trust": "Manages security concerns, fraud detection, and safety issues", 
        "dispute": "Processes transaction disputes, chargebacks, and billing issues",
        "collections": "Handles debt collection and overdue payment matters",
        "contracts": "Manages contract terms, agreements, and legal documents",
        "devcopilot": "Provides technical support and developer assistance",
        "carecredit": "Handles healthcare financing and medical payment queries",
        "narrator": "Manages general conversation and unclear intents"
    }
    
    return descriptions.get(agent_type, "Unknown agent type")

def route_with_fallback_analysis(message: str) -> Dict[str, any]:
    """
    Enhanced routing with fallback keyword analysis
    
    Args:
        message: User message to classify
        
    Returns:
        Dictionary with agent type, confidence, and reasoning
    """
    # First try Gemini classification
    primary_result = route(message)
    
    # If confidence is still low, try keyword-based fallback
    if primary_result["confidence"] < 0.6:
        keyword_result = _keyword_based_routing(message)
        
        # Use keyword result if it has higher confidence
        if keyword_result["confidence"] > primary_result["confidence"]:
            logger.info(f"Using keyword-based routing over Gemini classification")
            return {
                **keyword_result,
                "method": "keyword_fallback",
                "gemini_result": primary_result
            }
    
    return {
        **primary_result,
        "method": "gemini_classification"
    }

def _keyword_based_routing(message: str) -> Dict[str, any]:
    """
    Simple keyword-based routing as fallback
    
    Args:
        message: User message
        
    Returns:
        Classification result
    """
    message_lower = message.lower()
    
    # Define keyword patterns for each agent
    patterns = {
        "trust": [
            "fraud", "scam", "suspicious", "security", "hack", "phishing", 
            "stolen", "unauthorized", "breach", "compromise", "malware",
            "gift card", "wire transfer", "refund scam", "overpay"
        ],
        "dispute": [
            "dispute", "chargeback", "wrong charge", "billing error", 
            "refund", "cancel", "unauthorized charge", "double charge"
        ],
        "collections": [
            "overdue", "payment due", "debt", "collection", "past due",
            "late payment", "outstanding balance"
        ],
        "contracts": [
            "contract", "agreement", "terms", "legal", "merchant agreement",
            "terms of service", "privacy policy"
        ],
        "devcopilot": [
            "api", "integration", "technical", "developer", "code", "sdk",
            "documentation", "endpoint", "webhook"
        ],
        "carecredit": [
            "care credit", "medical", "healthcare", "dental", "veterinary",
            "health financing"
        ],
        "offer": [
            "offer", "promotion", "deal", "discount", "sale", "special",
            "limited time", "bonus"
        ]
    }
    
    # Score each agent based on keyword matches
    scores = {}
    for agent, keywords in patterns.items():
        score = sum(1 for keyword in keywords if keyword in message_lower)
        if score > 0:
            scores[agent] = score / len(keywords)  # Normalize by number of keywords
    
    if scores:
        # Get the agent with highest score
        best_agent = max(scores, key=scores.get)
        confidence = min(0.8, scores[best_agent] * 2)  # Cap at 0.8 for keyword matching
        
        return {
            "agent": best_agent,
            "confidence": confidence
        }
    
    # No keywords matched
    return {
        "agent": "narrator",
        "confidence": 0.4
    }



================================================
FILE: app/agents/__init__.py
================================================
# Agents Package



================================================
FILE: app/agents/carecredit.py
================================================
"""
CareCredit Treatment Translator
Converts medical estimates into plain-language options with provider availability and financing plans
"""

import json
import logging
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Literal
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat
from app.agents.offerpilot import OfferPilot
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Pydantic models for structured data
class InsuranceInfo(BaseModel):
    deductible_left: float
    coinsurance: float

class LineItem(BaseModel):
    name: str
    unit_cost: float
    qty: int = 1
    subtotal: float
    procedure_code: Optional[str] = None

class Provider(BaseModel):
    name: str
    address: str
    phone: str
    next_appt_days: int

class FinancingOption(BaseModel):
    offer_id: str
    months: int
    apr: float
    monthly: float
    total_cost: float

class OOPPResult(BaseModel):
    estimated_total: float
    assumptions: Dict[str, Any]

class Citation(BaseModel):
    source: str
    snippet: str

class CreditResponse(BaseModel):
    response: str  # counts + 12-mo explanation + next steps
    metadata: Dict[str, Any]  # ui_cards and disclosures

@dataclass
class ParsedProcedure:
    """Represents a parsed medical/dental procedure"""
    procedure_code: Optional[str]
    name: str
    unit_cost: float
    qty: int = 1

class CareCredit:
    """
    CareCredit Treatment Translator for medical/dental estimates
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize CareCredit agent with required components"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        self.rules_loader = rules_loader
        
        # Initialize OfferPilot for financing offers
        self.offer_pilot = OfferPilot(docstore, embedder, retriever)
        
        # Load provider data and rules
        self._load_provider_data()
        self._load_carecredit_rules()
    
    def _load_provider_data(self):
        """Load healthcare provider directory"""
        try:
            providers_path = Path("synchrony-demo-rules-repo/fixtures/providers.json")
            with open(providers_path, 'r') as f:
                data = json.load(f)
                self.providers = data["providers"]
                self.specialties = data.get("specialties", {})
                self.procedure_mappings = data.get("procedure_mappings", {})
            logger.info(f"Loaded {len(self.providers)} healthcare providers")
        except Exception as e:
            logger.error(f"Failed to load provider data: {e}")
            self.providers = []
            self.specialties = {}
            self.procedure_mappings = {}
    
    def _load_carecredit_rules(self):
        """Load CareCredit rules from YAML"""
        try:
            if self.rules_loader:
                self.carecredit_rules = self.rules_loader.get_rules('carecredit') or {}
                logger.info("Loaded CareCredit rules from rules_loader")
            else:
                self.carecredit_rules = {}
                logger.warning("No rules_loader provided - using defaults")
        except Exception as e:
            logger.error(f"Failed to load CareCredit rules: {e}")
            self.carecredit_rules = {}
    
    def process_estimate(
        self,
        estimate_text: str,
        location: Optional[str] = None,
        insurance: Optional[Dict[str, float]] = None
    ) -> CreditResponse:
        """
        Main processing pipeline: treatment ‚Üí providers ‚Üí OOPP ‚Üí financing
        
        Args:
            estimate_text: Medical/dental estimate text
            location: Patient location for provider search
            insurance: Insurance info with deductible_left and coinsurance
            
        Returns:
            CreditResponse with counts + 12-mo explanation + next steps + metadata
        """
        try:
            logger.info("Processing CareCredit treatment estimate")
            
            # Step 0: Validate that this is actually a medical/dental estimate
            if not self._is_medical_estimate(estimate_text):
                logger.info("Input is not a medical estimate - treating as general CareCredit query")
                return self._handle_general_query(estimate_text)
            
            # Step 1: Parse estimate into line items (deterministic parser)
            parsed_items = self.estimate_parse_table(estimate_text)
            logger.info(f"Parsed {len(parsed_items)} line items from estimate")
            
            # Step 2: Calculate total cost
            total_cost = sum(item.unit_cost * item.qty for item in parsed_items)
            
            # Step 3: Identify specialty from procedures
            specialty = self._identify_specialty(parsed_items, estimate_text)
            logger.info(f"Identified specialty: {specialty}")
            
            # Step 4: Provider shortlist (max 3) filtered by specialty/city
            providers = self.providers_search({"specialty": specialty, "location": location})
            
            # Step 5: OOPP estimate using rules/carecredit.yml defaults
            oopp_result = self.oopp_simulate(total_cost, None, insurance)
            
            # Step 6: Financing pairing - attach EP/DI options
            financing_offers = self._get_carecredit_offers(total_cost)
            
            # Step 7: Generate response with counts + 12-mo explanation + next steps
            response_text = self._generate_response_text(parsed_items, providers, financing_offers, oopp_result, total_cost)
            
            # Step 8: Build UI cards for metadata
            ui_cards = self._build_ui_cards(parsed_items, providers, financing_offers, total_cost)
            
            # Step 9: Always append carecredit_generic disclosure
            disclosures = self._get_disclosures(financing_offers)
            
            return CreditResponse(
                response=response_text,
                metadata={
                    "ui_cards": ui_cards,
                    "disclosures": disclosures,
                    "total_procedures": len(parsed_items),
                    "total_cost": total_cost,
                    "providers_found": len(providers),
                    "financing_options": len(financing_offers),
                    "oopp_estimate": oopp_result.estimated_total,
                    "specialty": specialty
                }
            )
            
        except Exception as e:
            logger.error(f"Error processing CareCredit estimate: {e}")
            return CreditResponse(
                response=f"Error processing estimate: {str(e)}",
                metadata={
                    "ui_cards": [],
                    "disclosures": ["carecredit_generic"],
                    "error": str(e)
                }
            )
    
    def process_query(self, query: str) -> Dict[str, Any]:
        """
        Main entry point for supervisor integration
        
        Args:
            query: User query about healthcare financing
            
        Returns:
            Dict with response, metadata, sources for supervisor
        """
        try:
            # Extract location if mentioned
            location = self._extract_location(query)
            
            # Extract insurance info if mentioned
            insurance = self._extract_insurance(query)
            
            # Process the estimate
            result = self.process_estimate(query, location, insurance)
            
            # Convert to supervisor-compatible format
            return {
                "response": result.response,
                "confidence": 0.8,
                "sources": [],
                "metadata": result.metadata
            }
            
        except Exception as e:
            logger.error(f"CareCredit process_query error: {e}")
            return {
                "response": f"Error processing CareCredit query: {str(e)}",
                "confidence": 0.2,
                "sources": [],
                "metadata": {"error": str(e)}
            }
    
    def _extract_location(self, query: str) -> Optional[str]:
        """Extract location from query text"""
        import re
        
        # Look for city patterns
        city_patterns = [
            r"in ([A-Z][a-z]+ ?[A-Z]?[a-z]*)",  # "in New York", "in Chicago"
            r"I'm in ([A-Z][a-z]+ ?[A-Z]?[a-z]*)",  # "I'm in New York"
            r"([A-Z][a-z]+) area",  # "Chicago area"
        ]
        
        for pattern in city_patterns:
            match = re.search(pattern, query, re.IGNORECASE)
            if match:
                return match.group(1).title()
        
        return None
    
    def _extract_insurance(self, query: str) -> Optional[Dict[str, float]]:
        """Extract insurance information from query text"""
        import re
        
        insurance = {}
        
        # Look for deductible
        deductible_match = re.search(r'\$?(\d+) deductible', query, re.IGNORECASE)
        if deductible_match:
            insurance["deductible_left"] = float(deductible_match.group(1))
        
        # Look for coinsurance
        coinsurance_match = re.search(r'(\d+)% coinsurance', query, re.IGNORECASE)
        if coinsurance_match:
            insurance["coinsurance"] = float(coinsurance_match.group(1)) / 100
        
        # Look for "no insurance"
        if re.search(r'no insurance|without insurance', query, re.IGNORECASE):
            return None
        
        return insurance if insurance else None
    
    def estimate_parse_table(self, text: str) -> List[ParsedProcedure]:
        """
        Parse medical estimate table using Gemini with regex fallback
        
        Args:
            text: Estimate text to parse
            
        Returns:
            List of parsed procedures
        """
        try:
            # First, try Gemini-powered parsing with table hints
            system_prompt = """You are a medical billing expert. Parse the following medical/dental estimate into a structured list.

Extract each procedure/service with:
- Procedure code (if present, like D0120, 99213, etc.)
- Procedure name/description  
- Unit cost (dollar amount)
- Quantity (default to 1 if not specified)

Return as JSON array with objects containing: procedure_code, name, unit_cost, qty

Focus on actual billable procedures, ignore totals and administrative text."""

            user_message = f"Medical/dental estimate to parse:\n\n{text}"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            # Try to parse Gemini response as JSON
            try:
                # Debug: Print the raw response
                logger.info(f"Raw Gemini response: {repr(response[:200])}")
                
                # Clean the response - handle markdown code blocks
                response_clean = self._extract_json(response)
                
                logger.info(f"Cleaned response: {repr(response_clean[:200])}")
                
                parsed_json = json.loads(response_clean)
                procedures = []
                
                for item in parsed_json:
                    if isinstance(item, dict) and "name" in item and "unit_cost" in item:
                        procedures.append(ParsedProcedure(
                            procedure_code=item.get("procedure_code"),
                            name=item["name"],
                            unit_cost=float(item["unit_cost"]),
                            qty=int(item.get("qty", 1))
                        ))
                
                if procedures:
                    logger.info("Successfully parsed estimate using Gemini")
                    return procedures
                    
            except (json.JSONDecodeError, ValueError, KeyError) as e:
                logger.warning(f"Failed to parse Gemini JSON response: {e}")
            
            # Fallback to regex parsing
            logger.info("Falling back to regex parsing")
            return self._regex_parse_estimate(text)
            
        except Exception as e:
            logger.error(f"Error parsing estimate: {e}")
            return self._regex_parse_estimate(text)
    
    def _regex_parse_estimate(self, text: str) -> List[ParsedProcedure]:
        """
        Fallback regex-based estimate parsing
        
        Args:
            text: Estimate text
            
        Returns:
            List of parsed procedures
        """
        procedures = []
        
        # Common patterns for medical estimates
        patterns = [
            # Pattern 1: Code | Description | $Amount
            r'([A-Z]?\d{4,5})\s*[|\-\s]+([^|\$]+?)\s*[|\-\s]*\$?\s*(\d+(?:\.\d{2})?)',
            # Pattern 2: Description $Amount
            r'([A-Za-z][^$\n]{10,50}?)\s+\$(\d+(?:\.\d{2})?)',
            # Pattern 3: Description ... $Amount
            r'([A-Za-z][^$\n]{5,40}?)\.{2,}\$?(\d+(?:\.\d{2})?)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.MULTILINE | re.IGNORECASE)
            
            for match in matches:
                try:
                    if len(match) == 3:  # Code, description, amount
                        code, name, amount = match
                        procedures.append(ParsedProcedure(
                            procedure_code=code.strip(),
                            name=name.strip(),
                            unit_cost=float(amount),
                            qty=1
                        ))
                    elif len(match) == 2:  # Description, amount
                        name, amount = match
                        procedures.append(ParsedProcedure(
                            procedure_code=None,
                            name=name.strip(),
                            unit_cost=float(amount),
                            qty=1
                        ))
                except (ValueError, IndexError):
                    continue
        
        # Remove duplicates and clean up
        seen_names = set()
        clean_procedures = []
        for proc in procedures:
            if proc.name.lower() not in seen_names and proc.unit_cost > 0:
                seen_names.add(proc.name.lower())
                clean_procedures.append(proc)
        
        # If still no results, create generic procedure from any dollar amounts
        if not clean_procedures:
            dollar_matches = re.findall(r'\$(\d+(?:\.\d{2})?)', text)
            for amount in dollar_matches[:3]:  # Take first 3 amounts
                try:
                    cost = float(amount)
                    if cost > 10:  # Reasonable minimum
                        clean_procedures.append(ParsedProcedure(
                            procedure_code=None,
                            name=f"Medical procedure (${cost})",
                            unit_cost=cost,
                            qty=1
                        ))
                except ValueError:
                    continue
        
        return clean_procedures
    
    def providers_search(self, criteria: Dict[str, str]) -> List[Provider]:
        """
        Search providers by specialty and city (max 3 results)
        
        Args:
            criteria: Dict with specialty and location/city
            
        Returns:
            List of matching providers (max 3)
        """
        specialty = criteria.get("specialty", "").lower()
        city = criteria.get("location", "").lower()
        
        matching_providers = []
        max_results = self.carecredit_rules.get("provider_search", {}).get("max_results", 3)
        
        for provider in self.providers:
            # Check specialty match
            if specialty and provider.get("specialty", "").lower() != specialty:
                continue
            
            # Check city match (if specified) 
            if city and city not in provider.get("city", "").lower():
                continue
            
            # Only include enrolled/CareCredit accepting providers
            if provider.get("accepts_carecredit", False) or provider.get("enrolled", False):
                matching_providers.append(Provider(
                    name=provider["name"],
                    address=provider.get("address", f"{provider.get('city', 'Unknown')}"),
                    phone=provider.get("phone", "Contact provider"),
                    next_appt_days=provider.get("next_appt_days", 7)
                ))
        
        # Sort by appointment availability (sooner appointments first)
        matching_providers.sort(key=lambda p: p.next_appt_days)
        
        return matching_providers[:max_results]  # Return max 3
    
    def _get_carecredit_offers(self, total_cost: float) -> List[FinancingOption]:
        """
        Get CareCredit financing offers with EP/DI options
        
        Args:
            total_cost: Total treatment cost
            
        Returns:
            List of financing options (EP + DI)
        """
        financing_options = []
        
        try:
            # Get financing rules from carecredit.yml
            financing_rules = self.carecredit_rules.get("financing_options", {})
            ep_rules = financing_rules.get("equal_payment", {})
            di_rules = financing_rules.get("deferred_interest", {})
            
            # Generate Equal Payment (EP) options
            ep_terms = ep_rules.get("terms", [12, 24, 36, 48, 60])
            ep_min = ep_rules.get("min_amount", 200.0)
            ep_max = ep_rules.get("max_amount", 25000.0)
            ep_promo_apr = ep_rules.get("apr_range", {}).get("promotional", 0.0)
            
            if ep_min <= total_cost <= ep_max:
                for months in ep_terms:
                    if months <= 24:  # Promotional 0% APR for shorter terms
                        apr = ep_promo_apr
                        offer_id = f"EP_{months}_0"
                    else:  # Standard APR for longer terms  
                        apr = 14.90  # Use standard rate
                        offer_id = f"EP_{months}_1490"
                    
                    # Calculate payment
                    if apr == 0:
                        monthly = total_cost / months
                        total_with_interest = total_cost
                    else:
                        monthly_rate = apr / 100 / 12
                        monthly = (total_cost * monthly_rate * (1 + monthly_rate) ** months) / ((1 + monthly_rate) ** months - 1)
                        total_with_interest = monthly * months
                    
                    financing_options.append(FinancingOption(
                        offer_id=offer_id,
                        months=months,
                        apr=apr,
                        monthly=round(monthly, 2),
                        total_cost=round(total_with_interest, 2)
                    ))
            
            # Generate Deferred Interest (DI) options  
            di_terms = di_rules.get("terms", [6, 12, 18, 24])
            di_min = di_rules.get("min_amount", 200.0)
            di_max = di_rules.get("max_amount", 25000.0)
            di_standard_apr = di_rules.get("standard_apr", 26.99)
            
            if di_min <= total_cost <= di_max:
                for months in di_terms:
                    offer_id = f"DI_{months}_0"
                    
                    # DI: 0% during promo period, standard APR if not paid off
                    financing_options.append(FinancingOption(
                        offer_id=offer_id,
                        months=months,
                        apr=0.0,  # Promotional rate during term
                        monthly=round(total_cost / months, 2),  # Minimum payment
                        total_cost=total_cost  # If paid during promo period
                    ))
            
            # Sort by APR, then by months (0% APR first, shorter terms first)
            financing_options.sort(key=lambda x: (x.apr > 0, x.apr, x.months))
            
        except Exception as e:
            logger.error(f"Error getting CareCredit offers: {e}")
            # Fallback default offers
            financing_options = [
                FinancingOption(offer_id="EP_12_0", months=12, apr=0.0, monthly=round(total_cost/12, 2), total_cost=total_cost),
                FinancingOption(offer_id="DI_12_0", months=12, apr=0.0, monthly=round(total_cost/12, 2), total_cost=total_cost)
            ]
        
        return financing_options
    
    def oopp_simulate(
        self, 
        total: float, 
        promo: Optional[FinancingOption], 
        insurance: Optional[Dict[str, float]]
    ) -> OOPPResult:
        """
        Simulate out-of-pocket costs using rules/carecredit.yml defaults
        
        Args:
            total: Total procedure cost
            promo: Selected financing option
            insurance: Insurance details
            
        Returns:
            OOPP simulation result
        """
        assumptions = {}
        
        try:
            # Start with total cost
            estimated_total = total
            assumptions["original_total"] = total
            
            # Get defaults from rules
            oopp_defaults = self.carecredit_rules.get("oopp_defaults", {})
            deductible_defaults = oopp_defaults.get("deductible", {})
            coinsurance_defaults = oopp_defaults.get("coinsurance", {})
            
            # Apply insurance if provided, otherwise use defaults
            if insurance:
                deductible_left = insurance.get("deductible_left", deductible_defaults.get("individual", 1500.0))
                coinsurance = insurance.get("coinsurance", coinsurance_defaults.get("in_network", 0.2))
            else:
                # Use rules defaults
                deductible_left = deductible_defaults.get("individual", 1500.0)
                coinsurance = coinsurance_defaults.get("in_network", 0.2)
                assumptions["insurance_status"] = f"Using default deductible ${deductible_left} and {coinsurance*100}% coinsurance"
            
            # Apply deductible
            after_deductible = max(0, total - deductible_left)
            deductible_used = min(total, deductible_left)
            
            # Apply coinsurance to remaining amount
            insurance_pays = after_deductible * (1 - coinsurance)
            patient_coinsurance = after_deductible * coinsurance
            
            estimated_total = deductible_used + patient_coinsurance
            
            assumptions.update({
                "deductible_applied": deductible_used,
                "coinsurance_rate": coinsurance,
                "insurance_payment": insurance_pays,
                "patient_portion": estimated_total,
                "caveat": self.carecredit_rules.get("oop_estimator", {}).get("caveat", "Illustrative only")
            })
            
            # Factor in financing if selected
            if promo:
                assumptions.update({
                    "financing_option": f"{promo.months} months at {promo.apr}% APR",
                    "monthly_payment": promo.monthly,
                    "total_with_interest": promo.total_cost
                })
                
                # For 0% APR, total cost doesn't change
                if promo.apr == 0:
                    assumptions["financing_benefit"] = "0% APR - no interest charges"
                else:
                    interest_cost = promo.total_cost - estimated_total
                    assumptions["interest_cost"] = interest_cost
            
        except Exception as e:
            logger.error(f"Error simulating OOPP: {e}")
            assumptions["error"] = str(e)
        
        return OOPPResult(
            estimated_total=round(estimated_total, 2),
            assumptions=assumptions
        )
    
    def terms_retrieve(self, query: str) -> List[Citation]:
        """
        Retrieve CareCredit terms with Tavily fallback
        
        Args:
            query: Terms query
            
        Returns:
            List of citations
        """
        citations = []
        
        try:
            # First try local knowledge base
            if self.retriever and self.embedder:
                from app.rag.core import retrieve
                results = retrieve(self.retriever, self.embedder, query, k=2)
                
                for result in results:
                    citations.append(Citation(
                        source=result.get("filename", "Terms Document"),
                        snippet=result.get("snippet", "")[:200] + "..."
                    ))
            
            # If no local results, search web with Tavily
            if not citations and self.docstore and self.embedder:
                logger.info("No local terms found, searching web for CareCredit terms")
                
                try:
                    web_docs = web_search_into_docstore(
                        self.docstore,
                        self.embedder,
                        "CareCredit promotional financing terms conditions healthcare",
                        max_results=2
                    )
                    
                    if web_docs:
                        # Re-retrieve after adding web content
                        from app.rag.core import retrieve
                        results = retrieve(self.retriever, self.embedder, query, k=2)
                        
                        for result in results:
                            citations.append(Citation(
                                source=result.get("filename", "Web Search - CareCredit"),
                                snippet=result.get("snippet", "")[:200] + "..."
                            ))
                
                except Exception as e:
                    logger.warning(f"Web search for CareCredit terms failed: {e}")
            
            # Add default citation if nothing found
            if not citations:
                citations.append(Citation(
                    source="CareCredit Terms",
                    snippet="Subject to credit approval. Minimum monthly payments required. See carecredit.com for full terms and conditions."
                ))
            
        except Exception as e:
            logger.error(f"Error retrieving terms: {e}")
        
        return citations
    
    def _identify_specialty(self, procedures: List[ParsedProcedure], text: str) -> str:
        """
        Identify medical specialty from procedures and text
        
        Args:
            procedures: Parsed procedures
            text: Original estimate text
            
        Returns:
            Medical specialty
        """
        # Check procedure codes first
        for proc in procedures:
            if proc.procedure_code:
                if proc.procedure_code in self.procedure_mappings:
                    return self.procedure_mappings[proc.procedure_code]["specialty"]
        
        # Check keywords in text and procedure names
        text_lower = text.lower()
        all_text = text_lower + " " + " ".join(proc.name.lower() for proc in procedures if proc.name)
        
        specialty_scores = {}
        for specialty, keywords in self.specialties.items():
            score = sum(1 for keyword in keywords if keyword in all_text)
            if score > 0:
                specialty_scores[specialty] = score
        
        if specialty_scores:
            return max(specialty_scores.items(), key=lambda x: x[1])[0]
        
        # Default to dental (most common CareCredit usage)
        return "dental"
    
    def _extract_json(self, text: str) -> str:
        """Extract JSON from LLM response that may contain markdown formatting"""
        import re
        
        # Try to find JSON in code blocks
        json_match = re.search(r'```(?:json)?\s*(\{.*?\}|\[.*?\])\s*```', text, re.DOTALL)
        if json_match:
            return json_match.group(1)
        
        # Try to find JSON directly
        json_match = re.search(r'(\{.*?\}|\[.*?\])', text, re.DOTALL)
        if json_match:
            return json_match.group(1)
        
        # Fallback
        return text.strip()
    
    def _is_medical_estimate(self, text: str) -> bool:
        """
        Check if the input text is a medical/dental estimate with procedures and costs
        
        Args:
            text: Input text to validate
            
        Returns:
            True if this appears to be a medical estimate, False otherwise
        """
        # Convert to lowercase for case-insensitive matching
        text_lower = text.lower()
        
        # Indicators that this is NOT a medical estimate (general queries)
        query_indicators = [
            "find me", "show me", "i need", "looking for", "search for",
            "what are", "how much", "can you", "help me find",
            "equipment", "financing options", "carecredit options"
        ]
        
        if any(indicator in text_lower for indicator in query_indicators):
            return False
        
        # Indicators that this IS a medical estimate
        estimate_indicators = [
            "$", "cost", "total", "procedure", "treatment", "exam", "cleaning",
            "filling", "crown", "implant", "extraction", "surgery", "consultation",
            "x-ray", "root canal", "orthodontic", "periodontal"
        ]
        
        # Medical billing patterns
        billing_patterns = [
            r'\$[\d,]+\.?\d*',  # Dollar amounts
            r'procedure.*\$',   # Procedure with cost
            r'treatment.*\$',   # Treatment with cost  
            r'\d+\.\d+',       # Decimal numbers (costs)
        ]
        
        # Check for cost indicators
        has_cost_indicators = any(indicator in text_lower for indicator in estimate_indicators)
        
        # Check for billing patterns
        import re
        has_billing_patterns = any(re.search(pattern, text_lower) for pattern in billing_patterns)
        
        # Must have either cost indicators or billing patterns
        return has_cost_indicators or has_billing_patterns
    
    def _handle_general_query(self, query: str) -> CreditResponse:
        """
        Handle general CareCredit queries (not medical estimates)
        
        Args:
            query: General query about CareCredit options
            
        Returns:
            CreditResponse with general information
        """
        # Extract any budget information from the query
        import re
        budget_match = re.search(r'under \$?([0-9,]+)', query.lower())
        budget = None
        if budget_match:
            budget = float(budget_match.group(1).replace(',', ''))
        
        # Generate a helpful response about CareCredit in general
        response_text = f"""# CareCredit Healthcare Financing

I can help you understand CareCredit financing options for healthcare expenses.

## CareCredit Overview

CareCredit is a specialized healthcare credit card designed to cover medical expenses:

- **Medical, dental, veterinary, and vision** expenses covered
- **Promotional financing** options: 6, 12, 18, and 24-month plans  
- **0% interest** if paid in full within promotional period
- **260,000+ healthcare providers** nationwide accept CareCredit

## Next Steps

1. **Get a specific treatment estimate** from your healthcare provider
2. **Upload the estimate** here for detailed financing analysis  
3. **Apply for CareCredit** at carecredit.com if you haven't already
4. **Use the CareCredit mobile app** to manage your account

> For detailed financing calculations, please provide a specific treatment estimate with procedures and costs."""

        if budget:
            response_text += f"\n\n**Budget Note:** For expenses around ${budget:,.0f}, CareCredit offers several promotional periods that can help manage costs."

        return CreditResponse(
            response=response_text,
            metadata={
                "ui_cards": [],
                "disclosures": ["carecredit_generic"],
                "query_type": "general_inquiry",
                "budget_mentioned": budget
            }
        )
    
    def _generate_response_text(
        self,
        procedures: List[ParsedProcedure],
        providers: List[Provider],
        financing: List[FinancingOption],
        oopp: OOPPResult,
        total_cost: float
    ) -> str:
        """
        Generate response: counts + 12-mo explanation + next steps
        
        Args:
            procedures: Parsed procedures
            providers: Available providers
            financing: Financing options
            oopp: Out-of-pocket projection
            total_cost: Total treatment cost
            
        Returns:
            Response with counts, 12-mo explanation, and next steps
        """
        response_parts = []
        
        # Main title
        response_parts.append("# CareCredit Treatment Financing Analysis")
        response_parts.append("")
        
        # Treatment overview
        response_parts.append("## Treatment Overview")
        response_parts.append(f"- **Procedures**: {len(procedures)} procedure{'s' if len(procedures) != 1 else ''}")
        response_parts.append(f"- **Total Cost**: ${total_cost:,.2f}")
        response_parts.append(f"- **Out-of-Pocket**: ${oopp.estimated_total:,.2f} *(estimate based on {oopp.assumptions.get('caveat', 'typical coverage')})*")
        response_parts.append("")
        
        # Financing options
        if financing:
            response_parts.append("## Financing Options")
            best_12mo = next((f for f in financing if f.months == 12), financing[0])
            if best_12mo.apr == 0:
                response_parts.append(f"**üéØ Recommended**: ${best_12mo.monthly:.2f}/month with **0% APR** promotional financing")
                response_parts.append("")
                response_parts.append("### Key Features:")
                response_parts.append("- No interest if paid in full within promotional period")
                response_parts.append("- Easy monthly payments")  
                response_parts.append("- Instant approval available")
            else:
                response_parts.append(f"**Monthly Payment**: ${best_12mo.monthly:.2f}/month at {best_12mo.apr}% APR")
            response_parts.append("")
        
        # Provider availability
        if providers:
            next_appt = min(p.next_appt_days for p in providers)
            response_parts.append("## Provider Availability")
            response_parts.append(f"- **{len(providers)} CareCredit providers** available in your area")
            response_parts.append(f"- **Next available appointment**: {next_appt} days")
            response_parts.append("")
        
        # Next steps
        response_parts.append("## Next Steps")
        if providers:
            response_parts.append("1. **Contact a provider** to schedule consultation")
        response_parts.append("2. **Apply for CareCredit** at carecredit.com")
        response_parts.append("3. **Bring your CareCredit card** to your appointment")
        response_parts.append("")
        
        # Important note
        response_parts.append("> **Note**: CareCredit is accepted at over 260,000 healthcare providers nationwide for medical, dental, veterinary, and vision expenses.")
        
        return "\n".join(response_parts)
    
    def _build_ui_cards(
        self,
        procedures: List[ParsedProcedure],
        providers: List[Provider],
        financing: List[FinancingOption],
        total_cost: float
    ) -> List[Dict[str, Any]]:
        """
        Build UI cards: estimate, providers, financing
        
        Returns:
            List of UI cards for metadata
        """
        ui_cards = []
        
        # Estimate card
        estimate_items = [
            {
                "name": proc.name,
                "code": proc.procedure_code or "",
                "unit_cost": proc.unit_cost,
                "qty": proc.qty,
                "subtotal": proc.unit_cost * proc.qty
            }
            for proc in procedures
        ]
        
        ui_cards.append({
            "type": "estimate",
            "items": estimate_items,
            "total": total_cost
        })
        
        # Providers card
        provider_items = [
            {
                "name": prov.name,
                "address": prov.address,
                "phone": prov.phone,
                "next_appt_days": prov.next_appt_days
            }
            for prov in providers
        ]
        
        ui_cards.append({
            "type": "providers",
            "items": provider_items
        })
        
        # Financing card
        financing_items = [
            {
                "offer_id": fin.offer_id,
                "months": fin.months,
                "apr": fin.apr,
                "monthly_payment": fin.monthly,
                "total_cost": fin.total_cost,
                "offer_type": "EP" if fin.offer_id.startswith("EP_") else "DI"
            }
            for fin in financing
        ]
        
        ui_cards.append({
            "type": "financing",
            "options": financing_items
        })
        
        return ui_cards
    
    def _get_disclosures(self, financing: List[FinancingOption]) -> List[str]:
        """
        Get disclosure list - always append carecredit_generic
        
        Args:
            financing: Financing options
            
        Returns:
            List of disclosure IDs
        """
        disclosures = ["carecredit_generic"]  # Always include
        
        # Add equal_payment_generic if EP options present
        if any(f.offer_id.startswith("EP_") for f in financing):
            disclosures.append("equal_payment_generic")
        
        # Add deferred_interest_generic if DI options present  
        if any(f.offer_id.startswith("DI_") for f in financing):
            disclosures.append("deferred_interest_generic")
        
        return disclosures

# Test cases for CareCredit scenarios  
def test_carecredit():
    """Test CareCredit with golden-path scenarios"""
    print("üß™ Testing CareCredit Treatment Translator")
    print("=" * 50)
    
    carecredit = CareCredit()
    
    test_cases = [
        {
            "name": "Dental cleaning estimate",
            "estimate_text": """
            Dental Estimate - City Dental Care
            
            D0120 | Periodic oral evaluation | $85.00
            D1110 | Prophylaxis - adult cleaning | $120.00
            D0274 | Bitewing X-rays (4 films) | $65.00
            
            Total: $270.00
            """,
            "location": "New York, NY",
            "insurance": {"deductible_left": 150.0, "coinsurance": 0.2},
            "expected_specialty": "dental",
            "expected_items": 3
        },
        {
            "name": "Dermatology procedure",
            "estimate_text": """
            Dermatology Treatment Estimate
            
            Mole removal procedure ........... $450.00
            Pathology examination ............ $125.00
            Follow-up visit .................. $85.00
            
            Estimated Total: $660.00
            """,
            "location": "Chicago, IL", 
            "insurance": None,
            "expected_specialty": "dermatology",
            "expected_items": 3
        },
        {
            "name": "Veterinary emergency",
            "estimate_text": """
            Pet Emergency Treatment
            
            Emergency exam: $150
            X-rays (2 views): $180
            Pain medication: $45
            
            Total due: $375
            """,
            "location": "Phoenix, AZ",
            "insurance": None,
            "expected_specialty": "veterinary", 
            "expected_items": 3
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            
            result = carecredit.process_estimate(
                estimate_text=case["estimate_text"],
                location=case["location"],
                insurance=case["insurance"]
            )
            
            # Validate response structure
            valid_structure = (
                isinstance(result, CreditResponse) and
                isinstance(result.line_items, list) and
                isinstance(result.providers, list) and
                isinstance(result.financing, list) and
                isinstance(result.oopp, OOPPResult) and
                isinstance(result.citations, list)
            )
            
            # Check line items parsing
            items_ok = len(result.line_items) >= case["expected_items"]
            
            # Check providers found
            providers_ok = len(result.providers) > 0
            
            # Check financing options
            financing_ok = len(result.financing) > 0
            
            # Check explanation generated
            explanation_ok = len(result.explanation) > 50
            
            # Check OOPP calculation
            oopp_ok = result.oopp.estimated_total > 0
            
            success = (valid_structure and items_ok and providers_ok and 
                      financing_ok and explanation_ok and oopp_ok)
            
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   Location: {case['location']}")
            print(f"   Line items parsed: {len(result.line_items)}")
            print(f"   Providers found: {len(result.providers)}")
            print(f"   Financing options: {len(result.financing)}")
            print(f"   Out-of-pocket estimate: ${result.oopp.estimated_total:.2f}")
            print(f"   Status: {status}")
            
            if success:
                passed += 1
            else:
                print(f"   Failure reasons:")
                if not valid_structure:
                    print(f"     - Invalid response structure")
                if not items_ok:
                    print(f"     - Insufficient line items parsed")
                if not providers_ok:
                    print(f"     - No providers found")
                if not financing_ok:
                    print(f"     - No financing options")
                if not explanation_ok:
                    print(f"     - Poor explanation generated")
                if not oopp_ok:
                    print(f"     - OOPP calculation failed")
            
            print()
            
        except Exception as e:
            print(f"   ‚ùå FAIL - Exception: {str(e)}")
            print()
    
    print(f"üìä CareCredit Test Results: {passed}/{total} tests passed")
    return passed == total

if __name__ == "__main__":
    test_carecredit()


================================================
FILE: app/agents/chat_agent.py
================================================
"""
Chat Agent for handling queries with RAG and optional Tavily fallback
"""

import os
import logging
from typing import Dict, Any, Optional

from tavily import TavilyClient

logger = logging.getLogger(__name__)

class ChatAgent:
    """
    Chat agent that processes queries using RAG pipeline with optional Tavily fallback
    """
    
    def __init__(self, rag_pipeline):
        """
        Initialize the chat agent.
        
        Args:
            rag_pipeline: The RAG pipeline instance
        """
        self.rag_pipeline = rag_pipeline
        self.tavily_client = None
        
        # Initialize Tavily client if enabled and API key is available
        if os.getenv("ALLOW_TAVILY", "false").lower() == "true":
            tavily_api_key = os.getenv("TAVILY_API_KEY")
            if tavily_api_key:
                try:
                    self.tavily_client = TavilyClient(api_key=tavily_api_key)
                    logger.info("Tavily client initialized successfully")
                except Exception as e:
                    logger.warning(f"Failed to initialize Tavily client: {e}")
            else:
                logger.warning("ALLOW_TAVILY is true but TAVILY_API_KEY not found")
    
    async def process_query(
        self, 
        query: str, 
        use_tavily: bool = False,
        confidence_threshold: float = 0.3
    ) -> Dict[str, Any]:
        """
        Process a query using RAG pipeline and optionally Tavily fallback.
        
        Args:
            query: The user's query
            use_tavily: Whether to use Tavily fallback if RAG results are poor
            confidence_threshold: Minimum confidence score for RAG results
            
        Returns:
            Dictionary containing response, sources, and metadata
        """
        try:
            logger.info(f"Processing query: {query}")
            
            # First, try RAG pipeline
            rag_result = await self.rag_pipeline.query(query)
            
            # Check if we should use Tavily fallback
            should_use_tavily = (
                use_tavily and 
                self.tavily_client and 
                self._should_fallback_to_tavily(rag_result, confidence_threshold)
            )
            
            if should_use_tavily:
                logger.info("RAG results below threshold, falling back to Tavily")
                tavily_result = await self._query_tavily(query)
                
                # Combine RAG and Tavily results
                return self._combine_results(rag_result, tavily_result)
            else:
                return {
                    **rag_result,
                    "used_tavily": False
                }
                
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            return {
                "response": f"I apologize, but I encountered an error while processing your query: {str(e)}",
                "sources": [],
                "used_tavily": False,
                "error": str(e)
            }
    
    def _should_fallback_to_tavily(self, rag_result: Dict[str, Any], threshold: float) -> bool:
        """
        Determine if we should fallback to Tavily based on RAG result quality.
        
        Args:
            rag_result: Result from RAG pipeline
            threshold: Confidence threshold
            
        Returns:
            True if should fallback to Tavily
        """
        # Check if we have few or no retrieved documents
        if rag_result.get("retrieved_documents", 0) == 0:
            return True
        
        # Check if response indicates lack of information
        response = rag_result.get("response", "").lower()
        fallback_indicators = [
            "i don't have information",
            "not available in the documents",
            "cannot find",
            "no information",
            "not mentioned in the documents"
        ]
        
        return any(indicator in response for indicator in fallback_indicators)
    
    async def _query_tavily(self, query: str) -> Dict[str, Any]:
        """
        Query Tavily for additional information.
        
        Args:
            query: The search query
            
        Returns:
            Dictionary with Tavily search results
        """
        try:
            logger.info(f"Querying Tavily for: {query}")
            
            # Search with Tavily
            search_result = self.tavily_client.search(
                query=query,
                search_depth="basic",
                max_results=3
            )
            
            # Extract relevant information
            tavily_sources = []
            tavily_content = []
            
            for result in search_result.get("results", []):
                title = result.get("title", "")
                url = result.get("url", "")
                content = result.get("content", "")
                
                if content:
                    tavily_sources.append(f"{title} - {url}")
                    tavily_content.append(content)
            
            # Create a summary response
            if tavily_content:
                combined_content = "\n\n".join(tavily_content[:2])  # Use top 2 results
                tavily_response = (
                    f"Based on web search results:\n\n{combined_content}\n\n"
                    f"Please note: This information comes from web search and may need verification."
                )
            else:
                tavily_response = "No additional information found through web search."
            
            return {
                "response": tavily_response,
                "sources": tavily_sources,
                "search_results_count": len(search_result.get("results", []))
            }
            
        except Exception as e:
            logger.error(f"Error querying Tavily: {e}")
            return {
                "response": "Unable to retrieve additional information from web search.",
                "sources": [],
                "search_results_count": 0,
                "error": str(e)
            }
    
    def _combine_results(self, rag_result: Dict[str, Any], tavily_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Combine RAG and Tavily results into a single response.
        
        Args:
            rag_result: Result from RAG pipeline
            tavily_result: Result from Tavily search
            
        Returns:
            Combined result dictionary
        """
        # Combine responses
        rag_response = rag_result.get("response", "")
        tavily_response = tavily_result.get("response", "")
        
        if rag_response and tavily_response:
            combined_response = (
                f"From knowledge base:\n{rag_response}\n\n"
                f"Additional information from web search:\n{tavily_response}"
            )
        elif tavily_response:
            combined_response = tavily_response
        else:
            combined_response = rag_response or "No information available."
        
        # Combine sources
        rag_sources = rag_result.get("sources", [])
        tavily_sources = tavily_result.get("sources", [])
        
        combined_sources = []
        if rag_sources:
            combined_sources.extend([f"KB: {source}" for source in rag_sources])
        if tavily_sources:
            combined_sources.extend([f"Web: {source}" for source in tavily_sources])
        
        return {
            "response": combined_response,
            "sources": combined_sources,
            "used_tavily": True,
            "rag_documents": rag_result.get("retrieved_documents", 0),
            "tavily_results": tavily_result.get("search_results_count", 0),
            "retrieval_method": "hybrid_with_web_fallback"
        }



================================================
FILE: app/agents/collections.py
================================================
"""
Collections & Hardship Advisor
Negotiation assistant that proposes compliant hardship plans
"""

import json
import logging
import math
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Literal
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat
from app.rag.core import retrieve
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Pydantic models for strict input/output schema enforcement
class CustomerState(BaseModel):
    balance: float
    apr: float
    bucket: Literal["current", "30", "60", "90", "120+"]
    income_monthly: Optional[float] = None
    expenses_monthly: Optional[float] = None
    preferences: Optional[dict] = None

class PaymentScheduleEntry(BaseModel):
    month: int
    payment: float
    interest: float
    principal: float
    balance: float

class PaymentPlan(BaseModel):
    plan_id: str
    name: str
    description: str
    monthly_payment: float
    duration_months: int
    total_paid: float
    payment_schedule: List[PaymentScheduleEntry]
    rationale: str
    score: float
    affordability_score: float
    bank_npv_score: float
    cure_probability_score: float

class CollectionsResponse(BaseModel):
    response: str  # top 2-3 options + why
    metadata: Dict[str, Any]  # ui_cards, disclosures, handoffs

class CollectionsAdvisor:
    """
    Collections & Hardship Advisor for proposing compliant hardship plans
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize CollectionsAdvisor with RAG components and rules loader"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        self.rules_loader = rules_loader
        
        # Load collections rules and policies
        self._load_collections_rules()
        self._load_hardship_policies()
    
    def _load_collections_rules(self):
        """Load collections rules from YAML"""
        try:
            if self.rules_loader:
                self.collections_rules = self.rules_loader.get_rules('collections') or {}
                logger.info("Loaded collections rules from rules_loader")
            else:
                self.collections_rules = {}
                logger.warning("No rules_loader provided - using defaults")
        except Exception as e:
            logger.error(f"Failed to load collections rules: {e}")
            self.collections_rules = {}
    
    def _load_hardship_policies(self):
        """Load hardship policies from JSON file"""
        try:
            policies_path = Path("app/data/hardship_policies.json")
            with open(policies_path, 'r') as f:
                self.policies = json.load(f)
            logger.info("Loaded hardship policies successfully")
        except Exception as e:
            logger.error(f"Failed to load hardship policies: {e}")
            self.policies = {}
    
    def policy_rules_load(self) -> Dict[str, Any]:
        """Load policy rules from hardship policies"""
        return self.policies
    
    def process_hardship_request(self, customer_state: CustomerState) -> CollectionsResponse:
        """
        Main processing pipeline: humane, policy-aware plans
        
        Args:
            customer_state: Customer's financial state and account information
            
        Returns:
            CollectionsResponse with top 2-3 options + rationale, UI cards, disclosures
        """
        try:
            logger.info(f"Processing hardship request for {customer_state.bucket} bucket, balance ${customer_state.balance:.2f}")
            
            # Step 1: Get plan menu from rules/collections.yml
            available_plans = self._get_plan_menu(customer_state)
            
            # Step 2: Simulate payment schedules with demo APR
            simulated_plans = self._simulate_payment_plans(available_plans, customer_state)
            
            # Step 3: Rank plans with weights (affordability, bank NPV, cure probability)
            ranked_plans = self._rank_payment_plans(simulated_plans, customer_state)
            
            # Step 4: Select top 2-3 options
            top_plans = ranked_plans[:3]
            
            # Step 5: Generate response with rationale
            response_text = self._generate_response_text(top_plans, customer_state)
            
            # Step 6: Build UI cards for metadata
            ui_cards = self._build_plan_ui_cards(top_plans)
            
            # Step 7: Include mandatory disclosures and handoffs
            disclosures = ["collections_generic"]
            handoffs = ["contracts"]  # for terms clarifications
            
            return CollectionsResponse(
                response=response_text,
                metadata={
                    "ui_cards": ui_cards,
                    "disclosures": disclosures,
                    "handoffs": handoffs,
                    "total_plans_evaluated": len(simulated_plans),
                    "customer_bucket": customer_state.bucket,
                    "balance": customer_state.balance
                }
            )
            
        except Exception as e:
            logger.error(f"Error processing hardship request: {e}")
            return CollectionsResponse(
                response=f"Error processing hardship request: {str(e)}",
                metadata={
                    "ui_cards": [],
                    "disclosures": ["collections_generic"],
                    "handoffs": [],
                    "error": str(e)
                }
            )
    
    def _get_plan_menu(self, customer_state: CustomerState) -> List[Dict[str, Any]]:
        """
        Get available plans from rules/collections.yml filtered by eligibility
        
        Args:
            customer_state: Customer financial information
            
        Returns:
            List of eligible payment plans
        """
        available_plans = []
        rules_plans = self.collections_rules.get("plans", {})
        
        for plan_id, plan_config in rules_plans.items():
            # Check eligibility
            eligibility = plan_config.get("eligibility", {})
            min_balance = eligibility.get("min_balance", 0)
            max_balance = eligibility.get("max_balance", float('inf'))
            
            if min_balance <= customer_state.balance <= max_balance:
                available_plans.append({
                    "plan_id": plan_id,
                    "config": plan_config
                })
                
        logger.info(f"Found {len(available_plans)} eligible plans for balance ${customer_state.balance}")
        return available_plans
    
    def _simulate_payment_plans(self, available_plans: List[Dict[str, Any]], customer_state: CustomerState) -> List[PaymentPlan]:
        """
        Simulate payment schedules with demo APR and compute totals
        
        Args:
            available_plans: List of eligible plans
            customer_state: Customer financial information
            
        Returns:
            List of simulated payment plans
        """
        simulated_plans = []
        sim_params = self.collections_rules.get("simulation_params", {})
        demo_apr = sim_params.get("demo_apr", 0.2399)  # 23.99%
        
        for plan_data in available_plans:
            plan_id = plan_data["plan_id"]
            config = plan_data["config"]
            
            # Calculate payment schedule based on plan type
            payment_schedule = self._calculate_payment_schedule(
                balance=customer_state.balance,
                apr=demo_apr,
                plan_config=config
            )
            
            # Calculate totals
            total_paid = sum(entry.payment for entry in payment_schedule)
            avg_monthly = total_paid / len(payment_schedule) if payment_schedule else 0
            
            plan = PaymentPlan(
                plan_id=plan_id,
                name=config.get("name", plan_id.replace("_", " ").title()),
                description=config.get("description", ""),
                monthly_payment=avg_monthly,
                duration_months=config.get("duration_months", 12),
                total_paid=total_paid,
                payment_schedule=payment_schedule,
                rationale="",  # Will be filled in ranking
                score=0.0,     # Will be calculated in ranking
                affordability_score=0.0,
                bank_npv_score=0.0,
                cure_probability_score=0.0
            )
            
            simulated_plans.append(plan)
        
        logger.info(f"Simulated {len(simulated_plans)} payment plans")
        return simulated_plans
    
    def _calculate_payment_schedule(self, balance: float, apr: float, plan_config: Dict[str, Any]) -> List[PaymentScheduleEntry]:
        """
        Calculate payment schedule based on plan type
        
        Args:
            balance: Outstanding balance
            apr: Annual percentage rate
            plan_config: Plan configuration from rules
            
        Returns:
            List of payment schedule entries
        """
        payment_schedule = []
        monthly_rate = apr / 12
        duration_months = plan_config.get("duration_months", 12)
        payment_type = plan_config.get("payment_type", "fixed")
        min_payment_percent = plan_config.get("min_payment_percent", 0.025)
        
        current_balance = balance
        
        for month in range(1, duration_months + 1):
            if payment_type == "interest_only":
                # Interest-only payments
                interest = current_balance * monthly_rate
                principal = 0
                payment = interest
                
            elif payment_type == "deferred":
                # Deferred payments - only interest accrues
                interest = current_balance * monthly_rate
                principal = 0
                payment = 0
                current_balance += interest  # Interest compounds
                
            elif payment_type == "reduced":
                # Reduced payments (minimum percent of balance)
                payment = max(current_balance * min_payment_percent, 25.0)  # Min $25
                interest = current_balance * monthly_rate
                principal = max(0, payment - interest)
                
            elif payment_type == "fixed":
                # Fixed payment plan to pay off balance
                if month == 1:
                    # Calculate fixed payment using amortization formula
                    if monthly_rate > 0:
                        fixed_payment = (balance * monthly_rate * (1 + monthly_rate) ** duration_months) / ((1 + monthly_rate) ** duration_months - 1)
                    else:
                        fixed_payment = balance / duration_months
                
                payment = fixed_payment
                interest = current_balance * monthly_rate
                principal = payment - interest
            
            else:
                # Default to minimum payment
                payment = current_balance * min_payment_percent
                interest = current_balance * monthly_rate
                principal = max(0, payment - interest)
            
            # Update balance
            current_balance = max(0, current_balance - principal)
            
            payment_schedule.append(PaymentScheduleEntry(
                month=month,
                payment=round(payment, 2),
                interest=round(interest, 2),
                principal=round(principal, 2),
                balance=round(current_balance, 2)
            ))
            
            # Break if balance is paid off
            if current_balance <= 0:
                break
        
        return payment_schedule
    
    def _rank_payment_plans(self, plans: List[PaymentPlan], customer_state: CustomerState) -> List[PaymentPlan]:
        """
        Rank plans using weighted scoring: affordability, bank NPV, cure probability
        
        Args:
            plans: List of simulated payment plans
            customer_state: Customer financial information
            
        Returns:
            List of ranked payment plans (highest score first)
        """
        weights = self.collections_rules.get("scoring", {}).get("weights", {})
        affordability_weight = weights.get("affordability", 0.4)
        bank_npv_weight = weights.get("bank_npv", 0.3)
        cure_probability_weight = weights.get("cure_probability", 0.3)
        
        for plan in plans:
            # Calculate affordability score (lower monthly payment = higher score)
            max_monthly = max(p.monthly_payment for p in plans) if plans else plan.monthly_payment
            plan.affordability_score = 1.0 - (plan.monthly_payment / max_monthly) if max_monthly > 0 else 1.0
            
            # Calculate bank NPV score (higher total paid = higher score for bank)
            max_total = max(p.total_paid for p in plans) if plans else plan.total_paid
            plan.bank_npv_score = plan.total_paid / max_total if max_total > 0 else 1.0
            
            # Calculate cure probability (shorter term + reasonable payment = higher score)
            duration_score = 1.0 - (plan.duration_months / 24.0)  # Prefer shorter terms
            payment_ratio = plan.monthly_payment / customer_state.balance if customer_state.balance > 0 else 0
            payment_reasonableness = 1.0 - min(payment_ratio, 0.1) / 0.1  # Reasonable if <10% of balance
            plan.cure_probability_score = (duration_score + payment_reasonableness) / 2
            
            # Calculate weighted total score
            plan.score = (
                plan.affordability_score * affordability_weight +
                plan.bank_npv_score * bank_npv_weight +
                plan.cure_probability_score * cure_probability_weight
            )
            
            # Generate rationale
            plan.rationale = self._generate_plan_rationale(plan, customer_state)
        
        # Sort by score (highest first)
        ranked_plans = sorted(plans, key=lambda p: p.score, reverse=True)
        logger.info(f"Ranked {len(ranked_plans)} plans, top score: {ranked_plans[0].score:.2f}")
        
        return ranked_plans
    
    def _generate_plan_rationale(self, plan: PaymentPlan, customer_state: CustomerState) -> str:
        """Generate rationale for why this plan is recommended"""
        rationale_parts = []
        
        if plan.affordability_score > 0.7:
            rationale_parts.append("Affordable monthly payments")
        elif plan.affordability_score > 0.4:
            rationale_parts.append("Moderate monthly payments")
        else:
            rationale_parts.append("Higher payments but faster resolution")
        
        if plan.duration_months <= 6:
            rationale_parts.append("short-term relief")
        elif plan.duration_months <= 12:
            rationale_parts.append("balanced timeline")
        else:
            rationale_parts.append("extended payment period")
        
        if customer_state.bucket in ["90", "120+"]:
            rationale_parts.append("suitable for delinquent accounts")
        
        return " ‚Ä¢ ".join(rationale_parts).capitalize()
    
    def _generate_response_text(self, top_plans: List[PaymentPlan], customer_state: CustomerState) -> str:
        """
        Generate response text with top 2-3 options + why
        
        Args:
            top_plans: Top ranked payment plans
            customer_state: Customer financial information
            
        Returns:
            Response text explaining the recommended options
        """
        response_parts = []
        
        # Header
        response_parts.append(f"**Payment Plan Options for ${customer_state.balance:,.2f} Balance**")
        response_parts.append(f"Account Status: {customer_state.bucket} days")
        response_parts.append("")
        
        # Top options
        for i, plan in enumerate(top_plans, 1):
            response_parts.append(f"**Option {i}: {plan.name}**")
            response_parts.append(f"‚Ä¢ Monthly Payment: ${plan.monthly_payment:.2f}")
            response_parts.append(f"‚Ä¢ Duration: {plan.duration_months} months")
            response_parts.append(f"‚Ä¢ Total Paid: ${plan.total_paid:,.2f}")
            response_parts.append(f"‚Ä¢ Why: {plan.rationale}")
            response_parts.append("")
        
        # Next steps
        response_parts.append("**Next Steps:**")
        response_parts.append("1. Review plan details with our specialist")
        response_parts.append("2. Provide income verification if required")
        response_parts.append("3. Set up automatic payments")
        response_parts.append("4. Contact us for terms clarification if needed")
        
        return "\n".join(response_parts)
    
    def _build_plan_ui_cards(self, plans: List[PaymentPlan]) -> List[Dict[str, Any]]:
        """
        Build UI cards for payment plans
        
        Args:
            plans: List of payment plans
            
        Returns:
            List of UI cards for metadata
        """
        ui_cards = []
        
        for plan in plans:
            # Build payment schedule summary (first 3 months + last month)
            schedule_summary = []
            for entry in plan.payment_schedule[:3]:
                schedule_summary.append({
                    "month": entry.month,
                    "payment": entry.payment,
                    "balance": entry.balance
                })
            
            if len(plan.payment_schedule) > 3:
                last_entry = plan.payment_schedule[-1]
                schedule_summary.append({
                    "month": last_entry.month,
                    "payment": last_entry.payment,
                    "balance": last_entry.balance
                })
            
            ui_cards.append({
                "type": "plan",
                "name": plan.name,
                "description": plan.description,
                "monthly_payment": plan.monthly_payment,
                "duration_months": plan.duration_months,
                "total_paid": plan.total_paid,
                "schedule": schedule_summary,
                "rationale": plan.rationale,
                "score": round(plan.score, 2),
                "affordability": round(plan.affordability_score, 2),
                "bank_npv": round(plan.bank_npv_score, 2),
                "cure_probability": round(plan.cure_probability_score, 2)
            })
        
        return ui_cards
    
    # Compatibility method for supervisor integration
    def process_query(self, query: str) -> Dict[str, Any]:
        """
        Process collections query for supervisor integration
        
        Args:
            query: User query about collections/hardship
            
        Returns:
            Dict with response, metadata, confidence, sources
        """
        try:
            # Extract balance and bucket from query (simplified)
            import re
            
            balance_match = re.search(r'\$?([\d,]+(?:\.\d{2})?)', query)
            balance = float(balance_match.group(1).replace(',', '')) if balance_match else 1000.0
            
            # Determine bucket based on query keywords
            if any(word in query.lower() for word in ['overdue', 'late', 'behind']):
                bucket = "90"
            elif any(word in query.lower() for word in ['current', 'up to date']):
                bucket = "current"
            else:
                bucket = "60"  # Default
            
            customer_state = CustomerState(
                balance=balance,
                apr=0.2399,  # Default APR
                bucket=bucket
            )
            
            result = self.process_hardship_request(customer_state)
            
            return {
                "response": result.response,
                "metadata": result.metadata,
                "confidence": 0.8,
                "sources": []
            }
            
        except Exception as e:
            logger.error(f"Collections process_query error: {e}")
            return {
                "response": f"Error processing collections query: {str(e)}",
                "confidence": 0.2,
                "sources": [],
                "metadata": {"error": str(e)}
            }



================================================
FILE: app/agents/contracts.py
================================================
"""
Merchant Onboarding & Contract Intelligence
Auto-ingest merchant agreements, extract key terms, generate operational checklists
"""

import json
import logging
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat
from app.rag.core import retrieve
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Pydantic models for strict input/output schema enforcement
class ContractSection(BaseModel):
    heading: str
    text: str
    page_span: str

class ChecklistItem(BaseModel):
    task: str
    owner: str
    due_in_days: int

class RiskFlag(BaseModel):
    severity: str  # low|med|high
    note: str

class Delta(BaseModel):
    field: str
    from_value: Any = None
    to_value: Any = None

class Citation(BaseModel):
    source: str
    snippet: str

class ContractResponse(BaseModel):
    summary: str
    extractions: Dict[str, Any]
    checklist: List[ChecklistItem]
    risk_flags: List[RiskFlag]
    deltas: List[Delta]
    citations: List[Citation]

class ContractIntelligence:
    """
    Merchant Onboarding & Contract Intelligence for automated contract analysis
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize ContractIntelligence with RAG components for terms retrieval"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        
        # Load contract ontology
        self._load_contract_ontology()
    
    def _load_contract_ontology(self):
        """Load contract ontology from knowledge base"""
        try:
            ontology_path = Path("app/kb/contract_ontology.md")
            if ontology_path.exists():
                self.ontology_doc = ontology_path.read_text()
                logger.info("Loaded contract ontology successfully")
            else:
                self.ontology_doc = ""
                logger.warning("Contract ontology not found")
        except Exception as e:
            logger.error(f"Failed to load contract ontology: {e}")
            self.ontology_doc = ""
    
    def process_contract(self, file_path: str, prev_version_path: Optional[str] = None) -> ContractResponse:
        """
        Main processing pipeline for contract analysis
        
        Args:
            file_path: Path to the contract file to analyze
            prev_version_path: Optional path to previous version for delta analysis
            
        Returns:
            ContractResponse with extractions, checklist, risk flags, and deltas
        """
        try:
            logger.info(f"Processing contract: {file_path}")
            
            # Step 1: Parse contract into sections
            sections = self.contract_parse(file_path)
            logger.info(f"Parsed {len(sections)} contract sections")
            
            # Step 2: Map sections to ontology using Gemini
            extractions = self.ontology_map(sections, self.ontology_doc)
            logger.info("Completed ontology mapping")
            
            # Step 3: Delta detection if previous version provided
            deltas = []
            if prev_version_path:
                prev_sections = self.contract_parse(prev_version_path)
                prev_extractions = self.ontology_map(prev_sections, self.ontology_doc)
                deltas = self.delta_detect(extractions, prev_extractions)
                logger.info(f"Detected {len(deltas)} deltas from previous version")
            
            # Step 4: Build operational checklist
            checklist = self._build_checklist(extractions)
            logger.info(f"Generated {len(checklist)} checklist items")
            
            # Step 5: Identify risk flags
            risk_flags = self._identify_risk_flags(extractions)
            logger.info(f"Identified {len(risk_flags)} risk flags")
            
            # Step 6: Get policy citations
            citations = self._get_contract_citations(extractions)
            
            # Step 7: Generate summary
            summary = self._generate_summary(extractions, risk_flags, deltas)
            
            return ContractResponse(
                summary=summary,
                extractions=extractions,
                checklist=checklist,
                risk_flags=risk_flags,
                deltas=deltas,
                citations=citations
            )
            
        except Exception as e:
            logger.error(f"Error processing contract: {e}")
            return ContractResponse(
                summary=f"Error processing contract: {str(e)}",
                extractions={},
                checklist=[],
                risk_flags=[],
                deltas=[],
                citations=[]
            )
    
    def contract_parse(self, path: str) -> List[ContractSection]:
        """
        Parse contract file into structured sections
        
        Args:
            path: Path to contract file (supports .md, .txt, and basic .pdf)
            
        Returns:
            List of ContractSection objects with heading, text, and page_span
        """
        try:
            file_path = Path(path)
            
            if not file_path.exists():
                logger.error(f"Contract file not found: {path}")
                return []
            
            # Read file content based on extension
            if file_path.suffix.lower() == '.pdf':
                # For PDF files, assume pre-extracted markdown version exists
                md_path = file_path.with_suffix('.md')
                if md_path.exists():
                    content = md_path.read_text(encoding='utf-8')
                    logger.info(f"Using pre-extracted markdown: {md_path}")
                else:
                    # Basic PDF text extraction (would use pdftotext in production)
                    logger.warning(f"PDF extraction not implemented, using placeholder for: {path}")
                    content = f"# Contract Document\n\nPDF content from {path} would be extracted here."
            else:
                content = file_path.read_text(encoding='utf-8')
            
            # Parse sections based on markdown headers and common contract patterns
            sections = []
            current_section = {"heading": "Preamble", "text": "", "page_span": "1"}
            
            lines = content.split('\n')
            for i, line in enumerate(lines):
                line = line.strip()
                
                # Detect section headers
                if self._is_section_header(line):
                    # Save previous section if it has content
                    if current_section["text"].strip():
                        sections.append(ContractSection(
                            heading=current_section["heading"],
                            text=current_section["text"].strip(),
                            page_span=current_section["page_span"]
                        ))
                    
                    # Start new section
                    current_section = {
                        "heading": self._clean_header(line),
                        "text": "",
                        "page_span": str((i // 50) + 1)  # Rough page estimation
                    }
                else:
                    # Add line to current section
                    if line:  # Skip empty lines
                        current_section["text"] += line + "\n"
            
            # Add final section
            if current_section["text"].strip():
                sections.append(ContractSection(
                    heading=current_section["heading"],
                    text=current_section["text"].strip(),
                    page_span=current_section["page_span"]
                ))
            
            logger.info(f"Parsed {len(sections)} sections from {path}")
            return sections
            
        except Exception as e:
            logger.error(f"Error parsing contract {path}: {e}")
            return []
    
    def _is_section_header(self, line: str) -> bool:
        """Detect if a line is a section header"""
        line = line.strip()
        
        # Markdown headers
        if line.startswith('#'):
            return True
        
        # Numbered sections
        if re.match(r'^\d+\.?\s+[A-Z]', line):
            return True
        
        # Article/Section patterns
        if re.match(r'^(ARTICLE|SECTION|SCHEDULE|APPENDIX|EXHIBIT)\s+[IVX\d]', line, re.IGNORECASE):
            return True
        
        # All caps headers (common in legal documents)
        if len(line) > 3 and line.isupper() and not re.search(r'[.!?]$', line):
            return True
        
        return False
    
    def _clean_header(self, line: str) -> str:
        """Clean and normalize section headers"""
        line = line.strip()
        
        # Remove markdown markers
        line = re.sub(r'^#+\s*', '', line)
        
        # Remove numbering
        line = re.sub(r'^\d+\.?\s*', '', line)
        
        # Remove article/section prefixes
        line = re.sub(r'^(ARTICLE|SECTION|SCHEDULE|APPENDIX|EXHIBIT)\s+[IVX\d]+\.?\s*', '', line, flags=re.IGNORECASE)
        
        return line.strip()
    
    def ontology_map(self, sections: List[ContractSection], ontology_doc: str) -> Dict[str, Any]:
        """
        Map contract sections to ontology using Gemini structured extraction
        
        Args:
            sections: Parsed contract sections
            ontology_doc: Contract ontology documentation
            
        Returns:
            Dictionary with extracted terms mapped to ontology categories
        """
        try:
            # Combine all section text for analysis
            full_text = "\n\n".join([f"## {section.heading}\n{section.text}" for section in sections])
            
            system_prompt = f"""You are a contract analysis expert. Extract key terms from the contract text according to the provided ontology.

ONTOLOGY REFERENCE:
{ontology_doc[:3000]}...

Extract information for these categories:
1. fees (setup_fees, monthly_fees, transaction_fees, volume_discounts, penalty_fees, termination_fees, payment_terms, fee_escalation)
2. sla (uptime_guarantee, response_times, resolution_times, processing_times, reporting_frequency, maintenance_windows, escalation_procedures, performance_penalties)
3. brand_usage (logo_usage_rights, trademark_usage, co_branding_requirements, marketing_approval, brand_guidelines, exclusivity_rights, attribution_requirements, usage_restrictions)
4. data_sharing (data_types_shared, data_retention_period, data_security_requirements, third_party_sharing, customer_consent_requirements, data_deletion_rights, compliance_standards, breach_notification)
5. security (security_certifications, encryption_requirements, access_controls, vulnerability_management, incident_response, audit_requirements, employee_screening, physical_security)
6. termination (termination_notice_period, termination_for_cause, termination_without_cause, data_return_obligations, transition_assistance, post_termination_restrictions, survival_clauses, termination_fees)
7. penalties (late_payment_penalties, performance_penalties, compliance_violations, data_breach_penalties, liquidated_damages, penalty_caps, cure_periods, escalating_penalties)
8. audit_rights (audit_frequency, audit_scope, audit_notice_period, audit_costs, audit_access_rights, third_party_audits, audit_remediation, audit_reporting)
9. marketing_obligations (marketing_spend_commitments, promotional_requirements, event_participation, content_creation, lead_generation, co_marketing_activities, marketing_performance_metrics, marketing_approval_process)

Return ONLY a JSON object with the extracted information. Use null for fields not found in the contract."""

            user_message = f"Extract key terms from this contract:\n\n{full_text[:8000]}"  # Limit for token constraints
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            # Parse Gemini response
            try:
                extractions = json.loads(response.strip())
                logger.info("Successfully extracted contract terms with Gemini")
                return extractions
            except json.JSONDecodeError:
                logger.warning("Gemini response not valid JSON, using fallback extraction")
                return self._fallback_extraction(sections)
                
        except Exception as e:
            logger.error(f"Error in ontology mapping: {e}")
            return self._fallback_extraction(sections)
    
    def _fallback_extraction(self, sections: List[ContractSection]) -> Dict[str, Any]:
        """Fallback extraction using regex patterns"""
        extractions = {
            "fees": {},
            "sla": {},
            "brand_usage": {},
            "data_sharing": {},
            "security": {},
            "termination": {},
            "penalties": {},
            "audit_rights": {},
            "marketing_obligations": {}
        }
        
        full_text = " ".join([section.text for section in sections])
        
        # Basic fee extraction
        fee_patterns = [
            (r'setup fee[:\s]+\$?([\d,]+)', 'setup_fees'),
            (r'monthly fee[:\s]+\$?([\d,]+)', 'monthly_fees'),
            (r'transaction fee[:\s]+(\d+\.?\d*%|\$[\d.]+)', 'transaction_fees'),
            (r'termination fee[:\s]+\$?([\d,]+)', 'termination_fees'),
            (r'net (\d+)', 'payment_terms')
        ]
        
        for pattern, field in fee_patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                extractions["fees"][field] = match.group(1)
        
        # Basic SLA extraction
        sla_patterns = [
            (r'(\d+\.?\d*)%\s+uptime', 'uptime_guarantee'),
            (r'response.*?(\d+)\s+(hours?|days?)', 'response_times'),
            (r'resolution.*?(\d+)\s+(hours?|days?)', 'resolution_times')
        ]
        
        for pattern, field in sla_patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                extractions["sla"][field] = f"{match.group(1)} {match.group(2) if len(match.groups()) > 1 else ''}"
        
        # Basic termination extraction
        termination_patterns = [
            (r'(\d+)\s+days?\s+notice', 'termination_notice_period'),
            (r'immediate termination', 'termination_for_cause')
        ]
        
        for pattern, field in termination_patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                if field == 'termination_for_cause':
                    extractions["termination"][field] = True
                else:
                    extractions["termination"][field] = match.group(1)
        
        return extractions
    
    def delta_detect(self, curr_extractions: Dict[str, Any], prev_extractions: Dict[str, Any]) -> List[Delta]:
        """
        Detect changes between current and previous contract extractions
        
        Args:
            curr_extractions: Current contract extractions
            prev_extractions: Previous contract extractions
            
        Returns:
            List of Delta objects representing changes
        """
        deltas = []
        
        try:
            # Compare each category
            for category in curr_extractions:
                if category not in prev_extractions:
                    # New category added
                    deltas.append(Delta(
                        field=category,
                        from_value=None,
                        to_value=curr_extractions[category]
                    ))
                    continue
                
                curr_cat = curr_extractions[category]
                prev_cat = prev_extractions[category]
                
                if isinstance(curr_cat, dict) and isinstance(prev_cat, dict):
                    # Compare fields within category
                    for field in curr_cat:
                        curr_val = curr_cat[field]
                        prev_val = prev_cat.get(field)
                        
                        if curr_val != prev_val:
                            deltas.append(Delta(
                                field=f"{category}.{field}",
                                from_value=prev_val,
                                to_value=curr_val
                            ))
                    
                    # Check for removed fields
                    for field in prev_cat:
                        if field not in curr_cat:
                            deltas.append(Delta(
                                field=f"{category}.{field}",
                                from_value=prev_cat[field],
                                to_value=None
                            ))
                
                elif curr_cat != prev_cat:
                    # Direct value comparison
                    deltas.append(Delta(
                        field=category,
                        from_value=prev_cat,
                        to_value=curr_cat
                    ))
            
            # Check for removed categories
            for category in prev_extractions:
                if category not in curr_extractions:
                    deltas.append(Delta(
                        field=category,
                        from_value=prev_extractions[category],
                        to_value=None
                    ))
            
            logger.info(f"Detected {len(deltas)} deltas between contract versions")
            return deltas
            
        except Exception as e:
            logger.error(f"Error in delta detection: {e}")
            return []
    
    def _build_checklist(self, extractions: Dict[str, Any]) -> List[ChecklistItem]:
        """Build operational checklist based on contract extractions"""
        checklist = []
        
        try:
            # Data sharing obligations
            if extractions.get("data_sharing", {}).get("data_types_shared"):
                checklist.append(ChecklistItem(
                    task="Implement data-share audit procedures",
                    owner="Risk",
                    due_in_days=30
                ))
                
                checklist.append(ChecklistItem(
                    task="Set up data retention and deletion processes",
                    owner="Operations",
                    due_in_days=45
                ))
            
            # Security requirements
            security = extractions.get("security", {})
            if security.get("security_certifications"):
                checklist.append(ChecklistItem(
                    task="Obtain required security certifications",
                    owner="Risk",
                    due_in_days=90
                ))
            
            if security.get("audit_requirements"):
                checklist.append(ChecklistItem(
                    task="Schedule security audit",
                    owner="Risk",
                    due_in_days=60
                ))
            
            # SLA monitoring
            sla = extractions.get("sla", {})
            if sla.get("uptime_guarantee") or sla.get("response_times"):
                checklist.append(ChecklistItem(
                    task="Set up SLA monitoring and alerting",
                    owner="Operations",
                    due_in_days=14
                ))
            
            # Brand usage compliance
            brand = extractions.get("brand_usage", {})
            if brand.get("marketing_approval"):
                checklist.append(ChecklistItem(
                    task="Establish marketing approval workflow",
                    owner="Marketing",
                    due_in_days=21
                ))
            
            if brand.get("brand_guidelines"):
                checklist.append(ChecklistItem(
                    task="Review and implement brand guidelines",
                    owner="Marketing",
                    due_in_days=14
                ))
            
            # Fee structure implementation
            fees = extractions.get("fees", {})
            if fees.get("setup_fees") or fees.get("monthly_fees"):
                checklist.append(ChecklistItem(
                    task="Configure billing system for fee structure",
                    owner="Finance",
                    due_in_days=30
                ))
            
            # Marketing obligations
            marketing = extractions.get("marketing_obligations", {})
            if marketing.get("marketing_spend_commitments"):
                checklist.append(ChecklistItem(
                    task="Plan marketing budget allocation",
                    owner="Marketing",
                    due_in_days=30
                ))
            
            if marketing.get("event_participation"):
                checklist.append(ChecklistItem(
                    task="Schedule required event participation",
                    owner="Marketing",
                    due_in_days=60
                ))
            
            # Termination procedures
            termination = extractions.get("termination", {})
            if termination.get("data_return_obligations"):
                checklist.append(ChecklistItem(
                    task="Document data return procedures",
                    owner="Legal",
                    due_in_days=45
                ))
            
            # Audit rights preparation
            audit = extractions.get("audit_rights", {})
            if audit.get("audit_frequency"):
                checklist.append(ChecklistItem(
                    task="Prepare audit documentation and procedures",
                    owner="Risk",
                    due_in_days=30
                ))
            
            logger.info(f"Generated {len(checklist)} checklist items")
            return checklist
            
        except Exception as e:
            logger.error(f"Error building checklist: {e}")
            return []
    
    def _identify_risk_flags(self, extractions: Dict[str, Any]) -> List[RiskFlag]:
        """Identify risk flags based on contract terms"""
        risk_flags = []
        
        try:
            # High risk: Uncapped penalties
            penalties = extractions.get("penalties", {})
            if penalties and not penalties.get("penalty_caps"):
                if any(penalties.get(key) for key in ["late_payment_penalties", "performance_penalties", "data_breach_penalties"]):
                    risk_flags.append(RiskFlag(
                        severity="high",
                        note="Uncapped penalties detected - unlimited liability exposure"
                    ))
            
            # High risk: Very high SLA requirements
            sla = extractions.get("sla", {})
            uptime = sla.get("uptime_guarantee", "")
            if isinstance(uptime, str) and "99.9" in uptime:
                risk_flags.append(RiskFlag(
                    severity="high",
                    note="Very high uptime SLA (>99.9%) - difficult to achieve"
                ))
            
            # Medium risk: Short termination notice
            termination = extractions.get("termination", {})
            notice_period = termination.get("termination_notice_period")
            if notice_period:
                try:
                    days = int(re.search(r'\d+', str(notice_period)).group())
                    if days < 30:
                        risk_flags.append(RiskFlag(
                            severity="high",
                            note=f"Short termination notice period ({days} days)"
                        ))
                    elif days < 90:
                        risk_flags.append(RiskFlag(
                            severity="med",
                            note=f"Moderate termination notice period ({days} days)"
                        ))
                except:
                    pass
            
            # Medium risk: Significant fees
            fees = extractions.get("fees", {})
            setup_fee = fees.get("setup_fees", "")
            if isinstance(setup_fee, str):
                try:
                    amount = int(re.sub(r'[^\d]', '', setup_fee))
                    if amount > 10000:
                        risk_flags.append(RiskFlag(
                            severity="med",
                            note=f"High setup fee (${amount:,})"
                        ))
                except:
                    pass
            
            # Medium risk: Broad audit rights
            audit = extractions.get("audit_rights", {})
            if audit.get("audit_frequency") and "annual" not in str(audit.get("audit_frequency", "")).lower():
                risk_flags.append(RiskFlag(
                    severity="med",
                    note="Frequent audit rights - operational burden"
                ))
            
            # High risk: Exclusive rights
            brand = extractions.get("brand_usage", {})
            if brand.get("exclusivity_rights"):
                risk_flags.append(RiskFlag(
                    severity="high",
                    note="Exclusive rights granted - limits future partnerships"
                ))
            
            # Medium risk: Complex data sharing
            data = extractions.get("data_sharing", {})
            if data.get("third_party_sharing") and data.get("compliance_standards"):
                risk_flags.append(RiskFlag(
                    severity="med",
                    note="Complex data sharing with compliance requirements"
                ))
            
            # Low risk: Standard terms
            if not risk_flags:
                risk_flags.append(RiskFlag(
                    severity="low",
                    note="Standard contract terms with typical risk profile"
                ))
            
            logger.info(f"Identified {len(risk_flags)} risk flags")
            return risk_flags
            
        except Exception as e:
            logger.error(f"Error identifying risk flags: {e}")
            return [RiskFlag(severity="med", note="Error in risk assessment")]
    
    def _get_contract_citations(self, extractions: Dict[str, Any]) -> List[Citation]:
        """Get contract policy citations from knowledge base with Tavily fallback"""
        citations = []
        
        if not all([self.retriever, self.embedder]):
            logger.warning("RAG components not available for contract citations")
            return citations
        
        try:
            # Create queries for key contract terms
            queries = []
            
            # Add queries based on extracted terms
            if extractions.get("audit_rights"):
                queries.append("audit rights contract terms")
            if extractions.get("sla"):
                queries.append("SLA days service level agreement")
            if extractions.get("data_sharing"):
                queries.append("data sharing reconciliation")
            
            # Default query if no specific terms
            if not queries:
                queries = ["contract terms merchant agreement"]
            
            # Retrieve relevant documents for each query
            for query in queries[:3]:  # Limit to 3 queries
                results = retrieve(self.retriever, self.embedder, query, k=2)
                
                for result in results:
                    citations.append(Citation(
                        source=result.get("filename", "Contract Policy"),
                        snippet=result.get("snippet", "")[:300] + "..."
                    ))
            
            # Tavily fallback if insufficient citations
            if len(citations) < 1:
                logger.info("Insufficient local contract citations, searching web...")
                try:
                    web_docs = web_search_into_docstore(
                        self.docstore,
                        self.embedder,
                        "contract audit rights SLA days reconciliation terms",
                        max_results=2
                    )
                    
                    # Re-retrieve after adding web content
                    if web_docs:
                        results = retrieve(self.retriever, self.embedder, 
                                         "contract terms audit SLA", k=2)
                        
                        for result in results:
                            citations.append(Citation(
                                source=result.get("filename", "Web Search"),
                                snippet=result.get("snippet", "")[:300] + "..."
                            ))
                            
                except Exception as e:
                    logger.warning(f"Web search for contract terms failed: {e}")
            
        except Exception as e:
            logger.error(f"Error retrieving contract citations: {e}")
        
        return citations
    
    def _generate_summary(self, extractions: Dict[str, Any], risk_flags: List[RiskFlag], 
                         deltas: List[Delta]) -> str:
        """Generate executive summary of contract analysis"""
        try:
            # Count non-empty categories
            populated_categories = sum(1 for cat in extractions.values() if cat)
            
            # Risk summary
            high_risks = len([r for r in risk_flags if r.severity == "high"])
            med_risks = len([r for r in risk_flags if r.severity == "med"])
            
            # Key terms summary
            key_terms = []
            
            fees = extractions.get("fees", {})
            if fees.get("setup_fees"):
                key_terms.append(f"Setup fee: {fees['setup_fees']}")
            if fees.get("monthly_fees"):
                key_terms.append(f"Monthly fee: {fees['monthly_fees']}")
            
            sla = extractions.get("sla", {})
            if sla.get("uptime_guarantee"):
                key_terms.append(f"Uptime SLA: {sla['uptime_guarantee']}")
            
            termination = extractions.get("termination", {})
            if termination.get("termination_notice_period"):
                key_terms.append(f"Termination notice: {termination['termination_notice_period']}")
            
            # Build summary
            summary_parts = [
                f"Contract analysis completed with {populated_categories} categories extracted."
            ]
            
            if key_terms:
                summary_parts.append(f"Key terms: {', '.join(key_terms[:3])}.")
            
            if high_risks > 0:
                summary_parts.append(f"‚ö†Ô∏è {high_risks} high-risk items require immediate attention.")
            elif med_risks > 0:
                summary_parts.append(f"üìã {med_risks} medium-risk items identified for review.")
            else:
                summary_parts.append("‚úÖ Standard risk profile with typical contract terms.")
            
            if deltas:
                summary_parts.append(f"üîÑ {len(deltas)} changes detected from previous version.")
            
            return " ".join(summary_parts)
            
        except Exception as e:
            logger.error(f"Error generating summary: {e}")
            return "Contract analysis completed with basic extraction."

# Test cases for contract scenarios
def test_contract_intelligence():
    """Test ContractIntelligence with golden-path scenarios"""
    print("üß™ Testing ContractIntelligence Golden Paths")
    print("=" * 50)
    
    intelligence = ContractIntelligence()
    
    test_cases = [
        {
            "name": "MD contract with audit rights ‚Üí checklist includes audit procedures",
            "file_path": "app/contracts/merchant_agreement.md",
            "expected_checklist_task": "audit",
            "expected_risk_flags": True
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            
            result = intelligence.process_contract(case["file_path"])
            
            # Validate response structure
            valid_structure = (
                hasattr(result, 'summary') and
                hasattr(result, 'extractions') and
                hasattr(result, 'checklist') and
                hasattr(result, 'risk_flags') and
                hasattr(result, 'deltas') and
                hasattr(result, 'citations')
            )
            
            # Check for expected checklist task
            checklist_ok = any(
                case["expected_checklist_task"].lower() in item.task.lower()
                for item in result.checklist
            )
            
            # Check for risk flags
            risk_flags_ok = len(result.risk_flags) > 0 if case["expected_risk_flags"] else True
            
            success = valid_structure and checklist_ok and risk_flags_ok
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   File: {case['file_path']}")
            print(f"   Extractions: {len(result.extractions)} categories")
            print(f"   Checklist: {len(result.checklist)} items")
            print(f"   Risk flags: {len(result.risk_flags)}")
            print(f"   Status: {status}")
            
            if success:
                passed += 1
            else:
                if not valid_structure:
                    print(f"   ‚ùå Invalid response structure")
                if not checklist_ok:
                    print(f"   ‚ùå Expected checklist task '{case['expected_checklist_task']}' not found")
                if not risk_flags_ok:
                    print(f"   ‚ùå Expected risk flags not found")
            
            print()
            
        except Exception as e:
            print(f"   ‚ùå FAIL - Exception: {e}")
            print()
    
    # Test delta detection with v1‚Üív2 penalty clause addition
    print("Testing Delta Detection: v1‚Üív2 penalty clause addition")
    print("-" * 50)
    
    try:
        # Create mock extractions for v1 and v2
        v1_extractions = {
            "fees": {"setup_fees": "$5000", "monthly_fees": "$1000"},
            "sla": {"uptime_guarantee": "99.5%"},
            "penalties": {}
        }
        
        v2_extractions = {
            "fees": {"setup_fees": "$5000", "monthly_fees": "$1000"},
            "sla": {"uptime_guarantee": "99.5%"},
            "penalties": {"late_payment_penalties": "5% per month", "penalty_caps": None}
        }
        
        deltas = intelligence.delta_detect(v2_extractions, v1_extractions)
        
        # Check if penalty clause delta is detected
        penalty_delta_found = any(
            "penalties" in delta.field and delta.to_value
            for delta in deltas
        )
        
        if penalty_delta_found:
            print("‚úÖ PASS - Penalty clause delta detected")
            print(f"   Deltas found: {len(deltas)}")
            for delta in deltas:
                print(f"   - {delta.field}: {delta.from_value} ‚Üí {delta.to_value}")
        else:
            print("‚ùå FAIL - Penalty clause delta not detected")
    
    except Exception as e:
        print(f"‚ùå FAIL - Delta detection test failed: {e}")
    
    print()
    print("=" * 50)
    print(f"üìä Test Results: {passed}/{total} passed")
    
    return passed == total


def main():
    """Main function for testing and demonstration"""
    print("üîç Contract Intelligence Agent")
    print("=" * 50)
    print("Analyzing merchant agreements and extracting key terms...")
    print()
    
    # Run tests
    success = test_contract_intelligence()
    
    if success:
        print("üéâ All tests passed! Contract Intelligence is working correctly.")
    else:
        print("‚ö†Ô∏è Some tests failed. Please review the implementation.")
    
    # Example usage
    print("\nüí° Example Usage:")
    print("-" * 20)
    print("from app.agents.contracts import ContractIntelligence")
    print("intelligence = ContractIntelligence(docstore, embedder, retriever)")
    print("result = intelligence.process_contract('path/to/contract.md')")
    print("print(result.summary)")
    print("for item in result.checklist:")
    print("    print(f'- {item.task} ({item.owner}, {item.due_in_days} days)')")


if __name__ == "__main__":
    main()



================================================
FILE: app/agents/contracts_enhanced.py
================================================
"""
Contract Intelligence - Hybrid Rules + LLM Approach
First applies rules-based clause extraction from contracts_lexicon.yml,
then falls back to LLM + Tavily web search for insufficient results
"""

import re
import logging
from typing import Dict, List, Any, Optional, Tuple

from pydantic import BaseModel

from app.llm.gemini import chat
from app.rag.core import retrieve
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Enhanced Pydantic models for systematic clause extraction
class ClauseChip(BaseModel):
    name: str  # apr, promotional_terms, late_fees, etc.
    snippet: str  # captured sentence/paragraph
    start: int  # character offset start
    end: int  # character offset end
    flags: List[str] = []  # risk flags

class RiskFlag(BaseModel):
    type: str  # missing_clause, conflicting_numbers, promo_ambiguity
    description: str
    severity: str  # low, medium, high
    clause_type: Optional[str] = None

class ContractResponse(BaseModel):
    response: str  # Plain English answer with 1-2 clause cites
    metadata: Dict[str, Any]  # Contains ui_cards, handoffs, risk_flags

class ContractIntelligence:
    """
    Hybrid Contract Intelligence: Rules-first, then LLM+Tavily fallback
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize ContractIntelligence with RAG components and rules-based processing"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        self.rules_loader = rules_loader
        
        # Load contract rules from centralized loader or use defaults
        if rules_loader:
            self.contract_rules = rules_loader.get_rules('contracts_lexicon') or {}
            logger.info("ContractIntelligence loaded rules from centralized rules loader")
        else:
            self.contract_rules = self._load_fallback_rules()
        
        # Extract rule components
        self.clauses = self.contract_rules.get("clauses", {})
        self.risk_flags = self.contract_rules.get("risk_flags", {})
        self.ask_legal_triggers = self.contract_rules.get("ask_legal_triggers", [])
        
    def _load_fallback_rules(self) -> Dict[str, Any]:
        """Fallback rules if centralized loader not available"""
        return {
            "clauses": {
                "apr": {"keywords": ["APR", "annual percentage", "interest rate", "finance charge"]},
                "promotional_terms": {"keywords": ["equal payment", "deferred interest", "paid in full", "promo period", "no interest"]},
                "late_fees": {"keywords": ["late fee", "returned payment", "penalty", "grace period"]},
                "dispute_resolution": {"keywords": ["arbitration", "binding", "small claims", "waiver", "class action"]},
                "data_sharing": {"keywords": ["share", "third party", "marketing partners", "opt out", "sell"]}
            },
            "risk_flags": {
                "missing_clause": "Key clause not found",
                "conflicting_numbers": "Conflicting numerical terms detected", 
                "promo_ambiguity": "Promotional wording lacks 'paid in full' condition"
            },
            "ask_legal_triggers": ["conflicting_numbers", "promo_ambiguity", "missing_clause"]
        }
    
    def analyze_contract(self, contract_text: str, question: Optional[str] = None) -> ContractResponse:
        """
        Hybrid analysis: Rules-first, then LLM+Tavily fallback
        
        Args:
            contract_text: The contract document text
            question: Specific question about the contract (optional)
            
        Returns:
            ContractResponse with plain English answer, clause chips, and handoffs
        """
        try:
            logger.info(f"Starting hybrid contract analysis: {len(contract_text)} chars")
            
            # PHASE 1: Rules-based extraction
            clause_chips = self._extract_clauses(contract_text)
            risk_flags = self._analyze_risks(clause_chips, contract_text)
            
            logger.info(f"Rules phase: {len(clause_chips)} clauses, {len(risk_flags)} risks")
            
            # PHASE 2: Check if rules results are sufficient
            is_sufficient = self._assess_sufficiency(clause_chips, question)
            
            # PHASE 3: LLM+Tavily fallback if insufficient
            llm_response = ""
            citations = []
            
            if not is_sufficient:
                logger.info("Rules insufficient, using LLM+Tavily fallback")
                llm_response, additional_chips, citations = self._llm_fallback(
                    contract_text, question, clause_chips
                )
                clause_chips.extend(additional_chips)
            
            # PHASE 4: Generate response
            if question:
                response_text = self._answer_question(question, clause_chips, llm_response)
            else:
                response_text = self._generate_summary(clause_chips, risk_flags, llm_response)
            
            # PHASE 5: Detect handoffs
            handoffs = self._detect_handoffs(question, risk_flags, clause_chips)
            needs_legal_review = self._check_legal_triggers(risk_flags)
            
            return ContractResponse(
                response=response_text,
                metadata={
                    "ui_cards": [chip.model_dump() for chip in clause_chips],
                    "handoffs": handoffs,
                    "risk_flags": [flag.model_dump() for flag in risk_flags],
                    "needs_legal_review": needs_legal_review,
                    "method_used": "hybrid" if not is_sufficient else "rules_only",
                    "citations": [{"source": c.get("source", ""), "snippet": c.get("snippet", "")} for c in citations]
                }
            )
            
        except Exception as e:
            logger.error(f"Contract analysis error: {e}")
            return ContractResponse(
                response="Contract analysis failed. Please try again or contact support.",
                metadata={"error": str(e), "ui_cards": [], "handoffs": [], "risk_flags": []}
            )
    
    def _extract_clauses(self, contract_text: str) -> List[ClauseChip]:
        """Extract clauses using keywords from contracts_lexicon.yml with precise locations"""
        clause_chips = []
        
        for clause_name, clause_config in self.clauses.items():
            keywords = clause_config.get("keywords", [])
            
            # Find keyword matches in text
            for keyword in keywords:
                # Case-insensitive search for keyword
                pattern = re.compile(re.escape(keyword), re.IGNORECASE)
                
                for match in pattern.finditer(contract_text):
                    # Capture surrounding context (sentence or paragraph)
                    snippet, start, end = self._capture_context(contract_text, match.start(), match.end())
                    
                    # Check for duplicates (same clause type in similar location)
                    if not self._is_duplicate_clause(clause_chips, clause_name, start, end):
                        clause_chip = ClauseChip(
                            name=clause_name,
                            snippet=snippet,
                            start=start,
                            end=end,
                            flags=[]
                        )
                        clause_chips.append(clause_chip)
        
        return clause_chips
    
    def _capture_context(self, text: str, keyword_start: int, keyword_end: int) -> Tuple[str, int, int]:
        """Capture nearest sentence/paragraph around keyword with char offsets"""
        
        # Find sentence boundaries around the keyword
        sentence_start = keyword_start
        sentence_end = keyword_end
        
        # Look backward for sentence start (period, exclamation, or start of text)
        for i in range(keyword_start - 1, max(0, keyword_start - 500), -1):
            if text[i] in '.!?\n' and i > 0:
                sentence_start = i + 1
                break
            elif i == 0:
                sentence_start = 0
                break
        
        # Look forward for sentence end (period, exclamation, or end of text)
        for i in range(keyword_end, min(len(text), keyword_end + 500)):
            if text[i] in '.!?\n':
                sentence_end = i + 1
                break
            elif i == len(text) - 1:
                sentence_end = len(text)
                break
        
        # If sentence is too short, expand to paragraph
        snippet = text[sentence_start:sentence_end].strip()
        if len(snippet) < 50:
            # Expand to paragraph (double newline or larger context)
            para_start = max(0, keyword_start - 200)
            para_end = min(len(text), keyword_end + 200)
            
            # Look for natural paragraph breaks
            for i in range(keyword_start - 1, para_start, -1):
                if text[i:i+2] == '\n\n':
                    para_start = i + 2
                    break
            
            for i in range(keyword_end, para_end):
                if text[i:i+2] == '\n\n':
                    para_end = i
                    break
            
            snippet = text[para_start:para_end].strip()
            sentence_start = para_start
            sentence_end = para_end
        
        return snippet, sentence_start, sentence_end
    
    def _is_duplicate_clause(self, existing_chips: List[ClauseChip], clause_name: str, 
                           start: int, end: int) -> bool:
        """Check if clause already captured in similar location"""
        for chip in existing_chips:
            if (chip.name == clause_name and 
                abs(chip.start - start) < 100):  # Within 100 chars
                return True
        return False
    
    def _analyze_risks(self, clause_chips: List[ClauseChip], contract_text: str) -> List[RiskFlag]:
        """Analyze risks: missing_clause, conflicting_numbers, promo_ambiguity"""
        risk_flags = []
        
        # Check for missing clauses
        expected_clauses = set(self.clauses.keys())
        found_clauses = set(chip.name for chip in clause_chips)
        missing_clauses = expected_clauses - found_clauses
        
        for missing in missing_clauses:
            risk_flags.append(RiskFlag(
                type="missing_clause",
                description=f"Missing {missing.replace('_', ' ')} clause",
                severity="medium",
                clause_type=missing
            ))
        
        # Check for conflicting numbers
        numbers_by_clause = {}
        for chip in clause_chips:
            numbers = re.findall(r'(\d+(?:\.\d+)?%?)', chip.snippet)
            if numbers:
                if chip.name not in numbers_by_clause:
                    numbers_by_clause[chip.name] = []
                numbers_by_clause[chip.name].extend(numbers)
        
        for clause_name, numbers in numbers_by_clause.items():
            unique_numbers = set(numbers)
            if len(unique_numbers) > 1 and clause_name in ['apr', 'late_fees']:
                risk_flags.append(RiskFlag(
                    type="conflicting_numbers",
                    description=f"Multiple different {clause_name} values found: {', '.join(unique_numbers)}",
                    severity="high",
                    clause_type=clause_name
                ))
        
        # Check for promotional ambiguity
        promo_chips = [chip for chip in clause_chips if chip.name == "promotional_terms"]
        for chip in promo_chips:
            snippet_lower = chip.snippet.lower()
            if ("deferred interest" in snippet_lower or "no interest" in snippet_lower):
                if "paid in full" not in snippet_lower:
                    risk_flags.append(RiskFlag(
                        type="promo_ambiguity",
                        description="Promotional terms lack 'paid in full' condition clarity",
                        severity="medium",
                        clause_type="promotional_terms"
                    ))
                    # Add flag to the clause chip
                    chip.flags.append("promo_ambiguity")
        
        return risk_flags
    
    def _check_legal_triggers(self, risk_flags: List[RiskFlag]) -> bool:
        """Check if any risk flags trigger legal review"""
        risk_types = [flag.type for flag in risk_flags]
        return any(trigger in risk_types for trigger in self.ask_legal_triggers)
    
    def _assess_sufficiency(self, clause_chips: List[ClauseChip], question: Optional[str]) -> bool:
        """Determine if rules-based results are sufficient"""
        # If specific question asked, check if we have relevant clauses
        if question:
            question_lower = question.lower()
            relevant_found = False
            
            # Check for question-relevant clauses
            if any(word in question_lower for word in ["apr", "interest", "rate"]):
                relevant_found = any(chip.name == "apr" for chip in clause_chips)
            elif any(word in question_lower for word in ["late", "fee", "penalty"]):
                relevant_found = any(chip.name == "late_fees" for chip in clause_chips)
            elif any(word in question_lower for word in ["promo", "promotional", "deferred"]):
                relevant_found = any(chip.name == "promotional_terms" for chip in clause_chips)
            elif any(word in question_lower for word in ["dispute", "arbitration"]):
                relevant_found = any(chip.name == "dispute_resolution" for chip in clause_chips)
            elif any(word in question_lower for word in ["data", "sharing", "privacy"]):
                relevant_found = any(chip.name == "data_sharing" for chip in clause_chips)
            else:
                # Generic question - sufficient if we have any clauses
                relevant_found = len(clause_chips) >= 2
            
            return relevant_found
        
        # For general analysis, sufficient if we found most expected clauses
        expected_clauses = len(self.clauses)
        found_clauses = len(set(chip.name for chip in clause_chips))
        
        return found_clauses >= (expected_clauses * 0.6)  # 60% threshold
    
    def _llm_fallback(self, contract_text: str, question: Optional[str], 
                     existing_chips: List[ClauseChip]) -> Tuple[str, List[ClauseChip], List[Dict]]:
        """Phase 2: LLM+Tavily fallback for insufficient results"""
        
        # Build context from existing rules results
        context = f"Rules-based analysis found {len(existing_chips)} clauses: "
        context += ", ".join(set(chip.name for chip in existing_chips))
        
        # LLM analysis with structured prompt
        if question:
            system_prompt = f"""You are a contract analysis expert. The initial rules-based analysis was insufficient.

CONTEXT: {context}

Answer the specific question about this contract. Focus on finding information not captured by the rules.
Provide specific quotes from the contract with location context.
If you cannot find the answer in the contract, say so clearly."""

            user_message = f"Question: {question}\n\nContract text:\n{contract_text[:6000]}"
        else:
            system_prompt = f"""You are a contract analysis expert. The initial rules-based analysis was insufficient.

CONTEXT: {context}

Analyze this contract for key terms not captured by basic keyword matching.
Look for: complex fee structures, SLA terms, termination conditions, liability clauses, warranties.
Provide specific quotes and explain their significance."""

            user_message = f"Analyze this contract:\n\n{contract_text[:6000]}"
        
        try:
            messages = [{"role": "user", "content": user_message}]
            llm_response = chat(messages, system=system_prompt)
            logger.info("LLM analysis completed")
            
        except Exception as e:
            logger.error(f"LLM analysis failed: {e}")
            llm_response = "LLM analysis unavailable"
        
        # Try to get additional context from RAG + Tavily
        citations = []
        additional_chips = []
        
        if self.retriever and self.embedder:
            try:
                # RAG search for contract terms
                query = question if question else "contract terms analysis"
                rag_results = retrieve(self.retriever, self.embedder, query, k=2)
                
                for result in rag_results:
                    citations.append({
                        "source": result.get("filename", "Knowledge Base"),
                        "snippet": result.get("snippet", "")[:200]
                    })
                
                # Tavily web search fallback
                if len(citations) < 2 and self.docstore:
                    try:
                        web_query = f"contract {question}" if question else "contract analysis terms"
                        web_docs = web_search_into_docstore(
                            self.docstore, self.embedder, web_query, max_results=2
                        )
                        
                        if web_docs:
                            web_results = retrieve(self.retriever, self.embedder, query, k=2)
                            for result in web_results:
                                citations.append({
                                    "source": result.get("filename", "Web Search"),
                                    "snippet": result.get("snippet", "")[:200]
                                })
                        
                    except Exception as e:
                        logger.warning(f"Tavily search failed: {e}")
                
            except Exception as e:
                logger.error(f"RAG search failed: {e}")
        
        return llm_response, additional_chips, citations

    def _answer_question(self, question: str, clause_chips: List[ClauseChip], 
                        llm_response: str) -> str:
        """Answer specific question with 1-2 clause citations"""
        question_lower = question.lower()
        
        # Find most relevant clauses based on question keywords
        relevant_chips = []
        relevance_scores = {}
        
        for chip in clause_chips:
            score = 0
            chip_text = chip.snippet.lower()
            
            # Score based on keyword overlap
            question_words = set(question_lower.split())
            chip_words = set(chip_text.split())
            common_words = question_words & chip_words
            score += len(common_words) * 2
            
            # Score based on clause type relevance
            if chip.name in question_lower:
                score += 5
            
            # Specific question patterns
            if "apr" in question_lower or "interest" in question_lower:
                if chip.name == "apr":
                    score += 10
            if "late" in question_lower or "fee" in question_lower:
                if chip.name == "late_fees":
                    score += 10
            if "promo" in question_lower or "promotional" in question_lower:
                if chip.name == "promotional_terms":
                    score += 10
            
            if score > 0:
                relevance_scores[chip] = score
        
        # Sort by relevance and take top 2
        sorted_chips = sorted(relevance_scores.keys(), 
                            key=lambda x: relevance_scores[x], reverse=True)
        relevant_chips = sorted_chips[:2]
        
        if not relevant_chips and not llm_response:
            return f"No specific information found for: '{question}'. The contract may not contain relevant terms."
        
        # Build response
        response_parts = []
        
        if relevant_chips:
            response_parts.append("**Contract Analysis:**\n")
            for i, chip in enumerate(relevant_chips, 1):
                key_info = self._extract_key_info(chip)
                response_parts.append(f"{i}. **{chip.name.replace('_', ' ').title()}:** {key_info}")
                response_parts.append(f"   *\"...{chip.snippet[:150]}...\"*\n")
        
        if llm_response and llm_response != "LLM analysis unavailable":
            response_parts.append("**Additional Analysis:**")
            response_parts.append(llm_response[:500] + ("..." if len(llm_response) > 500 else ""))
        
        return "\n".join(response_parts)
    
    def _extract_key_info(self, chip: ClauseChip) -> str:
        """Extract key information from clause snippet"""
        snippet = chip.snippet
        
        if chip.name == "apr":
            # Extract APR percentage
            numbers = re.findall(r'(\d+(?:\.\d+)?%)', snippet)
            if numbers:
                return f"Interest rate of {numbers[0]} identified"
            else:
                return "Interest rate terms present but specific rate not clearly stated"
        
        elif chip.name == "late_fees":
            # Extract fee amounts
            fees = re.findall(r'\$(\d+(?:\.\d+)?)', snippet)
            if fees:
                return f"Late fee of ${fees[0]} specified"
            else:
                return "Late fee terms present"
        
        elif chip.name == "promotional_terms":
            # Check for specific promotional periods
            months = re.findall(r'(\d+)\s*months?', snippet, re.IGNORECASE)
            if months:
                return f"Promotional period of {months[0]} months identified"
            else:
                return "Promotional financing terms available"
        
        elif chip.name == "dispute_resolution":
            if "arbitration" in snippet.lower():
                return "Arbitration required for dispute resolution"
            else:
                return "Dispute resolution process specified"
        
        elif chip.name == "data_sharing":
            if "opt out" in snippet.lower():
                return "Data sharing with opt-out option available"
            else:
                return "Data sharing practices disclosed"
        
        return f"{chip.name.replace('_', ' ').title()} terms identified"
    
    def _generate_summary(self, clause_chips: List[ClauseChip], risk_flags: List[RiskFlag], 
                         llm_response: str) -> str:
        """Generate contract analysis summary"""
        clause_types = set(chip.name for chip in clause_chips)
        
        summary_parts = []
        summary_parts.append(f"**Contract Analysis:** {len(clause_chips)} clauses identified across {len(clause_types)} categories.")
        
        if clause_types:
            categories = [name.replace('_', ' ').title() for name in sorted(clause_types)]
            summary_parts.append(f"**Categories:** {', '.join(categories)}")
        
        if risk_flags:
            high_risks = [f for f in risk_flags if f.severity == "high"]
            if high_risks:
                summary_parts.append(f"‚ö†Ô∏è **{len(high_risks)} High-Risk Items** require attention")
            else:
                summary_parts.append(f"üìã **{len(risk_flags)} Risk Items** identified")
        
        if llm_response and llm_response != "LLM analysis unavailable":
            summary_parts.append("**Enhanced Analysis:** Additional LLM insights included")
        
        return "\n".join(summary_parts)
    
    def _detect_handoffs(self, question: Optional[str], risk_flags: List[RiskFlag], 
                        clause_chips: List[ClauseChip]) -> List[str]:
        """Detect handoffs: back to dispute (remedy path) or imagegen/offer for compliant copy"""
        handoffs = []
        
        # Check question content for handoff triggers
        if question:
            question_lower = question.lower()
            
            # Dispute handoff triggers
            dispute_terms = ["dispute", "remedy", "resolution", "complaint", "chargeback", "refund"]
            if any(term in question_lower for term in dispute_terms):
                handoffs.append("dispute")
            
            # Offer/marketing handoff triggers
            offer_terms = ["copy", "marketing", "compliant", "disclosure", "advertisement"]
            if any(term in question_lower for term in offer_terms):
                handoffs.append("offerpilot")
            
            # Image generation for compliant copy
            image_terms = ["visual", "image", "graphic", "banner", "design"]
            if any(term in question_lower for term in image_terms):
                handoffs.append("imagegen")
        
        # Risk-based handoffs
        high_risk_flags = [f for f in risk_flags if f.severity == "high"]
        if high_risk_flags:
            handoffs.append("dispute")  # High risk may lead to disputes
        
        # Promotional ambiguity may need offer clarification
        promo_flags = [f for f in risk_flags if f.type == "promo_ambiguity"]
        if promo_flags:
            handoffs.append("offerpilot")
        
        return list(set(handoffs))  # Remove duplicates

# Backwards compatibility - create alias for existing import
ContractIntelligence_Enhanced = ContractIntelligence


================================================
FILE: app/agents/devcopilot.py
================================================
"""
Developer & Partner API Copilot with Partner Enablement
Mini doc index, stepwise checklists, and test flows for real partner enablement
"""

import json
import logging
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Literal

from pydantic import BaseModel, Field

from app.llm.gemini import chat

logger = logging.getLogger(__name__)

# Pydantic models for partner enablement
class ChecklistStep(BaseModel):
    step: str
    description: str
    code_sample: Optional[str] = None
    test_payload: Optional[Dict[str, Any]] = None

class TestFlow(BaseModel):
    name: str
    description: str
    payload: Dict[str, Any]
    expected_response: Dict[str, Any]

class DocSnippet(BaseModel):
    source: str  # "doc#heading" format
    content: str

class DevCopilotResponse(BaseModel):
    response: str  # 3-5 step guide + what to try now
    metadata: Dict[str, Any]  # ui_cards with checklist/samples, sources

class DevCopilot:
    """
    Developer & Partner API Copilot with Partner Enablement
    Mini doc index, stepwise checklists, and test flows for real partner enablement
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize DevCopilot with RAG components and dev docs index"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        self.rules_loader = rules_loader
        
        # Load dev docs index from fixtures
        self.dev_docs_path = Path("synchrony-demo-rules-repo/fixtures/dev_docs")
        self.doc_index = self._load_doc_index()
        
        # Common integration patterns
        self.common_patterns = {
            "embed prequal": self._get_prequal_checklist,
            "receive dispute webhooks": self._get_webhook_checklist,
            "sandbox run": self._get_sandbox_checklist
        }
    
    def process_request(
        self, 
        query: str,
        context: Optional[Dict[str, Any]] = None
    ) -> DevCopilotResponse:
        """
        Main processing pipeline for partner enablement with stepwise guides
        
        Args:
            query: Partner's question or integration ask
            context: Optional context (partner_id, environment, etc.)
            
        Returns:
            DevCopilotResponse with 3-5 step guide and what to try now
        """
        try:
            logger.info(f"Processing DevCopilot request: {query}")
            
            # Step 1: Detect common integration patterns
            pattern = self._detect_pattern(query)
            
            if pattern:
                # Step 2: Generate stepwise checklist
                checklist = self.common_patterns[pattern]()
                
                # Step 3: Get relevant doc snippets
                doc_snippets = self._search_docs(query)
                
                # Step 4: Generate test flows
                test_flows = self._generate_test_flows(pattern)
                
                # Step 5: Build response
                response = self._build_guide_response(pattern, checklist, doc_snippets, test_flows)
                
                return response
            else:
                # General query - search docs and provide guidance
                return self._handle_general_query(query, context)
            
        except Exception as e:
            logger.error(f"Error processing DevCopilot request: {e}")
            return self._error_response(f"Error: {str(e)}")
    
    def _load_doc_index(self) -> Dict[str, Dict[str, str]]:
        """Load mini doc index from fixtures/dev_docs/*.md with anchored snippets"""
        doc_index = {}
        
        try:
            if not self.dev_docs_path.exists():
                logger.warning(f"Dev docs path not found: {self.dev_docs_path}")
                return doc_index
            
            for doc_file in self.dev_docs_path.glob("*.md"):
                doc_name = doc_file.stem
                content = doc_file.read_text(encoding='utf-8')
                
                # Parse headings for anchored snippets
                sections = {}
                current_heading = "main"
                current_content = []
                
                for line in content.split('\n'):
                    if line.startswith('#'):
                        # Save previous section
                        if current_content:
                            sections[current_heading] = '\n'.join(current_content).strip()
                        
                        # Start new section
                        current_heading = line.strip('#').strip().lower().replace(' ', '_')
                        current_content = []
                    else:
                        current_content.append(line)
                
                # Save final section
                if current_content:
                    sections[current_heading] = '\n'.join(current_content).strip()
                
                doc_index[doc_name] = sections
                logger.info(f"Loaded {len(sections)} sections from {doc_name}.md")
            
            return doc_index
            
        except Exception as e:
            logger.error(f"Error loading doc index: {e}")
            return {}
    
    def _detect_pattern(self, query: str) -> Optional[str]:
        """Detect common integration patterns from query"""
        query_lower = query.lower()
        
        # Pattern matching with keywords
        if any(word in query_lower for word in ['embed', 'widget', 'prequal', 'qualification']):
            return "embed prequal"
        elif any(word in query_lower for word in ['webhook', 'dispute', 'status', 'callback']):
            return "receive dispute webhooks"
        elif any(word in query_lower for word in ['sandbox', 'test', 'run', 'try']):
            return "sandbox run"
        
        return None
    
    def _get_prequal_checklist(self) -> List[ChecklistStep]:
        """Generate prequalification widget embed checklist"""
        return [
            ChecklistStep(
                step="1. Get Sandbox Keys",
                description="Request sandbox API keys from partner portal",
                code_sample="""
# Set your sandbox credentials
API_KEY = "sk_sandbox_..."
PARTNER_ID = "partner_123"
ENVIRONMENT = "sandbox"
                """.strip()
            ),
            ChecklistStep(
                step="2. Add Widget Script",
                description="Include prequalification widget script in your page",
                code_sample="""
<script src="https://widgets.sandbox.syncpay.com/prequal.js"></script>
<div id="prequal-widget"></div>
                """.strip(),
                test_payload={
                    "amount": 2500.00,
                    "partner_id": "partner_123",
                    "customer_context": {"zip": "10001"}
                }
            ),
            ChecklistStep(
                step="3. Initialize Widget",
                description="Initialize with amount and partner context",
                code_sample="""
SyncPay.Prequal.init({
    containerId: 'prequal-widget',
    amount: 2500.00,
    partnerId: 'partner_123',
    environment: 'sandbox',
    onStart: (data) => console.log('Started:', data),
    onComplete: (result) => handlePrequalResult(result)
});
                """.strip()
            ),
            ChecklistStep(
                step="4. Handle Callbacks",
                description="Store prequalification outcomes and display offers",
                code_sample="""
function handlePrequalResult(result) {
    if (result.approved) {
        // Display financing options
        showFinancingOffers(result.offers);
    } else {
        // Handle decline gracefully
        showAlternativeOptions();
    }
}
                """.strip(),
                test_payload={
                    "prequal_id": "pq_123",
                    "approved": True,
                    "offers": [{"term_months": 12, "apr": 0.0}]
                }
            )
        ]
    
    def _get_webhook_checklist(self) -> List[ChecklistStep]:
        """Generate dispute webhook handling checklist"""
        return [
            ChecklistStep(
                step="1. Set Webhook Endpoint",
                description="Configure your endpoint to receive dispute status updates",
                code_sample="""
# Example Flask endpoint
@app.route('/webhooks/dispute-status', methods=['POST'])
def handle_dispute_webhook():
    payload = request.get_json()
    
    # Verify webhook signature
    if not verify_webhook_signature(request.headers, payload):
        return 'Unauthorized', 401
    
    process_dispute_update(payload)
    return 'OK', 200
                """.strip()
            ),
            ChecklistStep(
                step="2. Handle Status Changes",
                description="Process dispute status transitions: intake‚Üícompiled‚Üíready_to_submit‚Üísubmitted‚Üíunder_review",
                code_sample="""
def process_dispute_update(payload):
    dispute_id = payload['dispute_id']
    status = payload['status']
    
    # Update dispute record
    dispute = Dispute.get(dispute_id)
    dispute.status = status
    dispute.save()
    
    # Trigger appropriate actions
    if status == 'ready_to_submit':
        notify_customer(dispute, 'ready_for_submission')
    elif status == 'under_review':
        notify_customer(dispute, 'being_reviewed')
                """.strip(),
                test_payload={
                    "dispute_id": "disp_123",
                    "status": "ready_to_submit",
                    "timestamp": "2024-01-01T12:00:00Z",
                    "merchant": "Urban Living Co",
                    "amount": 350.00
                }
            ),
            ChecklistStep(
                step="3. Implement Retry Logic",
                description="Handle failed webhooks with exponential backoff",
                code_sample="""
# Webhook retry configuration
WEBHOOK_RETRY_ATTEMPTS = 3
WEBHOOK_RETRY_DELAY = [1, 5, 15]  # seconds

def send_webhook_with_retry(url, payload):
    for attempt in range(WEBHOOK_RETRY_ATTEMPTS):
        try:
            response = requests.post(url, json=payload, timeout=10)
            if response.status_code == 200:
                return True
        except requests.RequestException:
            pass
        
        time.sleep(WEBHOOK_RETRY_DELAY[attempt])
    
    # Log failed webhook for manual processing
    log_failed_webhook(url, payload)
    return False
                """.strip()
            )
        ]
    
    def _get_sandbox_checklist(self) -> List[ChecklistStep]:
        """Generate sandbox testing checklist"""
        return [
            ChecklistStep(
                step="1. Switch to Sandbox Environment",
                description="Configure your app to use sandbox URLs and keys",
                code_sample="""
# Sandbox configuration
BASE_URL = "https://api.sandbox.syncpay.com"
API_KEY = "sk_sandbox_test_..."
WIDGET_URL = "https://widgets.sandbox.syncpay.com"

# Enable debug mode
DEBUG_MODE = True
LOG_LEVEL = "DEBUG"
                """.strip()
            ),
            ChecklistStep(
                step="2. Use Test Credit Profiles",
                description="Test with deterministic credit profiles for predictable results",
                test_payload={
                    "test_profiles": [
                        {"ssn_last4": "1111", "result": "approved", "max_amount": 5000},
                        {"ssn_last4": "2222", "result": "declined", "reason": "insufficient_credit"},
                        {"ssn_last4": "3333", "result": "manual_review", "timeline": "1-2 business days"}
                    ]
                }
            ),
            ChecklistStep(
                step="3. Test Key Flows",
                description="Run through critical integration paths",
                code_sample="""
# Test prequalification flow
test_prequal = {
    "amount": 1500.00,
    "customer": {"ssn_last4": "1111"},  # Always approves
    "partner_id": "partner_sandbox"
}

# Test dispute creation
test_dispute = {
    "merchant": "Test Merchant",
    "amount": 299.99,
    "reason": "duplicate_charge",
    "evidence": ["receipt.pdf"]
}

# Run automated tests
run_integration_tests()
                """.strip()
            ),
            ChecklistStep(
                step="4. Validate Webhook Delivery",
                description="Ensure webhooks are received correctly in sandbox",
                code_sample="""
# Test webhook endpoint using ngrok or similar
# 1. Start your local server
# 2. Expose with ngrok: ngrok http 3000
# 3. Configure webhook URL in sandbox dashboard
# 4. Trigger test events

# Webhook test payload
webhook_test = {
    "dispute_id": "disp_sandbox_123",
    "status": "compiled",
    "test_mode": True
}
                """.strip(),
                test_payload={
                    "webhook_url": "https://your-ngrok-url.ngrok.io/webhooks/test",
                    "test_events": ["dispute.status_changed", "prequal.completed"]
                }
            )
        ]
    
    def _search_docs(self, query: str) -> List[DocSnippet]:
        """Search doc index for relevant snippets"""
        query_lower = query.lower()
        relevant_snippets = []
        
        try:
            # Search through doc index
            for doc_name, sections in self.doc_index.items():
                for section_name, content in sections.items():
                    # Check if query terms appear in content
                    content_lower = content.lower()
                    
                    # Simple relevance scoring
                    score = 0
                    query_words = query_lower.split()
                    
                    for word in query_words:
                        if len(word) > 2:  # Skip short words
                            if word in content_lower:
                                score += content_lower.count(word)
                    
                    if score > 0:
                        relevant_snippets.append(DocSnippet(
                            source=f"{doc_name}.md#{section_name}",
                            content=content[:300] + "..." if len(content) > 300 else content
                        ))
            
            # Sort by relevance and return top 3
            return relevant_snippets[:3]
            
        except Exception as e:
            logger.error(f"Error searching docs: {e}")
            return []
    
    def _generate_test_flows(self, pattern: str) -> List[TestFlow]:
        """Generate deterministic test flows for pattern"""
        if pattern == "embed prequal":
            return [
                TestFlow(
                    name="Approved Prequalification",
                    description="Test with auto-approval profile",
                    payload={
                        "amount": 2500.00,
                        "customer": {"ssn_last4": "1111", "zip": "10001"},
                        "partner_id": "partner_sandbox"
                    },
                    expected_response={
                        "approved": True,
                        "prequal_id": "pq_approved_123",
                        "offers": [
                            {"term_months": 12, "apr": 0.0, "monthly_payment": 208.33},
                            {"term_months": 24, "apr": 9.99, "monthly_payment": 115.38}
                        ]
                    }
                ),
                TestFlow(
                    name="Declined Prequalification",
                    description="Test decline handling",
                    payload={
                        "amount": 2500.00,
                        "customer": {"ssn_last4": "2222", "zip": "10001"},
                        "partner_id": "partner_sandbox"
                    },
                    expected_response={
                        "approved": False,
                        "prequal_id": "pq_declined_123",
                        "reason": "insufficient_credit_history"
                    }
                )
            ]
        
        elif pattern == "receive dispute webhooks":
            return [
                TestFlow(
                    name="Dispute Status Update",
                    description="Test webhook delivery for status change",
                    payload={
                        "dispute_id": "disp_test_123",
                        "status": "ready_to_submit",
                        "previous_status": "compiled",
                        "timestamp": "2024-01-01T12:00:00Z",
                        "test_mode": True
                    },
                    expected_response={
                        "received": True,
                        "processed": True,
                        "next_action": "notify_customer"
                    }
                )
            ]
        
        elif pattern == "sandbox run":
            return [
                TestFlow(
                    name="Full Integration Test",
                    description="End-to-end sandbox test",
                    payload={
                        "test_scenario": "happy_path",
                        "prequal_amount": 1500.00,
                        "customer_profile": "approved",
                        "dispute_test": True
                    },
                    expected_response={
                        "prequal_passed": True,
                        "webhook_delivered": True,
                        "integration_score": "100%"
                    }
                )
            ]
        
        return []
    
    def _build_guide_response(
        self, 
        pattern: str, 
        checklist: List[ChecklistStep], 
        doc_snippets: List[DocSnippet],
        test_flows: List[TestFlow]
    ) -> DevCopilotResponse:
        """Build step-by-step guide response"""
        
        # Generate response text (3-5 step guide) with proper markdown formatting
        guide_steps = []
        for i, step in enumerate(checklist, 1):
            guide_steps.append(f"{i}. **{step.step}**: {step.description}")
        
        response_text = f"""# {pattern.title()} Integration Guide

{chr(10).join(guide_steps)}

## What to try now:

- Use the code samples in the checklist below
- Test with the provided payloads in sandbox mode  
- Check the documentation snippets for additional details
- Validate webhook delivery if applicable"""
        
        # Build metadata for UI cards
        ui_cards = []
        
        # Add checklist cards
        for step in checklist:
            card = {
                "type": "checklist",
                "title": step.step,
                "content": step.description
            }
            
            if step.code_sample:
                card["code_sample"] = step.code_sample
            
            if step.test_payload:
                card["test_payload"] = step.test_payload
            
            ui_cards.append(card)
        
        # Add test flow cards
        for flow in test_flows:
            ui_cards.append({
                "type": "test_flow",
                "title": flow.name,
                "description": flow.description,
                "payload": flow.payload,
                "expected_response": flow.expected_response
            })
        
        # Build sources from doc snippets
        sources = [snippet.source for snippet in doc_snippets]
        
        return DevCopilotResponse(
            response=response_text,
            metadata={
                "ui_cards": ui_cards,
                "sources": sources,
                "pattern": pattern,
                "test_flows": [flow.model_dump() for flow in test_flows],
                "doc_snippets": [snippet.model_dump() for snippet in doc_snippets]
            }
        )
    
    def _handle_general_query(self, query: str, context: Optional[Dict[str, Any]]) -> DevCopilotResponse:
        """Handle general queries not matching specific patterns"""
        
        # Search docs for relevant content
        doc_snippets = self._search_docs(query)
        
        # Use LLM to generate response if needed
        try:
            system_prompt = """You are a developer support specialist. Help partners integrate with our APIs.
            
            Provide a concise 3-5 step guide based on the documentation snippets.
            Focus on actionable steps and what to try next.
            
            Format your response using proper markdown:
            - Use # for main titles
            - Use ## for section headers  
            - Use numbered lists for steps
            - Use bullet points for recommendations
            - Include proper spacing between sections
            - Use **bold** for emphasis on key terms
            - Use code blocks with ``` for code samples"""
            
            context_text = ""
            if doc_snippets:
                context_text = "\n\nRelevant documentation:\n"
                for snippet in doc_snippets:
                    context_text += f"- {snippet.source}: {snippet.content}\n"
            
            user_message = f"Partner question: {query}{context_text}"
            messages = [{"role": "user", "content": user_message}]
            
            llm_response = chat(messages, system=system_prompt)
            
            # Build basic response
            return DevCopilotResponse(
                response=llm_response,
                metadata={
                    "ui_cards": [
                        {
                            "type": "general_help",
                            "title": "General Guidance",
                            "content": llm_response
                        }
                    ],
                    "sources": [snippet.source for snippet in doc_snippets],
                    "doc_snippets": [snippet.model_dump() for snippet in doc_snippets]
                }
            )
            
        except Exception as e:
            logger.error(f"Error with LLM response: {e}")
            
            # Fallback to doc-only response
            if doc_snippets:
                response_text = "# Based on the documentation:\n\n"
                for snippet in doc_snippets:
                    response_text += f"## {snippet.source}\n\n{snippet.content}\n\n"
            else:
                response_text = "I don't have specific documentation for that question. Please check the partner portal or contact support."
            
            return DevCopilotResponse(
                response=response_text,
                metadata={
                    "ui_cards": [],
                    "sources": [snippet.source for snippet in doc_snippets],
                    "doc_snippets": [snippet.model_dump() for snippet in doc_snippets]
                }
            )
    
    def _error_response(self, message: str) -> DevCopilotResponse:
        """Create error response"""
        return DevCopilotResponse(
            response=f"**Error:** {message}\n\nPlease try rephrasing your question or contact support.",
            metadata={
                "ui_cards": [
                    {
                        "type": "error",
                        "title": "Error",
                        "content": message
                    }
                ],
                "sources": [],
                "error": message
            }
        )

# Test cases for DevCopilot partner enablement scenarios
def test_devcopilot():
    """Test DevCopilot with partner enablement scenarios"""
    print("üß™ Testing DevCopilot Partner Enablement")
    print("=" * 50)
    
    copilot = DevCopilot()
    
    test_cases = [
        {
            "name": "Embed prequalification widget",
            "query": "How do I embed the prequalification widget on my checkout page?",
            "expected_pattern": "embed prequal",
            "expected_checklist_steps": 4
        },
        {
            "name": "Receive dispute webhooks",
            "query": "I need to handle dispute status webhooks in my app",
            "expected_pattern": "receive dispute webhooks",
            "expected_checklist_steps": 3
        },
        {
            "name": "Sandbox testing",
            "query": "How can I test my integration in the sandbox?",
            "expected_pattern": "sandbox run",
            "expected_checklist_steps": 4
        },
        {
            "name": "General query",
            "query": "What's the API rate limit?",
            "expected_pattern": None,
            "expected_checklist_steps": 0
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            
            result = copilot.process_request(case["query"])
            
            # Validate response structure
            valid_structure = (
                hasattr(result, 'response') and
                hasattr(result, 'metadata') and
                'ui_cards' in result.metadata and
                'sources' in result.metadata
            )
            
            # Check pattern detection
            detected_pattern = result.metadata.get('pattern')
            pattern_ok = detected_pattern == case['expected_pattern']
            
            # Check checklist steps
            ui_cards = result.metadata.get('ui_cards', [])
            checklist_cards = [card for card in ui_cards if card.get('type') == 'checklist']
            checklist_ok = len(checklist_cards) == case['expected_checklist_steps']
            
            # Check response content
            response_ok = len(result.response) > 50 and 'step' in result.response.lower()
            
            success = valid_structure and pattern_ok and checklist_ok and response_ok
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   Query: {case['query']}")
            print(f"   Pattern: {detected_pattern}")
            print(f"   Checklist Steps: {len(checklist_cards)}")
            print(f"   UI Cards: {len(ui_cards)}")
            print(f"   Sources: {len(result.metadata.get('sources', []))}")
            print(f"   Status: {status}")
            
            if success:
                passed += 1
            else:
                print(f"   Failure reasons:")
                if not valid_structure:
                    print(f"     - Invalid response structure")
                if not pattern_ok:
                    print(f"     - Pattern mismatch: expected {case['expected_pattern']}, got {detected_pattern}")
                if not checklist_ok:
                    print(f"     - Checklist steps: expected {case['expected_checklist_steps']}, got {len(checklist_cards)}")
                if not response_ok:
                    print(f"     - Response content issue")
            
            print()
            
        except Exception as e:
            print(f"   ‚ùå FAIL - Exception: {str(e)}")
            print()
    
    print(f"üìä Results: {passed}/{total} tests passed")
    return passed == total

if __name__ == "__main__":
    test_devcopilot()


================================================
FILE: app/agents/dispute.py
================================================
"""
Dispute & Benefits Copilot - Reg-E-like Packet Processing
Turns messy customer narratives + receipts into compliant dispute packets with category detection,
eligibility windows, evidence classification, and structured packet assembly
"""

import re
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat
from app.rag.core import retrieve
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Enhanced Pydantic models for Reg-E-like processing
class EvidenceItem(BaseModel):
    type: str  # merchant, date, amount, order_id, chat, etc.
    value: str
    confidence: float
    source: str  # narrative, uploaded_text, extracted

class TimelineEvent(BaseModel):
    date: str
    event: str
    source: str

class DisputeStatus(BaseModel):
    stage: str  # intake, compiled, ready_to_submit, submitted, under_review
    likelihood: str  # low, medium, high
    next_milestone: str
    eligible: bool
    eligibility_reason: str

class PacketPreview(BaseModel):
    category: str
    merchant: str
    amount: float
    timeline: List[TimelineEvent]
    evidence: List[EvidenceItem]
    next_update_date: str

class DisputeResponse(BaseModel):
    response: str  # Short human summary + "ready to submit" note
    metadata: Dict[str, Any]  # Contains status, ui_cards, handoffs

class DisputeCopilot:
    """
    Dispute & Benefits Copilot for Reg-E-like dispute packet processing with category detection,
    eligibility windows, evidence classification, and structured packet assembly
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize DisputeCopilot with RAG components and rules-based processing"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        self.rules_loader = rules_loader
        
        # Load dispute rules from centralized loader or use defaults
        if rules_loader:
            self.dispute_rules = rules_loader.get_rules('dispute') or {}
            logger.info("DisputeCopilot loaded rules from centralized rules loader")
        else:
            self.dispute_rules = self._load_fallback_rules()
        
        # Extract rule components
        self.categories = self.dispute_rules.get("categories", {})
        self.demo_clocks = self.dispute_rules.get("demo_clocks", {"posting_window_days": 60, "purchase_window_days": 90})
        self.status_pipeline = self.dispute_rules.get("status_pipeline", ["intake", "compiled", "ready_to_submit", "submitted", "under_review"])
        self.likelihood_buckets = self.dispute_rules.get("likelihood_buckets", ["low", "medium", "high"])
        
    def _load_fallback_rules(self) -> Dict[str, Any]:
        """Fallback rules if centralized loader not available"""
        return {
            "categories": {
                "duplicate_charge": {"required_evidence": ["statement_screenshot", "merchant_name", "date", "amount"]},
                "item_not_received": {"required_evidence": ["order_confirmation", "expected_delivery", "merchant_contact_attempt"]},
                "wrong_amount": {"required_evidence": ["receipt", "statement_screenshot", "correct_amount"]},
                "canceled_but_charged": {"required_evidence": ["cancellation_confirmation", "statement_screenshot"]}
            },
            "demo_clocks": {"posting_window_days": 60, "purchase_window_days": 90},
            "status_pipeline": ["intake", "compiled", "ready_to_submit", "submitted", "under_review"],
            "likelihood_buckets": ["low", "medium", "high"]
        }
    
    def process_dispute(self, narrative: str, merchant: Optional[str] = None, 
                       amount: Optional[float] = None, uploaded_text: Optional[str] = None) -> DisputeResponse:
        """
        Main processing pipeline for dispute cases
        
        Args:
            narrative: Customer's description of the dispute
            merchant: Merchant name (optional)
            amount: Disputed amount (optional)
            uploaded_text: Receipt or document text (optional)
            
        Returns:
            DisputeResponse with triage, resolution, packet, and citations
        """
        try:
            logger.info(f"Processing dispute: {narrative[:100]}...")
            
            # Step 1: Triage with Gemini
            triage_result = self._triage_dispute(narrative)
            logger.info(f"Dispute triaged as: {triage_result}")
            
            # Step 2: Extract receipt information if uploaded
            receipt_data = {}
            if uploaded_text:
                receipt_data = self.receipt_extract(uploaded_text)
                logger.info(f"Extracted receipt data: {receipt_data}")
            
            # Step 3: Merge user inputs with extracted data
            merged_data = self._merge_dispute_data(
                narrative, merchant, amount, receipt_data
            )
            
            # Step 4: Retrieve merchant policy citations
            citations = self._get_policy_citations(merged_data.get("merchant"), triage_result)
            
            # Step 5: Generate merchant resolution (unless fraud)
            merchant_resolution = None
            if triage_result != "fraud":
                merchant_resolution = self._generate_merchant_resolution(
                    triage_result, merged_data, citations
                )
            else:
                merchant_resolution = MerchantResolution(
                    message="For fraudulent transactions, contact your card issuer immediately. Do not attempt merchant resolution.",
                    checklist=["Report fraud immediately", "Request account freeze", "File police report if amount > $500"]
                )
            
            # Step 6: Compose formal dispute packet
            dispute_packet = self._compose_dispute_packet(
                triage_result, merged_data, citations
            )
            
            return DisputeResponse(
                triage=triage_result,
                merchant_resolution=merchant_resolution,
                packet=dispute_packet,
                citations=citations
            )
            
        except Exception as e:
            logger.error(f"Error processing dispute: {e}")
            # Return minimal response on error
            return DisputeResponse(
                triage="billing_error",
                merchant_resolution=MerchantResolution(
                    message="Please contact customer service for assistance with your dispute.",
                    checklist=["Gather transaction documentation", "Contact customer service"]
                ),
                packet=DisputePacket(
                    summary="System error occurred during dispute processing",
                    fields=DisputeFields(
                        merchant=merchant or "Unknown",
                        date=datetime.now().strftime("%Y-%m-%d"),
                        amount=amount or 0.0,
                        reason="System error"
                    ),
                    letter="Please contact customer service for assistance.",
                    attachments=[]
                ),
                citations=[]
            )
    
    def receipt_extract(self, text: str) -> Dict[str, Any]:
        """
        Extract receipt information using Gemini + regex fallback
        
        Args:
            text: Receipt text to extract from
            
        Returns:
            Dictionary with merchant, date, amount, and items
        """
        try:
            # Use Gemini for structured extraction
            system_prompt = """You are a receipt parser. Extract structured information from receipt text.

Return ONLY a JSON object with these fields:
{
  "merchant": "merchant name or null",
  "date": "YYYY-MM-DD format or null", 
  "amount": "total amount as float or null",
  "items": ["list of purchased items or empty array"]
}

Be precise and only extract information that is clearly present."""

            user_message = f"Extract information from this receipt:\n\n{text}"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            # Parse Gemini response
            try:
                extracted = json.loads(response.strip())
                logger.info("Successfully extracted receipt data with Gemini")
                return extracted
            except json.JSONDecodeError:
                logger.warning("Gemini response not valid JSON, falling back to regex")
                return self._regex_receipt_fallback(text)
                
        except Exception as e:
            logger.error(f"Error in receipt extraction: {e}")
            return self._regex_receipt_fallback(text)
    
    def _regex_receipt_fallback(self, text: str) -> Dict[str, Any]:
        """Regex-based fallback for receipt extraction"""
        result = {
            "merchant": None,
            "date": None,
            "amount": None,
            "items": []
        }
        
        # Extract merchant (usually first line or after common patterns)
        merchant_patterns = [
            r'^([A-Z][A-Za-z\s&]+)(?:\n|\r)',  # First line capitalized
            r'(?:MERCHANT|STORE|RETAILER):\s*([^\n\r]+)',
            r'^([A-Z\s]+(?:INC|LLC|CORP|CO))',  # Corporate suffixes
        ]
        
        for pattern in merchant_patterns:
            match = re.search(pattern, text, re.MULTILINE | re.IGNORECASE)
            if match:
                result["merchant"] = match.group(1).strip()
                break
        
        # Extract date
        date_patterns = [
            r'(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})',  # MM/DD/YYYY or MM-DD-YYYY
            r'(\d{4}[/-]\d{1,2}[/-]\d{1,2})',    # YYYY/MM/DD or YYYY-MM-DD
            r'((?:JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)\s+\d{1,2},?\s+\d{4})'  # Month DD, YYYY
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    # Try to parse and standardize date
                    date_str = match.group(1)
                    # Simple conversion - in production would use dateutil
                    if '/' in date_str or '-' in date_str:
                        result["date"] = date_str
                    break
                except:
                    continue
        
        # Extract total amount
        amount_patterns = [
            r'(?:TOTAL|AMOUNT|BALANCE):\s*\$?(\d+\.?\d*)',
            r'TOTAL\s+\$?(\d+\.?\d*)',
            r'\$(\d+\.\d{2})\s*(?:TOTAL|$)',
        ]
        
        for pattern in amount_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    result["amount"] = float(match.group(1))
                    break
                except ValueError:
                    continue
        
        # Extract items (simple line-based extraction)
        lines = text.split('\n')
        items = []
        for line in lines:
            line = line.strip()
            # Look for lines that might be items (have price patterns)
            if re.search(r'\$\d+\.?\d*', line) and len(line) > 5:
                # Clean up the line
                item = re.sub(r'\s*\$\d+\.?\d*.*$', '', line).strip()
                if item and len(item) > 2:
                    items.append(item)
        
        result["items"] = items[:10]  # Limit to 10 items
        
        return result
    
    def _triage_dispute(self, narrative: str) -> str:
        """
        Triage dispute using Gemini classification
        
        Args:
            narrative: Customer dispute narrative
            
        Returns:
            Dispute type: fraud, goods_not_received, or billing_error
        """
        try:
            system_prompt = """You are a dispute triage specialist. Classify customer disputes into one of these categories:

Categories:
- fraud: Unauthorized transactions, stolen card, identity theft
- goods_not_received: Items/services paid for but not delivered or provided
- billing_error: Duplicate charges, wrong amounts, mathematical errors

Respond with ONLY a JSON object:
{"category": "category_name", "confidence": 0.85, "reasoning": "brief explanation"}

Focus on the primary issue described by the customer."""

            user_message = f"Classify this dispute: '{narrative}'"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            result = json.loads(response.strip())
            category = result.get("category", "billing_error")
            
            # Validate category
            valid_categories = ["fraud", "goods_not_received", "billing_error"]
            if category not in valid_categories:
                logger.warning(f"Invalid category '{category}', defaulting to billing_error")
                category = "billing_error"
            
            return category
            
        except Exception as e:
            logger.error(f"Error in dispute triage: {e}")
            return "billing_error"  # Safe default
    
    def _merge_dispute_data(self, narrative: str, merchant: Optional[str], 
                           amount: Optional[float], receipt_data: Dict[str, Any]) -> Dict[str, Any]:
        """Merge user inputs with extracted receipt data"""
        merged = {
            "narrative": narrative,
            "merchant": merchant or receipt_data.get("merchant"),
            "amount": amount or receipt_data.get("amount"),
            "date": receipt_data.get("date"),
            "items": receipt_data.get("items", [])
        }
        
        # Clean up merchant name
        if merged["merchant"]:
            merged["merchant"] = merged["merchant"].strip().title()
        
        return merged
    
    def _get_policy_citations(self, merchant: Optional[str], dispute_type: str) -> List[Citation]:
        """
        Retrieve merchant policy citations from knowledge base
        
        Args:
            merchant: Merchant name
            dispute_type: Type of dispute
            
        Returns:
            List of policy citations
        """
        citations = []
        
        if not all([self.retriever, self.embedder]):
            logger.warning("RAG components not available for policy citations")
            return citations
        
        try:
            # Create query for dispute policies
            if merchant:
                query = f"{merchant} dispute policy {dispute_type}"
            else:
                query = f"card dispute documentation {dispute_type} required items"
            
            # Retrieve relevant policy documents
            results = retrieve(self.retriever, self.embedder, query, k=3)
            
            for result in results:
                citations.append(Citation(
                    source=result.get("filename", "Dispute Policy"),
                    snippet=result.get("snippet", "")[:300] + "..."
                ))
            
            # If no local citations found, search web for card dispute documentation
            if not citations:
                logger.info("No local dispute policies found, searching web...")
                try:
                    web_docs = web_search_into_docstore(
                        self.docstore,
                        self.embedder,
                        "card dispute documentation duplicate charge required items",
                        max_results=2
                    )
                    
                    # Re-retrieve after adding web content
                    if web_docs:
                        results = retrieve(self.retriever, self.embedder, 
                                         f"dispute {dispute_type} documentation", k=2)
                        
                        for result in results:
                            citations.append(Citation(
                                source=result.get("filename", "Web Search"),
                                snippet=result.get("snippet", "")[:300] + "..."
                            ))
                            
                except Exception as e:
                    logger.warning(f"Web search for dispute policies failed: {e}")
            
        except Exception as e:
            logger.error(f"Error retrieving policy citations: {e}")
        
        return citations
    
    def _generate_merchant_resolution(self, dispute_type: str, data: Dict[str, Any], 
                                    citations: List[Citation]) -> MerchantResolution:
        """Generate merchant resolution draft"""
        merchant = data.get("merchant", "the merchant")
        amount = data.get("amount", 0.0)
        
        if dispute_type == "billing_error":
            message = f"""Dear {merchant} Customer Service,

I am writing to request resolution of a billing error on my account. I have identified a discrepancy in my recent transaction that requires your immediate attention.

Transaction Details:
- Date: {data.get('date', 'Not specified')}
- Amount: ${amount:.2f}
- Issue: {data.get('narrative', 'Billing discrepancy')}

I have reviewed my records and believe this charge is incorrect. Please investigate this matter and provide a correction or refund as appropriate.

I would appreciate your prompt response within 5-7 business days. Please confirm the resolution in writing.

Thank you for your attention to this matter."""

            checklist = [
                "Contact merchant customer service within 2-3 business days",
                "Provide transaction details and explanation",
                "Request written confirmation of resolution",
                "Keep records of all communication",
                "Allow 5-7 business days for merchant response",
                "Escalate to supervisor if initial contact unsuccessful"
            ]
            
        elif dispute_type == "goods_not_received":
            message = f"""Dear {merchant} Customer Service,

I am writing regarding an order that I paid for but have not received. I need your assistance in resolving this delivery issue.

Order Details:
- Date of Purchase: {data.get('date', 'Not specified')}
- Amount Paid: ${amount:.2f}
- Items: {', '.join(data.get('items', ['Not specified']))}

Despite payment being processed, I have not received the goods/services. Please investigate the status of my order and provide either:
1. Immediate shipment with tracking information, or
2. Full refund of the purchase amount

I request resolution within 10-15 business days as per standard delivery expectations.

Please confirm your resolution plan in writing."""

            checklist = [
                "Contact merchant within 30 days of expected delivery",
                "Provide order confirmation and payment proof",
                "Request tracking information if applicable",
                "Ask for delivery timeline or refund",
                "Document all communication attempts",
                "Allow 10-15 business days for resolution",
                "Request written confirmation of solution"
            ]
        
        else:  # Default case
            message = f"""Dear {merchant} Customer Service,

I need assistance resolving an issue with a recent transaction on my account.

Transaction Details:
- Date: {data.get('date', 'Not specified')}
- Amount: ${amount:.2f}
- Issue: {data.get('narrative', 'Transaction dispute')}

Please review this transaction and provide appropriate resolution.

Thank you for your prompt attention to this matter."""

            checklist = [
                "Contact merchant customer service",
                "Provide transaction documentation",
                "Explain the issue clearly",
                "Request written response",
                "Allow reasonable time for resolution"
            ]
        
        return MerchantResolution(message=message, checklist=checklist)
    
    def _compose_dispute_packet(self, dispute_type: str, data: Dict[str, Any], 
                               citations: List[Citation]) -> DisputePacket:
        """Compose formal dispute packet"""
        
        # Create summary
        merchant = data.get("merchant", "Unknown Merchant")
        amount = data.get("amount", 0.0)
        date = data.get("date", "Unknown Date")
        
        summary = f"Dispute for {dispute_type.replace('_', ' ')} involving {merchant} for ${amount:.2f} on {date}"
        
        # Create fields
        fields = DisputeFields(
            merchant=merchant,
            date=date,
            amount=amount,
            reason=data.get("narrative", "No reason provided")
        )
        
        # Generate formal dispute letter
        letter = self._generate_formal_letter(dispute_type, data, citations)
        
        # Determine required attachments
        attachments = self._get_required_attachments(dispute_type)
        
        return DisputePacket(
            summary=summary,
            fields=fields,
            letter=letter,
            attachments=attachments
        )
    
    def _generate_formal_letter(self, dispute_type: str, data: Dict[str, Any], 
                               citations: List[Citation]) -> str:
        """Generate formal dispute letter"""
        
        merchant = data.get("merchant", "Unknown Merchant")
        amount = data.get("amount", 0.0)
        date = data.get("date", "Unknown Date")
        narrative = data.get("narrative", "")
        
        current_date = datetime.now().strftime("%B %d, %Y")
        
        if dispute_type == "fraud":
            letter = f"""Date: {current_date}

To: Card Issuer Dispute Department

RE: Fraudulent Transaction Dispute

Dear Dispute Resolution Team,

I am writing to formally dispute fraudulent charges on my account. I did not authorize these transactions and believe my account has been compromised.

DISPUTED TRANSACTION DETAILS:
- Merchant: {merchant}
- Transaction Date: {date}
- Amount: ${amount:.2f}
- Description: {narrative}

FRAUD DECLARATION:
I hereby declare under penalty of perjury that:
1. I did not authorize this transaction
2. I did not participate in this transaction
3. I did not give permission for anyone else to use my account
4. I have not received any goods or services from this transaction

IMMEDIATE ACTIONS TAKEN:
- Reported fraud immediately upon discovery
- Reviewed all recent account activity
- Secured account and changed passwords

I request immediate provisional credit and permanent removal of this fraudulent charge. Please investigate this matter urgently and provide written confirmation of resolution.

Sincerely,
[Cardholder Name]
Account Number: [Account Number]"""

        elif dispute_type == "goods_not_received":
            letter = f"""Date: {current_date}

To: Card Issuer Dispute Department

RE: Goods Not Received Dispute

Dear Dispute Resolution Team,

I am formally disputing a charge for goods/services that were paid for but never received.

TRANSACTION DETAILS:
- Merchant: {merchant}
- Transaction Date: {date}
- Amount: ${amount:.2f}
- Items/Services: {', '.join(data.get('items', ['Not specified']))}

ISSUE DESCRIPTION:
{narrative}

MERCHANT CONTACT ATTEMPTS:
I have attempted to resolve this matter directly with the merchant through:
- Initial contact on [Date]
- Follow-up contact on [Date]
- No satisfactory resolution provided

SUPPORTING EVIDENCE:
- Original purchase receipt/confirmation
- Communication records with merchant
- Proof of non-delivery

I request provisional credit while this matter is investigated. The merchant has failed to deliver the goods/services as promised, and I should not be held liable for this charge.

Please investigate and provide permanent credit for this transaction.

Sincerely,
[Cardholder Name]
Account Number: [Account Number]"""

        else:  # billing_error
            letter = f"""Date: {current_date}

To: Card Issuer Dispute Department

RE: Billing Error Dispute

Dear Dispute Resolution Team,

I am writing to dispute a billing error on my account that requires correction.

TRANSACTION DETAILS:
- Merchant: {merchant}
- Transaction Date: {date}
- Disputed Amount: ${amount:.2f}
- Error Description: {narrative}

BILLING ERROR DETAILS:
This charge appears to be incorrect due to:
- Duplicate processing of the same transaction
- Incorrect amount charged
- Mathematical or computational error
- Charge for goods/services not received

MERCHANT RESOLUTION ATTEMPT:
I contacted the merchant on [Date] to resolve this billing error. [Outcome of merchant contact]

REQUESTED RESOLUTION:
Please investigate this billing error and provide appropriate correction to my account. I have supporting documentation available upon request.

I request provisional credit during the investigation period as provided under the Fair Credit Billing Act.

Sincerely,
[Cardholder Name]
Account Number: [Account Number]"""

        return letter
    
    def _get_required_attachments(self, dispute_type: str) -> List[str]:
        """Get list of required attachments for dispute type"""
        
        common_attachments = [
            "Copy of credit card statement showing the disputed charge",
            "Account holder identification",
            "Completed dispute form"
        ]
        
        if dispute_type == "fraud":
            return common_attachments + [
                "Affidavit of unauthorized use",
                "Police report (if filed)",
                "List of all unauthorized transactions",
                "Documentation of account security measures taken"
            ]
        
        elif dispute_type == "goods_not_received":
            return common_attachments + [
                "Original purchase receipt or confirmation",
                "Shipping/tracking information (if applicable)",
                "Communication records with merchant",
                "Proof of expected delivery date",
                "Evidence of non-delivery"
            ]
        
        else:  # billing_error
            return common_attachments + [
                "Original receipt showing correct amount",
                "Documentation of the billing error",
                "Calculation showing the discrepancy",
                "Correspondence with merchant (if any)"
            ]

# Test cases for dispute scenarios
def test_dispute_copilot():
    """Test DisputeCopilot with common dispute scenarios"""
    print("üß™ Testing DisputeCopilot")
    print("=" * 50)
    
    copilot = DisputeCopilot()
    
    test_cases = [
        {
            "name": "Duplicate Charge",
            "narrative": "I was charged twice for the same purchase at Best Buy. The amount of $299.99 appears twice on my statement for the same day.",
            "merchant": "Best Buy",
            "amount": 299.99,
            "uploaded_text": None,
            "expected_triage": "billing_error"
        },
        {
            "name": "Goods Not Received",
            "narrative": "I ordered a laptop from Dell on December 1st but never received it. They charged my card $899 but the item was never delivered.",
            "merchant": "Dell",
            "amount": 899.00,
            "uploaded_text": "DELL TECHNOLOGIES\nOrder Date: 12/01/2024\nLaptop Computer - $899.00\nTotal: $899.00\nExpected Delivery: 12/15/2024",
            "expected_triage": "goods_not_received"
        },
        {
            "name": "Fraudulent Transaction",
            "narrative": "I see a charge for $500 at a store I've never been to. This is definitely fraud as I was out of town that day.",
            "merchant": None,
            "amount": 500.00,
            "uploaded_text": None,
            "expected_triage": "fraud"
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            
            result = copilot.process_dispute(
                narrative=case["narrative"],
                merchant=case["merchant"],
                amount=case["amount"],
                uploaded_text=case["uploaded_text"]
            )
            
            # Validate response structure
            valid_structure = (
                hasattr(result, 'triage') and
                hasattr(result, 'merchant_resolution') and
                hasattr(result, 'packet') and
                hasattr(result, 'citations')
            )
            
            # Check triage accuracy
            triage_correct = result.triage == case["expected_triage"]
            
            # Check packet completeness
            packet_complete = (
                result.packet.fields.merchant and
                result.packet.fields.amount > 0 and
                len(result.packet.letter) > 100
            )
            
            success = valid_structure and triage_correct and packet_complete
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   Narrative: {case['narrative'][:60]}...")
            print(f"   Triage: Expected {case['expected_triage']}, Got {result.triage}")
            print(f"   Merchant Resolution: {len(result.merchant_resolution.message)} chars")
            print(f"   Dispute Letter: {len(result.packet.letter)} chars")
            print(f"   Citations: {len(result.citations)}")
            print(f"   Status: {status}")
            print()
            
            if success:
                passed += 1
                
        except Exception as e:
            print(f"   ‚ùå ERROR: {e}")
            print()
    
    print(f"DisputeCopilot Test Results: {passed}/{total} passed")
    return passed == total

if __name__ == "__main__":
    # Run tests
    success = test_dispute_copilot()
    print(f"\n{'üéâ All tests passed!' if success else '‚ö†Ô∏è Some tests failed.'}")



================================================
FILE: app/agents/dispute_reg_e.py
================================================
"""
Dispute & Benefits Copilot - Reg-E-like Packet Processing
Enhanced version with category detection, eligibility windows, evidence classification, and structured packet assembly
"""

import re
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat
from app.rag.core import retrieve

logger = logging.getLogger(__name__)

# Enhanced Pydantic models for Reg-E-like processing
class EvidenceItem(BaseModel):
    type: str  # merchant, date, amount, order_id, chat, etc.
    value: str
    confidence: float
    source: str  # narrative, uploaded_text, extracted

class TimelineEvent(BaseModel):
    date: str
    event: str
    source: str

class DisputeStatus(BaseModel):
    stage: str  # intake, compiled, ready_to_submit, submitted, under_review
    likelihood: str  # low, medium, high
    next_milestone: str
    eligible: bool
    eligibility_reason: str

class PacketPreview(BaseModel):
    category: str
    merchant: str
    amount: float
    timeline: List[TimelineEvent]
    evidence: List[EvidenceItem]
    next_update_date: str

class DisputeResponse(BaseModel):
    response: str  # Short human summary + "ready to submit" note
    metadata: Dict[str, Any]  # Contains status, ui_cards, handoffs

class DisputeCopilot:
    """
    Enhanced Dispute & Benefits Copilot for Reg-E-like dispute packet processing
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize DisputeCopilot with RAG components and rules-based processing"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        self.rules_loader = rules_loader
        
        # Load dispute rules from centralized loader or use defaults
        if rules_loader:
            self.dispute_rules = rules_loader.get_rules('dispute') or {}
            logger.info("DisputeCopilot loaded rules from centralized rules loader")
        else:
            self.dispute_rules = self._load_fallback_rules()
        
        # Extract rule components
        self.categories = self.dispute_rules.get("categories", {})
        self.demo_clocks = self.dispute_rules.get("demo_clocks", {"posting_window_days": 60, "purchase_window_days": 90})
        self.status_pipeline = self.dispute_rules.get("status_pipeline", ["intake", "compiled", "ready_to_submit", "submitted", "under_review"])
        self.likelihood_buckets = self.dispute_rules.get("likelihood_buckets", ["low", "medium", "high"])
        
    def _load_fallback_rules(self) -> Dict[str, Any]:
        """Fallback rules if centralized loader not available"""
        return {
            "categories": {
                "duplicate_charge": {"required_evidence": ["statement_screenshot", "merchant_name", "date", "amount"]},
                "item_not_received": {"required_evidence": ["order_confirmation", "expected_delivery", "merchant_contact_attempt"]},
                "wrong_amount": {"required_evidence": ["receipt", "statement_screenshot", "correct_amount"]},
                "canceled_but_charged": {"required_evidence": ["cancellation_confirmation", "statement_screenshot"]}
            },
            "demo_clocks": {"posting_window_days": 60, "purchase_window_days": 90},
            "status_pipeline": ["intake", "compiled", "ready_to_submit", "submitted", "under_review"],
            "likelihood_buckets": ["low", "medium", "high"]
        }
    
    def process_dispute(self, narrative: str, merchant: Optional[str] = None, 
                       amount: Optional[float] = None, uploaded_text: Optional[str] = None) -> DisputeResponse:
        """
        Enhanced Reg-E-like dispute processing pipeline with category detection, eligibility windows,
        evidence classification, and structured packet assembly
        
        Args:
            narrative: Customer's description of the dispute
            merchant: Merchant name (optional)
            amount: Disputed amount (optional)
            uploaded_text: Receipt or document text (optional)
            
        Returns:
            DisputeResponse with structured metadata for UI cards, status, and handoffs
        """
        try:
            logger.info(f"Processing Reg-E dispute: {narrative[:100]}...")
            
            # Step 1: Category Detection against rules/dispute.yml
            category = self._detect_category(narrative)
            logger.info(f"Dispute categorized as: {category}")
            
            # Step 2: Evidence Classification by regex/heuristic
            evidence = self._classify_evidence(narrative, uploaded_text, merchant, amount)
            logger.info(f"Classified {len(evidence)} evidence items")
            
            # Step 3: Eligibility Windows Check (demo clocks)
            eligibility = self._check_eligibility(evidence)
            logger.info(f"Eligibility check: {eligibility.eligible} - {eligibility.eligibility_reason}")
            
            # Step 4: Timeline Construction
            timeline = self._construct_timeline(evidence)
            
            # Step 5: Status Assessment
            status = self._assess_status(category, evidence, eligibility)
            
            # Step 6: Packet Assembly
            packet_preview = self._assemble_packet(category, evidence, timeline, merchant or "Unknown", amount or 0.0)
            
            # Step 7: Check for handoffs
            handoffs = self._detect_handoffs(narrative, category)
            
            # Step 8: Generate human summary
            response_summary = self._generate_summary(category, status, packet_preview)
            
            return DisputeResponse(
                response=response_summary,
                metadata={
                    "status": status.dict(),
                    "ui_cards": [packet_preview.dict()],
                    "handoffs": handoffs,
                    "category": category,
                    "evidence_count": len(evidence),
                    "timeline_events": len(timeline)
                }
            )
            
        except Exception as e:
            logger.error(f"Error processing Reg-E dispute: {e}")
            # Return fallback response
            return DisputeResponse(
                response="Unable to process dispute. Please contact customer service for assistance.",
                metadata={
                    "status": {"stage": "intake", "likelihood": "low", "next_milestone": "manual_review", "eligible": False, "eligibility_reason": "Processing error"},
                    "ui_cards": [],
                    "handoffs": [],
                    "error": str(e)
                }
            )
    
    def _detect_category(self, narrative: str) -> str:
        """Detect dispute category against rules/dispute.yml categories"""
        narrative_lower = narrative.lower()
        
        # Category detection patterns
        category_patterns = {
            "duplicate_charge": ["charged twice", "double charge", "duplicate", "same transaction", "multiple charges"],
            "item_not_received": ["not received", "never arrived", "didn't get", "not delivered", "missing order", "not shipped"],
            "wrong_amount": ["wrong amount", "charged more", "overcharged", "incorrect price", "different amount"],
            "canceled_but_charged": ["canceled", "cancelled", "refund", "returned", "charged after cancel"]
        }
        
        for category, patterns in category_patterns.items():
            if any(pattern in narrative_lower for pattern in patterns):
                return category
        
        return "duplicate_charge"  # Default category
    
    def _classify_evidence(self, narrative: str, uploaded_text: Optional[str], 
                          merchant: Optional[str], amount: Optional[float]) -> List[EvidenceItem]:
        """Classify evidence by regex/heuristic (merchant, dates, amounts, order id, chats)"""
        evidence = []
        
        # Extract from narrative
        if narrative:
            # Merchant names
            merchant_matches = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', narrative)
            for match in merchant_matches[:3]:  # Limit to first 3
                if len(match) > 2:
                    evidence.append(EvidenceItem(
                        type="merchant",
                        value=match,
                        confidence=0.7,
                        source="narrative"
                    ))
            
            # Dates
            date_patterns = [
                r'\b\d{1,2}/\d{1,2}/\d{4}\b',
                r'\b\d{4}-\d{2}-\d{2}\b',
                r'\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\s+\d{1,2},?\s+\d{4}\b'
            ]
            for pattern in date_patterns:
                dates = re.findall(pattern, narrative, re.IGNORECASE)
                for date in dates:
                    evidence.append(EvidenceItem(
                        type="date",
                        value=date,
                        confidence=0.8,
                        source="narrative"
                    ))
            
            # Amounts
            amount_pattern = r'\$(\d{1,3}(?:,\d{3})*(?:\.\d{2})?)'
            amounts = re.findall(amount_pattern, narrative)
            for amt in amounts:
                evidence.append(EvidenceItem(
                    type="amount",
                    value=f"${amt}",
                    confidence=0.9,
                    source="narrative"
                ))
            
            # Order IDs
            order_patterns = [
                r'\b(?:order|confirmation|ref|reference)[\s#:]*([A-Z0-9]{6,20})\b',
                r'\b[A-Z0-9]{8,16}\b'
            ]
            for pattern in order_patterns:
                orders = re.findall(pattern, narrative, re.IGNORECASE)
                for order in orders:
                    evidence.append(EvidenceItem(
                        type="order_id",
                        value=order,
                        confidence=0.6,
                        source="narrative"
                    ))
        
        # Add provided merchant and amount
        if merchant:
            evidence.append(EvidenceItem(
                type="merchant",
                value=merchant,
                confidence=1.0,
                source="provided"
            ))
        
        if amount:
            evidence.append(EvidenceItem(
                type="amount",
                value=f"${amount:.2f}",
                confidence=1.0,
                source="provided"
            ))
        
        # Extract from uploaded text if available
        if uploaded_text:
            # Simple receipt parsing
            receipt_amounts = re.findall(r'\$(\d{1,3}(?:,\d{3})*(?:\.\d{2})?)', uploaded_text)
            for amt in receipt_amounts[:2]:  # Limit to first 2
                evidence.append(EvidenceItem(
                    type="amount",
                    value=f"${amt}",
                    confidence=0.9,
                    source="uploaded_text"
                ))
        
        return evidence
    
    def _check_eligibility(self, evidence: List[EvidenceItem]) -> DisputeStatus:
        """Check eligibility windows (60d from posting or 90d from purchase) - demo clocks"""
        today = datetime.now()
        posting_window = timedelta(days=self.demo_clocks.get("posting_window_days", 60))
        purchase_window = timedelta(days=self.demo_clocks.get("purchase_window_days", 90))
        
        # Extract dates from evidence
        dates = [item for item in evidence if item.type == "date"]
        
        if not dates:
            # No dates found - assume within window for demo
            return DisputeStatus(
                stage="intake",
                likelihood="medium",
                next_milestone="evidence_review",
                eligible=True,
                eligibility_reason="No specific dates provided; assuming within demo window (illustrative only)"
            )
        
        # Check against demo clocks
        eligible = True
        reason = f"Within demo eligibility windows: {self.demo_clocks['posting_window_days']}d from posting or {self.demo_clocks['purchase_window_days']}d from purchase (illustrative only)"
        
        # Simple date parsing for demo purposes
        for date_item in dates:
            try:
                # Try to parse the date
                date_str = date_item.value
                if '/' in date_str:
                    date_obj = datetime.strptime(date_str, '%m/%d/%Y')
                elif '-' in date_str:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                else:
                    continue
                
                # Check if outside windows
                days_ago = (today - date_obj).days
                if days_ago > self.demo_clocks.get("purchase_window_days", 90):
                    eligible = False
                    reason = f"Date {date_str} is {days_ago} days ago, outside demo window (illustrative only)"
                    break
                    
            except ValueError:
                continue
        
        return DisputeStatus(
            stage="intake",
            likelihood="medium",
            next_milestone="eligibility_confirmed",
            eligible=eligible,
            eligibility_reason=reason
        )
    
    def _construct_timeline(self, evidence: List[EvidenceItem]) -> List[TimelineEvent]:
        """Construct timeline from evidence"""
        timeline = []
        
        # Add dates from evidence
        for item in evidence:
            if item.type == "date":
                timeline.append(TimelineEvent(
                    date=item.value,
                    event=f"Transaction date (from {item.source})",
                    source=item.source
                ))
        
        # Add current date as intake
        timeline.append(TimelineEvent(
            date=datetime.now().strftime("%Y-%m-%d"),
            event="Dispute intake initiated",
            source="system"
        ))
        
        return timeline
    
    def _assess_status(self, category: str, evidence: List[EvidenceItem], eligibility: DisputeStatus) -> DisputeStatus:
        """Assess dispute status based on category, evidence, and eligibility"""
        
        # Get required evidence for category
        required = self.categories.get(category, {}).get("required_evidence", [])
        evidence_types = [item.type for item in evidence]
        
        # Calculate likelihood based on evidence completeness
        evidence_score = 0
        for req in required:
            if any(req.replace("_", "") in etype or etype in req for etype in evidence_types):
                evidence_score += 1
        
        completion_ratio = evidence_score / len(required) if required else 0.8
        
        if completion_ratio >= 0.8:
            likelihood = "high"
            stage = "ready_to_submit"
            next_milestone = "submit_packet"
        elif completion_ratio >= 0.5:
            likelihood = "medium"
            stage = "compiled"
            next_milestone = "gather_remaining_evidence"
        else:
            likelihood = "low"
            stage = "intake"
            next_milestone = "evidence_collection"
        
        return DisputeStatus(
            stage=stage,
            likelihood=likelihood,
            next_milestone=next_milestone,
            eligible=eligibility.eligible,
            eligibility_reason=eligibility.eligibility_reason
        )
    
    def _assemble_packet(self, category: str, evidence: List[EvidenceItem], 
                        timeline: List[TimelineEvent], merchant: str, amount: float) -> PacketPreview:
        """Assemble packet with timeline, evidence bullets, and next update date"""
        
        # Next update date (today + 10 days)
        next_update = (datetime.now() + timedelta(days=10)).strftime("%Y-%m-%d")
        
        return PacketPreview(
            category=category,
            merchant=merchant,
            amount=amount,
            timeline=timeline,
            evidence=evidence,
            next_update_date=next_update
        )
    
    def _detect_handoffs(self, narrative: str, category: str) -> List[str]:
        """Detect if handoffs to contracts are needed for policy clause clarity"""
        handoffs = []
        
        # Check for contract/policy related terms
        contract_terms = ["terms", "policy", "contract", "agreement", "clause", "warranty", "guarantee"]
        narrative_lower = narrative.lower()
        
        if any(term in narrative_lower for term in contract_terms):
            handoffs.append("contracts")
        
        return handoffs
    
    def _generate_summary(self, category: str, status: DisputeStatus, packet: PacketPreview) -> str:
        """Generate short human summary + ready to submit note"""
        
        category_names = {
            "duplicate_charge": "Duplicate Charge",
            "item_not_received": "Item Not Received", 
            "wrong_amount": "Wrong Amount",
            "canceled_but_charged": "Canceled But Charged"
        }
        
        category_display = category_names.get(category, category.replace("_", " ").title())
        
        summary = f"**{category_display} Dispute** for ${packet.amount:.2f} at {packet.merchant}. "
        summary += f"Evidence: {len(packet.evidence)} items collected. "
        summary += f"Timeline: {len(packet.timeline)} events documented. "
        
        if status.eligible:
            if status.stage == "ready_to_submit":
                summary += "‚úÖ **Ready to submit** - all required evidence collected."
            else:
                summary += f"Status: {status.stage.replace('_', ' ').title()} ({status.likelihood} likelihood)."
        else:
            summary += f"‚ö†Ô∏è Eligibility issue: {status.eligibility_reason}"
        
        summary += f" Next update by {packet.next_update_date}."
        
        return summary

# Backwards compatibility - create alias for existing import
DisputeCopilot_Enhanced = DisputeCopilot


================================================
FILE: app/agents/imagegen.py
================================================
"""
ImageGen - B2B Marketing Studio with Real Image Generation
Template-driven creative generation with co-branding, dynamic disclosures, compliance redlining, and actual image generation
"""

import logging
import base64
import re
import os
from io import BytesIO
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path

from pydantic import BaseModel, Field
from PIL import Image
from google import genai
from google.genai import types
from dotenv import load_dotenv

from app.llm.gemini import chat

logger = logging.getLogger(__name__)

# Pydantic models for B2B marketing studio
class BrandSettings(BaseModel):
    name: str
    hex_color: str = "#2E86DE"
    placement: str = "top_left"

class CreativeCopy(BaseModel):
    headline: str
    body: Optional[str] = None
    cta: str
    legal: str

class RedlineChange(BaseModel):
    original: str
    replacement: str
    reason: str
    severity: str

class ImageGenResponse(BaseModel):
    response: str  # Brief creative summary + legal footer statement
    metadata: Dict[str, Any]  # ui_cards, disclosures, handoffs, image data

class ImageGenAgent:
    """
    B2B Marketing Studio with Real Image Generation
    Template selection, co-branding, dynamic disclosures, compliance redlining, and Gemini native image generation
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize ImageGen with marketing rules and Gemini image generation"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        self.rules_loader = rules_loader
        
        # Initialize Gemini image generation client
        self.client = None
        self.model_name = "gemini-2.0-flash-preview-image-generation"
        
        try:
            # Load environment variables
            load_dotenv()
            api_key = os.getenv("GOOGLE_API_KEY")
            if api_key:
                os.environ['GOOGLE_API_KEY'] = api_key  # Ensure env var is set
                self.client = genai.Client()
                logger.info("ImageGen Gemini client initialized for gemini-2.0-flash-preview-image-generation")
            else:
                logger.warning("GOOGLE_API_KEY not found - image generation will be disabled")
        except Exception as e:
            logger.error(f"Failed to initialize Gemini client: {e}")
        
        # Load marketing rules
        if rules_loader:
            self.imagegen_rules = rules_loader.get_rules('imagegen') or {}
            logger.info("ImageGenAgent loaded rules from centralized rules loader")
        else:
            self.imagegen_rules = self._load_fallback_rules()
        
        # Extract rule components
        self.templates = self.imagegen_rules.get("templates", {})
        self.co_brand_settings = self.imagegen_rules.get("co_brand_settings", {})
        self.dynamic_disclosures = self.imagegen_rules.get("dynamic_disclosures", {})
        self.banned_phrases = self.imagegen_rules.get("banned_phrases", {})
        self.legal_footers = self.imagegen_rules.get("legal_footers", {})
    
    def _load_fallback_rules(self) -> Dict[str, Any]:
        """Fallback rules if centralized loader not available"""
        return {
            "templates": {
                "a4_instore": {
                    "format": "A4", "dimensions": "8.5x11", "orientation": "portrait",
                    "layout": ["headline", "subhead", "price_callout", "cta", "legal_footer"],
                    "brand_placement": "top_left"
                },
                "social_square": {
                    "format": "square", "dimensions": "1080x1080", "orientation": "square", 
                    "layout": ["headline", "caption_with_legal"], "brand_placement": "bottom_right"
                }
            },
            "co_brand_settings": {
                "default_hex": "#2E86DE", "placeholder_style": "initials_in_circle"
            },
            "dynamic_disclosures": {
                "equal_payment": {"triggers": ["equal payment"], "disclosure_id": "equal_payment_generic"}
            },
            "banned_phrases": {
                "guaranteed_approval": {"phrases": ["guaranteed approval"], "replacement": "subject to credit approval", "severity": "high"}
            },
            "legal_footers": {
                "equal_payment_generic": "Equal monthly payments required. Subject to credit approval."
            }
        }
    
    def generate_creative(
        self,
        message: str,
        template: str = "a4_instore",
        brand: Optional[BrandSettings] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> ImageGenResponse:
        """
        Main creative generation pipeline with compliance, co-branding, and actual image generation
        
        Args:
            message: Marketing message content
            template: Template selection (a4_instore, social_square, etc.)
            brand: Brand settings for co-branding
            context: Additional context for creative generation
            
        Returns:
            ImageGenResponse with creative summary, metadata, and actual generated image
        """
        try:
            logger.info(f"Generating creative with template: {template}")
            
            # Step 1: Validate template selection
            template_config = self._validate_template(template)
            
            # Step 2: Redline pass - check for banned phrases using TrustShield-style logic
            redlined_message, redline_changes = self._redline_pass(message)
            
            # Step 3: Dynamic disclosure detection
            required_disclosures = self._detect_disclosures(redlined_message)
            
            # Step 4: Generate creative copy
            creative_copy = self._generate_creative_copy(redlined_message, template_config)
            
            # Step 5: Apply co-branding
            brand_config = self._apply_co_branding(brand, template_config)
            
            # Step 6: Generate actual image using Gemini
            image_data = self._generate_image(creative_copy, template_config, brand_config, redlined_message)
            
            # Step 7: Create preview reference and UI cards with image
            preview_ref, ui_cards = self._create_ui_cards(template, creative_copy, brand_config, image_data)
            
            # Step 8: Detect handoffs
            handoffs = self._detect_handoffs(message, redline_changes)
            
            # Step 9: Generate response summary
            response_text = self._generate_response_summary(creative_copy, redline_changes, required_disclosures, image_data)
            
            return ImageGenResponse(
                response=response_text,
                metadata={
                    "ui_cards": ui_cards,
                    "disclosures": required_disclosures,
                    "handoffs": handoffs,
                    "template": template,
                    "brand_config": brand_config,
                    "redline_changes": [change.model_dump() for change in redline_changes],
                    "preview_ref": preview_ref,
                    "image_generated": image_data is not None,
                    "image_base64": image_data.get("base64") if image_data else None,
                    "image_format": image_data.get("format") if image_data else None
                }
            )
            
        except Exception as e:
            logger.error(f"Creative generation error: {e}")
            return self._error_response(f"Creative generation failed: {str(e)}")
    
    def _generate_image(
        self, 
        creative_copy: CreativeCopy, 
        template_config: Dict[str, Any], 
        brand_config: Dict[str, Any],
        original_message: str
    ) -> Optional[Dict[str, Any]]:
        """Generate actual image using Gemini native image generation"""
        
        if not self.client:
            logger.warning("Gemini client not available - skipping image generation")
            return None
        
        try:
            # Build comprehensive prompt for image generation
            prompt = self._build_image_prompt(creative_copy, template_config, brand_config, original_message)
            logger.info(f"Generating image with prompt: {prompt[:150]}...")
            
            # Generate image using Gemini 2.0 Flash Preview Image Generation (matching working test)
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_modalities=['TEXT', 'IMAGE']
                )
            )
            
            # Process the response - extract image from response parts (matching working test structure)
            if response.candidates and len(response.candidates) > 0:
                for part in response.candidates[0].content.parts:
                    if part.inline_data is not None:
                        # Get image data directly from inline_data
                        image_bytes = part.inline_data.data
                        
                        # Convert to PIL Image to get dimensions and validate format
                        try:
                            pil_image = Image.open(BytesIO(image_bytes))
                            width, height = pil_image.size
                            
                            # Convert to base64 string for UI
                            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                            
                            logger.info(f"Successfully generated {width}x{height} image")
                            
                            return {
                                "base64": image_base64,
                                "format": "PNG",
                                "size": f"{width}x{height}",
                                "prompt": prompt
                            }
                        except Exception as img_error:
                            logger.error(f"Error processing generated image: {img_error}")
                            return None
            
            logger.warning("No image generated in Gemini response")
            return None
            
        except Exception as e:
            logger.error(f"Image generation failed: {e}")
            return None
    
    def _build_image_prompt(
        self, 
        creative_copy: CreativeCopy, 
        template_config: Dict[str, Any], 
        brand_config: Dict[str, Any],
        original_message: str
    ) -> str:
        """Build comprehensive prompt for image generation"""
        
        # Template specifications
        template_format = template_config.get("format", "A4")
        dimensions = template_config.get("dimensions", "8.5x11")
        orientation = template_config.get("orientation", "portrait")
        layout = template_config.get("layout", [])
        
        # Brand specifications
        brand_name = brand_config.get("brand_name", "Partner Brand")
        brand_hex = brand_config.get("brand_hex", "#2E86DE")
        brand_placement = brand_config.get("brand_placement", "top_left")
        brand_initials = brand_config.get("initials", "PB")
        
        # Build prompt parts
        prompt_parts = []
        
        # Base description
        prompt_parts.append(f"Create a professional {template_format} marketing {template_format.lower()} in {orientation} orientation")
        
        # Layout structure
        if "headline" in layout:
            prompt_parts.append(f"with prominent headline text '{creative_copy.headline}'")
        
        if creative_copy.body and ("body" in layout or "subhead" in layout):
            prompt_parts.append(f"body text '{creative_copy.body[:50]}...'")
        
        if "cta" in layout:
            prompt_parts.append(f"call-to-action button '{creative_copy.cta}'")
        
        # Brand elements
        prompt_parts.append(f"include {brand_name} branding in {brand_placement} position")
        prompt_parts.append(f"use brand color {brand_hex} as accent color")
        prompt_parts.append(f"show brand initials '{brand_initials}' in a circle logo placeholder")
        
        # Legal footer
        if "legal_footer" in layout:
            prompt_parts.append(f"small legal text at bottom: '{creative_copy.legal[:30]}...'")
        
        # Context from original message
        if "furniture" in original_message.lower():
            prompt_parts.append("background should suggest furniture/home decor theme")
        elif "dental" in original_message.lower() or "medical" in original_message.lower():
            prompt_parts.append("background should suggest healthcare/medical theme") 
        
        # Style specifications
        prompt_parts.extend([
            "professional financial services design",
            "clean modern layout with good typography",
            "high contrast for readability",
            "marketing poster style",
            "high quality, professional appearance"
        ])
        
        return ", ".join(prompt_parts)
    
    def _validate_template(self, template: str) -> Dict[str, Any]:
        """Validate and return template configuration"""
        if template not in self.templates:
            available = list(self.templates.keys())
            raise ValueError(f"Template '{template}' not found. Available: {available}")
        
        return self.templates[template]
    
    def _redline_pass(self, message: str) -> Tuple[str, List[RedlineChange]]:
        """TrustShield-style redline pass to flag/replace banned phrases"""
        redlined_message = message
        redline_changes = []
        
        try:
            for violation_type, config in self.banned_phrases.items():
                phrases = config.get("phrases", [])
                replacement = config.get("replacement", "[REDLINED]")
                severity = config.get("severity", "medium")
                
                for phrase in phrases:
                    # Case-insensitive search and replace
                    pattern = re.compile(re.escape(phrase), re.IGNORECASE)
                    matches = pattern.findall(redlined_message)
                    
                    if matches:
                        for match in matches:
                            redline_changes.append(RedlineChange(
                                original=match,
                                replacement=replacement,
                                reason=f"Banned phrase: {violation_type}",
                                severity=severity
                            ))
                        
                        redlined_message = pattern.sub(replacement, redlined_message)
            
            if redline_changes:
                logger.info(f"Applied {len(redline_changes)} redline changes")
            
            return redlined_message, redline_changes
            
        except Exception as e:
            logger.error(f"Redline pass error: {e}")
            return message, []
    
    def _detect_disclosures(self, message: str) -> List[str]:
        """Detect required disclosures based on message content"""
        required_disclosures = []
        message_lower = message.lower()
        
        try:
            for disclosure_type, config in self.dynamic_disclosures.items():
                triggers = config.get("triggers", [])
                disclosure_id = config.get("disclosure_id", "")
                
                # Check if any trigger phrases are present
                for trigger in triggers:
                    if trigger.lower() in message_lower:
                        if disclosure_id not in required_disclosures:
                            required_disclosures.append(disclosure_id)
                        break
            
            logger.info(f"Detected {len(required_disclosures)} required disclosures")
            return required_disclosures
            
        except Exception as e:
            logger.error(f"Disclosure detection error: {e}")
            return []
    
    def _generate_creative_copy(self, message: str, template_config: Dict[str, Any]) -> CreativeCopy:
        """Generate creative copy based on message and template layout"""
        try:
            layout = template_config.get("layout", [])
            
            # Use LLM to generate structured creative copy
            system_prompt = f"""You are a B2B marketing copywriter. Generate creative copy based on the layout requirements.

Layout elements needed: {', '.join(layout)}
Template format: {template_config.get('format', 'Unknown')}

Generate concise, professional copy with:
- Compelling headline (max 8 words)
- Clear body text if needed (max 25 words)
- Strong call-to-action (max 5 words)
- Appropriate legal language

Return as JSON with keys: headline, body, cta, legal"""
            
            user_message = f"Create marketing copy for: {message}"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            # Try to parse LLM response as JSON
            try:
                import json
                copy_data = json.loads(response.strip())
                return CreativeCopy(
                    headline=copy_data.get("headline", "Your Financial Solution"),
                    body=copy_data.get("body"),
                    cta=copy_data.get("cta", "Learn More"),
                    legal=copy_data.get("legal", "See terms and conditions.")
                )
            except json.JSONDecodeError:
                # Fallback to basic parsing
                return self._fallback_copy_generation(message)
                
        except Exception as e:
            logger.error(f"Creative copy generation error: {e}")
            return self._fallback_copy_generation(message)
    
    def _fallback_copy_generation(self, message: str) -> CreativeCopy:
        """Fallback creative copy generation"""
        return CreativeCopy(
            headline="Special Financing Available",
            body="Flexible payment options for your purchase",
            cta="Apply Today",
            legal="Subject to credit approval. See terms."
        )
    
    def _apply_co_branding(self, brand: Optional[BrandSettings], template_config: Dict[str, Any]) -> Dict[str, Any]:
        """Apply co-branding with brand name and hex colors"""
        default_hex = self.co_brand_settings.get("default_hex", "#2E86DE")
        placeholder_style = self.co_brand_settings.get("placeholder_style", "initials_in_circle")
        
        if brand:
            # Generate initials from brand name
            initials = ''.join([word[0].upper() for word in brand.name.split()[:2]])
            
            return {
                "brand_name": brand.name,
                "brand_hex": brand.hex_color,
                "brand_placement": brand.placement,
                "logo_placeholder": f"{placeholder_style}:{initials}",
                "initials": initials
            }
        else:
            return {
                "brand_name": "Partner Brand",
                "brand_hex": default_hex,
                "brand_placement": template_config.get("brand_placement", "top_left"),
                "logo_placeholder": f"{placeholder_style}:PB",
                "initials": "PB"
            }
    
    def _create_ui_cards(
        self, 
        template: str, 
        creative_copy: CreativeCopy, 
        brand_config: Dict[str, Any],
        image_data: Optional[Dict[str, Any]]
    ) -> Tuple[str, List[Dict[str, Any]]]:
        """Create preview reference and UI cards for creative output with actual image"""
        preview_ref = f"creative_preview_{template}_{hash(creative_copy.headline) % 10000}"
        
        ui_card = {
            "type": "creative",
            "template": template,
            "preview_ref": preview_ref,
            "copy": {
                "headline": creative_copy.headline,
                "body": creative_copy.body,
                "cta": creative_copy.cta,
                "legal": creative_copy.legal
            },
            "brand": brand_config,
            "dimensions": self.templates[template].get("dimensions", "Unknown")
        }
        
        # Add actual image data if generated
        if image_data:
            ui_card["image"] = {
                "base64": image_data["base64"],
                "format": image_data["format"],
                "size": image_data["size"],
                "data_uri": f"data:image/{image_data['format'].lower()};base64,{image_data['base64']}"
            }
        
        ui_cards = [ui_card]
        
        return preview_ref, ui_cards
    
    def _detect_handoffs(self, original_message: str, redline_changes: List[RedlineChange]) -> List[str]:
        """Detect handoffs to other agents"""
        handoffs = []
        message_lower = original_message.lower()
        
        # Handoff to narrator for campaign measurement
        if any(word in message_lower for word in ['campaign', 'measure', 'analytics', 'performance', 'roi']):
            handoffs.append("narrator")
        
        # Handoff back to imagegen for variants
        if any(word in message_lower for word in ['variant', 'alternative', 'different', 'another']):
            handoffs.append("imagegen")
        
        # If high severity redlines, might need manual review
        high_severity_redlines = [change for change in redline_changes if change.severity == "high"]
        if high_severity_redlines:
            handoffs.append("manual_review")
        
        return handoffs
    
    def _generate_response_summary(
        self, 
        creative_copy: CreativeCopy, 
        redline_changes: List[RedlineChange],
        required_disclosures: List[str],
        image_data: Optional[Dict[str, Any]]
    ) -> str:
        """Generate brief creative summary with legal footer and image status"""
        
        summary_parts = []
        
        # Creative summary
        summary_parts.append(f"**Creative Generated:** {creative_copy.headline}")
        
        if creative_copy.body:
            summary_parts.append(f"Body copy focuses on {creative_copy.body[:50]}...")
        
        summary_parts.append(f"Call-to-action: '{creative_copy.cta}'")
        
        # Image generation status
        if image_data:
            summary_parts.append(f"üñºÔ∏è **Image generated:** {image_data['size']} {image_data['format']}")
        else:
            summary_parts.append("‚ö†Ô∏è **Image generation unavailable** (API key required)")
        
        # Compliance notes
        if redline_changes:
            high_severity = len([c for c in redline_changes if c.severity == "high"])
            if high_severity > 0:
                summary_parts.append(f"‚ö†Ô∏è **{high_severity} high-priority redlines applied** for compliance")
            else:
                summary_parts.append(f"üìù **{len(redline_changes)} redlines applied** for compliance")
        
        if required_disclosures:
            summary_parts.append(f"üìã **{len(required_disclosures)} disclosures** automatically added")
        
        # Legal footer from first disclosure or default
        legal_footer = ""
        if required_disclosures:
            first_disclosure = required_disclosures[0]
            legal_footer = self.legal_footers.get(first_disclosure, "")
        
        if not legal_footer:
            legal_footer = "Subject to credit approval. See terms and conditions."
        
        response_text = "\n".join(summary_parts)
        response_text += f"\n\n**Legal Footer:** {legal_footer}"
        
        return response_text
    
    def _error_response(self, message: str) -> ImageGenResponse:
        """Create error response"""
        return ImageGenResponse(
            response=f"**Creative Generation Error:** {message}",
            metadata={
                "ui_cards": [],
                "disclosures": [],
                "handoffs": [],
                "error": message,
                "image_generated": False
            }
        )

# Test cases for ImageGen B2B marketing studio with real image generation
def test_imagegen():
    """Test ImageGen with B2B marketing studio and image generation"""
    print("üß™ Testing ImageGen B2B Marketing Studio with Real Image Generation")
    print("=" * 70)
    
    imagegen = ImageGenAgent()
    
    test_cases = [
        {
            "name": "Equal payment promotional creative with image",
            "message": "Get equal monthly payments on your furniture purchase with no money down!",
            "template": "a4_instore",
            "brand": BrandSettings(name="Urban Living Co", hex_color="#FF6B35"),
            "expected_disclosures": ["equal_payment_generic"],
            "expected_redlines": 0,
            "expect_image": True
        },
        {
            "name": "Banned phrase redlining with image",
            "message": "Guaranteed approval for everyone! No credit check required!",
            "template": "social_square", 
            "brand": BrandSettings(name="FastCash", hex_color="#E74C3C"),
            "expected_disclosures": [],
            "expected_redlines": 2,
            "expect_image": True
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            
            result = imagegen.generate_creative(
                message=case["message"],
                template=case["template"],
                brand=case["brand"]
            )
            
            # Validate response structure
            valid_structure = (
                hasattr(result, 'response') and
                hasattr(result, 'metadata') and
                'ui_cards' in result.metadata and
                'disclosures' in result.metadata
            )
            
            # Check disclosures
            disclosures = result.metadata.get('disclosures', [])
            disclosures_ok = len(disclosures) >= len(case['expected_disclosures'])
            
            # Check redlines
            redline_changes = result.metadata.get('redline_changes', [])
            redlines_ok = len(redline_changes) == case['expected_redlines']
            
            # Check UI cards
            ui_cards = result.metadata.get('ui_cards', [])
            ui_cards_ok = len(ui_cards) > 0 and ui_cards[0].get('type') == 'creative'
            
            # Check image generation
            image_generated = result.metadata.get('image_generated', False)
            image_ok = image_generated or not case['expect_image']  # OK if image generated OR not expected
            
            success = valid_structure and disclosures_ok and redlines_ok and ui_cards_ok and image_ok
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   Template: {case['template']}")
            print(f"   Brand: {case['brand'].name} ({case['brand'].hex_color})")
            print(f"   Disclosures: {len(disclosures)} (expected >= {len(case['expected_disclosures'])})")
            print(f"   Redlines: {len(redline_changes)} (expected {case['expected_redlines']})")
            print(f"   UI Cards: {len(ui_cards)}")
            print(f"   Image Generated: {image_generated}")
            print(f"   Status: {status}")
            
            if success:
                passed += 1
            else:
                print(f"   Failure reasons:")
                if not valid_structure:
                    print(f"     - Invalid response structure")
                if not disclosures_ok:
                    print(f"     - Disclosure count mismatch")
                if not redlines_ok:
                    print(f"     - Redline count mismatch")
                if not ui_cards_ok:
                    print(f"     - UI cards issue")
                if not image_ok:
                    print(f"     - Image generation issue")
            
            print()
            
        except Exception as e:
            print(f"   ‚ùå FAIL - Exception: {str(e)}")
            print()
    
    print(f"üìä Results: {passed}/{total} tests passed")
    return passed == total

if __name__ == "__main__":
    test_imagegen()


================================================
FILE: app/agents/narrator.py
================================================
"""
Portfolio Intel Narrator - Insights that Drive Action
Generates actionable insights from KPI analysis with impact ranking and action suggestions
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat

logger = logging.getLogger(__name__)

# Pydantic models for structured responses
class Insight(BaseModel):
    metric: str
    value: float
    delta: float
    delta_percent: float
    confidence: float
    impact_score: float
    total_score: float
    action: str
    target_agent: str
    rationale: str

class NarratorResponse(BaseModel):
    response: str  # 2-4 bullets with numbers + 1-2 "try next"
    metadata: Dict[str, Any]  # ui_cards with insights

class PortfolioIntelNarrator:
    """
    Portfolio Intel Narrator - Insights that Drive Action
    Generates actionable insights from KPI analysis with impact ranking
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize Narrator with rules and mock data"""
        self.docstore = docstore
        self.embedder = embedder  
        self.retriever = retriever
        self.rules_loader = rules_loader
        
        # Load narrator rules and mock data
        self._load_narrator_rules()
        self._load_portfolio_metrics()
    
    def _load_narrator_rules(self):
        """Load narrator rules from YAML"""
        try:
            if self.rules_loader:
                self.narrator_rules = self.rules_loader.get_rules('narrator') or {}
                logger.info("Loaded narrator rules from rules_loader")
            else:
                self.narrator_rules = {}
                logger.warning("No rules_loader provided - using defaults")
        except Exception as e:
            logger.error(f"Failed to load narrator rules: {e}")
            self.narrator_rules = {}
    
    def _load_portfolio_metrics(self):
        """Load mock portfolio metrics from JSON"""
        try:
            metrics_path = Path("synchrony-demo-rules-repo/fixtures/narrator/mock_portfolio_metrics.json")
            with open(metrics_path, 'r') as f:
                self.portfolio_data = json.load(f)
            logger.info("Loaded portfolio metrics data")
        except Exception as e:
            logger.error(f"Failed to load portfolio metrics: {e}")
            self.portfolio_data = {"segments": []}
    
    def generate_insights(self, query: str = "") -> NarratorResponse:
        """
        Main entry point: generate insights that drive action
        
        Args:
            query: Optional query to focus insights (unused for now - always analyzes all KPIs)
            
        Returns:
            NarratorResponse with insights and action suggestions
        """
        try:
            logger.info("Generating portfolio insights with KPI analysis")
            
            # Step 1: Calculate KPIs using formulas from rules
            kpi_results = self._calculate_kpis()
            
            # Step 2: Generate insights with impact and confidence scoring
            insights = self._generate_insights(kpi_results)
            
            # Step 3: Rank insights by weighted score (impact 0.6, confidence 0.4) 
            ranked_insights = self._rank_insights(insights)
            
            # Step 4: Select top insights and add action suggestions
            actionable_insights = self._add_action_suggestions(ranked_insights[:4])
            
            # Step 5: Generate response text (2-4 bullets + try next)
            response_text = self._generate_response_text(actionable_insights)
            
            # Step 6: Build UI cards for metadata
            ui_cards = self._build_insight_ui_cards(actionable_insights)
            
            return NarratorResponse(
                response=response_text,
                metadata={
                    "ui_cards": ui_cards,
                    "kpis_analyzed": len(kpi_results),
                    "insights_generated": len(insights),
                    "top_insights": len(actionable_insights),
                    "data_date": self.portfolio_data.get("date", "unknown")
                }
            )
            
        except Exception as e:
            logger.error(f"Error generating insights: {e}")
            return NarratorResponse(
                response=f"Error generating portfolio insights: {str(e)}",
                metadata={
                    "ui_cards": [],
                    "error": str(e)
                }
            )
    
    def _calculate_kpis(self) -> List[Dict[str, Any]]:
        """
        Calculate KPIs using formulas from rules/narrator.yml
        
        Returns:
            List of KPI calculations with current/previous values
        """
        kpi_results = []
        kpis = self.narrator_rules.get("kpis", {})
        
        for segment in self.portfolio_data.get("segments", []):
            platform = segment["platform"]
            
            for kpi_name, kpi_config in kpis.items():
                try:
                    # Get current and previous values
                    current_value = segment.get(kpi_name)
                    previous_value = segment.get("previous_values", {}).get(kpi_name)
                    
                    if current_value is not None and previous_value is not None:
                        # Calculate delta
                        delta = current_value - previous_value
                        delta_percent = (delta / previous_value) * 100 if previous_value != 0 else 0
                        
                        # Calculate confidence based on data completeness
                        confidence = self._calculate_confidence(segment, kpi_name, kpi_config)
                        
                        kpi_results.append({
                            "platform": platform,
                            "metric": kpi_name,
                            "current_value": current_value,
                            "previous_value": previous_value,
                            "delta": delta,
                            "delta_percent": delta_percent,
                            "confidence": confidence,
                            "formula": kpi_config.get("formula", ""),
                            "caveats": kpi_config.get("caveats", ""),
                            "thresholds": kpi_config.get("thresholds", {})
                        })
                        
                except Exception as e:
                    logger.warning(f"Error calculating KPI {kpi_name} for {platform}: {e}")
                    continue
        
        logger.info(f"Calculated {len(kpi_results)} KPI results")
        return kpi_results
    
    def _calculate_confidence(self, segment: Dict[str, Any], kpi_name: str, kpi_config: Dict[str, Any]) -> float:
        """Calculate confidence score based on data completeness and reliability"""
        confidence_factors = []
        
        # Data completeness
        required_fields = ["total_apps", "total_txn", "total_balance", "total_accounts"]
        completeness = sum(1 for field in required_fields if segment.get(field, 0) > 0) / len(required_fields)
        confidence_factors.append(completeness)
        
        # Sample size (higher sample = higher confidence)
        total_apps = segment.get("total_apps", 0)
        sample_score = min(total_apps / 10000, 1.0) if total_apps > 0 else 0.5
        confidence_factors.append(sample_score)
        
        # Threshold alignment (values in expected ranges)
        thresholds = kpi_config.get("thresholds", {})
        current_value = segment.get(kpi_name, 0)
        if thresholds:
            low = thresholds.get("low", 0)
            high = thresholds.get("high", 1)
            if low <= current_value <= high:
                confidence_factors.append(0.9)
            else:
                confidence_factors.append(0.6)
        else:
            confidence_factors.append(0.7)
        
        return sum(confidence_factors) / len(confidence_factors)
    
    def _generate_insights(self, kpi_results: List[Dict[str, Any]]) -> List[Insight]:
        """
        Generate insights from KPI calculations
        
        Args:
            kpi_results: List of KPI calculation results
            
        Returns:
            List of insights with impact scores
        """
        insights = []
        
        for kpi_data in kpi_results:
            try:
                # Calculate impact score based on delta magnitude and business importance
                impact_score = self._calculate_impact_score(kpi_data)
                
                # Only create insights for significant changes
                if abs(kpi_data["delta_percent"]) >= 5.0 or impact_score >= 0.6:
                    insight = Insight(
                        metric=f"{kpi_data['platform']}_{kpi_data['metric']}",
                        value=kpi_data["current_value"],
                        delta=kpi_data["delta"],
                        delta_percent=kpi_data["delta_percent"],
                        confidence=kpi_data["confidence"],
                        impact_score=impact_score,
                        total_score=0.0,  # Will be calculated in ranking
                        action="",        # Will be added later
                        target_agent="",  # Will be added later  
                        rationale=f"{kpi_data['metric']} changed {kpi_data['delta_percent']:.1f}% for {kpi_data['platform']}"
                    )
                    insights.append(insight)
                    
            except Exception as e:
                logger.warning(f"Error generating insight for {kpi_data.get('metric', 'unknown')}: {e}")
                continue
        
        logger.info(f"Generated {len(insights)} insights from {len(kpi_results)} KPIs")
        return insights
    
    def _calculate_impact_score(self, kpi_data: Dict[str, Any]) -> float:
        """Calculate business impact score for a KPI change"""
        metric = kpi_data["metric"]
        delta_percent = abs(kpi_data["delta_percent"])
        platform = kpi_data["platform"]
        
        # Base impact from change magnitude
        magnitude_score = min(delta_percent / 20.0, 1.0)  # Cap at 20% change
        
        # Business importance weights
        importance_weights = {
            "approval_rate": 0.9,    # High impact - affects acquisition
            "charge_off_rate": 0.95, # Very high impact - affects losses
            "promo_uptake": 0.7,     # Medium-high impact - affects revenue  
            "revolve_rate": 0.8,     # High impact - affects profitability
            "funnel_conversion": 0.6, # Medium impact - affects efficiency
            "acquisition_cost": 0.7, # Medium-high impact - affects unit economics
            "portfolio_yield": 0.85  # High impact - affects revenue
        }
        
        business_weight = importance_weights.get(metric, 0.5)
        
        # Platform importance (higher volume = higher impact)
        platform_weights = {"digital": 1.0, "home_auto": 0.8, "carecredit": 0.7}
        platform_weight = platform_weights.get(platform, 0.5)
        
        # Direction matters (negative changes in good metrics = higher impact)
        direction_multiplier = 1.0
        if metric in ["approval_rate", "promo_uptake", "revolve_rate", "funnel_conversion", "portfolio_yield"]:
            # Good metrics - declining is worse
            if kpi_data["delta"] < 0:
                direction_multiplier = 1.2
        elif metric in ["charge_off_rate", "acquisition_cost"]:
            # Bad metrics - increasing is worse  
            if kpi_data["delta"] > 0:
                direction_multiplier = 1.2
        
        impact_score = magnitude_score * business_weight * platform_weight * direction_multiplier
        return min(impact_score, 1.0)
    
    def _rank_insights(self, insights: List[Insight]) -> List[Insight]:
        """
        Rank insights by weighted score: impact (0.6) + confidence (0.4)
        
        Args:
            insights: List of insights to rank
            
        Returns:
            List of insights sorted by total score (highest first)
        """
        weights = self.narrator_rules.get("insight_ranking", {}).get("weights", {})
        impact_weight = weights.get("impact", 0.6)
        confidence_weight = weights.get("confidence", 0.4)
        
        for insight in insights:
            insight.total_score = (insight.impact_score * impact_weight + 
                                 insight.confidence * confidence_weight)
        
        ranked_insights = sorted(insights, key=lambda x: x.total_score, reverse=True)
        logger.info(f"Ranked {len(ranked_insights)} insights, top score: {ranked_insights[0].total_score:.2f}")
        
        return ranked_insights
    
    def _add_action_suggestions(self, top_insights: List[Insight]) -> List[Insight]:
        """
        Add action suggestions linking to imagegen or offer agents
        
        Args:
            top_insights: Top ranked insights
            
        Returns:
            Insights with action suggestions added
        """
        action_rules = self.narrator_rules.get("action_suggestions", {})
        
        for insight in top_insights:
            # Extract base metric name (remove platform prefix)
            base_metric = insight.metric.split("_", 1)[-1]
            current_value = insight.value
            
            # Determine action based on metric performance
            action_key = None
            if base_metric == "approval_rate" and current_value < 0.5:
                action_key = "low_approval_rate"
            elif base_metric == "promo_uptake" and current_value < 0.3:
                action_key = "low_promo_uptake"
            elif base_metric == "charge_off_rate" and current_value > 0.02:
                action_key = "high_charge_off"
            elif base_metric == "funnel_conversion" and current_value < 0.3:
                action_key = "low_funnel_conversion"
            
            if action_key and action_key in action_rules:
                rule = action_rules[action_key]
                insight.action = rule["action"]
                insight.target_agent = rule["target_agent"]
                insight.rationale += f" ‚Üí {rule['rationale']}"
            else:
                # Default actions based on trend
                if insight.delta < 0:
                    insight.action = "launch_asset"
                    insight.target_agent = "imagegen"
                    insight.rationale += " ‚Üí Create promotional materials to reverse trend"
                else:
                    insight.action = "monitor"
                    insight.target_agent = "narrator"
                    insight.rationale += " ‚Üí Continue monitoring performance"
        
        return top_insights
    
    def _generate_response_text(self, insights: List[Insight]) -> str:
        """
        Generate response text: 2-4 bullets with numbers + 1-2 "try next"
        
        Args:
            insights: Top actionable insights
            
        Returns:
            Response text with key findings and next actions
        """
        response_parts = []
        
        # Header
        response_parts.append("**üìä Portfolio Insights & Action Items**")
        response_parts.append("")
        
        # Key insights (2-4 bullets with numbers)
        insights_to_show = insights[:4]
        for i, insight in enumerate(insights_to_show, 1):
            platform = insight.metric.split("_")[0]
            metric_name = insight.metric.split("_", 1)[1].replace("_", " ").title()
            
            # Format the insight with numbers
            direction = "‚Üë" if insight.delta > 0 else "‚Üì"
            response_parts.append(
                f"**{i}. {platform.title()} {metric_name}: {insight.value:.1%} {direction}**"
            )
            response_parts.append(
                f"   Changed {insight.delta_percent:+.1f}% ‚Ä¢ Impact: {insight.impact_score:.2f} ‚Ä¢ Confidence: {insight.confidence:.2f}"
            )
            response_parts.append("")
        
        # Try next actions (1-2 suggestions)
        response_parts.append("**üéØ Try Next:**")
        
        action_suggestions = []
        for insight in insights_to_show[:2]:  # Top 2 actions
            if insight.action == "launch_asset":
                action_suggestions.append(f"Launch {insight.target_agent} asset for {insight.metric.split('_')[0]} performance")
            elif insight.action == "promo_tuning":
                action_suggestions.append(f"Optimize {insight.target_agent} promotional terms")
            elif insight.action == "portfolio_review":
                action_suggestions.append(f"Review {insight.target_agent} risk policies")
        
        # Deduplicate and add
        unique_actions = list(dict.fromkeys(action_suggestions))
        for i, action in enumerate(unique_actions[:2], 1):
            response_parts.append(f"{i}. {action}")
        
        return "\n".join(response_parts)
    
    def _build_insight_ui_cards(self, insights: List[Insight]) -> List[Dict[str, Any]]:
        """
        Build UI cards for insights
        
        Args:
            insights: List of insights
            
        Returns:
            List of UI cards for metadata
        """
        ui_cards = []
        
        for insight in insights:
            platform = insight.metric.split("_")[0]
            metric_name = insight.metric.split("_", 1)[1]
            
            ui_cards.append({
                "type": "insight",
                "platform": platform,
                "metric": metric_name,
                "value": round(insight.value, 4),
                "delta": round(insight.delta, 4),
                "delta_percent": round(insight.delta_percent, 1),
                "confidence": round(insight.confidence, 2),
                "impact_score": round(insight.impact_score, 2),
                "total_score": round(insight.total_score, 2),
                "action": insight.action,
                "target_agent": insight.target_agent,
                "rationale": insight.rationale
            })
        
        return ui_cards
    
    # Compatibility methods for supervisor integration
    def process_question(self, query: str) -> NarratorResponse:
        """
        Process narrator question for supervisor integration (legacy method)
        
        Args:
            query: User query about portfolio insights
            
        Returns:
            NarratorResponse with insights
        """
        return self.generate_insights(query)
    
    def process_query(self, query: str) -> Dict[str, Any]:
        """
        Process narrator query for supervisor integration
        
        Args:
            query: User query about portfolio insights
            
        Returns:
            Dict with response, metadata, confidence, sources
        """
        try:
            # Analyze query to determine response type
            query_analysis = self._analyze_query(query)
            
            if query_analysis["needs_kpi"]:
                result = self.generate_insights(query)
                return {
                    "response": result.response,
                    "metadata": result.metadata,
                    "confidence": 0.8,
                    "sources": []
                }
            else:
                # Generate conversational response for non-KPI queries
                result = self._handle_general_question(query, query_analysis)
                return {
                    "response": result,
                    "metadata": {"ui_cards": [], "query_type": "general"},
                    "confidence": 0.8,
                    "sources": []
                }
            
        except Exception as e:
            logger.error(f"Narrator process_query error: {e}")
            return {
                "response": f"Error processing query: {str(e)}",
                "confidence": 0.2,
                "sources": [],
                "metadata": {"error": str(e)}
            }
    
    def _analyze_query(self, query: str) -> Dict[str, Any]:
        """
        Use LLM to analyze the query and determine response type
        
        Args:
            query: User query
            
        Returns:
            Dict with query analysis results
        """
        try:
            system_prompt = """You are a query classifier for a Portfolio Intelligence Narrator. 
            
            Analyze the user's query and determine what type of response they need.
            
            Response types:
            1. KPI_ANALYSIS: User wants to see actual portfolio metrics, KPIs, performance data, analytics dashboard
            2. GENERAL_QUESTION: User has general questions, wants explanations, asking about capabilities, greeting, etc.
            
            Examples of KPI_ANALYSIS queries:
            - "Show me portfolio performance"
            - "What are the current metrics?"
            - "How is our business doing?"
            - "Generate insights from the data"
            - "I need a performance report"
            - "What are the KPIs?"
            
            Examples of GENERAL_QUESTION queries:
            - "Hello, what can you do?"
            - "What is portfolio analysis?"
            - "How do you calculate metrics?"
            - "Explain what you do"
            - "What are your capabilities?"
            - "Help me understand analytics"
            
            Respond with ONLY a JSON object:
            {"response_type": "KPI_ANALYSIS|GENERAL_QUESTION", "confidence": 0.85, "reasoning": "brief explanation"}"""
            
            messages = [{"role": "user", "content": f"Classify this query: {query}"}]
            response = chat(messages, system=system_prompt)
            
            # Parse LLM response
            import json
            try:
                # Clean the response to extract JSON
                response_clean = response.strip()
                if response_clean.startswith('```json'):
                    response_clean = response_clean.replace('```json', '').replace('```', '').strip()
                elif response_clean.startswith('```'):
                    lines = response_clean.split('\n')
                    response_clean = '\n'.join(lines[1:-1]).strip()
                
                result = json.loads(response_clean)
                
                needs_kpi = result.get("response_type") == "KPI_ANALYSIS"
                confidence = result.get("confidence", 0.7)
                reasoning = result.get("reasoning", "LLM classification")
                
                return {
                    "needs_kpi": needs_kpi,
                    "confidence": confidence,
                    "reasoning": reasoning,
                    "query_type": result.get("response_type", "GENERAL_QUESTION").lower()
                }
                
            except (json.JSONDecodeError, KeyError) as e:
                logger.warning(f"Failed to parse LLM classification response: {e}")
                # Fallback to conservative classification
                return {
                    "needs_kpi": False,
                    "confidence": 0.3,
                    "reasoning": "Classification parsing failed, defaulting to general question",
                    "query_type": "general_question"
                }
                
        except Exception as e:
            logger.error(f"Error in LLM query analysis: {e}")
            # Conservative fallback
            return {
                "needs_kpi": False,
                "confidence": 0.3,
                "reasoning": "LLM analysis failed, defaulting to general question",
                "query_type": "general_question"
            }
    
    def _handle_general_question(self, query: str, analysis: Dict[str, Any]) -> str:
        """
        Handle general questions using LLM
        
        Args:
            query: User query
            analysis: Query analysis results
            
        Returns:
            Conversational response
        """
        try:
            system_prompt = """You are a Portfolio Intelligence Narrator, a financial analytics specialist. 
            
            You help users understand portfolio performance, business metrics, and actionable insights.
            
            IMPORTANT: Format your response using proper markdown:
            - Use # for main titles
            - Use ## for section headers
            - Use ### for subsections
            - Use bullet points (-) for lists
            - Use **bold** for emphasis
            - Use proper paragraph spacing with empty lines
            - Keep responses conversational but professional
            
            Your capabilities include:
            - Analyzing portfolio performance metrics and KPIs
            - Generating actionable business insights with impact scores
            - Creating data-driven recommendations
            - Identifying revenue optimization opportunities
            - Providing trend analysis and forecasting
            
            If users want to see actual performance data, analytics, or KPIs, tell them to ask specifically about:
            "portfolio performance", "business metrics", "KPI dashboard", or "generate insights"."""
            
            messages = [{"role": "user", "content": query}]
            response = chat(messages, system=system_prompt)
            
            return response
            
        except Exception as e:
            logger.error(f"Error handling general question: {e}")
            return f"""# Portfolio Intelligence Narrator

I'm here to help you analyze portfolio performance and generate actionable business insights.

## What I can do:

- **Analyze KPIs and metrics** - Portfolio performance, growth trends, conversion rates
- **Generate insights** - Data-driven recommendations with impact scores  
- **Create reports** - Business intelligence dashboards and summaries
- **Identify opportunities** - Revenue optimization and improvement areas

## Get Started:

Ask me about "portfolio performance" or "business metrics" to see detailed analytics, or ask me any specific question about your business data.

> *To see your current KPI dashboard and insights, just ask: "Show me portfolio performance"*"""



================================================
FILE: app/agents/offerpilot.py
================================================
"""
OfferPilot - Marketplace Discovery ‚Üí Financing ‚Üí Apply
Conversational shopping with grounded products, promo financing, and credit pre-qualification
"""

import json
import logging
import math
import hashlib
import yaml
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.rag.core import retrieve
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Enhanced Pydantic models for rules-aware financing
class PromoOffer(BaseModel):
    type: str  # "equal_payment" or "deferred_interest"
    months: int
    est_monthly: Optional[float] = None
    disclosure_key: str
    min_purchase: int = 0

class ProductCard(BaseModel):
    title: str
    price: int  # in cents
    partner: str
    promos: List[PromoOffer]
    warnings: List[str] = []

class PrequalResult(BaseModel):
    status: str  # "eligible", "uncertain", "ineligible"
    explanation: str

class OfferPilotResponse(BaseModel):
    response: str  # 3-5 lines summary
    metadata: Dict[str, Any]  # Contains ui_cards, disclosures, handoffs

class Citation(BaseModel):
    source: str
    snippet: str

@dataclass
class UserStub:
    """Mock user data for credit screening"""
    credit_score: int = 720
    income: float = 75000.0
    debt_to_income: float = 0.25
    employment_status: str = "employed"
    years_at_job: int = 3

class OfferPilot:
    """
    Marketplace discovery agent with financing options and credit pre-qualification
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize OfferPilot with RAG components and rules-based financing"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        self.rules_loader = rules_loader
        
        # Load rules from centralized loader or fallback to local loading
        if rules_loader:
            self.promotions_rules = rules_loader.get_rules('promotions') or {}
            self.disclosures_rules = rules_loader.get_rules('disclosures') or {}
            self.prequalification_rules = rules_loader.get_rules('prequalification') or {}
            logger.info("OfferPilot loaded rules from centralized rules loader")
        else:
            self._load_rules()
        
        # Load data files
        self._load_marketplace_data()
        self._load_financing_data()
    
    def _load_rules(self):
        """Load rules from synchrony-demo-rules-repo"""
        try:
            rules_base = Path("synchrony-demo-rules-repo/rules")
            
            # Load promotions rules
            with open(rules_base / "promotions.yml", 'r') as f:
                self.promotions_rules = yaml.safe_load(f)
            
            # Load disclosures
            with open(rules_base / "disclosures.yml", 'r') as f:
                self.disclosures_rules = yaml.safe_load(f)
            
            # Load prequalification rules
            with open(rules_base / "prequalification.yml", 'r') as f:
                self.prequalification_rules = yaml.safe_load(f)
                
            logger.info("Loaded rules from synchrony-demo-rules-repo")
        except Exception as e:
            logger.error(f"Failed to load rules: {e}")
            # Fallback to empty rules
            self.promotions_rules = {"partners": [], "generic_defaults": {"equal_payment_months": [6, 12, 18], "deferred_interest_months": [6, 12]}}
            self.disclosures_rules = {"disclosures": {}}
            self.prequalification_rules = {"demo_scoring": {"buckets": []}}
    
    def _load_marketplace_data(self):
        """Load marketplace catalog from rules repo"""
        try:
            # First try centralized rules loader
            if self.rules_loader:
                products_data = self.rules_loader.get_fixture('products')
                merchants_data = self.rules_loader.get_fixture('merchants')
                
                if products_data and merchants_data:
                    self.marketplace_products = products_data
                    self.merchants_data = {m["partner_id"]: m for m in merchants_data}
                    logger.info(f"Loaded {len(self.marketplace_products)} products from centralized rules loader")
                    return
            
            # Fallback to direct file access
            products_path = Path("synchrony-demo-rules-repo/fixtures/products.json")
            merchants_path = Path("synchrony-demo-rules-repo/fixtures/merchants.json")
            
            if products_path.exists():
                with open(products_path, 'r') as f:
                    self.marketplace_products = json.load(f)
                with open(merchants_path, 'r') as f:
                    self.merchants_data = {m["partner_id"]: m for m in json.load(f)}
                logger.info(f"Loaded {len(self.marketplace_products)} products from rules repo")
            else:
                # Fallback to original catalog
                catalog_path = Path("app/data/marketplace_catalog.json")
                with open(catalog_path, 'r') as f:
                    data = json.load(f)
                    self.marketplace_products = data["products"]
                    self.merchants_data = {}
                logger.info(f"Loaded {len(self.marketplace_products)} products from fallback catalog")
                
        except Exception as e:
            logger.error(f"Failed to load marketplace data: {e}")
            self.marketplace_products = []
            self.merchants_data = {}
    
    def _load_financing_data(self):
        """Load financing offers from JSON file"""
        try:
            offers_path = Path("app/data/financing_offers.json")
            with open(offers_path, 'r') as f:
                data = json.load(f)
                self.financing_offers = {offer["id"]: offer for offer in data["offers"]}
                self.merchant_offers = data["merchant_offers"]
                self.offers_metadata = data["metadata"]
            logger.info(f"Loaded {len(self.financing_offers)} financing offers")
        except Exception as e:
            logger.error(f"Failed to load financing offers: {e}")
            self.financing_offers = {}
            self.merchant_offers = {}
            self.offers_metadata = {}
    
    def process_query(self, query: str, budget: Optional[float] = None, user_type: str = "consumer", user_id: str = "demo_user") -> OfferPilotResponse:
        """
        Enhanced rules-aware processing pipeline for OfferPilot
        
        Args:
            query: User search query
            budget: Optional budget constraint  
            user_type: consumer or partner
            user_id: User identifier for deterministic prequalification
            
        Returns:
            OfferPilotResponse with structured UI cards, disclosures, and handoffs
        """
        try:
            logger.info(f"Processing rules-aware OfferPilot query: {query}, user_type: {user_type}")
            
            # Step 1: Search and filter products
            matching_products = self._search_products(query, budget)
            if not matching_products:
                return self._empty_response("No products found matching your query.")
            
            # Step 2: Generate product cards with financing options
            ui_cards = []
            all_disclosures = set()
            
            for product in matching_products[:3]:  # Top 3 products
                card, disclosures = self._create_product_card(product)
                ui_cards.append(card)
                all_disclosures.update(disclosures)
            
            # Step 3: Deterministic prequalification
            if ui_cards:
                avg_price = sum(card.price for card in ui_cards) / len(ui_cards)
                prequal = self._deterministic_prequalification(user_id, avg_price)
            else:
                prequal = PrequalResult(status="ineligible", explanation="No products available")
            
            # Step 4: Generate response summary
            response_text = self._generate_response_summary(ui_cards, prequal)
            
            # Step 5: Check for handoffs
            handoffs = self._detect_handoffs(query)
            
            return OfferPilotResponse(
                response=response_text,
                metadata={
                    "ui_cards": [card.dict() for card in ui_cards],
                    "disclosures": list(all_disclosures),
                    "handoffs": handoffs,
                    "prequalification": prequal.dict()
                }
            )
            
        except Exception as e:
            logger.error(f"Error in OfferPilot processing: {e}")
            return self._empty_response("Unable to process your request. Please try again.")
    
    def marketplace_search(self, query: str, max_results: int = 8) -> List[Dict[str, Any]]:
        """
        Search marketplace catalog for products matching query
        
        Args:
            query: Search query
            max_results: Maximum number of results to return
            
        Returns:
            List of matching products
        """
        query_lower = query.lower()
        results = []
        
        for product in self.marketplace_products:
            score = 0
            
            # Title matching
            if any(word in product["title"].lower() for word in query_lower.split()):
                score += 3
            
            # Category matching
            if query_lower in product["category"].lower():
                score += 2
            
            # Features matching (if features field exists)
            if "features" in product and product["features"]:
                for feature in product["features"]:
                    if any(word in feature.lower() for word in query_lower.split()):
                        score += 1
            
            # Description matching (if description field exists)
            if "description" in product and product["description"]:
                if any(word in product["description"].lower() for word in query_lower.split()):
                    score += 1
            
            if score > 0:
                product_copy = product.copy()
                product_copy["relevance_score"] = score
                results.append(product_copy)
        
        # Sort by relevance score
        results.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        return results[:max_results]
    
    def offers_lookup(self, merchant: str, amount: float) -> List[Dict[str, Any]]:
        """
        Look up financing offers available for merchant and amount
        
        Args:
            merchant: Merchant name
            amount: Purchase amount
            
        Returns:
            List of applicable financing offers
        """
        applicable_offers = []
        
        # Get offers for this merchant
        merchant_offer_ids = self.merchant_offers.get(merchant, [])
        
        for offer_id in merchant_offer_ids:
            offer = self.financing_offers.get(offer_id)
            if not offer:
                continue
            
            # Check if amount qualifies for this offer
            if (amount >= offer["min_purchase"] and 
                amount <= offer["max_purchase"]):
                applicable_offers.append(offer)
        
        # Sort by APR (0% first, then ascending)
        applicable_offers.sort(key=lambda x: (x["apr"] > 0, x["apr"]))
        
        return applicable_offers
    
    def payments_simulate(self, amount: float, months: int, apr: float) -> Dict[str, Any]:
        """
        Simulate payment calculations for financing
        
        Args:
            amount: Principal amount
            months: Number of months
            apr: Annual percentage rate
            
        Returns:
            Payment simulation results
        """
        if apr == 0:
            # 0% APR - simple equal payments
            monthly = round(amount / months, 2)
            total_cost = amount
        else:
            # Standard loan calculation
            monthly_rate = apr / 100 / 12
            if monthly_rate == 0:
                monthly = round(amount / months, 2)
            else:
                monthly = round(
                    amount * (monthly_rate * (1 + monthly_rate) ** months) / 
                    ((1 + monthly_rate) ** months - 1), 2
                )
            total_cost = round(monthly * months, 2)
        
        payoff_date = datetime.now() + timedelta(days=months * 30)
        
        return {
            "monthly": monthly,
            "total_cost": total_cost,
            "payoff_date": payoff_date.strftime("%Y-%m-%d")
        }
    
    def credit_quickscreen(self, user_stub: UserStub) -> Dict[str, Any]:
        """
        Mock credit pre-qualification screening (deterministic)
        
        Args:
            user_stub: User information for screening
            
        Returns:
            Pre-qualification result
        """
        # Deterministic scoring based on user attributes
        score = 0
        reasons = []
        
        # Credit score evaluation
        if user_stub.credit_score >= 750:
            score += 40
        elif user_stub.credit_score >= 700:
            score += 30
        elif user_stub.credit_score >= 650:
            score += 20
        else:
            reasons.append("Credit score below preferred range")
        
        # Income evaluation
        if user_stub.income >= 60000:
            score += 25
        elif user_stub.income >= 40000:
            score += 15
        else:
            reasons.append("Income below minimum threshold")
        
        # Debt-to-income ratio
        if user_stub.debt_to_income <= 0.3:
            score += 20
        elif user_stub.debt_to_income <= 0.4:
            score += 10
        else:
            reasons.append("High debt-to-income ratio")
        
        # Employment stability
        if user_stub.employment_status == "employed" and user_stub.years_at_job >= 2:
            score += 15
        elif user_stub.employment_status == "employed":
            score += 10
        else:
            reasons.append("Employment history concerns")
        
        # Determine eligibility
        eligible = score >= 70
        
        if eligible:
            reason = "Pre-qualified based on credit profile"
        else:
            reason = "; ".join(reasons) if reasons else "Does not meet minimum requirements"
        
        return {
            "eligible": eligible,
            "reason": reason,
            "score": score
        }
    
    def _rank_items(self, items: List[ProductCard], query: str, budget: Optional[float]) -> List[ProductCard]:
        """
        Rank items by relevance √ó affordability √ó promo fit
        
        Args:
            items: List of product items with offers
            query: Original search query
            budget: Budget constraint
            
        Returns:
            Ranked list of items
        """
        scored_items = []
        
        for item in items:
            # Relevance score (based on title/query match)
            relevance = sum(1 for word in query.lower().split() 
                          if word in item.title.lower()) / len(query.split())
            
            # Affordability score (lower price = higher score)
            if budget:
                budget_cents = budget * 100
                affordability = max(0, (budget_cents - item.price) / budget_cents)
            else:
                # Use relative affordability within result set
                max_price = max(i.price for i in items)
                affordability = 1 - (item.price / max_price) if max_price > 0 else 0
            
            # Promo fit score (Equal Payment and DI both score well)
            promo_score = 0
            if item.promos:
                # Score based on number of promo options available
                promo_score = min(1.0, len(item.promos) * 0.3)
                # Bonus for having equal payment options (easier to understand)
                if any(promo.type == "equal_payment" for promo in item.promos):
                    promo_score += 0.2
            
            # Combined score
            combined_score = (relevance * 0.4 + affordability * 0.3 + promo_score * 0.3)
            
            scored_items.append((item, combined_score))
        
        # Sort by combined score
        scored_items.sort(key=lambda x: x[1], reverse=True)
        
        return [item for item, score in scored_items]
    
    def _get_promotional_citations(self, items: List[ProductCard]) -> List[Citation]:
        """
        Get promotional terms citations from knowledge base
        
        Args:
            items: List of product items
            
        Returns:
            List of citations
        """
        citations = []
        
        if not all([self.retriever, self.embedder]):
            logger.warning("RAG components not available for citations")
            return citations
        
        try:
            # Create query for promotional terms
            offer_types = set()
            for item in items:
                for promo in item.promos:
                    if promo.type == "deferred_interest":
                        offer_types.add("0% APR deferred interest financing")
                    elif promo.type == "equal_payment":
                        offer_types.add("equal payment financing")
            
            if offer_types:
                query = f"promotional terms {' '.join(offer_types)}"
                
                # Retrieve relevant terms documents
                results = retrieve(self.retriever, self.embedder, query, k=3)
                
                for result in results:
                    citations.append(Citation(
                        source=result.get("filename", "Promotional Terms"),
                        snippet=result.get("snippet", "")[:200] + "..."
                    ))
            
            # If no local terms found, search web for Synchrony terms
            if not citations:
                logger.info("No local promotional terms found, searching web...")
                try:
                    web_docs = web_search_into_docstore(
                        self.docstore, 
                        self.embedder, 
                        "0% APR equal monthly payments Synchrony terms",
                        max_results=2
                    )
                    
                    # Re-retrieve after adding web content
                    if web_docs:
                        results = retrieve(self.retriever, self.embedder, 
                                         "promotional financing terms", k=2)
                        
                        for result in results:
                            citations.append(Citation(
                                source=result.get("filename", "Web Search"),
                                snippet=result.get("snippet", "")[:200] + "..."
                            ))
                            
                except Exception as e:
                    logger.warning(f"Web search for terms failed: {e}")
            
        except Exception as e:
            logger.error(f"Error retrieving promotional citations: {e}")
        
        return citations
    
    # New rules-aware helper methods
    def _search_products(self, query: str, budget: Optional[float] = None) -> List[Dict[str, Any]]:
        """Search products using existing marketplace_search but with budget filter"""
        results = self.marketplace_search(query, max_results=5)
        
        if budget:
            # Convert budget from dollars to cents for comparison
            budget_cents = int(budget * 100)
            results = [p for p in results if p.get("price", 0) <= budget_cents]
        
        return results
    
    def _create_product_card(self, product: Dict[str, Any]) -> tuple[ProductCard, List[str]]:
        """Create a ProductCard with financing options based on rules"""
        partner_id = product.get("partner_id", "unknown")
        category = product.get("category", "")
        price = product.get("price", 0)
        
        # Get applicable promotions for this partner/category
        promos = []
        disclosures_used = []
        warnings = []
        
        # Check partner-specific promotions
        partner_promos = self._get_partner_promotions(partner_id, category, price)
        
        if partner_promos:
            for promo_config in partner_promos:
                promo = PromoOffer(
                    type=promo_config["type"],
                    months=promo_config["months"],
                    disclosure_key=promo_config["disclosure_key"],
                    min_purchase=promo_config["min_purchase"]
                )
                
                # Calculate estimated monthly payment
                if promo_config["type"] == "equal_payment":
                    promo.est_monthly = price / promo_config["months"]
                else:  # deferred_interest
                    promo.est_monthly = 0  # No payments during promo period
                    warnings.append("Deferred Interest: Interest accrues if not paid in full during promotional period")
                
                promos.append(promo)
                disclosures_used.append(promo_config["disclosure_key"])
        else:
            # Use generic defaults
            defaults = self.promotions_rules["generic_defaults"]
            
            # Add Equal Payment options
            for months in defaults["equal_payment_months"]:
                if price >= 10000:  # Minimum $100 threshold
                    promos.append(PromoOffer(
                        type="equal_payment",
                        months=months,
                        est_monthly=price / months,
                        disclosure_key="equal_payment_generic"
                    ))
                    disclosures_used.append("equal_payment_generic")
            
            # Add Deferred Interest options  
            for months in defaults["deferred_interest_months"]:
                if price >= 10000:
                    promos.append(PromoOffer(
                        type="deferred_interest", 
                        months=months,
                        est_monthly=0,
                        disclosure_key="deferred_interest_generic"
                    ))
                    disclosures_used.append("deferred_interest_generic")
                    warnings.append("DI accrues if not paid in full within promotional period")
        
        # Get merchant name
        merchant_name = self.merchants_data.get(partner_id, {}).get("name", partner_id.title())
        
        card = ProductCard(
            title=product.get("title", ""),
            price=price,
            partner=merchant_name,
            promos=promos,
            warnings=warnings
        )
        
        return card, disclosures_used
    
    def _get_partner_promotions(self, partner_id: str, category: str, price: int) -> List[Dict[str, Any]]:
        """Get partner-specific promotions based on rules"""
        partner_config = None
        for partner in self.promotions_rules["partners"]:
            if partner["partner_id"] == partner_id:
                partner_config = partner
                break
        
        if not partner_config:
            return []
        
        # Check category eligibility
        if category not in partner_config.get("categories_allowed", []):
            return []
        
        # Filter promotions by minimum purchase
        applicable_promos = []
        for promo in partner_config.get("promos", []):
            if price >= promo.get("min_purchase", 0):
                applicable_promos.append(promo)
        
        return applicable_promos
    
    def _deterministic_prequalification(self, user_id: str, price: float) -> PrequalResult:
        """Deterministic prequalification based on stable hash"""
        # Create stable hash from user_id and price
        hash_input = f"{user_id}:{int(price)}"
        hash_value = int(hashlib.md5(hash_input.encode()).hexdigest()[:8], 16)
        
        # Use hash to determine bucket
        buckets = self.prequalification_rules["demo_scoring"]["buckets"]
        
        for bucket in buckets:
            if price <= bucket["price_upper"]:
                # Use hash to add some variation within bucket
                if bucket["name"] == "eligible":
                    # 80% eligible, 20% uncertain within eligible range
                    status = "eligible" if hash_value % 10 < 8 else "uncertain"
                elif bucket["name"] == "uncertain":
                    # 60% uncertain, 40% eligible within uncertain range  
                    status = "uncertain" if hash_value % 10 < 6 else "eligible"
                else:  # ineligible
                    status = "ineligible"
                    
                return PrequalResult(
                    status=status,
                    explanation=bucket["explanation"]
                )
        
        # Fallback
        return PrequalResult(status="ineligible", explanation="Above demo threshold")
    
    def _generate_response_summary(self, ui_cards: List[ProductCard], prequal: PrequalResult) -> str:
        """Generate 3-5 line response summary"""
        if not ui_cards:
            return "No products found matching your criteria."
        
        best_card = ui_cards[0]
        best_promo = best_card.promos[0] if best_card.promos else None
        
        summary = f"Found {len(ui_cards)} great options! "
        summary += f"Top pick: {best_card.title} for ${best_card.price/100:.2f} from {best_card.partner}. "
        
        if best_promo:
            if best_promo.type == "equal_payment":
                summary += f"Available: {best_promo.months}-month equal payments of ${best_promo.est_monthly/100:.2f}/month. "
            else:
                summary += f"Available: {best_promo.months}-month deferred interest (0% if paid in full). "
        
        if prequal.status == "eligible":
            summary += "‚úÖ You're prequalified!"
        elif prequal.status == "uncertain": 
            summary += "Additional info may be needed for approval."
        else:
            summary += "Higher amounts may require additional review."
            
        return summary
    
    def _detect_handoffs(self, query: str) -> List[str]:
        """Detect if query should be handed off to other agents"""
        handoffs = []
        
        query_lower = query.lower()
        
        # Check for dispute-related terms
        dispute_terms = ["double charged", "charged twice", "dispute", "chargeback", "refund", "unauthorized"]
        if any(term in query_lower for term in dispute_terms):
            handoffs.append("dispute")
        
        # Check for collections-related terms  
        collections_terms = ["can't pay", "hardship", "payment plan", "financial difficulty"]
        if any(term in query_lower for term in collections_terms):
            handoffs.append("collections")
        
        return handoffs
    
    def _empty_response(self, message: str) -> OfferPilotResponse:
        """Generate empty response with error message"""
        return OfferPilotResponse(
            response=message,
            metadata={
                "ui_cards": [],
                "disclosures": [],
                "handoffs": [],
                "prequalification": {"status": "ineligible", "explanation": "No evaluation performed"}
            }
        )

# Golden-path tests
def test_offerpilot():
    """Test OfferPilot with golden-path scenarios"""
    print("üß™ Testing OfferPilot Golden Paths")
    print("=" * 50)
    
    # Initialize OfferPilot (without RAG for basic testing)
    pilot = OfferPilot()
    
    test_cases = [
        {
            "name": "Desk under $600",
            "query": "office desk",
            "budget": 600.0,
            "expected_items": 2,  # Should find both desk options
            "expected_financing": True
        },
        {
            "name": "Laptop around $1000",
            "query": "laptop computer",
            "budget": 1200.0,
            "expected_items": 3,  # Should find laptop options
            "expected_financing": True
        },
        {
            "name": "Healthcare with CareCredit",
            "query": "dental treatment",
            "budget": None,
            "expected_items": 2,  # Should find dental services
            "expected_carecredit": True
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            result = pilot.process_query(case["query"], case["budget"])
            
            # Validate response structure
            assert isinstance(result, OfferPilotResponse)
            assert isinstance(result.items, list)
            assert isinstance(result.prequal, PrequalResult)
            assert isinstance(result.citations, list)
            
            # Check item count
            items_found = len(result.items)
            items_ok = items_found > 0
            
            # Check financing offers
            has_financing = any(len(item.offers) > 0 for item in result.items)
            
            # Check for CareCredit if healthcare query
            has_carecredit = False
            if case.get("expected_carecredit"):
                has_carecredit = any(
                    any("CARECREDIT" in offer.id for offer in item.offers)
                    for item in result.items
                )
            
            # Check pre-qualification
            prequal_ok = isinstance(result.prequal.eligible, bool)
            
            # Overall success
            success = (items_ok and 
                      (has_financing if case["expected_financing"] else True) and
                      (has_carecredit if case.get("expected_carecredit") else True) and
                      prequal_ok)
            
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"{i}. {case['name']}")
            print(f"   Query: '{case['query']}', Budget: {case['budget']}")
            print(f"   Items found: {items_found}")
            print(f"   Has financing: {has_financing}")
            print(f"   Pre-qualified: {result.prequal.eligible}")
            if case.get("expected_carecredit"):
                print(f"   Has CareCredit: {has_carecredit}")
            print(f"   Status: {status}")
            print()
            
            if success:
                passed += 1
                
        except Exception as e:
            print(f"{i}. {case['name']}: ‚ùå ERROR - {e}")
            print()
    
    print(f"OfferPilot Test Results: {passed}/{total} passed")
    return passed == total

if __name__ == "__main__":
    # Run tests
    success = test_offerpilot()
    print(f"\n{'üéâ All tests passed!' if success else '‚ö†Ô∏è Some tests failed.'}")



================================================
FILE: app/agents/trustshield.py
================================================
"""
TrustShield - Real-time Scam & PII Defense System
Comprehensive fraud detection, PII protection, and safety guidance
"""

import re
import logging
import hashlib
import math
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

from presidio_analyzer import AnalyzerEngine
from presidio_anonymizer import AnonymizerEngine
from presidio_anonymizer.entities import OperatorConfig

from app.llm.gemini import chat
from app.rag.core import retrieve

logger = logging.getLogger(__name__)

@dataclass
class ThreatEvidence:
    """Evidence of a potential threat"""
    type: str
    evidence: str
    confidence: float
    severity: str  # low, medium, high, critical

@dataclass
class SafetyGuidance:
    """Safety guidance for users"""
    label: str
    url: str

@dataclass
class Citation:
    """Citation from knowledge base"""
    source: str
    snippet: str

class TrustShield:
    """
    Advanced threat detection and PII protection system
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None, rules_loader=None):
        """Initialize TrustShield with optional RAG components for safety guidance"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        
        # Initialize Presidio engines
        try:
            self.analyzer = AnalyzerEngine()
            self.anonymizer = AnonymizerEngine()
            logger.info("Presidio engines initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Presidio engines: {e}")
            self.analyzer = None
            self.anonymizer = None
        
        # Scam detection patterns
        self.scam_patterns = self._initialize_scam_patterns()
        
        # High-entropy patterns for gift cards, etc.
        self.entropy_patterns = self._initialize_entropy_patterns()
    
    def scan(self, text: str, user_type: str = "consumer") -> Dict[str, Any]:
        """
        Comprehensive scan of text for threats, PII, and scams
        
        Args:
            text: Text to analyze
            user_type: consumer or partner (for logging only)
            
        Returns:
            Dictionary with decision, reasons, redacted text, next steps, and citations
        """
        try:
            logger.info(f"TrustShield scanning text for {user_type}: {text[:100]}...")
            
            # Initialize result structure
            result = {
                "decision": "pass",
                "reasons": [],
                "redacted_text": text,
                "next_step": None,
                "citations": []
            }
            
            # 1. PII Detection using Presidio
            pii_threats = self._detect_pii(text)
            result["reasons"].extend(pii_threats)
            
            # 2. Heuristic-based detection (regex patterns)
            heuristic_threats = self._detect_heuristic_threats(text)
            result["reasons"].extend(heuristic_threats)
            
            # 3. High-entropy detection (gift cards, etc.)
            entropy_threats = self._detect_high_entropy_patterns(text)
            result["reasons"].extend(entropy_threats)
            
            # 4. Scam phrase detection
            phrase_threats = self._detect_scam_phrases(text)
            result["reasons"].extend(phrase_threats)
            
            # 5. Gemini-based intent classification
            intent_threats = self._classify_intent_with_gemini(text)
            result["reasons"].extend(intent_threats)
            
            # 6. Determine overall decision based on threat levels
            decision, next_step = self._make_decision(result["reasons"])
            result["decision"] = decision
            result["next_step"] = next_step
            
            # 7. Get safety guidance citations if high risk
            if decision in ["block", "warn"]:
                result["citations"] = self._get_safety_citations(result["reasons"])
            
            # 8. Redact text if needed
            if decision != "block":
                result["redacted_text"] = self._redact_sensitive_content(text, result["reasons"])
            else:
                result["redacted_text"] = "[BLOCKED - High risk content detected]"
            
            logger.info(f"TrustShield decision: {decision} with {len(result['reasons'])} threats detected")
            return result
            
        except Exception as e:
            logger.error(f"Error in TrustShield scan: {e}")
            return {
                "decision": "warn",
                "reasons": [ThreatEvidence("system_error", str(e), 0.8, "medium")],
                "redacted_text": text,
                "next_step": {"label": "Contact Support", "url": "/support"},
                "citations": []
            }
    
    def _detect_pii(self, text: str) -> List[ThreatEvidence]:
        """Detect PII using Presidio analyzer"""
        threats = []
        
        if not self.analyzer:
            return threats
        
        try:
            # Analyze text for PII
            results = self.analyzer.analyze(
                text=text,
                language='en',
                entities=None  # Detect all supported entities
            )
            
            for result in results:
                # Map Presidio confidence to our threat levels
                if result.score >= 0.8:
                    severity = "high"
                elif result.score >= 0.6:
                    severity = "medium"
                else:
                    severity = "low"
                
                evidence_text = text[result.start:result.end]
                
                threats.append(ThreatEvidence(
                    type="pii_detected",
                    evidence=f"{result.entity_type}: {evidence_text}",
                    confidence=result.score,
                    severity=severity
                ))
            
        except Exception as e:
            logger.error(f"Error in PII detection: {e}")
        
        return threats
    
    def _detect_heuristic_threats(self, text: str) -> List[ThreatEvidence]:
        """Detect threats using regex patterns"""
        threats = []
        
        # Credit card patterns (Luhn algorithm validation)
        cc_matches = re.finditer(r'\b(?:\d{4}[-\s]?){3}\d{4}\b', text)
        for match in cc_matches:
            cc_number = re.sub(r'[-\s]', '', match.group())
            if self._validate_luhn(cc_number):
                threats.append(ThreatEvidence(
                    type="credit_card",
                    evidence=f"Credit card number detected: {match.group()}",
                    confidence=0.9,
                    severity="critical"
                ))
        
        # SSN patterns
        ssn_matches = re.finditer(r'\b\d{3}-?\d{2}-?\d{4}\b', text)
        for match in ssn_matches:
            threats.append(ThreatEvidence(
                type="ssn",
                evidence=f"SSN detected: {match.group()}",
                confidence=0.85,
                severity="critical"
            ))
        
        # CVV patterns (3-4 digits, context-aware)
        cvv_matches = re.finditer(r'\b(?:cvv|cvc|security code|card code)[\s:]*(\d{3,4})\b', text, re.IGNORECASE)
        for match in cvv_matches:
            threats.append(ThreatEvidence(
                type="cvv",
                evidence=f"CVV code detected: {match.group()}",
                confidence=0.9,
                severity="critical"
            ))
        
        return threats
    
    def _detect_high_entropy_patterns(self, text: str) -> List[ThreatEvidence]:
        """Detect high-entropy strings that might be gift card codes"""
        threats = []
        
        # Look for potential gift card codes (high entropy alphanumeric strings)
        potential_codes = re.findall(r'\b[A-Z0-9]{10,20}\b', text)
        
        for code in potential_codes:
            entropy = self._calculate_entropy(code)
            
            # High entropy suggests random generation (like gift card codes)
            if entropy > 3.5 and len(code) >= 12:
                # Check if it's in a suspicious context
                context_words = ["gift card", "card code", "redeem", "activation", "voucher"]
                context_found = any(word in text.lower() for word in context_words)
                
                confidence = 0.7 if context_found else 0.5
                severity = "high" if context_found else "medium"
                
                threats.append(ThreatEvidence(
                    type="gift_card_code",
                    evidence=f"Potential gift card code: {code}",
                    confidence=confidence,
                    severity=severity
                ))
        
        return threats
    
    def _detect_scam_phrases(self, text: str) -> List[ThreatEvidence]:
        """Detect common scam phrases"""
        threats = []
        text_lower = text.lower()
        
        # High-risk scam phrases
        high_risk_phrases = [
            "overpay and send gift cards",
            "refund via gift card",
            "wire money to",
            "send gift cards for refund",
            "pay with gift cards",
            "buy gift cards and send codes",
            "verification fee required",
            "advance fee required",
            "send money via western union",
            "send bitcoin for verification"
        ]
        
        # Medium-risk phrases
        medium_risk_phrases = [
            "urgent action required",
            "account will be closed",
            "verify your account immediately",
            "click here to verify",
            "suspended account",
            "unusual activity detected",
            "confirm your identity",
            "update payment information"
        ]
        
        # Check high-risk phrases
        for phrase in high_risk_phrases:
            if phrase in text_lower:
                threats.append(ThreatEvidence(
                    type="scam_phrase",
                    evidence=f"High-risk scam phrase detected: '{phrase}'",
                    confidence=0.9,
                    severity="critical"
                ))
        
        # Check medium-risk phrases
        for phrase in medium_risk_phrases:
            if phrase in text_lower:
                threats.append(ThreatEvidence(
                    type="phishing_phrase",
                    evidence=f"Phishing phrase detected: '{phrase}'",
                    confidence=0.7,
                    severity="medium"
                ))
        
        return threats
    
    def _classify_intent_with_gemini(self, text: str) -> List[ThreatEvidence]:
        """Use Gemini to classify intent for sophisticated threats"""
        threats = []
        
        try:
            system_prompt = """You are a fraud detection specialist. Analyze the following text and classify it into one of these categories:

Categories:
- refund_scam: Attempts to trick users into paying for fake refunds
- account_takeover: Attempts to gain unauthorized access to accounts  
- pii_risk: Requests for sensitive personal information
- safe: Normal, legitimate communication

Respond with ONLY a JSON object:
{"category": "category_name", "confidence": 0.85, "reasoning": "brief explanation"}

Focus on detecting sophisticated social engineering attempts."""

            user_message = f"Analyze this text: '{text}'"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            import json
            # Handle markdown-wrapped JSON responses
            response_text = response.strip()
            if response_text.startswith('```json'):
                # Extract JSON from markdown code block
                response_text = response_text.replace('```json', '').replace('```', '').strip()
            elif response_text.startswith('```'):
                # Handle generic code blocks
                lines = response_text.split('\n')
                response_text = '\n'.join(lines[1:-1]).strip()
            
            result = json.loads(response_text)
            
            category = result.get("category", "safe")
            confidence = float(result.get("confidence", 0.5))
            reasoning = result.get("reasoning", "")
            
            # Map categories to threat levels
            if category == "refund_scam":
                threats.append(ThreatEvidence(
                    type="refund_scam",
                    evidence=f"Refund scam detected: {reasoning}",
                    confidence=confidence,
                    severity="critical"
                ))
            elif category == "account_takeover":
                threats.append(ThreatEvidence(
                    type="account_takeover",
                    evidence=f"Account takeover attempt: {reasoning}",
                    confidence=confidence,
                    severity="critical"
                ))
            elif category == "pii_risk":
                threats.append(ThreatEvidence(
                    type="pii_request",
                    evidence=f"Suspicious PII request: {reasoning}",
                    confidence=confidence,
                    severity="high"
                ))
            
        except Exception as e:
            logger.error(f"Error in Gemini intent classification: {e}")
        
        return threats
    
    def _make_decision(self, threats: List[ThreatEvidence]) -> Tuple[str, Optional[Dict[str, str]]]:
        """
        Make overall decision based on detected threats using weighted risk scoring
        """
        if not threats:
            return "pass", None
        
        # Calculate weighted risk score
        risk_score = self._calculate_risk_score(threats)
        
        # Count threats by severity for additional context
        critical_count = sum(1 for t in threats if t.severity == "critical")
        high_count = sum(1 for t in threats if t.severity == "high")
        medium_count = sum(1 for t in threats if t.severity == "medium")
        low_count = sum(1 for t in threats if t.severity == "low")
        
        # Get highest severity threat types for context-specific guidance
        threat_types = [t.type for t in threats]
        highest_severity_threats = [t for t in threats if t.severity == "critical"]
        if not highest_severity_threats:
            highest_severity_threats = [t for t in threats if t.severity == "high"]
        
        logger.info(f"Risk assessment: score={risk_score:.2f}, critical={critical_count}, high={high_count}, medium={medium_count}, low={low_count}")
        
        # Enhanced decision logic with risk score thresholds
        if risk_score >= 8.0 or critical_count > 0:
            # Immediate block for critical threats or very high risk
            return "block", self._get_next_step_for_threats(highest_severity_threats, "critical")
            
        elif risk_score >= 6.0 or (high_count >= 2) or (high_count >= 1 and medium_count >= 3):
            # Block for high cumulative risk
            return "block", self._get_next_step_for_threats(highest_severity_threats, "high")
            
        elif risk_score >= 4.0 or high_count >= 1 or medium_count >= 2:
            # Warning for moderate risk
            return "warn", self._get_next_step_for_threats(highest_severity_threats, "medium")
            
        elif risk_score >= 2.0 or medium_count >= 1 or low_count >= 3:
            # Pass with monitoring for low risk
            return "pass", {
                "label": "Low Risk Detected - Monitor Activity",
                "url": "/security/monitor"
            }
        else:
            # Clean pass
            return "pass", None
    
    def _calculate_risk_score(self, threats: List[ThreatEvidence]) -> float:
        """
        Calculate weighted risk score based on threat severity, confidence, and type
        """
        if not threats:
            return 0.0
        
        # Severity weights
        severity_weights = {
            "critical": 10.0,
            "high": 6.0,
            "medium": 3.0,
            "low": 1.0
        }
        
        # Threat type multipliers (some threats are inherently more dangerous)
        type_multipliers = {
            "credit_card": 1.5,
            "ssn": 1.5,
            "cvv": 1.4,
            "scam_phrase": 1.3,
            "refund_scam": 1.4,
            "account_takeover": 1.3,
            "pii_request": 1.2,
            "gift_card_code": 1.1,
            "phishing_phrase": 1.0,
            "pii_detected": 1.0,
            "system_error": 0.8
        }
        
        total_score = 0.0
        threat_count = len(threats)
        
        for threat in threats:
            # Base score from severity and confidence
            base_score = severity_weights.get(threat.severity, 1.0) * threat.confidence
            
            # Apply threat type multiplier
            type_multiplier = type_multipliers.get(threat.type, 1.0)
            threat_score = base_score * type_multiplier
            
            total_score += threat_score
        
        # Apply diminishing returns for multiple threats of same type
        unique_types = len(set(t.type for t in threats))
        diversity_factor = min(1.0, unique_types / threat_count + 0.3)
        
        # Apply escalation factor for multiple threats
        if threat_count > 1:
            escalation_factor = 1.0 + (threat_count - 1) * 0.2
            total_score *= escalation_factor
        
        # Apply diversity factor
        final_score = total_score * diversity_factor
        
        logger.debug(f"Risk calculation: base={total_score:.2f}, diversity={diversity_factor:.2f}, final={final_score:.2f}")
        
        return final_score
    
    def _get_next_step_for_threats(self, threats: List[ThreatEvidence], severity_level: str) -> Dict[str, str]:
        """
        Get context-specific next step guidance based on threat types
        """
        if not threats:
            return {"label": "Contact Support", "url": "/support"}
        
        # Categorize threats
        threat_types = set(t.type for t in threats)
        
        # PII exposure threats
        pii_threats = {"credit_card", "ssn", "cvv", "pii_detected", "pii_request"}
        if threat_types.intersection(pii_threats):
            if severity_level == "critical":
                return {
                    "label": "CRITICAL: PII Exposure Detected - Immediate Action Required",
                    "url": "/security/pii-breach"
                }
            else:
                return {
                    "label": "PII Risk Detected - Review and Secure Information",
                    "url": "/security/pii-guidance"
                }
        
        # Scam/fraud threats
        scam_threats = {"scam_phrase", "refund_scam", "account_takeover", "phishing_phrase"}
        if threat_types.intersection(scam_threats):
            if severity_level == "critical":
                return {
                    "label": "FRAUD ALERT: Scam Detected - Do Not Proceed",
                    "url": "/security/fraud-alert"
                }
            else:
                return {
                    "label": "Potential Scam Detected - Verify Before Proceeding",
                    "url": "/security/scam-guidance"
                }
        
        # Gift card/payment threats
        payment_threats = {"gift_card_code"}
        if threat_types.intersection(payment_threats):
            return {
                "label": "Suspicious Payment Method - Verify Legitimacy",
                "url": "/security/payment-verification"
            }
        
        # Default based on severity
        if severity_level == "critical":
            return {
                "label": "Critical Security Threat - Contact Support Immediately",
                "url": "/security/critical-support"
            }
        elif severity_level == "high":
            return {
                "label": "High Risk Activity - Security Review Required",
                "url": "/security/high-risk-review"
            }
        else:
            return {
                "label": "Security Warning - Proceed with Caution",
                "url": "/security/general-guidance"
            }
    
    def _get_safety_citations(self, threats: List[ThreatEvidence]) -> List[Dict[str, str]]:
        """Get safety guidance citations from knowledge base"""
        citations = []
        
        if not all([self.retriever, self.embedder]):
            return citations
        
        try:
            # Create query based on threat types
            threat_types = [t.type for t in threats]
            query = f"safety guidance for {', '.join(set(threat_types))} threats"
            
            # Retrieve relevant safety documents
            from app.rag.core import retrieve
            results = retrieve(self.retriever, self.embedder, query, k=3)
            
            for result in results:
                citations.append({
                    "source": result.get("filename", "Safety Guidelines"),
                    "snippet": result.get("snippet", "")[:200] + "..."
                })
                
        except Exception as e:
            logger.error(f"Error retrieving safety citations: {e}")
        
        return citations
    
    def _redact_sensitive_content(self, text: str, threats: List[ThreatEvidence]) -> str:
        """Redact sensitive content from text"""
        if not self.anonymizer:
            return text
        
        try:
            # Use Presidio to redact PII
            analyzer_results = self.analyzer.analyze(text=text, language='en')
            
            # Configure anonymization
            anonymized_result = self.anonymizer.anonymize(
                text=text,
                analyzer_results=analyzer_results,
                operators={
                    "CREDIT_CARD": OperatorConfig("replace", {"new_value": "[CREDIT_CARD]"}),
                    "SSN": OperatorConfig("replace", {"new_value": "[SSN]"}),
                    "PHONE_NUMBER": OperatorConfig("replace", {"new_value": "[PHONE]"}),
                    "EMAIL_ADDRESS": OperatorConfig("replace", {"new_value": "[EMAIL]"}),
                    "PERSON": OperatorConfig("replace", {"new_value": "[NAME]"}),
                    "DEFAULT": OperatorConfig("replace", {"new_value": "[REDACTED]"})
                }
            )
            
            redacted_text = anonymized_result.text
            
            # Additional redaction for gift card codes (but preserve medical procedure codes)
            # Only redact alphanumeric codes that are 10+ chars and don't look like procedure codes
            def gift_card_replacer(match):
                code = match.group(0)
                # Don't redact medical procedure codes (D####, CPT codes, etc.)
                if re.match(r'^[A-Z]\d{4}$', code):  # D2750, etc.
                    return code
                elif re.match(r'^\d{5}$', code):  # CPT codes like 99213
                    return code
                else:
                    return '[GIFT_CARD_CODE]'
            
            redacted_text = re.sub(r'\b[A-Z0-9]{10,20}\b', gift_card_replacer, redacted_text)
            
            return redacted_text
            
        except Exception as e:
            logger.error(f"Error in text redaction: {e}")
            return text
    
    def _validate_luhn(self, card_number: str) -> bool:
        """Validate credit card number using Luhn algorithm"""
        try:
            digits = [int(d) for d in card_number if d.isdigit()]
            if len(digits) < 13 or len(digits) > 19:
                return False
            
            checksum = 0
            for i, digit in enumerate(reversed(digits)):
                if i % 2 == 1:
                    digit *= 2
                    if digit > 9:
                        digit -= 9
                checksum += digit
            
            return checksum % 10 == 0
        except:
            return False
    
    def _calculate_entropy(self, string: str) -> float:
        """Calculate Shannon entropy of a string"""
        if not string:
            return 0
        
        # Count character frequencies
        char_counts = {}
        for char in string:
            char_counts[char] = char_counts.get(char, 0) + 1
        
        # Calculate entropy
        entropy = 0
        length = len(string)
        for count in char_counts.values():
            probability = count / length
            entropy -= probability * math.log2(probability)
        
        return entropy
    
    def _initialize_scam_patterns(self) -> Dict[str, List[str]]:
        """Initialize scam detection patterns"""
        return {
            "refund_scams": [
                r"overpay.*gift card",
                r"refund.*gift card",
                r"send.*gift card.*refund",
                r"buy.*gift card.*verification"
            ],
            "wire_fraud": [
                r"wire.*money.*to",
                r"western union.*transfer",
                r"send.*money.*urgent"
            ],
            "crypto_scams": [
                r"send.*bitcoin.*verification",
                r"crypto.*wallet.*verification",
                r"bitcoin.*address.*refund"
            ]
        }
    
    def _initialize_entropy_patterns(self) -> Dict[str, float]:
        """Initialize entropy thresholds for different pattern types"""
        return {
            "gift_card_codes": 3.5,
            "crypto_addresses": 4.0,
            "random_strings": 3.0
        }

# Unit tests for common scam scenarios
def test_trustshield():
    """Deterministic unit tests for TrustShield"""
    shield = TrustShield()
    
    test_cases = [
        {
            "name": "Refund Scam",
            "text": "You overpaid $500. Please buy gift cards and send the codes for your refund.",
            "expected_decision": "block",
            "expected_threats": ["scam_phrase", "refund_scam"]
        },
        {
            "name": "Credit Card Exposure",
            "text": "My card number is 4532-1234-5678-9012 and CVV is 123",
            "expected_decision": "block", 
            "expected_threats": ["credit_card", "cvv"]
        },
        {
            "name": "SSN Exposure",
            "text": "My social security number is 123-45-6789",
            "expected_decision": "block",
            "expected_threats": ["ssn"]
        },
        {
            "name": "Phishing Attempt",
            "text": "Urgent action required! Your account will be closed. Click here to verify immediately.",
            "expected_decision": "warn",
            "expected_threats": ["phishing_phrase"]
        },
        {
            "name": "Safe Message",
            "text": "Hello, I'd like to know about your payment processing fees.",
            "expected_decision": "pass",
            "expected_threats": []
        }
    ]
    
    results = []
    for case in test_cases:
        result = shield.scan(case["text"])
        
        # Check decision
        decision_correct = result["decision"] == case["expected_decision"]
        
        # Check threat types
        detected_types = [threat.type for threat in result["reasons"]]
        threats_correct = all(expected in detected_types for expected in case["expected_threats"])
        
        test_result = {
            "name": case["name"],
            "passed": decision_correct and threats_correct,
            "expected_decision": case["expected_decision"],
            "actual_decision": result["decision"],
            "expected_threats": case["expected_threats"],
            "detected_threats": detected_types
        }
        
        results.append(test_result)
        
        print(f"Test '{case['name']}': {'PASS' if test_result['passed'] else 'FAIL'}")
        if not test_result['passed']:
            print(f"  Expected: {case['expected_decision']}, Got: {result['decision']}")
            print(f"  Expected threats: {case['expected_threats']}")
            print(f"  Detected threats: {detected_types}")
    
    return results

if __name__ == "__main__":
    # Run tests
    test_results = test_trustshield()
    passed = sum(1 for r in test_results if r["passed"])
    total = len(test_results)
    print(f"\nTest Results: {passed}/{total} passed")



================================================
FILE: app/config/rules_loader.py
================================================
"""
Centralized rules loader for synchrony-demo-rules-repo
Loads all YAML rules files at application startup
"""

import yaml
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

class RulesLoader:
    """Centralized loader for all rules from synchrony-demo-rules-repo"""
    
    def __init__(self, rules_base_path: str = "synchrony-demo-rules-repo"):
        self.rules_base = Path(rules_base_path)
        self.rules = {}
        self.fixtures = {}
        self._load_all_rules()
        self._load_all_fixtures()
    
    def _load_all_rules(self):
        """Load all YAML rules files"""
        rules_dir = self.rules_base / "rules"
        
        if not rules_dir.exists():
            logger.warning(f"Rules directory not found: {rules_dir}")
            return
        
        rule_files = [
            "promotions.yml",
            "disclosures.yml", 
            "prequalification.yml",
            "trustshield.yml",
            "collections.yml",
            "contracts_lexicon.yml",
            "dispute.yml",
            "carecredit.yml",
            "narrator.yml",
            "imagegen.yml",
            "routing.yml"
        ]
        
        loaded_count = 0
        for rule_file in rule_files:
            rule_path = rules_dir / rule_file
            if rule_path.exists():
                try:
                    with open(rule_path, 'r') as f:
                        rule_name = rule_file.replace('.yml', '')
                        self.rules[rule_name] = yaml.safe_load(f)
                        loaded_count += 1
                        logger.debug(f"Loaded rules: {rule_file}")
                except Exception as e:
                    logger.error(f"Failed to load {rule_file}: {e}")
            else:
                logger.warning(f"Rule file not found: {rule_file}")
        
        logger.info(f"Loaded {loaded_count} rules files from synchrony-demo-rules-repo")
    
    def _load_all_fixtures(self):
        """Load all fixture JSON files"""
        fixtures_dir = self.rules_base / "fixtures"
        
        if not fixtures_dir.exists():
            logger.warning(f"Fixtures directory not found: {fixtures_dir}")
            return
        
        fixture_files = [
            "products.json",
            "merchants.json"
        ]
        
        loaded_count = 0
        for fixture_file in fixture_files:
            fixture_path = fixtures_dir / fixture_file
            if fixture_path.exists():
                try:
                    with open(fixture_path, 'r') as f:
                        fixture_name = fixture_file.replace('.json', '')
                        self.fixtures[fixture_name] = json.load(f)
                        loaded_count += 1
                        logger.debug(f"Loaded fixture: {fixture_file}")
                except Exception as e:
                    logger.error(f"Failed to load {fixture_file}: {e}")
            else:
                logger.warning(f"Fixture file not found: {fixture_file}")
        
        logger.info(f"Loaded {loaded_count} fixture files from synchrony-demo-rules-repo")
    
    def get_rules(self, rule_type: str) -> Optional[Dict[str, Any]]:
        """Get rules by type (e.g., 'promotions', 'trustshield')"""
        return self.rules.get(rule_type)
    
    def get_fixture(self, fixture_type: str) -> Optional[Dict[str, Any]]:
        """Get fixture by type (e.g., 'products', 'merchants')"""
        return self.fixtures.get(fixture_type)
    
    def get_all_rules(self) -> Dict[str, Any]:
        """Get all loaded rules"""
        return self.rules.copy()
    
    def get_all_fixtures(self) -> Dict[str, Any]:
        """Get all loaded fixtures"""
        return self.fixtures.copy()
    
    def reload_rules(self):
        """Reload all rules from files"""
        self.rules = {}
        self.fixtures = {}
        self._load_all_rules()
        self._load_all_fixtures()

# Global rules loader instance
_rules_loader: Optional[RulesLoader] = None

def get_rules_loader() -> RulesLoader:
    """Get the global rules loader instance"""
    global _rules_loader
    if _rules_loader is None:
        _rules_loader = RulesLoader()
    return _rules_loader

def get_rules(rule_type: str) -> Optional[Dict[str, Any]]:
    """Convenience function to get rules by type"""
    return get_rules_loader().get_rules(rule_type)

def get_fixture(fixture_type: str) -> Optional[Dict[str, Any]]:
    """Convenience function to get fixture by type"""
    return get_rules_loader().get_fixture(fixture_type)


================================================
FILE: app/contracts/merchant_agreement.md
================================================
# Merchant Service Agreement

## Agreement Overview

This Merchant Service Agreement ("Agreement") governs the provision of payment processing and related services.

## Merchant Obligations

### Compliance Requirements
- Maintain PCI DSS compliance at all times
- Implement proper security measures for cardholder data
- Report security incidents within 24 hours
- Undergo annual security assessments

### Transaction Processing
- Process transactions only for legitimate business purposes
- Maintain accurate transaction records
- Provide clear refund and return policies
- Honor all valid chargebacks within specified timeframes

### Documentation
- Maintain detailed transaction logs for minimum 3 years
- Provide monthly reconciliation reports
- Submit compliance certificates annually
- Keep business licenses and permits current

## Service Levels

### Processing Times
- Standard transactions: 2-3 business days
- Express processing: Same day (additional fees apply)
- International transactions: 3-5 business days
- Refunds: 5-7 business days

### Availability
- System uptime: 99.9% guaranteed
- Maintenance windows: Sundays 2-4 AM EST
- Emergency maintenance: 4-hour advance notice
- Support availability: 24/7 for critical issues

## Fee Structure

### Transaction Fees
- Domestic cards: 2.9% + $0.30 per transaction
- International cards: 3.4% + $0.30 per transaction
- American Express: 3.5% + $0.30 per transaction
- Corporate cards: 3.2% + $0.30 per transaction

### Monthly Fees
- Account maintenance: $25/month
- Statement fee: $10/month
- Gateway access: $15/month
- PCI compliance fee: $20/month (waived if compliant)

### Additional Fees
- Chargeback fee: $15 per occurrence
- Retrieval request: $10 per request
- Early termination: $200 (if within first 12 months)
- Setup fee: $100 (one-time)

## Risk Management

### Transaction Monitoring
- Real-time fraud detection
- Velocity checking
- Geographic risk assessment
- Machine learning-based scoring

### Account Holds
- Suspicious activity may trigger holds
- High-risk transactions require manual review
- Rolling reserves may be applied (up to 10%)
- Release conditions clearly defined

## Termination

### Termination Rights
- Either party may terminate with 30 days notice
- Immediate termination for material breach
- Automatic termination for insolvency
- Regulatory termination as required

### Post-Termination
- Final settlement within 30 days
- Return of all confidential information
- Continued liability for processed transactions
- Data retention as per regulatory requirements

## Dispute Resolution

### Process
1. Direct negotiation (30 days)
2. Mediation (if negotiation fails)
3. Binding arbitration (final resort)
4. Governing law: Delaware

### Limitations
- Claims must be filed within 12 months
- Liability limited to fees paid in prior 12 months
- No consequential damages
- Class action waiver applies

## Contact Information

**Business Support:**
- Phone: 1-800-MERCHANT
- Email: support@merchantservices.com
- Hours: Monday-Friday 8 AM - 8 PM EST

**Technical Support:**
- Phone: 1-800-TECH-HELP
- Email: technical@merchantservices.com
- Hours: 24/7

**Compliance Department:**
- Phone: 1-800-COMPLY
- Email: compliance@merchantservices.com
- Hours: Monday-Friday 9 AM - 5 PM EST

---

*This agreement is effective as of the date of electronic acceptance or signature. Last updated: January 2025.*



================================================
FILE: app/data/financing_offers.json
================================================
{
  "offers": [
    {
      "id": "SYNC-0APR-12",
      "name": "0% APR for 12 Months",
      "type": "promotional",
      "merchant": "OfficeMax",
      "months": 12,
      "apr": 0.0,
      "min_purchase": 299.00,
      "max_purchase": 2000.00,
      "disclaimer": "0% APR for 12 months on purchases of $299 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 12 months."
    },
    {
      "id": "SYNC-0APR-18",
      "name": "0% APR for 18 Months",
      "type": "promotional",
      "merchant": "Apple Store",
      "months": 18,
      "apr": 0.0,
      "min_purchase": 500.00,
      "max_purchase": 5000.00,
      "disclaimer": "0% APR for 18 months on purchases of $500 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 18 months."
    },
    {
      "id": "SYNC-0APR-24",
      "name": "0% APR for 24 Months",
      "type": "promotional",
      "merchant": "Dell",
      "months": 24,
      "apr": 0.0,
      "min_purchase": 750.00,
      "max_purchase": 3000.00,
      "disclaimer": "0% APR for 24 months on purchases of $750 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 24 months."
    },
    {
      "id": "SYNC-STD-12",
      "name": "Standard 12 Month Plan",
      "type": "standard",
      "merchant": "IKEA",
      "months": 12,
      "apr": 19.99,
      "min_purchase": 199.00,
      "max_purchase": 10000.00,
      "disclaimer": "Standard APR of 19.99% applies. Minimum monthly payments required."
    },
    {
      "id": "SYNC-STD-24",
      "name": "Standard 24 Month Plan",
      "type": "standard",
      "merchant": "HP",
      "months": 24,
      "apr": 22.99,
      "min_purchase": 299.00,
      "max_purchase": 10000.00,
      "disclaimer": "Standard APR of 22.99% applies. Minimum monthly payments required."
    },
    {
      "id": "CARECREDIT-0APR-6",
      "name": "CareCredit 6 Months No Interest",
      "type": "healthcare",
      "merchant": "SmileCare Dental",
      "months": 6,
      "apr": 0.0,
      "min_purchase": 200.00,
      "max_purchase": 25000.00,
      "disclaimer": "No Interest if paid in full in 6 months on purchases of $200 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 6 months."
    },
    {
      "id": "CARECREDIT-0APR-12",
      "name": "CareCredit 12 Months No Interest",
      "type": "healthcare",
      "merchant": "BrightSmile Clinic",
      "months": 12,
      "apr": 0.0,
      "min_purchase": 300.00,
      "max_purchase": 25000.00,
      "disclaimer": "No Interest if paid in full in 12 months on purchases of $300 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 12 months."
    },
    {
      "id": "CARECREDIT-0APR-18",
      "name": "CareCredit 18 Months No Interest",
      "type": "veterinary",
      "merchant": "VetCare Animal Hospital",
      "months": 18,
      "apr": 0.0,
      "min_purchase": 500.00,
      "max_purchase": 25000.00,
      "disclaimer": "No Interest if paid in full in 18 months on purchases of $500 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 18 months."
    },
    {
      "id": "CARECREDIT-STD-24",
      "name": "CareCredit Extended Payment Plan",
      "type": "healthcare",
      "merchant": "SmileCare Dental",
      "months": 24,
      "apr": 17.90,
      "min_purchase": 1000.00,
      "max_purchase": 25000.00,
      "disclaimer": "17.90% APR applies to extended payment plans. Minimum monthly payments required."
    }
  ],
  "merchant_offers": {
    "OfficeMax": ["SYNC-0APR-12", "SYNC-STD-12"],
    "IKEA": ["SYNC-STD-12"],
    "Apple Store": ["SYNC-0APR-18"],
    "Dell": ["SYNC-0APR-24"],
    "HP": ["SYNC-STD-24"],
    "SmileCare Dental": ["CARECREDIT-0APR-6", "CARECREDIT-STD-24"],
    "BrightSmile Clinic": ["CARECREDIT-0APR-12"],
    "VetCare Animal Hospital": ["CARECREDIT-0APR-18"]
  },
  "metadata": {
    "total_offers": 9,
    "offer_types": ["promotional", "standard", "healthcare", "veterinary"],
    "apr_range": {
      "min": 0.0,
      "max": 22.99
    },
    "term_range": {
      "min_months": 6,
      "max_months": 24
    },
    "last_updated": "2025-01-08T00:00:00Z"
  }
}



================================================
FILE: app/data/hardship_policies.json
================================================
{
  "policy_version": "2025.1",
  "effective_date": "2025-01-01",
  "allowed_actions": {
    "deferral": {
      "enabled": true,
      "max_months": 6,
      "min_balance": 100.0,
      "max_balance": 50000.0,
      "eligible_buckets": ["current", "30", "60", "90", "120+"],
      "required_income_verification": true,
      "max_deferrals_per_year": 2
    },
    "re_aging": {
      "enabled": true,
      "min_bucket": "60",
      "eligible_buckets": ["60", "90", "120+"],
      "min_payment_history": 3,
      "min_payment_amount_pct": 0.10,
      "max_re_aging_per_year": 1,
      "requires_hardship_documentation": true
    },
    "settlement": {
      "enabled": true,
      "min_settlement_pct": 0.40,
      "max_settlement_pct": 0.85,
      "eligible_buckets": ["90", "120+"],
      "requires_lump_sum": false,
      "split_payment_max_months": 12,
      "requires_financial_hardship": true
    },
    "interest_reduction": {
      "enabled": true,
      "min_reduction_pct": 0.25,
      "max_reduction_pct": 0.75,
      "max_cycles": 12,
      "eligible_buckets": ["current", "30", "60"],
      "requires_autopay": true,
      "min_payment_amount_pct": 0.02
    },
    "payment_plan": {
      "enabled": true,
      "min_months": 6,
      "max_months": 60,
      "min_monthly_payment": 25.0,
      "eligible_buckets": ["current", "30", "60", "90", "120+"],
      "requires_income_verification": true
    }
  },
  "risk_parameters": {
    "chargeoff_risk_factors": {
      "bucket_multipliers": {
        "current": 0.02,
        "30": 0.08,
        "60": 0.20,
        "90": 0.45,
        "120+": 0.75
      },
      "income_ratio_impact": {
        "high_ratio": 0.1,
        "medium_ratio": 0.3,
        "low_ratio": 0.7
      },
      "balance_size_impact": {
        "small": 0.1,
        "medium": 0.2,
        "large": 0.4
      }
    },
    "affordability_thresholds": {
      "comfortable": 0.3,
      "manageable": 0.5,
      "stretched": 0.8
    }
  },
  "mandatory_disclosures": {
    "deferral": [
      "Interest will continue to accrue during the deferral period",
      "Your account will remain past due during deferral",
      "Credit reporting may continue during deferral period",
      "This is a temporary hardship accommodation",
      "You must resume regular payments after the deferral period"
    ],
    "re_aging": [
      "Re-aging will bring your account current",
      "You must make consecutive on-time payments to maintain current status",
      "Re-aging is limited to once per 12-month period",
      "Failure to maintain payments may result in immediate acceleration",
      "This accommodation may be reported to credit bureaus"
    ],
    "settlement": [
      "Settlement amount is less than the full balance owed",
      "Forgiven debt may be reported as taxable income",
      "Settlement will be reported to credit bureaus as 'settled for less than full amount'",
      "This will have a negative impact on your credit score",
      "Payment must be received by the agreed deadline"
    ],
    "interest_reduction": [
      "Reduced interest rate is temporary and subject to terms",
      "Rate will return to standard APR after the promotional period",
      "You must maintain automatic payments to qualify",
      "Missing payments will result in immediate rate restoration",
      "This is a hardship accommodation and may be reported"
    ],
    "payment_plan": [
      "You must make all scheduled payments on time",
      "Missing payments may result in plan termination",
      "Interest continues to accrue at your current APR",
      "Plan terms are subject to credit review and approval",
      "Additional fees may apply for plan setup"
    ]
  },
  "compliance_requirements": {
    "udaap_safe": true,
    "cfpb_compliant": true,
    "state_regulations": {
      "california": {
        "additional_disclosures": ["California residents have additional rights under state law"],
        "cooling_off_period": 3
      },
      "new_york": {
        "additional_disclosures": ["New York residents may contact the state attorney general"],
        "mandatory_review_period": 5
      }
    },
    "documentation_required": {
      "income_verification": ["pay stubs", "tax returns", "bank statements"],
      "hardship_documentation": ["medical bills", "unemployment notice", "divorce decree"],
      "identity_verification": ["government ID", "SSN verification"]
    }
  },
  "escalation_triggers": {
    "supervisor_review": {
      "settlement_above_pct": 0.70,
      "deferral_months_above": 4,
      "multiple_hardships_per_year": 2
    },
    "legal_review": {
      "settlement_below_pct": 0.50,
      "disputed_debt": true,
      "bankruptcy_indication": true
    },
    "executive_approval": {
      "balance_above": 25000.0,
      "settlement_below_pct": 0.45,
      "regulatory_complaint": true
    }
  }
}



================================================
FILE: app/data/marketplace_catalog.json
================================================
{
  "products": [
    {
      "sku": "DESK-001",
      "title": "Executive Standing Desk with Drawers",
      "merchant": "OfficeMax",
      "price": 549.99,
      "category": "furniture",
      "features": ["height adjustable", "3 drawers", "cable management", "oak finish"],
      "description": "Premium standing desk perfect for home office"
    },
    {
      "sku": "DESK-002", 
      "title": "Compact Writing Desk",
      "merchant": "IKEA",
      "price": 299.99,
      "category": "furniture",
      "features": ["compact design", "2 drawers", "white finish", "easy assembly"],
      "description": "Simple and functional desk for small spaces"
    },
    {
      "sku": "LAPTOP-001",
      "title": "MacBook Air M2 13-inch",
      "merchant": "Apple Store",
      "price": 1199.99,
      "category": "electronics",
      "features": ["M2 chip", "8GB RAM", "256GB SSD", "13.6-inch display"],
      "description": "Latest MacBook Air with M2 processor"
    },
    {
      "sku": "LAPTOP-002",
      "title": "Dell XPS 13 Laptop",
      "merchant": "Dell",
      "price": 999.99,
      "category": "electronics", 
      "features": ["Intel i7", "16GB RAM", "512GB SSD", "13.4-inch 4K display"],
      "description": "Premium ultrabook with stunning display"
    },
    {
      "sku": "LAPTOP-003",
      "title": "HP Pavilion 15 Laptop",
      "merchant": "HP",
      "price": 699.99,
      "category": "electronics",
      "features": ["AMD Ryzen 5", "8GB RAM", "256GB SSD", "15.6-inch display"],
      "description": "Reliable laptop for everyday computing"
    },
    {
      "sku": "DENTAL-001",
      "title": "Dental Crown Treatment",
      "merchant": "SmileCare Dental",
      "price": 1200.00,
      "category": "healthcare",
      "features": ["porcelain crown", "same-day service", "5-year warranty"],
      "description": "High-quality dental crown restoration"
    },
    {
      "sku": "DENTAL-002",
      "title": "Teeth Whitening Treatment",
      "merchant": "BrightSmile Clinic",
      "price": 450.00,
      "category": "healthcare",
      "features": ["professional whitening", "1-hour treatment", "guaranteed results"],
      "description": "Professional teeth whitening service"
    },
    {
      "sku": "VET-001",
      "title": "Pet Surgery - ACL Repair",
      "merchant": "VetCare Animal Hospital",
      "price": 2500.00,
      "category": "veterinary",
      "features": ["orthopedic surgery", "post-op care", "rehabilitation included"],
      "description": "ACL repair surgery for dogs"
    },
    {
      "sku": "PHONE-001",
      "title": "iPhone 15 Pro",
      "merchant": "Apple Store",
      "price": 999.99,
      "category": "electronics",
      "features": ["A17 Pro chip", "128GB storage", "titanium design", "48MP camera"],
      "description": "Latest iPhone with titanium design"
    },
    {
      "sku": "TABLET-001",
      "title": "iPad Air 5th Gen",
      "merchant": "Apple Store", 
      "price": 599.99,
      "category": "electronics",
      "features": ["M1 chip", "64GB storage", "10.9-inch display", "Apple Pencil compatible"],
      "description": "Powerful tablet for creativity and productivity"
    }
  ],
  "metadata": {
    "total_products": 10,
    "categories": ["furniture", "electronics", "healthcare", "veterinary"],
    "merchants": ["OfficeMax", "IKEA", "Apple Store", "Dell", "HP", "SmileCare Dental", "BrightSmile Clinic", "VetCare Animal Hospital"],
    "price_range": {
      "min": 299.99,
      "max": 2500.00
    },
    "last_updated": "2025-01-08T00:00:00Z"
  }
}



================================================
FILE: app/data/metrics_schema.json
================================================
{
  "schemas": {
    "portfolio_spend": {
      "table_name": "portfolio_spend",
      "description": "Daily portfolio spending metrics by merchant and promo type",
      "columns": {
        "date": {"type": "date", "description": "Transaction date"},
        "merchant": {"type": "string", "description": "Merchant name"},
        "promo_type": {"type": "string", "description": "Promotional offer type"},
        "spend_amount": {"type": "float", "description": "Total spend amount in USD"},
        "transaction_count": {"type": "integer", "description": "Number of transactions"},
        "avg_ticket": {"type": "float", "description": "Average transaction amount"},
        "new_customers": {"type": "integer", "description": "New customer count"}
      },
      "primary_key": ["date", "merchant", "promo_type"],
      "time_column": "date"
    },
    "delinquency_rates": {
      "table_name": "delinquency_rates", 
      "description": "Monthly delinquency rates by customer segment and vintage",
      "columns": {
        "month": {"type": "date", "description": "Month-end date"},
        "segment": {"type": "string", "description": "Customer credit segment"},
        "vintage": {"type": "string", "description": "Account vintage (origination quarter)"},
        "total_accounts": {"type": "integer", "description": "Total active accounts"},
        "delinq_30": {"type": "float", "description": "30+ days delinquency rate"},
        "delinq_60": {"type": "float", "description": "60+ days delinquency rate"},
        "delinq_90": {"type": "float", "description": "90+ days delinquency rate"},
        "charge_off_rate": {"type": "float", "description": "Charge-off rate"}
      },
      "primary_key": ["month", "segment", "vintage"],
      "time_column": "month"
    },
    "promo_performance": {
      "table_name": "promo_performance",
      "description": "Promotional campaign performance metrics",
      "columns": {
        "date": {"type": "date", "description": "Campaign date"},
        "promo_id": {"type": "string", "description": "Promotion identifier"},
        "promo_name": {"type": "string", "description": "Promotion name"},
        "start_date": {"type": "date", "description": "Promotion start date"},
        "end_date": {"type": "date", "description": "Promotion end date"},
        "applications": {"type": "integer", "description": "Credit applications"},
        "approvals": {"type": "integer", "description": "Credit approvals"},
        "approval_rate": {"type": "float", "description": "Approval rate percentage"},
        "activation_rate": {"type": "float", "description": "Card activation rate"},
        "spend_per_approval": {"type": "float", "description": "Average spend per approval"}
      },
      "primary_key": ["date", "promo_id"],
      "time_column": "date"
    },
    "credit_metrics": {
      "table_name": "credit_metrics",
      "description": "Credit portfolio health metrics",
      "columns": {
        "date": {"type": "date", "description": "Metric date"},
        "product": {"type": "string", "description": "Credit product type"},
        "outstanding_balance": {"type": "float", "description": "Total outstanding balance"},
        "utilization_rate": {"type": "float", "description": "Credit utilization rate"},
        "payment_rate": {"type": "float", "description": "Payment rate"},
        "net_charge_offs": {"type": "float", "description": "Net charge-offs"},
        "provision_expense": {"type": "float", "description": "Provision expense"},
        "yield": {"type": "float", "description": "Portfolio yield percentage"}
      },
      "primary_key": ["date", "product"],
      "time_column": "date"
    }
  },
  "allowed_operations": {
    "select": {
      "functions": ["COUNT", "SUM", "AVG", "MIN", "MAX", "STDDEV"],
      "aggregations": true,
      "joins": false
    },
    "where": {
      "operators": ["=", "!=", "<", "<=", ">", ">=", "IN", "LIKE", "BETWEEN"],
      "functions": ["DATE", "MONTH", "YEAR", "QUARTER"]
    },
    "group_by": {
      "allowed": true,
      "max_columns": 3
    },
    "order_by": {
      "allowed": true,
      "max_columns": 2
    },
    "limit": {
      "allowed": true,
      "max_rows": 10000
    }
  },
  "metric_definitions": {
    "spend_amount": "Total dollar amount spent by customers using credit products",
    "delinq_30": "Percentage of accounts 30+ days past due on payments", 
    "approval_rate": "Percentage of credit applications that are approved",
    "utilization_rate": "Average credit utilization across active accounts",
    "charge_off_rate": "Percentage of accounts charged off as uncollectible",
    "payment_rate": "Percentage of minimum payment made on time",
    "portfolio_yield": "Annual percentage yield earned on outstanding balances",
    "provision_expense": "Expected credit loss provisions for future charge-offs"
  }
}


================================================
FILE: app/data/provider_catalog.json
================================================
{
  "providers": [
    {
      "id": "prov_001",
      "name": "GlobalPay Solutions",
      "type": "payment_processor",
      "status": "active",
      "supported_regions": ["US", "CA", "EU", "UK"],
      "supported_currencies": ["USD", "CAD", "EUR", "GBP"],
      "features": {
        "real_time_processing": true,
        "fraud_detection": true,
        "recurring_billing": true,
        "mobile_payments": true,
        "cryptocurrency": false
      },
      "pricing": {
        "setup_fee": 100,
        "monthly_fee": 25,
        "transaction_rate": 2.9,
        "international_rate": 3.4
      },
      "integration": {
        "api_version": "v2.1",
        "webhook_support": true,
        "sdk_available": ["javascript", "python", "php", "java"],
        "documentation_url": "https://docs.globalpay.com"
      },
      "compliance": {
        "pci_dss": "Level 1",
        "gdpr_compliant": true,
        "sox_compliant": true,
        "certifications": ["ISO 27001", "SOC 2 Type II"]
      },
      "contact": {
        "support_email": "support@globalpay.com",
        "support_phone": "+1-800-555-0123",
        "account_manager": "Sarah Johnson",
        "technical_contact": "tech@globalpay.com"
      }
    },
    {
      "id": "prov_002",
      "name": "SecureTransact Inc",
      "type": "payment_gateway",
      "status": "active",
      "supported_regions": ["US", "CA", "MX"],
      "supported_currencies": ["USD", "CAD", "MXN"],
      "features": {
        "real_time_processing": true,
        "fraud_detection": true,
        "recurring_billing": false,
        "mobile_payments": true,
        "cryptocurrency": true
      },
      "pricing": {
        "setup_fee": 200,
        "monthly_fee": 35,
        "transaction_rate": 2.7,
        "international_rate": 3.2
      },
      "integration": {
        "api_version": "v3.0",
        "webhook_support": true,
        "sdk_available": ["javascript", "python", "ruby"],
        "documentation_url": "https://api.securetransact.com"
      },
      "compliance": {
        "pci_dss": "Level 1",
        "gdpr_compliant": false,
        "sox_compliant": true,
        "certifications": ["ISO 27001"]
      },
      "contact": {
        "support_email": "help@securetransact.com",
        "support_phone": "+1-888-555-0456",
        "account_manager": "Mike Chen",
        "technical_contact": "developers@securetransact.com"
      }
    },
    {
      "id": "prov_003",
      "name": "EuroPayments Ltd",
      "type": "payment_processor",
      "status": "active",
      "supported_regions": ["EU", "UK", "CH", "NO"],
      "supported_currencies": ["EUR", "GBP", "CHF", "NOK", "SEK", "DKK"],
      "features": {
        "real_time_processing": true,
        "fraud_detection": true,
        "recurring_billing": true,
        "mobile_payments": true,
        "cryptocurrency": false
      },
      "pricing": {
        "setup_fee": 150,
        "monthly_fee": 30,
        "transaction_rate": 2.5,
        "international_rate": 3.0
      },
      "integration": {
        "api_version": "v2.3",
        "webhook_support": true,
        "sdk_available": ["javascript", "python", "php", "java", "dotnet"],
        "documentation_url": "https://developers.europayments.com"
      },
      "compliance": {
        "pci_dss": "Level 1",
        "gdpr_compliant": true,
        "sox_compliant": false,
        "certifications": ["ISO 27001", "SOC 2 Type II", "PSD2"]
      },
      "contact": {
        "support_email": "support@europayments.com",
        "support_phone": "+44-20-7123-4567",
        "account_manager": "Emma Thompson",
        "technical_contact": "api-support@europayments.com"
      }
    }
  ],
  "metadata": {
    "total_providers": 3,
    "active_providers": 3,
    "last_updated": "2025-01-08T00:00:00Z",
    "version": "1.2.0",
    "supported_regions_total": ["US", "CA", "EU", "UK", "MX", "CH", "NO"],
    "supported_currencies_total": ["USD", "CAD", "EUR", "GBP", "MXN", "CHF", "NOK", "SEK", "DKK"]
  }
}



================================================
FILE: app/data/providers.json
================================================
{
  "providers": [
    {
      "id": "dent_001",
      "name": "City Dental Care",
      "specialty": "dental",
      "address": "123 Main St, New York, NY 10001",
      "phone": "(212) 555-0123",
      "next_appt_days": 7,
      "location": "New York, NY",
      "accepts_carecredit": true,
      "rating": 4.8
    },
    {
      "id": "dent_002", 
      "name": "Smile Bright Dentistry",
      "specialty": "dental",
      "address": "456 Oak Ave, Los Angeles, CA 90210",
      "phone": "(323) 555-0456",
      "next_appt_days": 14,
      "location": "Los Angeles, CA",
      "accepts_carecredit": true,
      "rating": 4.6
    },
    {
      "id": "derm_001",
      "name": "Advanced Dermatology Center",
      "specialty": "dermatology",
      "address": "789 Elm St, Chicago, IL 60601",
      "phone": "(312) 555-0789",
      "next_appt_days": 21,
      "location": "Chicago, IL",
      "accepts_carecredit": true,
      "rating": 4.9
    },
    {
      "id": "orth_001",
      "name": "Orthopedic Specialists",
      "specialty": "orthopedic",
      "address": "321 Pine St, Houston, TX 77001",
      "phone": "(713) 555-0321",
      "next_appt_days": 10,
      "location": "Houston, TX",
      "accepts_carecredit": true,
      "rating": 4.7
    },
    {
      "id": "vet_001",
      "name": "Pet Care Veterinary Hospital",
      "specialty": "veterinary",
      "address": "654 Birch Rd, Phoenix, AZ 85001",
      "phone": "(602) 555-0654",
      "next_appt_days": 3,
      "location": "Phoenix, AZ",
      "accepts_carecredit": true,
      "rating": 4.8
    },
    {
      "id": "opht_001",
      "name": "Vision Care Center",
      "specialty": "ophthalmology",
      "address": "987 Cedar St, Philadelphia, PA 19101",
      "phone": "(215) 555-0987",
      "next_appt_days": 28,
      "location": "Philadelphia, PA",
      "accepts_carecredit": true,
      "rating": 4.5
    },
    {
      "id": "dent_003",
      "name": "Downtown Dental Group",
      "specialty": "dental",
      "address": "147 Broadway, New York, NY 10002", 
      "phone": "(212) 555-0147",
      "next_appt_days": 5,
      "location": "New York, NY",
      "accepts_carecredit": true,
      "rating": 4.7
    },
    {
      "id": "derm_002",
      "name": "Skin Health Associates",
      "specialty": "dermatology",
      "address": "258 Sunset Blvd, Los Angeles, CA 90211",
      "phone": "(323) 555-0258",
      "next_appt_days": 35,
      "location": "Los Angeles, CA",
      "accepts_carecredit": true,
      "rating": 4.4
    }
  ],
  "specialties": {
    "dental": ["teeth", "tooth", "dental", "dentist", "cavity", "crown", "root canal", "cleaning", "whitening"],
    "dermatology": ["skin", "dermatology", "dermatologist", "acne", "mole", "rash", "cosmetic", "botox"],
    "orthopedic": ["bone", "joint", "orthopedic", "knee", "hip", "shoulder", "fracture", "surgery"],
    "veterinary": ["pet", "dog", "cat", "veterinary", "vet", "animal"],
    "ophthalmology": ["eye", "vision", "glasses", "contacts", "laser", "cataract", "glaucoma"]
  },
  "procedure_mappings": {
    "D0120": {"name": "Periodic oral evaluation", "specialty": "dental"},
    "D0150": {"name": "Comprehensive oral evaluation", "specialty": "dental"},
    "D1110": {"name": "Prophylaxis - adult", "specialty": "dental"},
    "D2140": {"name": "Amalgam - one surface", "specialty": "dental"},
    "D2750": {"name": "Crown - porcelain fused to metal", "specialty": "dental"},
    "D3310": {"name": "Endodontic therapy, anterior tooth", "specialty": "dental"},
    "11200": {"name": "Removal of skin tags", "specialty": "dermatology"},
    "17000": {"name": "Destruction of benign lesions", "specialty": "dermatology"},
    "29881": {"name": "Arthroscopy, knee, surgical", "specialty": "orthopedic"},
    "27447": {"name": "Total knee arthroplasty", "specialty": "orthopedic"}
  }
}


================================================
FILE: app/kb/contract_ontology.md
================================================
# Contract Ontology - Key Terms Extraction Guide

## Overview

This document defines the standard ontology for extracting key terms from merchant agreements, partnership contracts, and vendor agreements. It serves as a reference for automated contract analysis and obligation mapping.

## Core Extraction Categories

### 1. Fees Structure

**Definition**: All monetary obligations, charges, and payment terms

**Key Fields to Extract:**
- `setup_fees`: One-time implementation or onboarding costs
- `monthly_fees`: Recurring monthly charges
- `transaction_fees`: Per-transaction charges (fixed or percentage)
- `volume_discounts`: Tiered pricing based on transaction volume
- `penalty_fees`: Charges for non-compliance or violations
- `termination_fees`: Costs associated with contract termination
- `payment_terms`: When payments are due (net 30, etc.)
- `fee_escalation`: Annual increases or adjustment mechanisms

**Example Patterns:**
- "Setup fee of $5,000 due within 30 days"
- "Monthly service fee: $2,500"
- "Transaction fee: 2.5% + $0.30 per transaction"
- "Volume discount: >$1M monthly = 2.0% rate"

### 2. Service Level Agreements (SLAs)

**Definition**: Performance commitments and operational requirements

**Key Fields to Extract:**
- `uptime_guarantee`: System availability commitments (99.9%)
- `response_times`: Support response requirements
- `resolution_times`: Issue resolution commitments
- `processing_times`: Transaction or request processing speeds
- `reporting_frequency`: How often reports are provided
- `maintenance_windows`: Scheduled downtime allowances
- `escalation_procedures`: How issues are escalated
- `performance_penalties`: Consequences for SLA breaches

**Example Patterns:**
- "99.5% uptime guarantee"
- "Support response within 4 business hours"
- "Critical issues resolved within 24 hours"
- "Transaction processing within 2 seconds"

### 3. Brand Usage Rights

**Definition**: Intellectual property usage, marketing rights, and brand guidelines

**Key Fields to Extract:**
- `logo_usage_rights`: Permission to use company logos
- `trademark_usage`: Rights to use trademarks and service marks
- `co_branding_requirements`: Joint branding obligations
- `marketing_approval`: Requirement for marketing material approval
- `brand_guidelines`: Standards for brand representation
- `exclusivity_rights`: Exclusive usage or territory rights
- `attribution_requirements`: How to credit the brand
- `usage_restrictions`: Limitations on brand usage

**Example Patterns:**
- "Merchant may use Company logo in approved marketing materials"
- "All marketing materials require prior written approval"
- "Exclusive rights within the healthcare vertical"
- "Logo usage must comply with brand guidelines v2.1"

### 4. Data Sharing & Privacy

**Definition**: Data handling, sharing, and privacy obligations

**Key Fields to Extract:**
- `data_types_shared`: Categories of data being exchanged
- `data_retention_period`: How long data is kept
- `data_security_requirements`: Security standards and controls
- `third_party_sharing`: Rights to share data with third parties
- `customer_consent_requirements`: Consent obligations
- `data_deletion_rights`: Right to delete or return data
- `compliance_standards`: GDPR, CCPA, PCI-DSS requirements
- `breach_notification`: Data breach notification procedures

**Example Patterns:**
- "Customer transaction data retained for 7 years"
- "PCI-DSS Level 1 compliance required"
- "Data may be shared with approved payment processors"
- "Breach notification within 72 hours"

### 5. Security Requirements

**Definition**: Cybersecurity, physical security, and operational security obligations

**Key Fields to Extract:**
- `security_certifications`: Required certifications (SOC 2, ISO 27001)
- `encryption_requirements`: Data encryption standards
- `access_controls`: User access and authentication requirements
- `vulnerability_management`: Security testing and patching
- `incident_response`: Security incident procedures
- `audit_requirements`: Security audit obligations
- `employee_screening`: Background check requirements
- `physical_security`: Facility security requirements

**Example Patterns:**
- "SOC 2 Type II certification required annually"
- "AES-256 encryption for data at rest"
- "Multi-factor authentication for all admin access"
- "Quarterly vulnerability assessments required"

### 6. Termination Clauses

**Definition**: Contract termination conditions, procedures, and consequences

**Key Fields to Extract:**
- `termination_notice_period`: Required notice before termination
- `termination_for_cause`: Conditions allowing immediate termination
- `termination_without_cause`: General termination rights
- `data_return_obligations`: Requirements to return or delete data
- `transition_assistance`: Support during transition period
- `post_termination_restrictions`: Ongoing obligations after termination
- `survival_clauses`: Terms that survive contract termination
- `termination_fees`: Costs associated with early termination

**Example Patterns:**
- "90 days written notice required for termination"
- "Immediate termination for material breach"
- "All customer data returned within 30 days"
- "Early termination fee: 6 months of monthly fees"

### 7. Penalties & Compliance

**Definition**: Consequences for non-compliance and violation remedies

**Key Fields to Extract:**
- `late_payment_penalties`: Charges for overdue payments
- `performance_penalties`: Consequences for SLA breaches
- `compliance_violations`: Penalties for regulatory non-compliance
- `data_breach_penalties`: Consequences for security incidents
- `liquidated_damages`: Pre-agreed damage amounts
- `penalty_caps`: Maximum penalty amounts
- `cure_periods`: Time allowed to remedy violations
- `escalating_penalties`: Increasing penalties for repeated violations

**Example Patterns:**
- "Late payment penalty: 1.5% per month"
- "SLA breach penalty: $1,000 per hour of downtime"
- "Data breach penalty: up to $100,000"
- "30-day cure period for material breaches"

### 8. Audit Rights

**Definition**: Rights to inspect, audit, and verify compliance

**Key Fields to Extract:**
- `audit_frequency`: How often audits may be conducted
- `audit_scope`: What can be audited
- `audit_notice_period`: Advance notice required for audits
- `audit_costs`: Who pays for audit expenses
- `audit_access_rights`: What records and systems can be accessed
- `third_party_audits`: Rights to use external auditors
- `audit_remediation`: Requirements to address audit findings
- `audit_reporting`: Audit report sharing requirements

**Example Patterns:**
- "Annual compliance audits permitted with 30 days notice"
- "Audit costs borne by requesting party unless violations found"
- "Access to all relevant records and systems"
- "Third-party auditors subject to confidentiality agreements"

### 9. Marketing Obligations

**Definition**: Marketing, promotion, and business development commitments

**Key Fields to Extract:**
- `marketing_spend_commitments`: Required marketing investments
- `promotional_requirements`: Mandatory promotional activities
- `event_participation`: Trade show or conference obligations
- `content_creation`: Requirements to create marketing content
- `lead_generation`: Lead generation and sharing obligations
- `co_marketing_activities`: Joint marketing initiatives
- `marketing_performance_metrics`: Success measurement criteria
- `marketing_approval_process`: Review and approval procedures

**Example Patterns:**
- "Minimum $50,000 annual marketing spend required"
- "Participation in 2 major industry conferences annually"
- "Monthly case study or success story required"
- "Joint webinar quarterly"

## Extraction Guidelines

### Document Structure Recognition

**Section Identification Patterns:**
- Headers: "FEES", "SERVICE LEVELS", "TERMINATION", "DATA PRIVACY"
- Numbered sections: "3. Payment Terms", "7. Intellectual Property"
- Article references: "Article IV - Confidentiality"
- Appendix references: "Schedule A - Fee Structure"

### Risk Flag Triggers

**High Risk Indicators:**
- Uncapped penalties or unlimited liability
- SLA requirements >99.9% uptime
- Termination notice <30 days
- Exclusive rights or exclusivity clauses
- Personal guarantees or joint liability

**Medium Risk Indicators:**
- SLA requirements 95-99% uptime
- Termination notice 30-90 days
- Significant setup or termination fees
- Complex fee structures with multiple tiers
- Broad audit rights or frequent audits

**Low Risk Indicators:**
- Standard industry terms
- Reasonable notice periods (90+ days)
- Capped penalties and liability
- Clear termination procedures
- Standard data protection requirements

### Owner Assignment Heuristics

**Legal Team:**
- Contract amendments and modifications
- Intellectual property and trademark issues
- Liability and indemnification matters
- Regulatory compliance requirements

**Risk Team:**
- Data privacy and security requirements
- Audit rights and compliance monitoring
- Risk assessment and mitigation
- Insurance and liability coverage

**Finance Team:**
- Fee structures and payment terms
- Revenue recognition implications
- Cost analysis and budgeting
- Financial reporting requirements

**Operations Team:**
- SLA monitoring and performance
- System integration and technical requirements
- Day-to-day contract administration
- Vendor relationship management

**Marketing Team:**
- Brand usage and co-marketing
- Marketing obligations and commitments
- Promotional requirements
- Content creation and approval

## Common Contract Patterns

### Payment Terms Variations
- "Net 30" = Payment due 30 days after invoice
- "2/10 Net 30" = 2% discount if paid within 10 days, otherwise net 30
- "Monthly in advance" = Payment due at start of service period
- "Quarterly in arrears" = Payment due at end of quarter

### SLA Measurement Methods
- "Calendar time" = 24/7 including weekends and holidays
- "Business hours" = Typically 8 AM - 6 PM, Monday-Friday
- "Scheduled maintenance excluded" = Planned downtime doesn't count
- "Force majeure excluded" = Natural disasters and external factors excluded

### Termination Notice Calculations
- "Business days" = Excludes weekends and holidays
- "Calendar days" = Includes all days
- "Written notice" = Formal documentation required
- "Email acceptable" = Electronic delivery permitted

This ontology serves as the foundation for automated contract analysis, ensuring consistent extraction of key terms and proper risk assessment across all merchant agreements and partnership contracts.



================================================
FILE: app/kb/data_privacy_policy.md
================================================
# Data Privacy Policy

## Overview

This document outlines our comprehensive data privacy policy and practices for handling user information.

## Data Collection

We collect the following types of data:

### Personal Information
- Name and contact details
- Email addresses
- Phone numbers
- Billing addresses

### Usage Data
- Website interaction patterns
- Feature usage statistics
- Performance metrics
- Error logs

## Data Usage

We use collected data for:

1. **Service Provision**: To deliver our core services and features
2. **Communication**: To send important updates and notifications
3. **Improvement**: To enhance user experience and system performance
4. **Compliance**: To meet legal and regulatory requirements

## User Rights

Users have the following rights regarding their data:

- **Access**: Request copies of personal data
- **Rectification**: Correct inaccurate information
- **Erasure**: Request deletion of personal data
- **Portability**: Receive data in a structured format
- **Objection**: Object to certain data processing activities

## Data Security

We implement robust security measures including:

- Encryption of data in transit and at rest
- Regular security audits and assessments
- Access controls and authentication
- Employee training on data protection

## Data Retention

- Personal data is retained for the minimum period necessary
- Account data is deleted within 30 days of account closure
- Usage logs are retained for 12 months for security purposes
- Backup data is automatically purged after 2 years

## Third-Party Sharing

We do not sell personal data to third parties. Limited sharing occurs only for:

- Payment processing (with PCI-compliant processors)
- Legal compliance (when required by law)
- Service providers (under strict data processing agreements)

## Contact Information

For privacy-related inquiries, contact our Data Protection Officer at:
- Email: privacy@company.com
- Phone: +1-555-0123
- Address: 123 Privacy Lane, Data City, DC 12345

Last updated: January 2025



================================================
FILE: app/kb/disputes_policy.md
================================================
# Card Dispute and Chargeback Policy

## Overview

This document outlines the policies and procedures for handling credit card disputes, chargebacks, and billing error resolution for Synchrony and CareCredit accounts.

## Types of Disputes

### 1. Billing Errors
**Definition**: Incorrect charges, duplicate transactions, or mathematical errors on statements.

**Common Examples:**
- Duplicate charges for the same transaction
- Charges for incorrect amounts
- Charges for items not purchased
- Mathematical or computational errors
- Failure to credit payments or returns

**Resolution Process:**
1. Contact merchant first for direct resolution
2. If unresolved, file formal dispute within 60 days
3. Provide transaction details and supporting documentation
4. Temporary credit may be issued during investigation

**Required Documentation:**
- Original receipt or transaction record
- Proof of attempted merchant contact
- Bank or credit card statement showing the charge
- Any correspondence with the merchant

### 2. Goods Not Received
**Definition**: Items or services paid for but never delivered or provided.

**Qualifying Conditions:**
- Payment was made but goods/services not received
- Delivery was significantly delayed beyond agreed timeframe
- Services were not performed as contracted

**Resolution Steps:**
1. **Merchant Contact**: Contact merchant within 30 days of expected delivery
2. **Documentation**: Gather proof of purchase and delivery expectations
3. **Dispute Filing**: File dispute if merchant doesn't resolve within 15 business days
4. **Investigation**: Card issuer investigates and may issue provisional credit

**Required Evidence:**
- Purchase receipt or confirmation
- Shipping/tracking information (if applicable)
- Communication records with merchant
- Proof of non-delivery (e.g., delivery confirmation showing different address)

### 3. Fraudulent Transactions
**Definition**: Unauthorized charges made without cardholder's knowledge or consent.

**Immediate Actions:**
1. **Report Immediately**: Contact card issuer within 2 business days
2. **Freeze Account**: Request immediate account freeze if necessary
3. **File Police Report**: For fraud amounts over $500
4. **Monitor Statements**: Review all recent transactions

**Zero Liability Protection:**
- Cardholders are not liable for unauthorized transactions
- Maximum liability is $50 for reported fraud
- No liability if reported within 2 business days

**Investigation Process:**
- Immediate provisional credit for disputed amount
- 10 business day investigation period
- Permanent credit if fraud is confirmed
- New card issued if account is compromised

## Dispute Filing Requirements

### Timeline Requirements
- **Billing Errors**: Must be reported within 60 days of statement date
- **Goods Not Received**: File within 120 days of expected delivery
- **Fraudulent Charges**: Report immediately, no later than 60 days

### Required Information
**For All Disputes:**
- Account number and cardholder name
- Transaction date and amount
- Merchant name and location
- Description of the dispute
- Steps taken to resolve with merchant

**Additional for Billing Errors:**
- Copy of receipt showing correct amount
- Bank statement showing incorrect charge
- Calculation showing the error

**Additional for Goods Not Received:**
- Purchase confirmation or receipt
- Expected delivery date
- Tracking information (if available)
- Proof of merchant contact attempts

**Additional for Fraud:**
- Affidavit of unauthorized use
- Police report number (if filed)
- List of all unauthorized transactions

## Merchant Resolution Process

### First Contact Requirements
Before filing a formal dispute, cardholders should:

1. **Contact Merchant Directly**
   - Call customer service number on receipt
   - Email customer support if available
   - Visit physical location if applicable

2. **Document the Contact**
   - Date and time of contact
   - Name of representative spoken to
   - Summary of conversation
   - Any reference numbers provided

3. **Allow Resolution Time**
   - Give merchant 5-10 business days to respond
   - For billing errors: 2-3 business days
   - For non-delivery: 10-15 business days

4. **Escalate if Necessary**
   - Request supervisor or manager
   - Ask for written confirmation of resolution
   - Get timeline for refund or correction

### Merchant Cooperation
**Merchants are expected to:**
- Respond to customer inquiries within 2 business days
- Provide clear explanation of charges
- Process legitimate refunds within 5-7 business days
- Maintain transaction records for dispute resolution

## Formal Dispute Process

### Step 1: Initial Filing
- Complete dispute form with all required information
- Submit supporting documentation
- Receive confirmation and reference number
- Account receives provisional credit (if applicable)

### Step 2: Investigation
- Card issuer reviews all documentation
- May contact merchant for response
- Additional information may be requested
- Investigation typically takes 30-45 days

### Step 3: Resolution
- **Dispute Upheld**: Permanent credit issued, case closed
- **Dispute Denied**: Provisional credit reversed, detailed explanation provided
- **Partial Resolution**: Partial credit based on investigation findings

### Step 4: Appeal Process
If dispute is denied:
- Request detailed explanation
- Provide additional evidence if available
- File appeal within 30 days
- Consider arbitration for amounts over $500

## Documentation Best Practices

### Receipt Management
- Keep all receipts for at least 2 years
- Store digital copies in secure location
- Include receipts for returns and exchanges
- Photograph receipts immediately after purchase

### Communication Records
- Save all emails with merchants
- Document phone calls with date, time, and summary
- Keep screenshots of online transactions
- Maintain shipping and tracking information

### Financial Records
- Review statements monthly
- Report discrepancies immediately
- Keep statements for at least 3 years
- Monitor credit reports for unauthorized accounts

## Special Considerations

### Promotional Financing Disputes
For 0% APR promotional financing:
- Disputes may affect promotional terms
- Interest may accrue during investigation
- Resolution may require promotional rate restoration
- Document promotional offer terms carefully

### Healthcare and Veterinary Services
For CareCredit disputes:
- Medical necessity may be factor in resolution
- Insurance coordination may complicate disputes
- Provider licensing and credentials relevant
- Treatment outcomes may affect dispute validity

### Recurring Charges
For subscription or recurring services:
- Cancellation must be properly documented
- Terms of service cancellation policy applies
- Advance notice requirements must be met
- Partial month charges may be valid

## Contact Information

### Customer Service
- **Synchrony Customer Service**: 1-866-396-8254
- **CareCredit Customer Service**: 1-800-677-0718
- **Dispute Department**: 1-800-DISPUTE (1-800-347-7883)

### Online Resources
- **Account Management**: mysynchrony.com
- **CareCredit Portal**: carecredit.com
- **Dispute Forms**: Available in online account portal
- **Document Upload**: Secure portal for evidence submission

### Regulatory Contacts
- **Consumer Financial Protection Bureau**: consumerfinance.gov
- **Federal Trade Commission**: ftc.gov/complaint
- **State Attorney General**: Contact local office
- **Better Business Bureau**: bbb.org

---

*This policy is subject to change. Cardholders should review current terms and conditions for the most up-to-date dispute procedures. Last updated: January 2025*



================================================
FILE: app/kb/promotional_terms.md
================================================
# Promotional Financing Terms and Conditions

## Synchrony Promotional Financing

### 0% APR Equal Monthly Payments

**Eligibility Requirements:**
- Subject to credit approval
- Minimum purchase amounts vary by merchant and promotion
- Valid government-issued photo ID required
- Must be 18 years or older

**How It Works:**
- 0% APR for the promotional period when you make equal monthly payments
- No interest charges if promotional balance is paid in full by the end of the promotional period
- If promotional balance is not paid in full, interest will be charged from the purchase date

**Payment Terms:**
- Equal monthly payments required during promotional period
- Payments must be made on time to maintain promotional rate
- Late payments may result in loss of promotional rate
- Minimum payment due if less than promotional payment amount

**Important Disclosures:**
- Standard APR applies after promotional period ends
- Interest will be charged from purchase date if promotional balance not paid in full
- Account must remain in good standing to maintain promotional terms
- Subject to credit limit and account terms

### Standard APR Financing

**Interest Rates:**
- APR varies based on creditworthiness
- Rates typically range from 17.90% to 29.99%
- Rate determined at time of credit approval

**Payment Options:**
- Minimum monthly payments based on balance
- Pay more than minimum to reduce interest charges
- No prepayment penalties

## CareCredit Healthcare Financing

### No Interest Promotional Plans

**Available Terms:**
- 6 months no interest on purchases of $200+
- 12 months no interest on purchases of $300+
- 18 months no interest on purchases of $500+
- 24 months no interest on purchases of $1,000+

**Eligible Services:**
- Dental procedures and treatments
- Vision care and LASIK surgery
- Veterinary care for pets
- Cosmetic and dermatology procedures
- Hearing aids and audiology services

**How No Interest Works:**
- No interest if paid in full within promotional period
- Interest will be charged from purchase date if promotional balance not paid in full
- Minimum monthly payments required during promotional period

### Extended Payment Plans

**Long-term Financing:**
- 24, 36, 48, or 60 month payment plans available
- Fixed APR typically 17.90% for qualified applicants
- Predictable monthly payments
- Available for purchases of $1,000 or more

**Benefits:**
- Lower monthly payments compared to no interest plans
- Interest charges spread over longer term
- Helps manage larger healthcare expenses

## Application Process

### Online Application
1. **Quick Pre-qualification:** Soft credit check, no impact to credit score
2. **Instant Decision:** Most applications approved within seconds
3. **Use Immediately:** Start using your account right away

### In-Store Application
1. **Apply at Point of Sale:** Complete application with merchant
2. **Instant Approval:** Get decision immediately
3. **Complete Purchase:** Use financing for same-day purchase

### Required Information
- Full legal name and date of birth
- Social Security number
- Current address and phone number
- Employment information and income
- Valid government-issued photo ID

## Account Management

### Online Account Access
- View statements and payment history
- Make payments online or by phone
- Set up automatic payments
- Update account information
- Access promotional offers

### Payment Options
- Online payments from bank account
- Phone payments available 24/7
- Mail payments to processing center
- Automatic payment setup available

### Customer Service
- 24/7 customer service available
- Dedicated healthcare financing specialists
- Account management support
- Dispute resolution assistance

## Important Notices

### Credit Impact
- Credit applications may impact credit score
- Payment history reported to credit bureaus
- Responsible use can help build credit history

### Fees and Penalties
- Late payment fees may apply
- Returned payment fees for insufficient funds
- No annual fees on most accounts
- No prepayment penalties

### Promotional Rate Protection
- Make all payments on time to maintain promotional rate
- Pay at least the minimum promotional payment amount
- Account must remain in good standing
- Contact customer service if experiencing payment difficulties

## Merchant-Specific Terms

### Electronics and Technology
- Apple Store: 0% APR for 18 months on purchases $500+
- Dell: 0% APR for 24 months on purchases $750+
- HP: Standard APR financing available

### Furniture and Home
- OfficeMax: 0% APR for 12 months on purchases $299+
- IKEA: Standard APR financing available

### Healthcare Providers
- Dental practices: CareCredit 6-12 month no interest plans
- Veterinary clinics: CareCredit 18 month no interest plans
- Vision centers: CareCredit promotional financing available

---

*Terms and conditions subject to change. All financing subject to credit approval. See merchant or visit website for current terms and complete details.*

**Last Updated:** January 2025



================================================
FILE: app/kb/security_guidelines.md
================================================
# Security Guidelines and Threat Response

## Overview

This document provides comprehensive security guidelines for identifying and responding to various threats, scams, and security incidents.

## PII Protection Guidelines

### Credit Card Information
- **Never share** complete credit card numbers in unsecured communications
- **Immediately report** any suspected credit card data exposure
- **Use secure channels** for payment processing only
- **Verify legitimacy** of any payment requests

### Social Security Numbers (SSN)
- **Critical sensitivity**: SSNs should never be shared via chat, email, or phone
- **Identity theft risk**: Exposure can lead to serious financial fraud
- **Immediate action**: Report any SSN exposure to security team immediately
- **Verification required**: Always verify identity before discussing SSN-related matters

### Personal Identifiable Information (PII)
- **Minimize collection**: Only collect PII that is absolutely necessary
- **Secure storage**: All PII must be encrypted and access-controlled
- **Limited sharing**: PII should only be shared on a need-to-know basis
- **Regular audits**: Conduct regular reviews of PII handling practices

## Scam Detection and Prevention

### Refund Scams
**Common patterns:**
- Claims of overpayment requiring gift card refunds
- Requests to purchase gift cards for verification
- Urgent demands for immediate payment via unconventional methods

**Response protocol:**
1. **Stop all communication** immediately
2. **Do not provide** any payment information
3. **Verify independently** through official channels
4. **Report the incident** to security team

### Gift Card Fraud
**Warning signs:**
- Requests for gift card codes as payment
- Claims that gift cards are required for refunds
- High-pressure tactics demanding immediate gift card purchases

**Prevention measures:**
- **Educate users** that legitimate businesses don't request gift card payments
- **Verify all requests** through independent communication channels
- **Report suspicious activity** immediately

### Wire Transfer Fraud
**Red flags:**
- Urgent requests for wire transfers
- Instructions to send money to unfamiliar recipients
- Claims of emergency situations requiring immediate wire transfers

**Safety measures:**
- **Verify recipient identity** through multiple channels
- **Confirm legitimacy** of transfer requests independently
- **Use secure, traceable** transfer methods when legitimate

## Phishing and Social Engineering

### Common Phishing Tactics
- **Urgent action required** messages
- **Account suspension** threats
- **Immediate verification** demands
- **Suspicious links** and attachments

### Protection strategies:**
- **Verify sender identity** through independent channels
- **Check URLs carefully** before clicking
- **Never provide credentials** via email or chat
- **Report suspicious messages** to security team

## Account Security

### Account Takeover Prevention
**Warning signs:**
- Unexpected password reset requests
- Unfamiliar login notifications
- Changes to account information without user action
- Suspicious account activity

**Response actions:**
1. **Change passwords** immediately
2. **Enable two-factor authentication**
3. **Review account activity** for unauthorized changes
4. **Contact security team** for investigation

### Multi-Factor Authentication (MFA)
- **Enable MFA** on all critical accounts
- **Use authenticator apps** rather than SMS when possible
- **Keep backup codes** in a secure location
- **Regularly review** MFA settings

## Incident Response Procedures

### Immediate Response (0-15 minutes)
1. **Contain the threat** - Stop ongoing malicious activity
2. **Assess the scope** - Determine what information may be compromised
3. **Notify security team** - Alert appropriate personnel immediately
4. **Document the incident** - Record all relevant details

### Short-term Response (15 minutes - 4 hours)
1. **Investigate thoroughly** - Gather all available evidence
2. **Implement safeguards** - Prevent further damage
3. **Notify affected parties** - Inform users if their data is involved
4. **Coordinate response** - Work with relevant teams and authorities

### Long-term Response (4+ hours)
1. **Complete investigation** - Determine root cause and full impact
2. **Implement improvements** - Update security measures to prevent recurrence
3. **Monitor for recurrence** - Watch for similar threats
4. **Update procedures** - Revise security protocols based on lessons learned

## Contact Information

### Security Team
- **Emergency hotline**: 1-800-SECURITY (24/7)
- **Email**: security@company.com
- **Incident reporting**: incidents@company.com

### Law Enforcement
- **FBI Internet Crime Complaint Center**: ic3.gov
- **Local police**: 911 (for immediate threats)
- **FTC Fraud Reporting**: reportfraud.ftc.gov

## Training and Awareness

### Regular Training Topics
- **Phishing recognition** - Monthly awareness sessions
- **Social engineering tactics** - Quarterly workshops
- **Incident response** - Annual drills and simulations
- **New threat briefings** - As needed based on emerging threats

### Resources
- **Security awareness portal**: security.company.com
- **Threat intelligence updates**: Weekly security bulletins
- **Best practices guide**: Available on company intranet
- **Reporting tools**: Integrated into all communication platforms

## Compliance and Regulatory Requirements

### Data Protection Regulations
- **GDPR compliance** for European users
- **CCPA compliance** for California residents
- **PCI DSS standards** for payment processing
- **SOX requirements** for financial reporting

### Audit and Monitoring
- **Continuous monitoring** of security events
- **Regular compliance audits** by third-party assessors
- **Penetration testing** conducted quarterly
- **Vulnerability assessments** performed monthly

---

*This document is updated regularly to reflect the latest security threats and best practices. Last updated: January 2025*



================================================
FILE: app/llm/__init__.py
================================================
# LLM Package



================================================
FILE: app/llm/gemini.py
================================================
"""
Gemini chat model integration for LLM functionality
"""

import os
import logging
from typing import List, Dict, Any, Optional

from google import genai

logger = logging.getLogger(__name__)

def chat(messages: List[Dict[str, str]], system: Optional[str] = None) -> str:
    """
    Generate chat response using Gemini chat model
    
    Args:
        messages: List of message dictionaries with 'role' and 'content' keys
                 Roles should be 'user' or 'assistant'
        system: Optional system prompt to prepend to the conversation
        
    Returns:
        Generated response string
        
    Raises:
        ValueError: If API key is not configured
        Exception: For API errors or other failures
    """
    # Get configuration
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GOOGLE_API_KEY environment variable is required")
    
    model_name = os.getenv("GEMINI_CHAT_MODEL", "gemini-2.5-flash")
    
    # Initialize the modern Gemini client
    client = genai.Client(api_key=api_key)
    
    try:
        # Build the prompt
        prompt_parts = []
        
        # Add system prompt if provided
        if system:
            prompt_parts.append(f"System: {system}\n")
        
        # Add conversation messages
        for message in messages:
            role = message.get("role", "user")
            content = message.get("content", "")
            
            if role == "user":
                prompt_parts.append(f"User: {content}")
            elif role == "assistant":
                prompt_parts.append(f"Assistant: {content}")
            else:
                # Handle unknown roles as user messages
                prompt_parts.append(f"User: {content}")
        
        # Add final assistant prompt
        prompt_parts.append("Assistant:")
        
        # Combine into single prompt
        full_prompt = "\n\n".join(prompt_parts)
        
        logger.debug(f"Sending prompt to Gemini model {model_name}")
        
        # Generate response using modern API
        response = client.models.generate_content(
            model=model_name,
            contents=full_prompt
        )
        
        if not response.text:
            logger.warning("Empty response from Gemini API")
            return "I apologize, but I couldn't generate a response. Please try again."
        
        logger.debug(f"Received response from Gemini: {len(response.text)} characters")
        return response.text.strip()
        
    except Exception as e:
        logger.error(f"Error generating chat response with Gemini: {e}")
        return f"I apologize, but I encountered an error while processing your request: {str(e)}"

def chat_with_context(
    query: str,
    context_documents: List[Dict[str, Any]],
    system_prompt: Optional[str] = None
) -> str:
    """
    Generate chat response with retrieved document context
    
    Args:
        query: User's query
        context_documents: List of retrieved documents with 'snippet' and 'source' keys
        system_prompt: Optional system prompt
        
    Returns:
        Generated response string
    """
    # Default system prompt for RAG
    default_system = (
        "You are a helpful assistant that answers questions based on provided documents. "
        "Use only the information from the documents to answer questions. "
        "If the information is not available in the documents, say so clearly. "
        "Provide specific references to the source documents when possible."
    )
    
    system = system_prompt or default_system
    
    # Build context from documents
    context_parts = []
    for i, doc in enumerate(context_documents, 1):
        snippet = doc.get("snippet", "")
        source = doc.get("source", "unknown")
        filename = doc.get("filename", "unknown")
        doc_type = doc.get("type", "unknown")
        
        context_parts.append(
            f"Document {i}:\n"
            f"Source: {filename} ({doc_type})\n"
            f"Content: {snippet}\n"
        )
    
    context_text = "\n".join(context_parts)
    
    # Create user message with context
    user_message = f"""
Based on the following documents, please answer this question: {query}

Documents:
{context_text}

Question: {query}

Please provide a comprehensive answer based on the information in the documents above.
"""
    
    messages = [{"role": "user", "content": user_message}]
    
    return chat(messages, system=system)

def summarize_text(text: str, max_length: int = 500) -> str:
    """
    Summarize text using Gemini
    
    Args:
        text: Text to summarize
        max_length: Maximum length of summary in words
        
    Returns:
        Summarized text
    """
    system_prompt = (
        f"You are a helpful assistant that creates concise summaries. "
        f"Summarize the following text in no more than {max_length} words. "
        f"Focus on the key points and maintain accuracy."
    )
    
    messages = [{"role": "user", "content": f"Please summarize this text:\n\n{text}"}]
    
    return chat(messages, system=system_prompt)

def extract_key_points(text: str, num_points: int = 5) -> List[str]:
    """
    Extract key points from text using Gemini
    
    Args:
        text: Text to analyze
        num_points: Number of key points to extract
        
    Returns:
        List of key points as strings
    """
    system_prompt = (
        "You are a helpful assistant that extracts key points from text. "
        f"Extract the {num_points} most important points from the following text. "
        "Return each point as a separate line starting with a bullet point (‚Ä¢)."
    )
    
    messages = [{"role": "user", "content": f"Extract key points from this text:\n\n{text}"}]
    
    response = chat(messages, system=system_prompt)
    
    # Parse bullet points
    lines = response.split('\n')
    key_points = []
    
    for line in lines:
        line = line.strip()
        if line.startswith('‚Ä¢') or line.startswith('-') or line.startswith('*'):
            # Remove bullet point and clean up
            point = line[1:].strip()
            if point:
                key_points.append(point)
    
    return key_points[:num_points]  # Ensure we don't exceed requested number

def classify_query(query: str, categories: List[str]) -> str:
    """
    Classify a query into one of the provided categories
    
    Args:
        query: Query to classify
        categories: List of possible categories
        
    Returns:
        Best matching category
    """
    categories_text = ", ".join(categories)
    
    system_prompt = (
        "You are a helpful assistant that classifies user queries. "
        f"Classify the following query into one of these categories: {categories_text}. "
        "Return only the category name, nothing else."
    )
    
    messages = [{"role": "user", "content": f"Classify this query: {query}"}]
    
    response = chat(messages, system=system_prompt).strip()
    
    # Find best match from categories
    response_lower = response.lower()
    for category in categories:
        if category.lower() in response_lower:
            return category
    
    # Return first category as fallback
    return categories[0] if categories else "general"

def chat_with_context_and_fallback(
    query: str,
    context_documents: List[Dict[str, Any]],
    allow_llm_knowledge: bool = True,
    allow_web_search: bool = False,
    system_prompt: Optional[str] = None
) -> Dict[str, Any]:
    """
    Generate chat response with fallback options when documents are insufficient
    
    Args:
        query: User's query
        context_documents: List of retrieved documents with 'snippet' and 'source' keys
        allow_llm_knowledge: Whether to fallback to LLM's own knowledge if documents insufficient
        allow_web_search: Whether to use web search if documents insufficient
        system_prompt: Optional system prompt
        
    Returns:
        Dictionary with response, fallback_used, and confidence
    """
    # Check document quality/relevance intelligently
    doc_quality = assess_document_quality(query, context_documents)
    
    fallback_used = None
    confidence = doc_quality["confidence"]
    
    if doc_quality["sufficient"]:
        # Use regular RAG response
        response = chat_with_context(query, context_documents, system_prompt)
    else:
        # Documents are insufficient - use fallback
        if allow_llm_knowledge:
            response = chat_with_llm_knowledge(query, context_documents, system_prompt)
            fallback_used = "llm_knowledge"
            confidence = max(0.6, confidence)  # Boost confidence for LLM knowledge fallback
        elif allow_web_search:
            try:
                # Import here to avoid circular dependency
                from app.tools.tavily_search import web_search_into_docstore
                
                # Perform web search (this should be done in the main endpoint, but for now we'll indicate it)
                response = chat_with_web_search_fallback(query, context_documents, system_prompt)
                fallback_used = "web_search"
                confidence = 0.7  # Higher confidence for web search results
            except ImportError:
                response = f"Based on the documents provided, there is insufficient information to answer '{query}'. Web search functionality is not available."
                fallback_used = "web_search_unavailable"
                confidence = 0.3
        else:
            response = f"Based on the documents provided, there is insufficient information to answer '{query}'. Consider enabling fallback options (LLM knowledge or web search) to access additional information sources."
            fallback_used = "none"
            confidence = 0.2
    
    return {
        "response": response,
        "fallback_used": fallback_used,
        "confidence": confidence,
        "document_assessment": doc_quality
    }

def assess_document_quality(query: str, context_documents: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Intelligently assess whether retrieved documents are sufficient to answer the query
    
    Args:
        query: User's query
        context_documents: Retrieved documents
        
    Returns:
        Dictionary with assessment results
    """
    if not context_documents:
        return {
            "sufficient": False,
            "confidence": 0.0,
            "reason": "No documents found",
            "document_quality_score": 0.0,
            "semantic_relevance": 0.0,
            "coverage_score": 0.0
        }
    
    # Use LLM to assess document relevance and coverage
    assessment_prompt = f"""
Analyze whether these documents contain sufficient information to answer the user's question comprehensively.

Question: {query}

Documents:
{_format_docs_for_assessment(context_documents)}

Rate the documents on a scale of 0-10 for:
1. Semantic Relevance: How well do the documents relate to the question?
2. Information Coverage: How completely do they address what the user is asking?
3. Answer Sufficiency: Can the question be fully answered using only these documents?

Respond in this exact JSON format:
{{
    "semantic_relevance": <0-10>,
    "coverage_score": <0-10>, 
    "answer_sufficiency": <0-10>,
    "sufficient": <true/false>,
    "reasoning": "<brief explanation>"
}}
"""
    
    try:
        # Get LLM assessment
        messages = [{"role": "user", "content": assessment_prompt}]
        assessment_response = chat(messages, system="You are an expert at evaluating document relevance. Provide only valid JSON responses.")
        
        logger.debug(f"Raw Gemini assessment response: {assessment_response[:200]}...")
        
        # Parse JSON response with robust handling
        import json
        
        # Handle markdown-wrapped JSON responses
        response_text = assessment_response.strip()
        if response_text.startswith('```json'):
            # Extract JSON from markdown code block
            response_text = response_text.replace('```json', '').replace('```', '').strip()
        elif response_text.startswith('```'):
            # Handle generic code blocks
            lines = response_text.split('\n')
            response_text = '\n'.join(lines[1:-1]).strip()
        
        # Check if response is empty or contains fallback message
        if not response_text or "I apologize, but I couldn't generate a response" in response_text:
            logger.error("Empty or fallback response from Gemini API for document assessment")
            raise ValueError("Empty or fallback response from Gemini API")
        
        logger.debug(f"Cleaned response text: {response_text[:200]}...")
        assessment = json.loads(response_text)
        
        # Validate assessment structure
        required_fields = ['semantic_relevance', 'coverage_score', 'answer_sufficiency', 'sufficient']
        missing_fields = [field for field in required_fields if field not in assessment]
        if missing_fields:
            logger.warning(f"Missing fields in assessment: {missing_fields}")
            # Set default values for missing fields
            for field in missing_fields:
                if field == 'sufficient':
                    assessment[field] = False
                else:
                    assessment[field] = 0
        
        # Calculate overall quality score
        quality_score = (
            assessment.get("semantic_relevance", 0) * 0.4 +
            assessment.get("coverage_score", 0) * 0.4 +
            assessment.get("answer_sufficiency", 0) * 0.2
        ) / 10.0
        
        # Determine sufficiency with intelligent thresholds
        sufficient = assessment.get("sufficient", False) and quality_score >= 0.6
        
        return {
            "sufficient": sufficient,
            "confidence": quality_score,
            "reason": assessment.get("reasoning", "Assessment completed"),
            "document_quality_score": quality_score,
            "semantic_relevance": assessment.get("semantic_relevance", 0) / 10.0,
            "coverage_score": assessment.get("coverage_score", 0) / 10.0,
            "answer_sufficiency": assessment.get("answer_sufficiency", 0) / 10.0
        }
        
    except json.JSONDecodeError as e:
        logger.warning(f"Failed to parse Gemini JSON response for assessment, falling back to heuristics. Response was: '{assessment_response[:100]}...' Error: {e}")
        
        # Fallback to enhanced heuristic assessment
    except Exception as e:
        logger.warning(f"Failed to get intelligent assessment, falling back to heuristics: {e}")
        
        # Fallback to enhanced heuristic assessment
        scores = [doc.get("score", 0.0) for doc in context_documents]
        avg_score = sum(scores) / len(scores) if scores else 0.0
        
        # Enhanced heuristics
        keyword_matches = _count_keyword_matches(query, context_documents)
        length_score = min(1.0, sum(len(doc.get("snippet", "")) for doc in context_documents) / 1000)
        diversity_score = _calculate_document_diversity(context_documents)
        
        quality_score = (avg_score * 0.4) + (keyword_matches * 0.3) + (length_score * 0.2) + (diversity_score * 0.1)
        sufficient = quality_score >= 0.5 and len(context_documents) >= 1
        
        return {
            "sufficient": sufficient,
            "confidence": quality_score,
            "reason": f"Heuristic assessment - relevance: {avg_score:.2f}, keywords: {keyword_matches:.2f}, content: {length_score:.2f}",
            "document_quality_score": quality_score,
            "semantic_relevance": avg_score,
            "coverage_score": keyword_matches,
            "answer_sufficiency": length_score
        }

def chat_with_llm_knowledge(
    query: str,
    context_documents: List[Dict[str, Any]],
    system_prompt: Optional[str] = None
) -> str:
    """
    Generate chat response using LLM's own knowledge with document context as supporting info
    
    Args:
        query: User's query
        context_documents: Retrieved documents (used as supporting context)
        system_prompt: Optional system prompt
        
    Returns:
        Generated response string
    """
    # Enhanced system prompt that allows LLM knowledge
    enhanced_system = (
        "You are a helpful assistant with extensive knowledge. "
        "Answer the user's question using your knowledge and training. "
        "If relevant documents are provided, use them as supporting evidence, but you may "
        "also draw from your general knowledge to provide a comprehensive answer. "
        "Clearly distinguish between information from documents and your general knowledge. "
        "If the documents have limited relevance, focus more on your training knowledge."
    )
    
    system = system_prompt or enhanced_system
    
    # Build supporting context from documents if available
    if context_documents:
        context_parts = []
        for i, doc in enumerate(context_documents[:3], 1):  # Limit to top 3
            snippet = doc.get("snippet", "")[:400]  # Limit length
            filename = doc.get("filename", "unknown")
            score = doc.get("score", 0.0)
            
            context_parts.append(f"Supporting Document {i} ({filename}, relevance: {score:.2f}):\n{snippet}")
        
        context_text = "\n\n".join(context_parts)
        
        user_message = f"""
Question: {query}

Supporting documents (may have limited relevance):
{context_text}

Please answer the question comprehensively using your knowledge. You may reference the supporting documents if relevant, but feel free to provide additional context and information from your training to give a complete answer. If the documents don't fully address the question, supplement with your general knowledge.
"""
    else:
        user_message = f"Question: {query}\n\nPlease provide a comprehensive answer using your knowledge and training."
    
    messages = [{"role": "user", "content": user_message}]
    
    return chat(messages, system=system)

def _format_docs_for_assessment(context_documents: List[Dict[str, Any]]) -> str:
    """Format documents for LLM assessment"""
    formatted = []
    for i, doc in enumerate(context_documents[:5], 1):  # Limit to top 5 docs
        snippet = doc.get("snippet", "")[:300]  # Limit snippet length
        filename = doc.get("filename", "unknown")
        score = doc.get("score", 0.0)
        
        formatted.append(f"Doc {i} ({filename}, score: {score:.2f}):\n{snippet}")
    
    return "\n\n".join(formatted)

def _count_keyword_matches(query: str, context_documents: List[Dict[str, Any]]) -> float:
    """Count keyword matches between query and documents"""
    import re
    
    # Extract keywords from query (simple approach)
    query_words = set(re.findall(r'\b\w+\b', query.lower()))
    query_words = {w for w in query_words if len(w) > 2}  # Filter short words
    
    if len(query_words) == 0:
        return 0.0
    
    total_matches = 0
    for doc in context_documents:
        snippet = doc.get("snippet", "").lower()
        doc_words = set(re.findall(r'\b\w+\b', snippet))
        matches = len(query_words.intersection(doc_words))
        total_matches += matches
    
    # Normalize by query length and document count
    return min(1.0, total_matches / (len(query_words) * len(context_documents)))

def _calculate_document_diversity(context_documents: List[Dict[str, Any]]) -> float:
    """Calculate diversity score based on different document sources"""
    if len(context_documents) <= 1:
        return 0.5
    
    sources = set()
    for doc in context_documents:
        filename = doc.get("filename", "unknown")
        doc_type = doc.get("type", "unknown")
        sources.add(f"{filename}_{doc_type}")
    
    # More diverse sources = higher score
    diversity = len(sources) / len(context_documents)
    return min(1.0, diversity * 2)  # Scale up the impact

def chat_with_web_search_fallback(
    query: str,
    context_documents: List[Dict[str, Any]],
    system_prompt: Optional[str] = None
) -> str:
    """
    Generate chat response indicating web search would be performed
    (Actual web search should be handled in the main endpoint)
    
    Args:
        query: User's query
        context_documents: Retrieved documents (used as supporting context)
        system_prompt: Optional system prompt
        
    Returns:
        Generated response string
    """
    # Enhanced system prompt that acknowledges web search capability
    enhanced_system = (
        "You are a helpful assistant with access to both document knowledge and web search. "
        "The provided documents have limited relevance to the user's question, so you should "
        "indicate that web search would provide more current and comprehensive information. "
        "Acknowledge what limited information is available in the documents, then suggest "
        "that web search would be performed to get more complete answers."
    )
    
    system = system_prompt or enhanced_system
    
    # Build context information
    if context_documents:
        doc_info = f"Available documents ({len(context_documents)} found) have limited relevance to your question."
    else:
        doc_info = "No relevant documents were found in the knowledge base."
    
    user_message = f"""
Question: {query}

{doc_info}

Since the document knowledge is insufficient to fully answer your question, a web search would typically be performed here to find more current and comprehensive information. This would help provide you with up-to-date answers that go beyond the available document knowledge base.
    
Please provide a response acknowledging the limitation and indicating what a web search could help find.
"""
    
    messages = [{"role": "user", "content": user_message}]
    
    return chat(messages, system=system)



================================================
FILE: app/multi_agent/__init__.py
================================================
"""
Multi-Agent Financial Services System using LangGraph
"""


================================================
FILE: app/multi_agent/state.py
================================================
"""
LangGraph State Management for Multi-Agent Financial Services System
"""

from typing import TypedDict, List, Dict, Any, Optional, Annotated
from dataclasses import dataclass, field
from enum import Enum
import operator

from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage


class TaskComplexity(Enum):
    """Task complexity levels"""
    SIMPLE = "simple"        # Single agent can handle
    MODERATE = "moderate"    # 2-3 agents needed
    COMPLEX = "complex"      # Multiple agents + coordination needed


class ExecutionStrategy(Enum):
    """How agents should be executed"""
    SEQUENTIAL = "sequential"  # One after another
    PARALLEL = "parallel"     # Simultaneously  
    CONDITIONAL = "conditional"  # Based on results


@dataclass
class AgentTask:
    """Individual task for a specific agent"""
    agent_type: str
    query: str
    priority: int = 1
    dependencies: List[str] = field(default_factory=list)
    context: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AgentResult:
    """Result from an individual agent"""
    agent_type: str
    success: bool
    response: str
    confidence: float
    sources: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    error: Optional[str] = None
    processing_time: float = 0.0


class FinancialServicesState(TypedDict):
    """
    Comprehensive state for financial services multi-agent system
    Based on LangGraph best practices with financial domain specifics
    """
    # Core conversation state - using LangGraph's add_messages reducer
    messages: Annotated[List[BaseMessage], add_messages]
    
    # Original user query and intent
    original_query: str
    user_intent: Optional[str]
    
    # Agent coordination
    current_agent: Optional[str] 
    supervisor_active: bool
    active_agents: List[str]
    completed_agents: List[str]
    
    # Task planning and execution
    task_complexity: Optional[TaskComplexity]
    execution_strategy: Optional[ExecutionStrategy] 
    agent_tasks: List[AgentTask]
    
    # Results aggregation
    agent_results: Dict[str, AgentResult]
    final_response: Optional[str]
    total_confidence: float
    
    # Financial services specific
    requires_pii_protection: bool
    compliance_check_needed: bool
    risk_level: str  # low, medium, high
    
    # Citation and source tracking
    all_sources: List[str]
    citation_map: Dict[str, List[str]]  # agent -> sources
    
    # User preferences and context
    allow_tavily: bool
    allow_llm_knowledge: bool 
    allow_web_search: bool
    user_context: Dict[str, Any]
    
    # Error handling and recovery
    errors: List[str]
    fallback_used: bool
    retry_count: int


class SupervisorState(TypedDict):
    """
    Simplified state for supervisor agent routing decisions
    Focuses on what supervisor needs to make routing decisions
    """
    messages: Annotated[List[BaseMessage], add_messages]
    original_query: str
    user_intent: Optional[str]
    task_complexity: Optional[TaskComplexity]
    next_agent: Optional[str]
    routing_reason: Optional[str]
    available_agents: List[str]
    user_preferences: Dict[str, bool]


class WorkerState(TypedDict):
    """
    State for individual worker agents
    Contains only what each agent needs to operate
    """
    messages: Annotated[List[BaseMessage], add_messages]
    query: str
    context: Dict[str, Any]
    user_preferences: Dict[str, bool]
    previous_results: Dict[str, Any]  # Results from other agents


# State reducer functions for complex state management
def reduce_agent_results(current: Dict[str, AgentResult], new: Dict[str, AgentResult]) -> Dict[str, AgentResult]:
    """Reducer for agent results - merge without overwriting"""
    merged = current.copy()
    merged.update(new)
    return merged


def reduce_sources(current: List[str], new: List[str]) -> List[str]:
    """Reducer for sources - combine and deduplicate"""
    combined = current + new
    return list(dict.fromkeys(combined))  # Preserves order while deduplicating


def reduce_errors(current: List[str], new: List[str]) -> List[str]:
    """Reducer for errors - append new errors"""
    return current + new


# Enhanced state with custom reducers
class EnhancedFinancialState(TypedDict):
    """Enhanced state with custom reducers for better state management"""
    # Core state
    messages: Annotated[List[BaseMessage], add_messages]
    original_query: str
    
    # Enhanced fields with custom reducers
    agent_results: Annotated[Dict[str, AgentResult], reduce_agent_results]
    all_sources: Annotated[List[str], reduce_sources] 
    errors: Annotated[List[str], reduce_errors]
    
    # Simple fields
    current_agent: Optional[str]
    final_response: Optional[str]
    total_confidence: float
    task_complexity: Optional[TaskComplexity]
    
    # User preferences
    allow_tavily: bool
    allow_llm_knowledge: bool
    allow_web_search: bool


# Factory functions for creating initial states
def create_initial_state(
    original_query: str,
    allow_tavily: bool = False,
    allow_llm_knowledge: bool = True, 
    allow_web_search: bool = False,
    user_context: Optional[Dict[str, Any]] = None
) -> FinancialServicesState:
    """Create initial state for multi-agent workflow"""
    return FinancialServicesState(
        messages=[],
        original_query=original_query,
        user_intent=None,
        current_agent=None,
        supervisor_active=True,
        active_agents=[],
        completed_agents=[],
        task_complexity=None,
        execution_strategy=None,
        agent_tasks=[],
        agent_results={},
        final_response=None,
        total_confidence=0.0,
        requires_pii_protection=False,
        compliance_check_needed=True,
        risk_level="low",
        all_sources=[],
        citation_map={},
        allow_tavily=allow_tavily,
        allow_llm_knowledge=allow_llm_knowledge,
        allow_web_search=allow_web_search,
        user_context=user_context or {},
        errors=[],
        fallback_used=False,
        retry_count=0
    )


def create_supervisor_state(base_state: FinancialServicesState) -> SupervisorState:
    """Extract supervisor-relevant state from full state"""
    return SupervisorState(
        messages=base_state["messages"],
        original_query=base_state["original_query"],
        user_intent=base_state["user_intent"],
        task_complexity=base_state["task_complexity"],
        next_agent=None,
        routing_reason=None,
        available_agents=[
            "trustshield", "offerpilot", "dispute", "collections", 
            "contracts", "devcopilot", "carecredit", "narrator", "imagegen"
        ],
        user_preferences={
            "allow_tavily": base_state["allow_tavily"],
            "allow_llm_knowledge": base_state["allow_llm_knowledge"],
            "allow_web_search": base_state["allow_web_search"]
        }
    )


def create_worker_state(
    base_state: FinancialServicesState, 
    agent_query: str,
    agent_context: Optional[Dict[str, Any]] = None
) -> WorkerState:
    """Create worker agent state from base state"""
    return WorkerState(
        messages=base_state["messages"], 
        query=agent_query,
        context=agent_context or {},
        user_preferences={
            "allow_tavily": base_state["allow_tavily"],
            "allow_llm_knowledge": base_state["allow_llm_knowledge"], 
            "allow_web_search": base_state["allow_web_search"]
        },
        previous_results={
            agent: result.response 
            for agent, result in base_state["agent_results"].items()
            if result.success
        }
    )


================================================
FILE: app/multi_agent/supervisor.py
================================================
"""
LangGraph Supervisor Agent for Financial Services Multi-Agent System
Enhanced Smart Chat with multi-agent orchestration capabilities
"""

import logging
import json
from typing import Dict, List, Any, Optional, Union
from dataclasses import asdict

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END, START
from langgraph.constants import Send
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.tool_node import tools_condition

from .state import (
    FinancialServicesState, SupervisorState, WorkerState,
    TaskComplexity, ExecutionStrategy, AgentTask, AgentResult,
    create_initial_state, create_supervisor_state, create_worker_state
)
from ..utils.tracer import get_tracer

logger = logging.getLogger(__name__)


class FinancialServicesSupervisor:
    """
    LangGraph-based supervisor for coordinating financial services agents
    Enhanced Smart Chat with full reasoning access and graceful degradation
    """
    
    def __init__(self, agents: Dict[str, Any], google_api_key: str):
        self.agents = agents
        # Available agents for routing (exclude trustshield as it's middleware only)
        self.available_agents = [name for name in agents.keys() if name != 'trustshield']
        
        # Initialize Gemini model for supervisor reasoning
        self.supervisor_model = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            api_key=google_api_key,
            temperature=0.1,  # Lower temperature for more consistent routing
            max_tokens=4096
        )
        
        # Initialize analysis model for query complexity
        self.analysis_model = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash", 
            api_key=google_api_key,
            temperature=0.0,  # Deterministic for analysis
            max_tokens=2048
        )
        
        self.graph = self._build_graph()
        
    def _build_graph(self) -> StateGraph:
        """
        Build the LangGraph multi-agent workflow with hierarchical orchestration
        Following Tier-0 Master ‚Üí Tier-1 Persona Supervisors ‚Üí Tier-2 Agents pattern
        """
        # Create the graph with our financial services state
        graph = StateGraph(FinancialServicesState)
        
        # Tier-0: Master node - persona and platform detection
        graph.add_node("master", self._master_node)
        
        # Tier-1: Persona-specific supervisors
        graph.add_node("consumer_supervisor", self._consumer_supervisor_node)
        graph.add_node("partner_supervisor", self._partner_supervisor_node)
        
        # Tier-2: Analysis, planning, coordination, execution (reused from existing)
        graph.add_node("analyze_query", self._analyze_query_node)
        graph.add_node("plan_execution", self._plan_execution_node)
        graph.add_node("coordinator", self._coordinator_node)  # Routes to individual agents
        graph.add_node("synthesize_results", self._synthesize_results_node)
        graph.add_node("fallback_handler", self._fallback_node)
        
        # Add individual agent nodes (trustshield already excluded from available_agents)
        for agent_name in self.available_agents:
            graph.add_node(f"agent_{agent_name}", self._create_agent_node(agent_name))
        
        # Define the hierarchical workflow edges
        graph.add_edge(START, "master")
        
        # Master routes to persona-specific supervisors
        graph.add_conditional_edges(
            "master",
            self._master_routing,
            {
                "consumer": "consumer_supervisor",
                "partner": "partner_supervisor", 
                "fallback": "fallback_handler"
            }
        )
        
        # Persona supervisors route to analysis
        graph.add_edge("consumer_supervisor", "analyze_query")
        graph.add_edge("partner_supervisor", "analyze_query")
        
        # From analysis, decide single vs multi-agent
        graph.add_conditional_edges(
            "analyze_query",
            self._route_after_analysis,
            {
                "single_agent": "plan_execution",  # Still need planning for agent selection
                "multi_agent": "plan_execution",   # Plan multi-agent execution
                "fallback": "fallback_handler"     # Handle errors
            }
        )
        
        # From planning, route to coordinator 
        graph.add_conditional_edges(
            "plan_execution", 
            self._route_execution_strategy,
            {
                "sequential": "coordinator",  # Coordinator manages sequential execution
                "parallel": "coordinator",    # Coordinator handles parallel execution  
                "conditional": "coordinator", # Coordinator manages conditional logic
                "fallback": "fallback_handler"
            }
        )
        
        # Coordinator routes to specific agents
        graph.add_conditional_edges(
            "coordinator",
            self._coordinator_routing,
            {
                **{f"agent_{agent}": f"agent_{agent}" for agent in self.available_agents},
                "synthesize": "synthesize_results",
                "fallback": "fallback_handler"
            }
        )
        
        # All agent nodes return to coordinator for sequence management
        for agent_name in self.available_agents:
            graph.add_edge(f"agent_{agent_name}", "coordinator")
        
        # Synthesis completes or falls back
        graph.add_conditional_edges(
            "synthesize_results",
            self._check_synthesis_completion,
            {
                "complete": END,
                "fallback": "fallback_handler"
            }
        )
        
        # Fallback always tries to end gracefully
        graph.add_edge("fallback_handler", END)
        
        return graph.compile()
    
    async def process_query(
        self, 
        query: str,
        allow_tavily: bool = False,
        allow_llm_knowledge: bool = True,
        allow_web_search: bool = False,
        user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Main entry point for processing queries with multi-agent orchestration
        """
        logger.info(f"Processing query with enhanced Smart Chat: {query[:100]}...")
        
        # Start tracing for Agent Theater
        tracer = get_tracer()
        trace_id = tracer.start_trace()
        
        try:
            with tracer.trace_agent('smart', 'Smart Chat') as smart_execution:
                if smart_execution:
                    tracer.set_agent_summaries(
                        input_summary=query[:200],
                        output_summary="Processing multi-agent orchestration"
                    )
                
                # Create initial state
                initial_state = create_initial_state(
                    original_query=query,
                    allow_tavily=allow_tavily,
                    allow_llm_knowledge=allow_llm_knowledge,
                    allow_web_search=allow_web_search,
                    user_context=user_context
                )
                
                # Add user message to state
                initial_state["messages"] = [HumanMessage(content=query)]
                
                # Execute the graph workflow
                logger.info(f"üöÄ Executing LangGraph with initial state: {list(initial_state.keys())}")
                final_state = await self.graph.ainvoke(initial_state)
                logger.info(f"‚úÖ Graph execution completed. Final state keys: {list(final_state.keys())}")
                logger.info(f"üîç Graph final state final_response: {final_state.get('final_response')}")
                
                # Update smart agent execution with final response
                if smart_execution:
                    response_preview = str(final_state.get('final_response', ''))[:200]
                    tracer.set_agent_summaries(output_summary=response_preview)
            
            # Format response for API compatibility
            response = self._format_response(final_state)
            
            # Add trace to response
            trace = tracer.finish_trace()
            if trace:
                response['agent_trace'] = {
                    'execution_id': trace.execution_id,
                    'total_duration_ms': trace.total_duration_ms,
                    'agent_executions': [
                        {
                            'agent_name': execution.agent_name,
                            'display_name': execution.display_name,
                            'started_at': execution.started_at,
                            'duration_ms': execution.duration_ms,
                            'status': execution.status,
                            'tool_calls': [
                                {
                                    'tool_name': tc.tool_name,
                                    'duration_ms': tc.duration_ms,
                                    'status': tc.status,
                                    'input_summary': tc.input_summary,
                                    'output_summary': tc.output_summary,
                                    'metadata': tc.metadata
                                }
                                for tc in execution.tool_calls
                            ],
                            'input_summary': execution.input_summary,
                            'output_summary': execution.output_summary,
                            'confidence': execution.confidence,
                            'sources_used': execution.sources_used
                        }
                        for execution in trace.agent_executions
                    ],
                    'routing_decision': trace.routing_decision
                }
            
            return response
            
        except Exception as e:
            logger.error(f"Multi-agent processing failed: {e}", exc_info=True)
            
            # Ensure trace is finished even on error
            tracer.finish_trace()
            
            # Graceful degradation - fallback to single agent
            return await self._emergency_fallback(query, allow_tavily, allow_llm_knowledge, allow_web_search)
    
    async def _master_node(self, state: FinancialServicesState) -> Dict[str, Any]:
        """
        Tier-0 Master node: Detect user persona and platform from query context
        """
        query = state["original_query"]
        user_context = state.get("user_context", {})
        
        # Extract any existing user_type from context
        existing_user_type = user_context.get("user_type", "")
        
        persona_prompt = f"""You are a persona detection system for a financial services platform. Analyze the query and context to determine if this is from a Consumer or Partner.

Consumer indicators:
- Personal financial questions ("my account", "I was charged", "help me pay")
- Individual transactions and disputes
- Personal financing needs
- General customer service requests

Partner indicators:
- Business operations ("our campaign", "promo design", "widget integration")
- Merchant/provider language ("enrollment", "compliance", "co-branded")
- Developer/technical requests ("API", "webhook", "sandbox", "POS")
- Business analytics ("portfolio metrics", "campaign performance")
- Marketing/creative requests ("signage", "promotional copy")

Query: "{query}"
Existing context user_type: "{existing_user_type}"

Respond with JSON:
{{
    "persona": "consumer|partner",
    "confidence": 0.85,
    "reasoning": "brief explanation of decision",
    "detected_indicators": ["indicator1", "indicator2"]
}}"""

        try:
            messages = [
                SystemMessage(content=persona_prompt),
                HumanMessage(content=f"Analyze persona for: {query}")
            ]
            
            response = await self.analysis_model.ainvoke(messages)
            
            # Debug: Print raw response
            logger.info(f"Raw persona detection response: {repr(response.content)}")
            
            extracted_json = self._extract_json(response.content)
            logger.info(f"Extracted JSON: {repr(extracted_json)}")
            
            result = json.loads(extracted_json)
            
            detected_persona = result.get("persona", "consumer")
            confidence = result.get("confidence", 0.5)
            
            # Override with existing user_type if available and confident
            if existing_user_type in ["consumer", "partner"] and confidence < 0.8:
                detected_persona = existing_user_type
                logger.info(f"Using existing user_type: {existing_user_type}")
            
            logger.info(f"Master node detected persona: {detected_persona} (confidence: {confidence})")
            
            return {
                "detected_persona": detected_persona,
                "persona_confidence": confidence,
                "persona_reasoning": result.get("reasoning", ""),
                "user_context": {
                    **user_context,
                    "user_type": detected_persona
                }
            }
            
        except Exception as e:
            logger.error(f"Master persona detection failed: {e}")
            # Default to consumer
            return {
                "detected_persona": "consumer",
                "persona_confidence": 0.3,
                "fallback_used": True,
                "errors": [f"Persona detection failed: {str(e)}"]
            }
    
    def _master_routing(self, state: FinancialServicesState) -> str:
        """Route from master to appropriate persona supervisor"""
        if state.get("fallback_used"):
            return "fallback"
        
        persona = state.get("detected_persona", "consumer")
        logger.info(f"üîÄ Master routing to {persona} supervisor")
        return persona
    
    async def _consumer_supervisor_node(self, state: FinancialServicesState) -> Dict[str, Any]:
        """
        Tier-1 Consumer supervisor: Filter to consumer-available agents
        """
        logger.info("Consumer supervisor: filtering agents for consumer persona")
        
        # Consumer-available agents (actual agents from initialization)
        consumer_agents = ['offerpilot', 'dispute', 'collections', 'contracts', 'carecredit', 'narrator']
        
        # Filter agent tasks to only include consumer agents
        original_tasks = state.get("agent_tasks", [])
        filtered_tasks = [task for task in original_tasks if task.agent_type in consumer_agents]
        
        return {
            "available_agents": consumer_agents,
            "agent_tasks": filtered_tasks,
            "persona_context": "consumer"
        }
    
    async def _partner_supervisor_node(self, state: FinancialServicesState) -> Dict[str, Any]:
        """
        Tier-1 Partner supervisor: Filter to partner-available agents  
        """
        logger.info("Partner supervisor: filtering agents for partner persona")
        
        # Partner-available agents (actual agents, no collections/dispute filing)  
        partner_agents = ['devcopilot', 'narrator', 'contracts', 'offerpilot', 'carecredit']
        
        # Filter agent tasks to only include partner agents
        original_tasks = state.get("agent_tasks", [])
        filtered_tasks = [task for task in original_tasks if task.agent_type in partner_agents]
        
        return {
            "available_agents": partner_agents,
            "agent_tasks": filtered_tasks,
            "persona_context": "partner"
        }

    async def _coordinator_node(self, state: FinancialServicesState) -> Dict[str, Any]:
        """
        Coordinator node: Routes to individual agents based on execution plan
        Replaces the removed supervisor node for agent orchestration
        """
        try:
            current_agent = state.get("current_agent")
            completed_agents = state.get("completed_agents", [])
            active_agents = state.get("active_agents", [])
            agent_results = state.get("agent_results", {})
            
            # Check if we're done with all agents
            if current_agent is None and active_agents:
                # Find the next agent to execute
                remaining_agents = [agent for agent in active_agents if agent not in completed_agents]
                if remaining_agents:
                    current_agent = remaining_agents[0]
                    logger.info(f"Coordinator setting current_agent to: {current_agent}")
                    return {"current_agent": current_agent}
            
            # If we've completed all agents, move to synthesis
            if len(completed_agents) >= len(active_agents) and active_agents:
                logger.info("All agents completed, coordinator moving to synthesis")
                return {"current_agent": None}  # Will route to synthesis
            
            # If we have a current agent, prepare for execution
            if current_agent and current_agent not in completed_agents:
                logger.info(f"Coordinator routing to agent: {current_agent}")
                return {"current_agent": current_agent}
            
            # Default case - move to synthesis
            return {"current_agent": None}
            
        except Exception as e:
            logger.error(f"Coordinator failed: {e}")
            return {
                "fallback_used": True,
                "errors": [f"Coordinator failed: {str(e)}"]
            }
    
    def _coordinator_routing(self, state: FinancialServicesState) -> str:
        """Route from coordinator to agents or synthesis"""
        if state.get("fallback_used"):
            return "fallback"
        
        current_agent = state.get("current_agent")
        
        if current_agent and current_agent in self.available_agents:
            logger.info(f"üîÄ Coordinator routing to agent_{current_agent}")
            return f"agent_{current_agent}"
        else:
            logger.info("üîÄ Coordinator routing to synthesize")
            return "synthesize"

    async def _analyze_query_node(self, state: FinancialServicesState) -> Dict[str, Any]:
        """
        Analyze query to determine if multi-agent approach is needed
        """
        query = state["original_query"]
        
        analysis_prompt = """You are a query analyzer for a financial services AI system. Determine if this query requires multiple specialized agents.

Available Specialized Agents:
- trustshield: Fraud detection, scam analysis, PII protection
- offerpilot: Product search, deals, financing options  
- dispute: Transaction disputes, chargebacks, billing issues
- collections: Payment plans, hardship assistance
- contracts: Contract analysis, legal terms review
- devcopilot: Code generation, API documentation, technical support
- carecredit: Medical/dental expense analysis, healthcare financing
- narrator: Business analytics, portfolio insights, spending analysis

Query needs MULTIPLE agents if:
- Has multiple distinct tasks (e.g., "check if this is fraud AND find financing options")
- Requires different expertise domains (e.g., legal + financial + technical)  
- Has conditional logic (e.g., "if this is legitimate, then help me dispute it")
- Needs validation from multiple perspectives
- Involves complex multi-step workflows

Query needs SINGLE agent if:
- Clear single intent that fits one domain
- Simple, straightforward question
- Can be fully answered by one specialist

Respond with JSON:
{
    "complexity": "simple|moderate|complex",
    "needs_multi_agent": true/false,
    "primary_agents": ["agent1", "agent2"],
    "execution_strategy": "sequential|parallel|conditional",
    "reasoning": "brief explanation",
    "confidence": 0.85
}"""

        try:
            messages = [
                SystemMessage(content=analysis_prompt),
                HumanMessage(content=f"Analyze this query: {query}")
            ]
            
            response = await self.analysis_model.ainvoke(messages)
            result = json.loads(self._extract_json(response.content))
            
            # Update state with analysis results
            strategy_mapping = {
                "sequential": ExecutionStrategy.SEQUENTIAL,
                "parallel": ExecutionStrategy.PARALLEL, 
                "conditional": ExecutionStrategy.CONDITIONAL,
                "direct": ExecutionStrategy.SEQUENTIAL  # Map invalid 'direct' to sequential
            }
            
            strategy_str = result.get("execution_strategy", "sequential")
            execution_strategy = strategy_mapping.get(strategy_str, ExecutionStrategy.SEQUENTIAL)
            
            # Normalize agent names to match our available agents
            agent_normalization = {
                "offeringpilot": "offerpilot",
                "offering": "offerpilot", 
                "trust": "trustshield",
                "care": "carecredit",
                "dev": "devcopilot",
                "image": "narrator"
            }
            
            normalized_agents = []
            for agent in result.get("primary_agents", []):
                normalized_agent = agent_normalization.get(agent, agent)
                if normalized_agent in ["trustshield", "offerpilot", "dispute", "collections", "contracts", "devcopilot", "carecredit", "narrator"]:
                    normalized_agents.append(normalized_agent)
            
            updates = {
                "task_complexity": TaskComplexity(result["complexity"]),
                "user_intent": result.get("reasoning", ""),
                "agent_tasks": [
                    AgentTask(agent_type=agent, query=query, priority=i+1)
                    for i, agent in enumerate(normalized_agents)
                ],
                "execution_strategy": execution_strategy
            }
            
            logger.info(f"Query analysis: {result['complexity']} complexity, multi-agent: {result['needs_multi_agent']}")
            
            return updates
            
        except Exception as e:
            logger.error(f"Query analysis failed: {e}")
            # Default to single agent on analysis failure
            return {
                "task_complexity": TaskComplexity.SIMPLE,
                "fallback_used": True,
                "errors": [f"Analysis failed: {str(e)}"]
            }
    
    def _route_after_analysis(self, state: FinancialServicesState) -> str:
        """Route based on analysis results"""
        if state.get("fallback_used"):
            logger.info("üîÄ Routing to fallback due to fallback_used flag")
            return "fallback"
        
        complexity = state.get("task_complexity")
        if complexity == TaskComplexity.SIMPLE:
            logger.info("üîÄ Routing to single_agent (simple complexity)")
            return "single_agent"
        else:
            logger.info(f"üîÄ Routing to multi_agent ({complexity} complexity)")
            return "multi_agent"
    
    async def _plan_execution_node(self, state: FinancialServicesState) -> Dict[str, Any]:
        """
        Plan execution strategy for multi-agent workflows with parallel support
        """
        try:
            agent_tasks = state.get("agent_tasks", [])
            strategy = state.get("execution_strategy", ExecutionStrategy.SEQUENTIAL)
            available_agents = state.get("available_agents", self.available_agents)
            
            # Filter tasks to only available agents for current persona
            filtered_tasks = [task for task in agent_tasks if task.agent_type in available_agents]
            
            logger.info(f"Planning execution: {strategy.value} strategy with {len(filtered_tasks)} agents")
            
            if not filtered_tasks:
                # No valid agents, fallback to simple routing
                from app.router import route
                route_result = route(state["original_query"])
                agent_name = route_result["agent"]
                
                # Check if routed agent is available for this persona
                if agent_name in available_agents:
                    filtered_tasks = [AgentTask(agent_type=agent_name, query=state["original_query"], priority=1)]
                else:
                    # Default to smart chat
                    filtered_tasks = [AgentTask(agent_type="smart", query=state["original_query"], priority=1)]
            
            active_agents = [task.agent_type for task in filtered_tasks]
            
            # For parallel execution, execute all agents simultaneously
            if strategy == ExecutionStrategy.PARALLEL and len(active_agents) > 1:
                logger.info(f"Executing {len(active_agents)} agents in parallel")
                # Execute all agents in parallel
                agent_results = {}
                import asyncio
                
                async def execute_single_agent(agent_name: str) -> tuple[str, AgentResult]:
                    result = await self._execute_agent(agent_name, state["original_query"], state)
                    return agent_name, result
                
                # Run all agents in parallel
                tasks = [execute_single_agent(agent) for agent in active_agents]
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # Process results
                for result in results:
                    if isinstance(result, Exception):
                        logger.error(f"Parallel agent execution error: {result}")
                        continue
                    agent_name, agent_result = result
                    agent_results[agent_name] = agent_result
                
                return {
                    "active_agents": active_agents,
                    "completed_agents": active_agents,
                    "agent_results": agent_results,
                    "execution_strategy": strategy
                }
            else:
                # Sequential execution - set up for traditional flow
                return {
                    "active_agents": active_agents,
                    "current_agent": active_agents[0] if active_agents else None,
                    "execution_strategy": strategy
                }
            
        except Exception as e:
            logger.error(f"Execution planning failed: {e}")
            return {
                "fallback_used": True,
                "errors": [f"Planning failed: {str(e)}"]
            }
    
    def _route_execution_strategy(self, state: FinancialServicesState) -> str:
        """Route based on execution strategy"""
        if state.get("fallback_used"):
            return "fallback"
        
        strategy = state.get("execution_strategy", ExecutionStrategy.SEQUENTIAL)
        
        # All strategies are handled by supervisor for coordination
        # Return the strategy name that matches the conditional edges mapping
        if strategy == ExecutionStrategy.PARALLEL:
            return "parallel"
        elif strategy == ExecutionStrategy.CONDITIONAL:
            return "conditional"
        else:
            return "sequential"
    
    async def _supervisor_node(self, state: FinancialServicesState) -> Dict[str, Any]:
        """
        Central supervisor node - coordinates agent execution
        Implements full reasoning access with smart routing
        """
        try:
            current_agent = state.get("current_agent")
            completed_agents = state.get("completed_agents", [])
            active_agents = state.get("active_agents", [])
            agent_results = state.get("agent_results", {})
            
            # Check if we're done with all agents
            if current_agent is None and active_agents:
                # Find the next agent to execute
                remaining_agents = [agent for agent in active_agents if agent not in completed_agents]
                if remaining_agents:
                    current_agent = remaining_agents[0]
                    logger.info(f"Setting current_agent to: {current_agent}")
                    return {"current_agent": current_agent}
            
            # If we've completed all agents, move to synthesis
            if len(completed_agents) >= len(active_agents) and active_agents:
                logger.info("All agents completed, moving to synthesis")
                return {"current_agent": None}  # Will route to synthesis
            
            # Select next agent or continue current workflow
            if current_agent and current_agent not in completed_agents:
                # Normalize agent name first
                agent_normalization = {
                    "offeringpilot": "offerpilot",
                    "offering": "offerpilot", 
                    "trust": "trustshield",
                    "care": "carecredit",
                    "dev": "devcopilot",
                    "image": "narrator"
                }
                normalized_current_agent = agent_normalization.get(current_agent, current_agent)
                
                logger.info(f"Routing to agent: {normalized_current_agent} (from {current_agent})")
                
                # Prepare context with full reasoning from other agents
                previous_reasoning = {}
                for agent, result in agent_results.items():
                    if result.success:
                        previous_reasoning[agent] = {
                            "response": result.response,
                            "confidence": result.confidence,
                            "sources": result.sources,
                            "reasoning": result.metadata.get("reasoning", "")
                        }
                
                return {
                    "current_agent": normalized_current_agent,  # Use normalized name
                    "user_context": {
                        **state.get("user_context", {}),
                        "previous_agent_reasoning": previous_reasoning,
                        "current_step": f"{len(completed_agents) + 1} of {len(active_agents)}"
                    }
                }
            
            # Default case - move to synthesis or end
            return {"current_agent": None}
            
        except Exception as e:
            logger.error(f"Supervisor routing failed: {e}")
            return {
                "fallback_used": True,
                "errors": [f"Supervisor failed: {str(e)}"]
            }
    
    def _supervisor_routing(self, state: FinancialServicesState) -> str:
        """Determine where supervisor should route next"""
        if state.get("fallback_used"):
            logger.info("üîÄ Supervisor routing to fallback")
            return "fallback"
        
        current_agent = state.get("current_agent")
        completed_agents = state.get("completed_agents", [])
        agent_results = state.get("agent_results", {})
        active_agents = state.get("active_agents", [])
        task_complexity = state.get("task_complexity")
        
        logger.info(f"üîç Supervisor state: current_agent={current_agent}, completed={len(completed_agents)}, active={len(active_agents)}, complexity={task_complexity}")
        
        # For single agent tasks, route directly to the appropriate agent
        if task_complexity == TaskComplexity.SIMPLE and not current_agent and not completed_agents:
            # Need to determine which agent to use for single agent routing
            from app.router import route
            route_result = route(state["original_query"])
            agent_name = route_result["agent"]
            
            # Map legacy agent names to current names
            agent_name_mapping = {
                "offer": "offerpilot",
                "trust": "trustshield", 
                "dev": "devcopilot",
                "care": "carecredit",
                "image": "narrator",
                "dispute": "dispute",
                "collections": "collections",
                "contracts": "contracts",
                "devcopilot": "devcopilot",
                "carecredit": "carecredit",
                "narrator": "narrator",
            }
            
            mapped_agent = agent_name_mapping.get(agent_name, agent_name)
            logger.info(f"üîÄ Single agent routing: {agent_name} -> {mapped_agent}")
            
            # Set current agent for routing
            return f"agent_{mapped_agent}"
            
        # For multi-agent tasks, execute the active agents
        if active_agents and not current_agent and not completed_agents:
            # Start with the first active agent
            first_agent = active_agents[0]
            logger.info(f"üîÄ Multi-agent routing: starting with {first_agent}")
            return f"agent_{first_agent}"
        
        # Normalize current_agent name to match available agents
        if current_agent:
            agent_normalization = {
                "offeringpilot": "offerpilot",
                "offering": "offerpilot", 
                "trust": "trustshield",
                "care": "carecredit",
                "dev": "devcopilot",
                "image": "narrator"
            }
            normalized_current_agent = agent_normalization.get(current_agent, current_agent)
            
            if normalized_current_agent in self.available_agents:
                logger.info(f"üîÄ Supervisor routing to agent_{normalized_current_agent} (normalized from {current_agent})")
                return f"agent_{normalized_current_agent}"
        elif agent_results and len(completed_agents) > 0:
            logger.info(f"üîÄ Supervisor routing to synthesize (completed: {len(completed_agents)})")
            return "synthesize"
        else:
            logger.info("üîÄ Supervisor routing to end")
            return "end"
    
    def _create_agent_node(self, agent_name: str):
        """Create a node function for a specific agent"""
        async def agent_node(state: FinancialServicesState) -> Dict[str, Any]:
            try:
                query = state["original_query"]
                user_context = state.get("user_context", {})
                
                # For ImageGen, always use original query to avoid redacted trigger words
                imagegen_query = query if agent_name == "imagegen" else query
                
                # Get full reasoning from previous agents
                previous_reasoning = user_context.get("previous_agent_reasoning", {})
                
                # Enhanced query with context if available
                enhanced_query = query
                if previous_reasoning:
                    context_summary = "\n".join([
                        f"{agent.title()}: {result['response'][:200]}..."
                        for agent, result in previous_reasoning.items()
                    ])
                    enhanced_query = f"{query}\n\nContext from other agents:\n{context_summary}"
                
                logger.info(f"Executing agent: {agent_name}")
                
                # Execute the actual agent
                result = await self._execute_agent(agent_name, enhanced_query, state)
                
                # Update state with results
                agent_results = state.get("agent_results", {}).copy()
                agent_results[agent_name] = result
                
                completed_agents = state.get("completed_agents", []).copy()
                if agent_name not in completed_agents:
                    completed_agents.append(agent_name)
                
                # Move to next agent in sequence
                active_agents = state.get("active_agents", [])
                try:
                    current_index = active_agents.index(agent_name)
                    next_agent = active_agents[current_index + 1] if current_index + 1 < len(active_agents) else None
                except (ValueError, IndexError):
                    next_agent = None
                
                return {
                    "agent_results": agent_results,
                    "completed_agents": completed_agents,
                    "current_agent": next_agent,
                    "all_sources": result.sources if result.success else []
                }
                
            except Exception as e:
                logger.error(f"Agent {agent_name} execution failed: {e}")
                
                # Record error but continue workflow
                errors = state.get("errors", []).copy()
                errors.append(f"Agent {agent_name} failed: {str(e)}")
                
                return {
                    "errors": errors,
                    "agent_results": {
                        **state.get("agent_results", {}),
                        agent_name: AgentResult(
                            agent_type=agent_name,
                            success=False,
                            response="",
                            confidence=0.0,
                            error=str(e)
                        )
                    }
                }
        
        return agent_node
    
    async def _execute_agent(self, agent_name: str, query: str, state: FinancialServicesState) -> AgentResult:
        """Execute individual agent with error handling"""
        import time
        start_time = time.time()
        
        # Get tracer for this execution
        tracer = get_tracer()
        
        try:
            agent = self.agents.get(agent_name)
            if not agent:
                raise ValueError(f"Agent {agent_name} not found")
            
            # Trace this agent execution
            with tracer.trace_agent(agent_name, agent_name.title()) as agent_execution:
                if agent_execution:
                    tracer.set_agent_summaries(input_summary=query[:200])
                
                # Execute based on agent type with proper method calls
                if agent_name == "trustshield":
                    with tracer.trace_tool('fraud_scan', query):
                        result = agent.scan(query)
                    
                    if agent_execution:
                        tracer.set_agent_summaries(output_summary=result.get("analysis", "")[:200])
                        tracer.add_sources(result.get("citations", []))
                        tracer.set_agent_confidence(result.get("confidence", 0.5))
                    
                    return AgentResult(
                        agent_type=agent_name,
                        success=True,
                        response=result.get("analysis", "No analysis provided"),
                        confidence=result.get("confidence", 0.5),
                        sources=result.get("citations", []),
                        metadata={"threat_detected": result.get("threat_detected", False)},
                        processing_time=time.time() - start_time
                    )
            
                elif agent_name == "offerpilot":
                    with tracer.trace_tool('product_search', query):
                        result = agent.process_query(query, None)  # No budget specified
                    
                    # Use the response text from OfferPilotResponse
                    response_text = result.response
                    
                    # Get UI cards from metadata
                    ui_cards = result.metadata.get("ui_cards", [])
                    prequal = result.metadata.get("prequalification", {})
                    disclosures = result.metadata.get("disclosures", [])
                    
                    # Add disclosure information if available
                    if disclosures:
                        response_text += f"\n\n**Important Terms:**\n"
                        for disclosure in disclosures[:2]:  # Limit to first 2
                            response_text += f"‚Ä¢ {disclosure}\n"
                    
                    sources = []  # OfferPilotResponse doesn't have citations in the old format
                    
                    if agent_execution:
                        tracer.set_agent_summaries(output_summary=response_text[:200])
                        tracer.set_agent_confidence(0.8)
                    
                    return AgentResult(
                        agent_type=agent_name,
                        success=True,
                        response=response_text,
                        confidence=0.8,  # Default confidence for structured responses
                        sources=sources,
                        metadata={"offers_found": len(ui_cards), "prequalification": prequal},
                        processing_time=time.time() - start_time
                    )
            
            
                else:
                    # Generic agent execution for other agents with proper method mapping
                    result = None
                    response_text = ""
                    sources = []
                    confidence = 0.7
                    
                    # Try different method names based on agent
                    if agent_name == "narrator":
                        result = agent.process_question(query)
                        # Handle new NarratorResponse format with insights and UI cards
                        response_text = result.response
                        ui_cards = result.metadata.get("ui_cards", [])
                        sources = result.metadata.get("sources", [])
                        
                        # Add insights summary to response if available
                        if ui_cards:
                            insights_count = len(ui_cards)
                            kpis_analyzed = result.metadata.get("kpis_analyzed", 0)
                            response_text += f"\n\nüí° **Analysis Summary:** {insights_count} key insights from {kpis_analyzed} KPIs"
                        
                    elif agent_name == "dispute":
                        result = agent.process_dispute(query)
                        
                        # Handle new DisputeResponse format
                        response_text = result.response
                        ui_cards = result.metadata.get("ui_cards", [])
                        status = result.metadata.get("status", {})
                        handoffs = result.metadata.get("handoffs", [])
                        
                        # Add status information to response
                        if status:
                            response_text += f"\n\n**Status:** {status.get('stage', 'unknown').replace('_', ' ').title()}"
                            response_text += f" (Likelihood: {status.get('likelihood', 'unknown')})"
                            if not status.get('eligible', True):
                                response_text += f"\n‚ö†Ô∏è {status.get('eligibility_reason', 'Eligibility concerns')}"
                        
                        sources = []  # Enhanced dispute doesn't use traditional sources
                        confidence = 0.8
                            
                    elif agent_name == "collections":
                        if hasattr(agent, 'process_hardship'):
                            result = agent.process_hardship(query)
                        elif hasattr(agent, 'process_query'):
                            result = agent.process_query(query)
                        else:
                            result = {"response": "Collections agent processing not implemented", "confidence": 0.5}
                        
                        if isinstance(result, dict):
                            response_text = result.get('response', str(result))
                            confidence = result.get('confidence', 0.7)
                            sources = result.get('sources', [])
                        else:
                            response_text = str(result)
                            
                    elif agent_name == "contracts":
                        # Use enhanced contract analysis with systematic clause extraction
                        result = agent.analyze_contract(query)
                        
                        # Handle new ContractResponse format
                        response_text = result.response
                        ui_cards = result.metadata.get("ui_cards", [])
                        risk_flags = result.metadata.get("risk_flags", [])
                        handoffs = result.metadata.get("handoffs", [])
                        needs_legal_review = result.metadata.get("needs_legal_review", False)
                        
                        # Add risk flags to response if present
                        if risk_flags:
                            high_risks = [f for f in risk_flags if f.get("severity") == "high"]
                            if high_risks:
                                response_text += f"\n\n‚ö†Ô∏è **High Priority Risks:** {len(high_risks)} identified"
                            if needs_legal_review:
                                response_text += "\nüìã **Legal Review Required**"
                        
                        sources = []  # Enhanced contracts doesn't use traditional sources
                        confidence = 0.8
                            
                    elif agent_name == "devcopilot":
                        try:
                            result = agent.process_request(query)
                            response_text = result.response
                            confidence = 0.8
                            
                            # Extract sources from metadata
                            sources = result.metadata.get('sources', [])
                            
                        except Exception as e:
                            logger.error(f"DevCopilot error: {e}")
                            response_text = f"DevCopilot processing failed: {str(e)}"
                            confidence = 0.3
                            sources = []
                            
                    elif agent_name == "carecredit":
                        if hasattr(agent, 'process_care_query'):
                            result = agent.process_care_query(query)
                        elif hasattr(agent, 'process_query'):
                            result = agent.process_query(query)
                        else:
                            result = {"response": "CareCredit processing not implemented", "confidence": 0.5}
                            
                        if isinstance(result, dict):
                            response_text = result.get('response', str(result))
                            confidence = result.get('confidence', 0.7)
                            sources = result.get('sources', [])
                        else:
                            response_text = str(result)
                            
                    else:
                        # Fallback for unknown agents
                        if hasattr(agent, 'process_query'):
                            result = agent.process_query(query)
                        elif hasattr(agent, 'process'):
                            result = agent.process(query)
                        else:
                            result = {"response": f"Agent {agent_name} processing not implemented", "confidence": 0.3}
                        
                        # Handle different result types
                        if hasattr(result, 'response'):
                            response_text = result.response
                            confidence = getattr(result, 'confidence', 0.7)
                            sources = getattr(result, 'sources', [])
                        elif isinstance(result, dict):
                            response_text = result.get('response', str(result))
                            confidence = result.get('confidence', 0.7)
                            sources = result.get('sources', [])
                        else:
                            response_text = str(result)
                    
                    # Build metadata for agents with enhanced responses
                    metadata = {}
                    if agent_name == "narrator" and hasattr(result, 'metadata'):
                        metadata = result.metadata
                    elif agent_name in ["dispute", "collections", "carecredit"] and hasattr(result, 'metadata'):
                        metadata = result.metadata
                
                return AgentResult(
                    agent_type=agent_name,
                    success=True,
                    response=response_text,
                    confidence=confidence,
                    sources=sources,
                    metadata=metadata,
                    processing_time=time.time() - start_time
                )
                
        except Exception as e:
            logger.error(f"Agent {agent_name} execution error: {e}")
            return AgentResult(
                agent_type=agent_name,
                success=False,
                response="",
                confidence=0.0,
                error=str(e),
                processing_time=time.time() - start_time
            )
    
    async def _synthesize_results_node(self, state: FinancialServicesState) -> Dict[str, Any]:
        """
        Synthesize results from multiple agents into coherent response
        """
        try:
            agent_results = state.get("agent_results", {})
            successful_results = {k: v for k, v in agent_results.items() if v.success}
            
            if not successful_results:
                return {
                    "fallback_used": True,
                    "errors": ["No successful agent results to synthesize"]
                }
            
            original_query = state["original_query"]
            
            # Prepare synthesis prompt with full reasoning
            results_for_synthesis = []
            all_sources = []
            
            for agent_name, result in successful_results.items():
                results_for_synthesis.append({
                    "agent": agent_name,
                    "response": result.response,
                    "confidence": result.confidence,
                    "sources": result.sources,
                    "metadata": result.metadata,
                    "processing_time": result.processing_time
                })
                all_sources.extend(result.sources)
            
            synthesis_prompt = f"""You are a response synthesizer for a multi-agent financial services AI system. Create a comprehensive, coherent response from multiple specialized agent outputs.

Original User Query: {original_query}

Agent Results:
{json.dumps(results_for_synthesis, indent=2, default=str)}

IMPORTANT: Format your response using proper markdown:
- Use # for main titles
- Use ## for section headers
- Use ### for subsections  
- Use numbered lists (1. 2. 3.) for steps
- Use bullet points (-) for lists
- Use **bold** for emphasis and key terms
- Use `code` for technical terms
- Use proper paragraph spacing with empty lines
- Use > for important notes or quotes

Guidelines:
1. Synthesize information into one cohesive, natural response
2. Preserve expertise and insights from each agent  
3. Resolve conflicts between agents logically
4. Organize with clear sections using markdown headers
5. Maintain professional financial services tone
6. Include relevant details and maintain source attribution
7. Make it feel like a single intelligent response, not separate answers
8. Ensure proper spacing and formatting throughout

Format your response in clean, well-structured markdown that will render beautifully."""

            messages = [
                SystemMessage(content=synthesis_prompt),
                HumanMessage(content="Please synthesize these agent results into a comprehensive response.")
            ]
            
            response = await self.supervisor_model.ainvoke(messages)
            synthesized_response = response.content
            
            # Calculate weighted confidence
            total_confidence = sum(r.confidence for r in successful_results.values()) / len(successful_results)
            
            logger.info(f"Synthesized response from {len(successful_results)} agents")
            
            logger.info(f"‚ú® Synthesis successful. Response length: {len(synthesized_response)}")
            
            return {
                "final_response": synthesized_response,
                "total_confidence": total_confidence,
                "all_sources": list(set(all_sources))  # Deduplicate sources
            }
            
        except Exception as e:
            logger.error(f"Response synthesis failed: {e}")
            
            # Fallback: concatenate responses
            agent_results = state.get("agent_results", {})
            successful_results = {k: v for k, v in agent_results.items() if v.success}
            
            if successful_results:
                fallback_response = f"# Analysis Results\n\nBased on analysis from {len(successful_results)} specialized agents:\n\n"
                all_sources = []
                
                for agent_name, result in successful_results.items():
                    fallback_response += f"## {agent_name.title()} Analysis\n\n{result.response}\n\n"
                    all_sources.extend(result.sources)
                
                return {
                    "final_response": fallback_response,
                    "total_confidence": sum(r.confidence for r in successful_results.values()) / len(successful_results),
                    "all_sources": list(set(all_sources)),
                    "fallback_used": True
                }
            else:
                return {
                    "final_response": "I apologize, but I was unable to process your request successfully.",
                    "total_confidence": 0.0,
                    "fallback_used": True,
                    "errors": [f"Synthesis failed: {str(e)}"]
                }
    
    def _check_synthesis_completion(self, state: FinancialServicesState) -> str:
        """Check if synthesis is complete or needs fallback"""
        if state.get("final_response") and not state.get("fallback_used"):
            return "complete"
        else:
            return "fallback"
    
    async def _fallback_node(self, state: FinancialServicesState) -> Dict[str, Any]:
        """
        Graceful degradation - fallback to single agent routing
        """
        try:
            logger.info("Executing graceful fallback to single agent")
            
            original_query = state["original_query"]
            
            # Use simple routing for fallback
            from app.router import route
            route_result = route(original_query)
            agent_name = route_result["agent"]
            
            # Map legacy agent names to current names
            agent_name_mapping = {
                "offer": "offerpilot",
                "trust": "trustshield", 
                "dev": "devcopilot",
                "care": "carecredit",
                "image": "narrator",
                "dispute": "dispute",        # Already matches
                "collections": "collections", # Already matches
                "contracts": "contracts",    # Already matches
                "devcopilot": "devcopilot",  # Already matches
                "carecredit": "carecredit",  # Already matches
                "narrator": "narrator"       # Already matches
            }
            
            mapped_agent = agent_name_mapping.get(agent_name, agent_name)
            
            # Execute single agent
            result = await self._execute_agent(mapped_agent, original_query, state)
            
            if result.success:
                logger.info(f"üéØ Fallback agent {mapped_agent} succeeded. Response length: {len(result.response)}")
                return {
                    "final_response": result.response,
                    "total_confidence": result.confidence,
                    "all_sources": result.sources,
                    "fallback_used": True,
                    "agent_results": {mapped_agent: result}
                }
            else:
                # Ultimate fallback
                return {
                    "final_response": "I apologize, but I'm unable to process your request at this time. Please try again or contact support.",
                    "total_confidence": 0.1,
                    "fallback_used": True,
                    "errors": [f"Fallback agent {agent_name} also failed: {result.error}"]
                }
                
        except Exception as e:
            logger.error(f"Fallback handler failed: {e}")
            return {
                "final_response": "I apologize, but I'm experiencing technical difficulties. Please try again later.",
                "total_confidence": 0.0,
                "fallback_used": True,
                "errors": [f"Complete fallback failure: {str(e)}"]
            }
    
    def _format_response(self, final_state: FinancialServicesState) -> Dict[str, Any]:
        """Format final state into API-compatible response"""
        logger.info(f"üîç Formatting response from final state keys: {list(final_state.keys())}")
        logger.info(f"üîç final_response value: {final_state.get('final_response')}")
        logger.info(f"üîç fallback_used: {final_state.get('fallback_used')}")
        
        agent_results = final_state.get("agent_results", {})
        successful_agents = [name for name, result in agent_results.items() if result.success]
        
        logger.info(f"üîç Agent results count: {len(agent_results)}, successful: {len(successful_agents)}")
        
        # Determine primary agent for backwards compatibility
        primary_agent = "smart"  # Default to smart for multi-agent responses
        if len(successful_agents) == 1:
            primary_agent = successful_agents[0]
        
        final_response = final_state.get("final_response")
        if not final_response:
            # If no final_response, check if we have any agent results
            agent_results = final_state.get("agent_results", {})
            if agent_results:
                # Use the first successful agent result
                for agent_name, result in agent_results.items():
                    if result.success and result.response:
                        final_response = result.response
                        break
            
            if not final_response:
                final_response = "I apologize, but I was unable to generate a response. Please try again."
        
        # Collect UI cards from all successful agent results
        all_ui_cards = []
        for agent_name, result in agent_results.items():
            if result.success and hasattr(result, 'metadata') and result.metadata:
                ui_cards = result.metadata.get('ui_cards', [])
                all_ui_cards.extend(ui_cards)

        response_data = {
            "response": final_response,
            "agent": primary_agent,
            "confidence": final_state.get("total_confidence", 0.0),
            "sources": final_state.get("all_sources", []),
            "used_tavily": final_state.get("allow_tavily", False),
            "fallback_used": "yes" if final_state.get("fallback_used", False) else None,
            "document_assessment": {
                "multi_agent_used": len(successful_agents) > 1,
                "agents_involved": successful_agents,
                "task_complexity": final_state.get("task_complexity", "simple").value if final_state.get("task_complexity") else "simple",
                "execution_strategy": final_state.get("execution_strategy", "sequential").value if final_state.get("execution_strategy") else "sequential"
            },
            "metadata": {
                "agent_results": {
                    name: {
                        "success": result.success,
                        "confidence": result.confidence,
                        "processing_time": result.processing_time,
                        "error": result.error
                    }
                    for name, result in agent_results.items()
                },
                "ui_cards": all_ui_cards,
                "errors": final_state.get("errors", []),
                "retry_count": final_state.get("retry_count", 0)
            }
        }
        
        logger.info(f"üîç Final response data: response='{response_data['response']}', agent={response_data['agent']}")
        logger.info(f"üîç UI cards included: {len(all_ui_cards)} cards")
        if all_ui_cards:
            for i, card in enumerate(all_ui_cards):
                card_type = card.get('type', 'unknown')
                has_image = 'image' in card
                logger.info(f"üîç UI Card {i+1}: type={card_type}, has_image={has_image}")
        
        return response_data
    
    async def _emergency_fallback(self, query: str, allow_tavily: bool, allow_llm_knowledge: bool, allow_web_search: bool) -> Dict[str, Any]:
        """Emergency fallback when entire system fails"""
        logger.warning("Executing emergency fallback - using basic routing")
        
        try:
            from app.router import route
            route_result = route(query)
            agent_name = route_result["agent"]
            
            # Map legacy agent names to current names
            agent_name_mapping = {
                "offer": "offerpilot",
                "trust": "trustshield", 
                "dev": "devcopilot",
                "care": "carecredit",
                "image": "narrator",
                "dispute": "dispute",        # Already matches
                "collections": "collections", # Already matches
                "contracts": "contracts",    # Already matches
                "devcopilot": "devcopilot",  # Already matches
                "carecredit": "carecredit",  # Already matches
                "narrator": "narrator"       # Already matches
            }
            
            mapped_agent = agent_name_mapping.get(agent_name, agent_name)
            
            # Create minimal state for emergency execution
            emergency_state = create_initial_state(
                original_query=query,
                allow_tavily=allow_tavily,
                allow_llm_knowledge=allow_llm_knowledge,
                allow_web_search=allow_web_search
            )
            
            result = await self._execute_agent(mapped_agent, query, emergency_state)
            
            return {
                "response": result.response if result.success else "I apologize, but I'm unable to process your request at this time.",
                "agent": mapped_agent,
                "confidence": result.confidence if result.success else 0.1,
                "sources": result.sources if result.success else [],
                "used_tavily": allow_tavily,
                "fallback_used": "emergency",
                "document_assessment": {
                    "emergency_fallback": True,
                    "error": result.error if not result.success else None
                }
            }
            
        except Exception as e:
            logger.error(f"Emergency fallback failed: {e}")
            return {
                "response": "I apologize, but I'm experiencing technical difficulties. Please try again later.",
                "agent": "system",
                "confidence": 0.0,
                "sources": [],
                "used_tavily": False,
                "fallback_used": "complete_failure",
                "document_assessment": {
                    "complete_system_failure": True,
                    "error": str(e)
                }
            }
    
    def _extract_json(self, text: str) -> str:
        """Extract JSON from LLM response that may contain markdown formatting"""
        import re
        
        if not text or not text.strip():
            return "{}"
        
        # Try to find JSON in code blocks (more flexible pattern)
        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL | re.IGNORECASE)
        if json_match:
            return json_match.group(1).strip()
        
        # Try to find JSON directly (non-greedy)
        json_match = re.search(r'\{.*?\}', text, re.DOTALL)
        if json_match:
            return json_match.group(0).strip()
        
        # Try to extract everything between first { and last }
        first_brace = text.find('{')
        last_brace = text.rfind('}')
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            return text[first_brace:last_brace+1].strip()
        
        # Fallback - return empty JSON
        logger.warning(f"Could not extract JSON from: {repr(text[:200])}")
        return '{"persona": "consumer", "confidence": 0.3, "reasoning": "Failed to parse response"}'


================================================
FILE: app/openapi/payments.json
================================================
{
  "openapi": "3.0.0",
  "info": {
    "title": "Synchrony Payments API",
    "version": "1.0.0",
    "description": "Partner API for processing payments and managing transactions"
  },
  "servers": [
    {
      "url": "https://api.synchrony.com/v1",
      "description": "Production server"
    },
    {
      "url": "https://sandbox-api.synchrony.com/v1",
      "description": "Sandbox server"
    }
  ],
  "security": [
    {
      "ApiKeyAuth": []
    }
  ],
  "paths": {
    "/payments": {
      "post": {
        "summary": "Create a payment",
        "description": "Process a new payment transaction",
        "operationId": "createPayment",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/PaymentRequest"
              }
            }
          }
        },
        "responses": {
          "201": {
            "description": "Payment created successfully",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/PaymentResponse"
                }
              }
            }
          },
          "400": {
            "description": "Invalid request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/payments/{paymentId}": {
      "get": {
        "summary": "Get payment details",
        "description": "Retrieve details of a specific payment",
        "operationId": "getPayment",
        "parameters": [
          {
            "name": "paymentId",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Payment details",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/PaymentResponse"
                }
              }
            }
          }
        }
      }
    },
    "/accounts/{accountId}/balance": {
      "get": {
        "summary": "Get account balance",
        "description": "Retrieve current balance for an account",
        "operationId": "getAccountBalance",
        "parameters": [
          {
            "name": "accountId",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Account balance",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/BalanceResponse"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "securitySchemes": {
      "ApiKeyAuth": {
        "type": "apiKey",
        "in": "header",
        "name": "X-API-Key"
      }
    },
    "schemas": {
      "PaymentRequest": {
        "type": "object",
        "required": ["amount", "currency", "accountId"],
        "properties": {
          "amount": {
            "type": "number",
            "minimum": 0.01,
            "description": "Payment amount"
          },
          "currency": {
            "type": "string",
            "enum": ["USD"],
            "description": "Currency code"
          },
          "accountId": {
            "type": "string",
            "description": "Account identifier"
          },
          "description": {
            "type": "string",
            "maxLength": 255,
            "description": "Payment description"
          },
          "metadata": {
            "type": "object",
            "description": "Additional metadata"
          }
        }
      },
      "PaymentResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Payment ID"
          },
          "amount": {
            "type": "number",
            "description": "Payment amount"
          },
          "currency": {
            "type": "string",
            "description": "Currency code"
          },
          "status": {
            "type": "string",
            "enum": ["pending", "completed", "failed"],
            "description": "Payment status"
          },
          "createdAt": {
            "type": "string",
            "format": "date-time",
            "description": "Creation timestamp"
          }
        }
      },
      "BalanceResponse": {
        "type": "object",
        "properties": {
          "accountId": {
            "type": "string",
            "description": "Account identifier"
          },
          "availableBalance": {
            "type": "number",
            "description": "Available balance"
          },
          "currentBalance": {
            "type": "number",
            "description": "Current balance"
          },
          "currency": {
            "type": "string",
            "description": "Currency code"
          }
        }
      },
      "Error": {
        "type": "object",
        "properties": {
          "error": {
            "type": "string",
            "description": "Error message"
          },
          "code": {
            "type": "string",
            "description": "Error code"
          }
        }
      }
    }
  }
}



================================================
FILE: app/orchestrator/multi_agent.py
================================================
"""
Multi-Agent Orchestration System
Handles complex queries requiring multiple specialized agents
"""

import logging
import asyncio
import json
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum

from app.llm.gemini import chat
from app.router import route, AGENT_TYPES

logger = logging.getLogger(__name__)

class TaskType(Enum):
    ANALYSIS = "analysis"
    SEARCH = "search"
    GENERATION = "generation"
    VALIDATION = "validation"
    SYNTHESIS = "synthesis"

class ExecutionStrategy(Enum):
    PARALLEL = "parallel"      # All agents run simultaneously
    SEQUENTIAL = "sequential"  # Agents run in order
    CONDITIONAL = "conditional" # Next agent depends on previous results

@dataclass
class SubTask:
    """Individual task for a specific agent"""
    id: str
    agent_type: str
    task_type: TaskType
    query: str
    context: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)  # Task IDs this depends on
    priority: int = 1  # Higher number = higher priority

@dataclass
class AgentResult:
    """Result from an individual agent"""
    task_id: str
    agent_type: str
    success: bool
    response: str
    confidence: float
    sources: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    error: Optional[str] = None

@dataclass
class OrchestrationResult:
    """Final orchestrated result"""
    success: bool
    synthesized_response: str
    agent_results: List[AgentResult]
    execution_trace: List[Dict[str, Any]]
    total_confidence: float
    sources: List[str] = field(default_factory=list)

class MultiAgentOrchestrator:
    """
    Orchestrates multiple agents to handle complex queries
    """
    
    def __init__(self, agents: Dict[str, Any]):
        self.agents = agents
        self.max_concurrent = 3  # Limit concurrent agent calls
        
    async def process_query(
        self, 
        query: str, 
        context: Optional[Dict[str, Any]] = None
    ) -> OrchestrationResult:
        """
        Main entry point for multi-agent processing
        """
        logger.info(f"Starting multi-agent orchestration for query: {query[:100]}...")
        
        try:
            # Step 1: Analyze if multi-agent approach is needed
            needs_multi_agent = await self._should_use_multi_agent(query)
            
            if not needs_multi_agent:
                logger.info("Query can be handled by single agent, routing normally")
                return await self._single_agent_fallback(query, context)
            
            # Step 2: Decompose query into sub-tasks
            sub_tasks = await self._decompose_query(query, context or {})
            
            # Step 3: Determine execution strategy
            strategy = self._determine_execution_strategy(sub_tasks)
            
            # Step 4: Execute agents based on strategy
            agent_results = await self._execute_agents(sub_tasks, strategy)
            
            # Step 5: Synthesize final response
            final_result = await self._synthesize_results(query, agent_results, sub_tasks)
            
            logger.info(f"Multi-agent orchestration completed successfully with {len(agent_results)} agents")
            return final_result
            
        except Exception as e:
            logger.error(f"Multi-agent orchestration failed: {e}")
            return OrchestrationResult(
                success=False,
                synthesized_response=f"I encountered an error processing your complex query: {str(e)}",
                agent_results=[],
                execution_trace=[{"error": str(e)}],
                total_confidence=0.0
            )
    
    async def _should_use_multi_agent(self, query: str) -> bool:
        """
        Determine if query requires multiple agents using LLM analysis
        """
        system_prompt = """You are a query analyzer for a multi-agent system. Determine if this query requires multiple specialized agents.

A query needs multiple agents if it:
- Has multiple distinct tasks (e.g., "analyze this contract AND check if merchant is trustworthy")
- Requires different types of expertise (e.g., technical + financial + legal)
- Has conditional logic (e.g., "if this is fraud, then dispute it")
- Needs validation from multiple perspectives

Single agent queries:
- Simple questions with one clear intent
- Questions that fit clearly into one domain

Respond with only JSON:
{"needs_multi_agent": true/false, "reasoning": "brief explanation", "estimated_agents": 2}"""

        try:
            response = chat([{"role": "user", "content": f"Analyze this query: {query}"}], system=system_prompt)
            result = json.loads(response.strip().replace('```json', '').replace('```', ''))
            
            return result.get("needs_multi_agent", False)
            
        except Exception as e:
            logger.error(f"Error in multi-agent analysis: {e}")
            return False  # Default to single agent on error
    
    async def _decompose_query(self, query: str, context: Dict[str, Any]) -> List[SubTask]:
        """
        Break down complex query into sub-tasks for different agents
        """
        system_prompt = f"""You are a query decomposition expert. Break down this complex query into specific sub-tasks for our specialized agents.

Available Agents:
{', '.join(AGENT_TYPES)}

Agent Capabilities:
- offer: Product search, deals, financing options
- trust: Fraud detection, scam analysis, PII protection
- dispute: Transaction disputes, chargebacks, billing issues
- collections: Payment plans, hardship assistance
- contracts: Contract analysis, terms review
- devcopilot: Code generation, API documentation
- carecredit: Medical/dental expense analysis
- narrator: Business analytics, portfolio insights
- imagegen: Image generation from text

Create specific, actionable sub-tasks. Each task should:
1. Be assignable to ONE agent
2. Have a clear, specific query
3. Include context/dependencies if needed

Respond with JSON array:
[
  {{
    "id": "task_1",
    "agent_type": "agent_name",
    "task_type": "analysis|search|generation|validation",
    "query": "specific query for this agent",
    "context": {{}},
    "dependencies": [],
    "priority": 1
  }}
]"""

        try:
            user_message = f"Decompose this query: {query}\nContext: {json.dumps(context)}"
            response = chat([{"role": "user", "content": user_message}], system=system_prompt)
            
            # Parse JSON response
            response_text = response.strip().replace('```json', '').replace('```', '').strip()
            tasks_data = json.loads(response_text)
            
            # Convert to SubTask objects
            sub_tasks = []
            for task_data in tasks_data:
                sub_task = SubTask(
                    id=task_data["id"],
                    agent_type=task_data["agent_type"],
                    task_type=TaskType(task_data["task_type"]),
                    query=task_data["query"],
                    context=task_data.get("context", {}),
                    dependencies=task_data.get("dependencies", []),
                    priority=task_data.get("priority", 1)
                )
                sub_tasks.append(sub_task)
            
            logger.info(f"Decomposed query into {len(sub_tasks)} sub-tasks")
            return sub_tasks
            
        except Exception as e:
            logger.error(f"Error in query decomposition: {e}")
            # Fallback: create single task
            return [SubTask(
                id="fallback_task",
                agent_type="trust",  # Default to trust agent
                task_type=TaskType.ANALYSIS,
                query=query,
                context=context
            )]
    
    def _determine_execution_strategy(self, sub_tasks: List[SubTask]) -> ExecutionStrategy:
        """
        Determine how to execute the sub-tasks (parallel, sequential, conditional)
        """
        # Check for dependencies
        has_dependencies = any(task.dependencies for task in sub_tasks)
        
        if has_dependencies:
            return ExecutionStrategy.SEQUENTIAL
        elif len(sub_tasks) <= self.max_concurrent:
            return ExecutionStrategy.PARALLEL
        else:
            return ExecutionStrategy.SEQUENTIAL
    
    async def _execute_agents(
        self, 
        sub_tasks: List[SubTask], 
        strategy: ExecutionStrategy
    ) -> List[AgentResult]:
        """
        Execute agents based on the determined strategy
        """
        results = []
        
        if strategy == ExecutionStrategy.PARALLEL:
            # Execute all tasks simultaneously
            tasks = [self._execute_single_agent(task, {}) for task in sub_tasks]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
        elif strategy == ExecutionStrategy.SEQUENTIAL:
            # Execute tasks in order, building context
            context = {}
            for task in sorted(sub_tasks, key=lambda t: t.priority, reverse=True):
                result = await self._execute_single_agent(task, context)
                results.append(result)
                
                # Add result to context for next tasks
                if result.success:
                    context[f"{task.agent_type}_result"] = {
                        "response": result.response,
                        "confidence": result.confidence,
                        "sources": result.sources
                    }
        
        # Filter out exceptions and convert to AgentResult objects
        valid_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Task {sub_tasks[i].id} failed with exception: {result}")
                valid_results.append(AgentResult(
                    task_id=sub_tasks[i].id,
                    agent_type=sub_tasks[i].agent_type,
                    success=False,
                    response="",
                    confidence=0.0,
                    error=str(result)
                ))
            else:
                valid_results.append(result)
        
        return valid_results
    
    async def _execute_single_agent(self, task: SubTask, context: Dict[str, Any]) -> AgentResult:
        """
        Execute a single agent task
        """
        try:
            agent = self.agents.get(task.agent_type)
            if not agent:
                return AgentResult(
                    task_id=task.id,
                    agent_type=task.agent_type,
                    success=False,
                    response="",
                    confidence=0.0,
                    error=f"Agent {task.agent_type} not found"
                )
            
            # Prepare query with context
            enhanced_query = task.query
            if context:
                enhanced_query = f"{task.query}\n\nContext from previous agents: {json.dumps(context)}"
            
            # Execute agent based on type
            if task.agent_type == "trust":
                result = agent.scan(enhanced_query)
                return AgentResult(
                    task_id=task.id,
                    agent_type=task.agent_type,
                    success=True,
                    response=result.get("analysis", ""),
                    confidence=result.get("confidence", 0.5),
                    sources=result.get("citations", [])
                )
            
            elif task.agent_type == "offerpilot":
                result = agent.process_query(enhanced_query, None)
                return AgentResult(
                    task_id=task.id,
                    agent_type=task.agent_type,
                    success=True,
                    response=result.response,
                    confidence=result.confidence,
                    sources=result.sources
                )
            
            # Add more agent types as needed...
            else:
                # Generic agent execution
                result = agent.process_query(enhanced_query)
                return AgentResult(
                    task_id=task.id,
                    agent_type=task.agent_type,
                    success=True,
                    response=getattr(result, 'response', str(result)),
                    confidence=getattr(result, 'confidence', 0.5),
                    sources=getattr(result, 'sources', [])
                )
                
        except Exception as e:
            logger.error(f"Error executing agent {task.agent_type}: {e}")
            return AgentResult(
                task_id=task.id,
                agent_type=task.agent_type,
                success=False,
                response="",
                confidence=0.0,
                error=str(e)
            )
    
    async def _synthesize_results(
        self, 
        original_query: str,
        agent_results: List[AgentResult], 
        sub_tasks: List[SubTask]
    ) -> OrchestrationResult:
        """
        Synthesize multiple agent results into a coherent final response
        """
        successful_results = [r for r in agent_results if r.success]
        
        if not successful_results:
            return OrchestrationResult(
                success=False,
                synthesized_response="I was unable to process your request with any of the specialized agents.",
                agent_results=agent_results,
                execution_trace=[{"error": "No successful agent results"}],
                total_confidence=0.0
            )
        
        # Prepare synthesis prompt
        results_summary = []
        for result in successful_results:
            results_summary.append({
                "agent": result.agent_type,
                "response": result.response,
                "confidence": result.confidence,
                "sources": result.sources
            })
        
        system_prompt = """You are a response synthesizer for a multi-agent AI system. Your job is to create a coherent, comprehensive response from multiple specialized agent outputs.

Guidelines:
1. Synthesize information from all agents into one cohesive response
2. Maintain the expertise and insights from each agent
3. Resolve any conflicts between agent responses logically
4. Organize the response clearly with proper sections if needed
5. Preserve important details and citations
6. Make it feel like a single, intelligent response, not multiple separate answers

Format your response naturally, addressing the original user query completely."""

        try:
            synthesis_query = f"""Original user query: {original_query}

Agent Results:
{json.dumps(results_summary, indent=2)}

Please synthesize these results into a comprehensive response that fully addresses the user's original query."""

            synthesized_response = chat([{"role": "user", "content": synthesis_query}], system=system_prompt)
            
            # Combine all sources
            all_sources = []
            for result in successful_results:
                all_sources.extend(result.sources)
            
            # Calculate weighted average confidence
            total_confidence = sum(r.confidence for r in successful_results) / len(successful_results)
            
            return OrchestrationResult(
                success=True,
                synthesized_response=synthesized_response,
                agent_results=agent_results,
                execution_trace=[{
                    "agents_used": [r.agent_type for r in successful_results],
                    "synthesis_completed": True
                }],
                total_confidence=total_confidence,
                sources=list(set(all_sources))  # Remove duplicates
            )
            
        except Exception as e:
            logger.error(f"Error in response synthesis: {e}")
            # Fallback: concatenate responses
            fallback_response = f"Based on analysis from {len(successful_results)} specialized agents:\n\n"
            for result in successful_results:
                fallback_response += f"**{result.agent_type.title()} Agent:** {result.response}\n\n"
            
            return OrchestrationResult(
                success=True,
                synthesized_response=fallback_response,
                agent_results=agent_results,
                execution_trace=[{"synthesis_fallback": True}],
                total_confidence=sum(r.confidence for r in successful_results) / len(successful_results),
                sources=list(set(all_sources))
            )
    
    async def _single_agent_fallback(self, query: str, context: Optional[Dict[str, Any]]) -> OrchestrationResult:
        """
        Fallback to single agent routing when multi-agent isn't needed
        """
        from app.router import route
        
        route_result = route(query)
        agent_type = route_result["agent"]
        
        # Execute single agent
        task = SubTask(
            id="single_task",
            agent_type=agent_type,
            task_type=TaskType.ANALYSIS,
            query=query,
            context=context or {}
        )
        
        result = await self._execute_single_agent(task, {})
        
        return OrchestrationResult(
            success=result.success,
            synthesized_response=result.response,
            agent_results=[result],
            execution_trace=[{"single_agent": agent_type, "confidence": route_result["confidence"]}],
            total_confidence=result.confidence,
            sources=result.sources
        )


================================================
FILE: app/rag/__init__.py
================================================
# RAG Pipeline Package



================================================
FILE: app/rag/core.py
================================================
"""
Core RAG functionality with Gemini embeddings and Haystack integration
"""

import os
import logging
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import re

from google import genai
from haystack import Document
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever

logger = logging.getLogger(__name__)

class WebDisabled(Exception):
    """Raised when web search is disabled but requested"""
    pass

def init_docstore() -> InMemoryDocumentStore:
    """Initialize Haystack InMemoryDocumentStore"""
    return InMemoryDocumentStore()

class GeminiEmbedder:
    """Gemini embeddings API wrapper with batching and retry logic"""
    
    def __init__(self, model: str = None, api_key: str = None):
        self.model = model or os.getenv("GEMINI_EMBED_MODEL", "models/text-embedding-004")
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")
        
        if not self.api_key:
            raise ValueError("Google API key is required")
        
        self.client = genai.Client(api_key=self.api_key)
        logger.info(f"Initialized GeminiEmbedder with model: {self.model}")
    
    def embed_texts(self, texts: List[str], batch_size: int = 10, max_retries: int = 3) -> List[List[float]]:
        """
        Embed a list of texts using Gemini embeddings API
        
        Args:
            texts: List of text strings to embed
            batch_size: Number of texts to process in each batch
            max_retries: Maximum number of retry attempts
            
        Returns:
            List of embedding vectors, same length as input texts
        """
        if not texts:
            return []
        
        all_embeddings = []
        
        # Process in batches
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_embeddings = self._embed_batch_with_retry(batch, max_retries)
            all_embeddings.extend(batch_embeddings)
        
        logger.info(f"Generated embeddings for {len(texts)} texts")
        return all_embeddings
    
    def _embed_batch_with_retry(self, batch: List[str], max_retries: int) -> List[List[float]]:
        """Embed a batch of texts with retry logic"""
        for attempt in range(max_retries + 1):
            try:
                # Use modern Gemini embeddings API
                result = self.client.models.embed_content(
                    model=self.model,
                    contents=batch
                )
                
                # Extract embeddings from response
                if hasattr(result, 'embeddings'):
                    embeddings = []
                    for embedding in result.embeddings:
                        if hasattr(embedding, 'values'):
                            embeddings.append(embedding.values)
                        else:
                            embeddings.append(embedding)
                    return embeddings
                else:
                    # Fallback - return zero vectors
                    return [[0.0] * 768 for _ in batch]
                
            except Exception as e:
                if attempt < max_retries:
                    wait_time = 2 ** attempt  # Exponential backoff
                    logger.warning(f"Embedding attempt {attempt + 1} failed: {e}. Retrying in {wait_time}s...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"Failed to generate embeddings after {max_retries + 1} attempts: {e}")
                    # Return zero vectors as fallback
                    return [[0.0] * 768 for _ in batch]  # Default dimension
    
    def embed_query(self, query: str) -> List[float]:
        """Embed a single query text"""
        try:
            result = self.client.models.embed_content(
                model=self.model,
                contents=query
            )
            
            if hasattr(result, 'embeddings') and result.embeddings:
                # Get first embedding for single query
                embedding = result.embeddings[0]
                if hasattr(embedding, 'values'):
                    return embedding.values
                else:
                    return embedding
            else:
                # Fallback
                return [0.0] * 768
                
        except Exception as e:
            logger.error(f"Failed to embed query: {e}")
            return [0.0] * 768  # Default dimension fallback

def _count_tokens(text: str) -> int:
    """Rough token count estimation (1 token ‚âà 4 characters)"""
    return len(text) // 4

def _split_text_into_chunks(text: str, max_tokens: int = 1500, overlap_tokens: int = 150) -> List[Dict[str, Any]]:
    """
    Split text into chunks with token limits and overlap
    
    Args:
        text: Text to split
        max_tokens: Maximum tokens per chunk
        overlap_tokens: Overlap between chunks
        
    Returns:
        List of chunk dictionaries with text and line span info
    """
    lines = text.split('\n')
    chunks = []
    current_chunk = []
    current_tokens = 0
    start_line = 0
    
    for i, line in enumerate(lines):
        line_tokens = _count_tokens(line)
        
        # If adding this line would exceed max tokens, finalize current chunk
        if current_tokens + line_tokens > max_tokens and current_chunk:
            chunk_text = '\n'.join(current_chunk)
            chunks.append({
                'text': chunk_text,
                'start_line': start_line,
                'end_line': i - 1,
                'token_count': current_tokens
            })
            
            # Start new chunk with overlap
            overlap_lines = []
            overlap_tokens = 0
            
            # Add lines from the end of current chunk for overlap
            for j in range(len(current_chunk) - 1, -1, -1):
                line_overlap_tokens = _count_tokens(current_chunk[j])
                if overlap_tokens + line_overlap_tokens <= overlap_tokens:
                    overlap_lines.insert(0, current_chunk[j])
                    overlap_tokens += line_overlap_tokens
                else:
                    break
            
            current_chunk = overlap_lines + [line]
            current_tokens = overlap_tokens + line_tokens
            start_line = max(0, i - len(overlap_lines))
        else:
            current_chunk.append(line)
            current_tokens += line_tokens
            if not current_chunk or len(current_chunk) == 1:
                start_line = i
    
    # Add final chunk if it exists
    if current_chunk:
        chunk_text = '\n'.join(current_chunk)
        chunks.append({
            'text': chunk_text,
            'start_line': start_line,
            'end_line': len(lines) - 1,
            'token_count': current_tokens
        })
    
    return chunks

def index_markdown(docstore: InMemoryDocumentStore, embedder: GeminiEmbedder, base_dir: str = "app") -> int:
    """
    Index markdown files from /kb and /contracts directories
    
    Args:
        docstore: Haystack document store
        embedder: Gemini embedder instance
        base_dir: Base directory path
        
    Returns:
        Number of documents indexed
    """
    base_path = Path(base_dir)
    kb_path = base_path / "kb"
    contracts_path = base_path / "contracts"
    
    documents = []
    
    # Process both directories
    for dir_path in [kb_path, contracts_path]:
        if not dir_path.exists():
            logger.warning(f"Directory not found: {dir_path}")
            continue
            
        for md_file in dir_path.glob("*.md"):
            try:
                content = md_file.read_text(encoding="utf-8")
                file_type = "policy" if dir_path.name == "kb" else "contract"
                
                # Split into chunks
                chunks = _split_text_into_chunks(content)
                
                for i, chunk in enumerate(chunks):
                    doc_id = f"{md_file.stem}_chunk_{i}"
                    
                    doc = Document(
                        content=chunk['text'],
                        meta={
                            "source": str(md_file),
                            "filename": md_file.name,
                            "type": file_type,
                            "chunk_id": i,
                            "start_line": chunk['start_line'],
                            "end_line": chunk['end_line'],
                            "token_count": chunk['token_count']
                        }
                    )
                    documents.append(doc)
                    
            except Exception as e:
                logger.error(f"Error processing {md_file}: {e}")
    
    if not documents:
        logger.warning("No documents found to index")
        return 0
    
    # Generate embeddings for all documents
    logger.info(f"Generating embeddings for {len(documents)} document chunks...")
    texts = [doc.content for doc in documents]
    embeddings = embedder.embed_texts(texts)
    
    # Add embeddings to documents
    for doc, embedding in zip(documents, embeddings):
        doc.embedding = embedding
    
    # Write to document store
    docstore.write_documents(documents)
    
    logger.info(f"Successfully indexed {len(documents)} document chunks")
    return len(documents)

def build_retriever(docstore: InMemoryDocumentStore) -> InMemoryEmbeddingRetriever:
    """Build Haystack InMemoryEmbeddingRetriever"""
    return InMemoryEmbeddingRetriever(document_store=docstore)

def retrieve(retriever: InMemoryEmbeddingRetriever, embedder: GeminiEmbedder, query: str, k: int = 5) -> List[Dict[str, Any]]:
    """
    Retrieve relevant documents for a query
    
    Args:
        retriever: Haystack embedding retriever
        embedder: Gemini embedder for query embedding
        query: Search query
        k: Number of results to return
        
    Returns:
        List of dictionaries with source, snippet, and score
    """
    try:
        # Embed the query
        query_embedding = embedder.embed_query(query)
        
        # Retrieve documents
        result = retriever.run(query_embedding=query_embedding, top_k=k)
        documents = result.get("documents", [])
        
        # Format results
        formatted_results = []
        for doc in documents:
            formatted_results.append({
                "source": doc.meta.get("source", "unknown"),
                "snippet": doc.content,
                "score": getattr(doc, 'score', 0.0),
                "filename": doc.meta.get("filename", "unknown"),
                "type": doc.meta.get("type", "unknown"),
                "chunk_id": doc.meta.get("chunk_id", 0),
                "line_span": f"{doc.meta.get('start_line', 0)}-{doc.meta.get('end_line', 0)}"
            })
        
        logger.info(f"Retrieved {len(formatted_results)} documents for query: {query}")
        return formatted_results
        
    except Exception as e:
        logger.error(f"Error during retrieval: {e}")
        return []



================================================
FILE: app/rag/pipeline.py
================================================
"""
Hybrid RAG Pipeline Implementation using Haystack 2.x and Gemini API
"""

import os
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional

import google.generativeai as genai
from haystack import Pipeline, Document
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.retrievers.in_memory import InMemoryBM25Retriever, InMemoryEmbeddingRetriever
from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder
from haystack.components.writers import DocumentWriter
from haystack.components.preprocessors.document_splitter import DocumentSplitter
from haystack.components.joiners import DocumentJoiner
from haystack.components.rankers import TransformersSimilarityRanker
from haystack.components.builders.chat_prompt_builder import ChatPromptBuilder
from haystack.dataclasses import ChatMessage

from app.tools.gemini_chat import GeminiChatGenerator

logger = logging.getLogger(__name__)

class RAGPipeline:
    """Hybrid RAG Pipeline using Haystack 2.x with BM25 + Embedding retrieval and Gemini chat"""
    
    def __init__(self):
        self.document_store = None
        self.indexing_pipeline = None
        self.retrieval_pipeline = None
        self.rag_pipeline = None
        self.chat_generator = None
        
        # Initialize Gemini API
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY environment variable is required")
        
        genai.configure(api_key=api_key)
        
    async def initialize(self):
        """Initialize the hybrid RAG pipeline components"""
        try:
            logger.info("Initializing document store...")
            self.document_store = InMemoryDocumentStore()
            
            logger.info("Building indexing pipeline...")
            self._build_indexing_pipeline()
            
            logger.info("Loading knowledge base documents...")
            await self._load_knowledge_base()
            
            logger.info("Building hybrid retrieval pipeline...")
            self._build_retrieval_pipeline()
            
            logger.info("Building RAG pipeline...")
            self._build_rag_pipeline()
            
            logger.info("Hybrid RAG pipeline initialization complete")
            
        except Exception as e:
            logger.error(f"Failed to initialize RAG pipeline: {e}")
            raise
    
    def _build_indexing_pipeline(self):
        """Build the document indexing pipeline"""
        # Document splitter for chunking
        document_splitter = DocumentSplitter(
            split_by="word", 
            split_length=512, 
            split_overlap=32
        )
        
        # Document embedder using sentence transformers
        document_embedder = SentenceTransformersDocumentEmbedder(
            model="sentence-transformers/all-MiniLM-L6-v2"  # Lightweight model for PoC
        )
        
        # Document writer
        document_writer = DocumentWriter(self.document_store)
        
        # Build indexing pipeline
        self.indexing_pipeline = Pipeline()
        self.indexing_pipeline.add_component("document_splitter", document_splitter)
        self.indexing_pipeline.add_component("document_embedder", document_embedder)
        self.indexing_pipeline.add_component("document_writer", document_writer)
        
        # Connect components
        self.indexing_pipeline.connect("document_splitter", "document_embedder")
        self.indexing_pipeline.connect("document_embedder", "document_writer")
    
    def _build_retrieval_pipeline(self):
        """Build the hybrid retrieval pipeline"""
        # Text embedder for query embedding
        text_embedder = SentenceTransformersTextEmbedder(
            model="sentence-transformers/all-MiniLM-L6-v2"  # Same model as document embedder
        )
        
        # Retrievers
        embedding_retriever = InMemoryEmbeddingRetriever(self.document_store)
        bm25_retriever = InMemoryBM25Retriever(self.document_store)
        
        # Document joiner to combine results
        document_joiner = DocumentJoiner()
        
        # Ranker to score and rank combined results
        ranker = TransformersSimilarityRanker(
            model="cross-encoder/ms-marco-MiniLM-L-6-v2"  # Lightweight cross-encoder
        )
        
        # Build retrieval pipeline
        self.retrieval_pipeline = Pipeline()
        self.retrieval_pipeline.add_component("text_embedder", text_embedder)
        self.retrieval_pipeline.add_component("embedding_retriever", embedding_retriever)
        self.retrieval_pipeline.add_component("bm25_retriever", bm25_retriever)
        self.retrieval_pipeline.add_component("document_joiner", document_joiner)
        self.retrieval_pipeline.add_component("ranker", ranker)
        
        # Connect components
        self.retrieval_pipeline.connect("text_embedder", "embedding_retriever")
        self.retrieval_pipeline.connect("bm25_retriever", "document_joiner")
        self.retrieval_pipeline.connect("embedding_retriever", "document_joiner")
        self.retrieval_pipeline.connect("document_joiner", "ranker")
    
    def _build_rag_pipeline(self):
        """Build the complete RAG pipeline with chat generation"""
        # Initialize Gemini chat generator
        self.chat_generator = GeminiChatGenerator(
            model=os.getenv("GEMINI_CHAT_MODEL", "gemini-2.5-flash")
        )
        
        # Define the prompt template
        prompt_template = [
            ChatMessage.from_system(
                "You are a helpful assistant that answers questions based on the provided documents. "
                "Use only the information from the documents to answer questions. "
                "If the information is not available in the documents, say so clearly. "
                "Provide specific references to the source documents when possible."
            ),
            ChatMessage.from_user(
                "Given these documents, answer the question.\n\n"
                "Documents:\n{% for doc in documents %}{{ doc.content }}\n"
                "Source: {{ doc.meta.get('filename', 'Unknown') }} ({{ doc.meta.get('type', 'unknown') }})\n"
                "---\n{% endfor %}\n"
                "Question: {{question}}\n\n"
                "Answer:"
            )
        ]
        
        # Create prompt builder
        prompt_builder = ChatPromptBuilder(
            template=prompt_template,
            required_variables={"question", "documents"}
        )
        
        # Build RAG pipeline
        self.rag_pipeline = Pipeline()
        
        # Add retrieval components
        self.rag_pipeline.add_component("text_embedder", SentenceTransformersTextEmbedder(
            model="sentence-transformers/all-MiniLM-L6-v2"
        ))
        self.rag_pipeline.add_component("embedding_retriever", InMemoryEmbeddingRetriever(self.document_store))
        self.rag_pipeline.add_component("bm25_retriever", InMemoryBM25Retriever(self.document_store))
        self.rag_pipeline.add_component("document_joiner", DocumentJoiner())
        self.rag_pipeline.add_component("ranker", TransformersSimilarityRanker(
            model="cross-encoder/ms-marco-MiniLM-L-6-v2"
        ))
        
        # Add generation components
        self.rag_pipeline.add_component("prompt_builder", prompt_builder)
        self.rag_pipeline.add_component("llm", self.chat_generator)
        
        # Connect retrieval components
        self.rag_pipeline.connect("text_embedder", "embedding_retriever")
        self.rag_pipeline.connect("bm25_retriever", "document_joiner")
        self.rag_pipeline.connect("embedding_retriever", "document_joiner")
        self.rag_pipeline.connect("document_joiner", "ranker")
        
        # Connect to generation
        self.rag_pipeline.connect("ranker", "prompt_builder.documents")
        self.rag_pipeline.connect("prompt_builder", "llm.messages")
    
    async def _load_knowledge_base(self):
        """Load documents from the knowledge base directories"""
        documents = []
        
        # Load from kb directory (markdown policies/terms)
        kb_path = Path("app/kb")
        if kb_path.exists():
            for file_path in kb_path.glob("*.md"):
                content = file_path.read_text(encoding="utf-8")
                doc = Document(
                    content=content,
                    meta={
                        "source": str(file_path),
                        "type": "policy",
                        "filename": file_path.name
                    }
                )
                documents.append(doc)
        
        # Load from contracts directory
        contracts_path = Path("app/contracts")
        if contracts_path.exists():
            for file_path in contracts_path.glob("*.md"):
                content = file_path.read_text(encoding="utf-8")
                doc = Document(
                    content=content,
                    meta={
                        "source": str(file_path),
                        "type": "contract",
                        "filename": file_path.name
                    }
                )
                documents.append(doc)
        
        # Load from data directory (JSON/CSV stubs)
        data_path = Path("app/data")
        if data_path.exists():
            for file_path in data_path.glob("*.json"):
                content = file_path.read_text(encoding="utf-8")
                doc = Document(
                    content=f"Data file: {file_path.name}\n\n{content}",
                    meta={
                        "source": str(file_path),
                        "type": "data",
                        "filename": file_path.name
                    }
                )
                documents.append(doc)
        
        if not documents:
            # Add some sample documents for testing
            logger.warning("No documents found in knowledge base, adding sample documents")
            documents = [
                Document(
                    content="This is a sample policy document about data privacy and user rights. "
                    "Users have the right to access, modify, and delete their personal data. "
                    "We collect minimal data necessary for service provision.",
                    meta={"source": "sample", "type": "policy", "filename": "sample_policy.md"}
                ),
                Document(
                    content="This is a sample contract document outlining merchant terms and conditions. "
                    "Merchants must comply with payment processing standards and maintain accurate records. "
                    "Commission rates vary based on transaction volume.",
                    meta={"source": "sample", "type": "contract", "filename": "sample_contract.md"}
                ),
                Document(
                    content="Sample data: {'providers': ['Provider A', 'Provider B'], 'offers': ['Offer 1', 'Offer 2'], "
                    "'metrics': {'total_transactions': 1000, 'success_rate': 0.95}}",
                    meta={"source": "sample", "type": "data", "filename": "sample_data.json"}
                )
            ]
        
        logger.info(f"Indexing {len(documents)} documents...")
        
        # Run indexing pipeline
        self.indexing_pipeline.run({"document_splitter": {"documents": documents}})
        
        logger.info(f"Successfully indexed {self.document_store.count_documents()} document chunks")
    
    async def query(self, question: str, top_k: int = 5) -> Dict[str, Any]:
        """Query the hybrid RAG pipeline"""
        if not self.rag_pipeline:
            raise RuntimeError("RAG pipeline not initialized")
        
        try:
            logger.info(f"Processing query: {question}")
            
            # Run the RAG pipeline
            results = self.rag_pipeline.run({
                "text_embedder": {"text": question},
                "bm25_retriever": {"query": question, "top_k": top_k},
                "embedding_retriever": {"top_k": top_k},
                "ranker": {"query": question, "top_k": top_k},
                "prompt_builder": {"question": question}
            })
            
            # Extract response and sources
            response = results["llm"]["replies"][0].content if results["llm"]["replies"] else "No response generated"
            
            # Get source information from ranked documents
            ranked_docs = results.get("ranker", {}).get("documents", [])
            sources = [
                f"{doc.meta.get('filename', 'Unknown')} ({doc.meta.get('type', 'unknown')}) - Score: {doc.score:.3f}"
                for doc in ranked_docs[:3]  # Top 3 sources
            ]
            
            return {
                "response": response,
                "sources": sources,
                "retrieved_documents": len(ranked_docs),
                "retrieval_method": "hybrid"
            }
            
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            raise
    
    def get_document_count(self) -> int:
        """Get the number of documents in the document store"""
        if not self.document_store:
            return 0
        return self.document_store.count_documents()



================================================
FILE: app/services/pdf_processor.py
================================================
"""
PDF Processing Service with Landing AI Document Extraction
Processes uploaded PDFs and extracts structured content with bounding boxes
"""

import os
import logging
import base64
import tempfile
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path
import json
import time

import requests
from PIL import Image
import fitz  # PyMuPDF
from haystack import Document

try:
    from agentic_doc.parse import parse
    AGENTIC_DOC_AVAILABLE = True
except ImportError:
    AGENTIC_DOC_AVAILABLE = False
    logging.warning("agentic_doc not available - falling back to REST API")

logger = logging.getLogger(__name__)

@dataclass
class BoundingBox:
    """Bounding box coordinates"""
    x: float
    y: float
    width: float
    height: float
    page: int
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "x": self.x,
            "y": self.y,
            "width": self.width,
            "height": self.height,
            "page": self.page
        }

@dataclass
class PDFChunk:
    """Extracted PDF chunk with location and content"""
    text: str
    bbox: BoundingBox
    page_number: int
    chunk_id: str
    confidence: float = 1.0
    metadata: Optional[Dict[str, Any]] = None
    
    def to_document(self, pdf_name: str) -> Document:
        """Convert to Haystack document"""
        return Document(
            content=self.text,
            meta={
                "source": pdf_name,
                "type": "pdf",
                "chunk_id": self.chunk_id,
                "page_number": self.page_number,
                "bbox": self.bbox.to_dict(),
                "confidence": self.confidence,
                "metadata": self.metadata or {}
            }
        )

@dataclass
class ProcessedPDF:
    """Complete processed PDF with chunks and page images"""
    filename: str
    chunks: List[PDFChunk]
    page_images: List[str]  # Base64 encoded page images
    total_pages: int
    file_size: int
    processing_time: float
    
class LandingAIPDFProcessor:
    """
    PDF processor using Landing AI's Document Extraction API
    """
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("VISION_AGENT_API_KEY")
        if not self.api_key:
            logger.warning("Vision Agent API key not found - using fallback processing")
        
        self.base_url = "https://predict.app.landing.ai/inference/v1"
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}" if self.api_key else ""
        }
    
    def process_pdf(self, pdf_path: str, chunk_strategy: str = "semantic") -> ProcessedPDF:
        """
        Process PDF using Landing AI or fallback method
        
        Args:
            pdf_path: Path to PDF file
            chunk_strategy: Strategy for chunking ("semantic", "page", "paragraph")
            
        Returns:
            ProcessedPDF with extracted chunks and metadata
        """
        start_time = time.time()
        pdf_name = Path(pdf_path).name
        
        try:
            # Try Landing AI SDK first if available and API key is set
            if AGENTIC_DOC_AVAILABLE and self.api_key:
                logger.info(f"Processing {pdf_name} with Landing AI SDK...")
                result = self._process_with_agentic_doc(pdf_path, chunk_strategy)
            elif self.api_key:
                logger.info(f"Processing {pdf_name} with Landing AI REST API...")
                result = self._process_with_landing_ai(pdf_path, chunk_strategy)
            else:
                logger.info(f"Processing {pdf_name} with fallback method...")
                result = self._process_with_fallback(pdf_path, chunk_strategy)
            
            processing_time = time.time() - start_time
            result.processing_time = processing_time
            
            logger.info(f"Successfully processed {pdf_name}: {len(result.chunks)} chunks, "
                       f"{result.total_pages} pages in {processing_time:.2f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"Error processing PDF {pdf_name}: {e}")
            # Fallback to basic processing
            return self._process_with_fallback(pdf_path, chunk_strategy)
    
    def _process_with_agentic_doc(self, pdf_path: str, chunk_strategy: str) -> ProcessedPDF:
        """Process PDF using Landing AI agentic_doc SDK"""
        
        # Set API key as environment variable for the SDK
        if self.api_key:
            os.environ["VISION_AGENT_API_KEY"] = self.api_key
        
        # First, extract page images for visualization
        page_images = self._extract_page_images(pdf_path)
        
        try:
            # Parse PDF using agentic_doc
            logger.info(f"Calling agentic_doc.parse on {pdf_path}")
            result = parse(pdf_path)
            
            if not result:
                raise Exception("No results from agentic_doc.parse")
            
            # Get the first document result
            doc_result = result[0]
            
            # Extract chunks from the result
            chunks = []
            if hasattr(doc_result, 'chunks') and doc_result.chunks:
                # Open PDF once for all coordinate conversions
                pdf_doc = fitz.open(pdf_path)
                scale_factor = 2  # We render images at 2x scale
                
                try:
                    for i, chunk_data in enumerate(doc_result.chunks):
                        # Get text from chunk
                        text = chunk_data.text if hasattr(chunk_data, 'text') else str(chunk_data)
                        
                        # Extract grounding information for bounding boxes
                        if hasattr(chunk_data, 'grounding') and chunk_data.grounding:
                            ground = chunk_data.grounding[0]  # Take first grounding
                            page_num = ground.page
                            box = ground.box
                            
                            # Get page dimensions for coordinate conversion
                            if page_num < pdf_doc.page_count:
                                page = pdf_doc[page_num]
                                page_rect = page.rect
                                
                                # Convert normalized coordinates to pixel coordinates
                                # Landing AI format: l, t, r, b (normalized 0-1)
                                l = box.l
                                t = box.t
                                r = box.r
                                b = box.b
                                
                                # Convert to absolute coordinates with scaling
                                x = l * page_rect.width * scale_factor
                                y = t * page_rect.height * scale_factor
                                width = (r - l) * page_rect.width * scale_factor
                                height = (b - t) * page_rect.height * scale_factor
                                
                                bbox = BoundingBox(
                                    x=x,
                                    y=y,
                                    width=width,
                                    height=height,
                                    page=page_num
                                )
                            else:
                                # Invalid page number - use first page
                                page = pdf_doc[0]
                                page_rect = page.rect
                                bbox = BoundingBox(
                                    x=0, y=0,
                                    width=page_rect.width * scale_factor,
                                    height=page_rect.height * scale_factor,
                                    page=0
                                )
                                page_num = 0
                        else:
                            # No grounding info - use whole first page
                            page = pdf_doc[0]
                            page_rect = page.rect
                            bbox = BoundingBox(
                                x=0, y=0,
                                width=page_rect.width * scale_factor,
                                height=page_rect.height * scale_factor,
                                page=0
                            )
                            page_num = 0
                        
                        # Create chunk with proper confidence handling
                        confidence = 1.0
                        if hasattr(chunk_data, 'confidence') and chunk_data.confidence is not None:
                            confidence = float(chunk_data.confidence)
                        
                        chunk = PDFChunk(
                            text=text,
                            bbox=bbox,
                            page_number=page_num,
                            chunk_id=f"chunk_{i}",
                            confidence=confidence,
                            metadata={}
                        )
                        chunks.append(chunk)
                
                finally:
                    pdf_doc.close()
            
            # Get total pages from the PDF
            doc = fitz.open(pdf_path)
            total_pages = doc.page_count
            doc.close()
            
            return ProcessedPDF(
                filename=Path(pdf_path).name,
                chunks=chunks,
                page_images=page_images,
                total_pages=total_pages,
                file_size=os.path.getsize(pdf_path),
                processing_time=0  # Will be set by caller
            )
            
        except Exception as e:
            logger.error(f"agentic_doc processing failed: {e}")
            raise

    def _process_with_landing_ai(self, pdf_path: str, chunk_strategy: str) -> ProcessedPDF:
        """Process PDF using Landing AI API"""
        
        # First, extract page images for visualization
        page_images = self._extract_page_images(pdf_path)
        
        # Encode PDF for API
        with open(pdf_path, 'rb') as f:
            pdf_base64 = base64.b64encode(f.read()).decode('utf-8')
        
        # Landing AI Document Extraction API call
        payload = {
            "file_content": pdf_base64,
            "file_type": "pdf",
            "extraction_config": {
                "chunk_strategy": chunk_strategy,
                "include_bboxes": True,
                "include_confidence": True,
                "page_images": True
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/documents/extract",
                headers=self.headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                data = response.json()
                return self._parse_landing_ai_response(data, page_images, pdf_path)
            else:
                logger.error(f"Landing AI API error: {response.status_code} - {response.text}")
                raise Exception(f"API returned {response.status_code}")
                
        except Exception as e:
            logger.error(f"Landing AI processing failed: {e}")
            raise
    
    def _process_with_fallback(self, pdf_path: str, chunk_strategy: str) -> ProcessedPDF:
        """Fallback processing using PyMuPDF"""
        
        doc = fitz.open(pdf_path)
        chunks = []
        page_images = []
        
        try:
            # Extract page images
            for page_num in range(doc.page_count):
                page = doc[page_num]
                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x scale for better quality
                img_data = pix.tobytes("png")
                img_base64 = base64.b64encode(img_data).decode('utf-8')
                page_images.append(img_base64)
            
            # Extract text chunks based on strategy
            if chunk_strategy == "page":
                chunks = self._chunk_by_page(doc)
            elif chunk_strategy == "paragraph":
                chunks = self._chunk_by_paragraph(doc)
            else:  # semantic (default)
                chunks = self._chunk_semantically(doc)
            
            return ProcessedPDF(
                filename=Path(pdf_path).name,
                chunks=chunks,
                page_images=page_images,
                total_pages=doc.page_count,
                file_size=os.path.getsize(pdf_path),
                processing_time=0  # Will be set by caller
            )
            
        finally:
            doc.close()
    
    def _extract_page_images(self, pdf_path: str) -> List[str]:
        """Extract page images as base64 strings"""
        doc = fitz.open(pdf_path)
        images = []
        
        try:
            for page_num in range(doc.page_count):
                page = doc[page_num]
                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
                img_data = pix.tobytes("png")
                img_base64 = base64.b64encode(img_data).decode('utf-8')
                images.append(img_base64)
        finally:
            doc.close()
            
        return images
    
    def _parse_landing_ai_response(self, data: Dict[str, Any], 
                                  page_images: List[str], pdf_path: str) -> ProcessedPDF:
        """Parse Landing AI API response into ProcessedPDF"""
        
        chunks = []
        extracted_chunks = data.get("chunks", [])
        
        # Get page dimensions for coordinate conversion
        doc = fitz.open(pdf_path)
        
        try:
            for i, chunk_data in enumerate(extracted_chunks):
                # Landing AI uses normalized coordinates in 'grounding' field
                grounding = chunk_data.get("grounding", [])
                if not grounding:
                    continue
                
                ground = grounding[0]  # Take first grounding
                page_num = ground.get("page", 0)
                box = ground.get("box", {})
                
                # Get page dimensions (PDF uses 2x scale for images)
                page = doc[page_num]
                page_rect = page.rect
                scale_factor = 2  # We render images at 2x scale
                
                # Convert normalized coordinates to pixel coordinates
                # Landing AI format: l, t, r, b (normalized 0-1)
                l = box.get("l", 0)  # Left
                t = box.get("t", 0)  # Top
                r = box.get("r", 0)  # Right  
                b = box.get("b", 0)  # Bottom
                
                # Convert to absolute coordinates with scaling
                x = l * page_rect.width * scale_factor
                y = t * page_rect.height * scale_factor
                width = (r - l) * page_rect.width * scale_factor
                height = (b - t) * page_rect.height * scale_factor
                
                bbox = BoundingBox(
                    x=x,
                    y=y,
                    width=width,
                    height=height,
                    page=page_num
                )
                
                chunk = PDFChunk(
                    text=chunk_data.get("text", ""),
                    bbox=bbox,
                    page_number=page_num,
                    chunk_id=f"chunk_{i}",
                    confidence=chunk_data.get("confidence", 1.0),
                    metadata=chunk_data.get("metadata", {})
                )
                chunks.append(chunk)
        
        finally:
            doc.close()
        
        return ProcessedPDF(
            filename=Path(pdf_path).name,
            chunks=chunks,
            page_images=page_images,
            total_pages=data.get("total_pages", len(page_images)),
            file_size=os.path.getsize(pdf_path),
            processing_time=0
        )
    
    def _chunk_by_page(self, doc: fitz.Document) -> List[PDFChunk]:
        """Chunk PDF by page"""
        chunks = []
        
        for page_num in range(doc.page_count):
            page = doc[page_num]
            text = page.get_text()
            
            if text.strip():
                # Get page dimensions for bounding box
                rect = page.rect
                bbox = BoundingBox(
                    x=0, y=0,
                    width=rect.width,
                    height=rect.height,
                    page=page_num
                )
                
                chunk = PDFChunk(
                    text=text.strip(),
                    bbox=bbox,
                    page_number=page_num,
                    chunk_id=f"page_{page_num}",
                    confidence=1.0
                )
                chunks.append(chunk)
        
        return chunks
    
    def _chunk_by_paragraph(self, doc: fitz.Document) -> List[PDFChunk]:
        """Chunk PDF by paragraphs using text blocks"""
        chunks = []
        chunk_id = 0
        
        for page_num in range(doc.page_count):
            page = doc[page_num]
            blocks = page.get_text("dict")["blocks"]
            
            for block in blocks:
                if "lines" in block:  # Text block
                    text_parts = []
                    
                    for line in block["lines"]:
                        for span in line["spans"]:
                            text_parts.append(span["text"])
                    
                    text = "".join(text_parts).strip()
                    if text and len(text) > 20:  # Minimum length filter
                        
                        # Create bounding box from block (apply 2x scale to match image rendering)
                        scale_factor = 2
                        bbox = BoundingBox(
                            x=block["bbox"][0] * scale_factor,
                            y=block["bbox"][1] * scale_factor,
                            width=(block["bbox"][2] - block["bbox"][0]) * scale_factor,
                            height=(block["bbox"][3] - block["bbox"][1]) * scale_factor,
                            page=page_num
                        )
                        
                        chunk = PDFChunk(
                            text=text,
                            bbox=bbox,
                            page_number=page_num,
                            chunk_id=f"para_{chunk_id}",
                            confidence=0.9
                        )
                        chunks.append(chunk)
                        chunk_id += 1
        
        return chunks
    
    def _chunk_semantically(self, doc: fitz.Document) -> List[PDFChunk]:
        """Semantic chunking - group related paragraphs"""
        # For now, use paragraph chunking with larger minimum sizes
        paragraphs = self._chunk_by_paragraph(doc)
        
        # Merge small adjacent paragraphs
        merged_chunks = []
        current_chunk = None
        
        for para in paragraphs:
            if current_chunk is None:
                current_chunk = para
            elif (len(current_chunk.text) < 300 and 
                  para.page_number == current_chunk.page_number):
                # Merge with previous chunk
                current_chunk.text += "\n\n" + para.text
                # Expand bounding box
                current_chunk.bbox.width = max(
                    current_chunk.bbox.x + current_chunk.bbox.width,
                    para.bbox.x + para.bbox.width
                ) - current_chunk.bbox.x
                current_chunk.bbox.height = max(
                    current_chunk.bbox.y + current_chunk.bbox.height,
                    para.bbox.y + para.bbox.height
                ) - current_chunk.bbox.y
            else:
                merged_chunks.append(current_chunk)
                current_chunk = para
        
        if current_chunk:
            merged_chunks.append(current_chunk)
        
        return merged_chunks

def save_processed_pdf(processed_pdf: ProcessedPDF, 
                      output_dir: str = "processed_pdfs") -> str:
    """Save processed PDF data to disk for caching"""
    
    os.makedirs(output_dir, exist_ok=True)
    
    # Create filename from original
    base_name = Path(processed_pdf.filename).stem
    output_file = Path(output_dir) / f"{base_name}_processed.json"
    
    # Convert to serializable format
    data = {
        "filename": processed_pdf.filename,
        "chunks": [
            {
                "text": chunk.text,
                "bbox": chunk.bbox.to_dict(),
                "page_number": chunk.page_number,
                "chunk_id": chunk.chunk_id,
                "confidence": chunk.confidence,
                "metadata": chunk.metadata
            }
            for chunk in processed_pdf.chunks
        ],
        "page_images": processed_pdf.page_images,
        "total_pages": processed_pdf.total_pages,
        "file_size": processed_pdf.file_size,
        "processing_time": processed_pdf.processing_time
    }
    
    with open(output_file, 'w') as f:
        json.dump(data, f, indent=2)
    
    logger.info(f"Saved processed PDF to {output_file}")
    return str(output_file)

# Test function
def test_pdf_processor():
    """Test PDF processing with sample file"""
    print("üîç Testing PDF Processor")
    print("=" * 40)
    
    processor = LandingAIPDFProcessor()
    
    # Create a simple test PDF if none exists
    test_file = "test_document.pdf"
    
    try:
        result = processor.process_pdf(test_file, chunk_strategy="semantic")
        
        print(f"‚úÖ Processed: {result.filename}")
        print(f"   Pages: {result.total_pages}")
        print(f"   Chunks: {len(result.chunks)}")
        print(f"   Processing time: {result.processing_time:.2f}s")
        
        for i, chunk in enumerate(result.chunks[:3]):
            print(f"   Chunk {i}: {chunk.text[:50]}...")
            print(f"     Page: {chunk.page_number}, BBox: {chunk.bbox.to_dict()}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        return False

if __name__ == "__main__":
    test_pdf_processor()


================================================
FILE: app/tools/__init__.py
================================================
# Tools Package



================================================
FILE: app/tools/gemini_chat.py
================================================
"""
Gemini Chat Generator for Haystack 2.x
"""

import os
import logging
from typing import List, Dict, Any, Optional

import google.generativeai as genai
from haystack import component, default_from_dict, default_to_dict
from haystack.dataclasses import ChatMessage, ChatRole

logger = logging.getLogger(__name__)

@component
class GeminiChatGenerator:
    """
    A component for generating chat responses using Google's Gemini API.
    
    This component integrates with Haystack 2.x pipelines and provides
    chat completion functionality using Gemini models.
    """
    
    def __init__(
        self,
        model: str = "gemini-2.5-flash",
        api_key: Optional[str] = None,
        generation_config: Optional[Dict[str, Any]] = None,
        safety_settings: Optional[List[Dict[str, Any]]] = None
    ):
        """
        Initialize the Gemini Chat Generator.
        
        Args:
            model: The Gemini model to use
            api_key: Google API key (if not provided, uses GOOGLE_API_KEY env var)
            generation_config: Generation configuration parameters
            safety_settings: Safety settings for content filtering
        """
        self.model_name = model
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")
        
        if not self.api_key:
            raise ValueError("Google API key is required")
        
        # Configure Gemini API
        genai.configure(api_key=self.api_key)
        
        # Initialize the model
        self.model = genai.GenerativeModel(
            model_name=self.model_name,
            generation_config=generation_config,
            safety_settings=safety_settings
        )
        
        logger.info(f"Initialized Gemini Chat Generator with model: {self.model_name}")
    
    def to_dict(self) -> Dict[str, Any]:
        """Serialize component to dictionary."""
        return default_to_dict(
            self,
            model=self.model_name,
            api_key=self.api_key,
        )
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "GeminiChatGenerator":
        """Deserialize component from dictionary."""
        return default_from_dict(cls, data)
    
    def _convert_messages_to_gemini_format(self, messages: List[ChatMessage]) -> List[Dict[str, str]]:
        """Convert Haystack ChatMessage format to Gemini format."""
        gemini_messages = []
        
        for message in messages:
            # Map Haystack roles to Gemini roles
            if message.role == ChatRole.SYSTEM:
                # Gemini doesn't have a system role, so we'll prepend system messages to user messages
                gemini_messages.append({
                    "role": "user",
                    "parts": [{"text": f"System: {message.content}"}]
                })
            elif message.role == ChatRole.USER:
                gemini_messages.append({
                    "role": "user",
                    "parts": [{"text": message.content}]
                })
            elif message.role == ChatRole.ASSISTANT:
                gemini_messages.append({
                    "role": "model",
                    "parts": [{"text": message.content}]
                })
        
        return gemini_messages
    
    @component.output_types(replies=List[ChatMessage])
    def run(self, messages: List[ChatMessage]) -> Dict[str, Any]:
        """
        Generate a chat response using Gemini.
        
        Args:
            messages: List of ChatMessage objects representing the conversation
            
        Returns:
            Dictionary with 'replies' key containing generated ChatMessage responses
        """
        try:
            logger.info(f"Generating response with {len(messages)} input messages")
            
            # Convert messages to Gemini format
            gemini_messages = self._convert_messages_to_gemini_format(messages)
            
            # For Gemini, we need to handle the conversation differently
            # We'll combine all messages into a single prompt for simplicity
            combined_prompt = ""
            for msg in messages:
                if msg.role == ChatRole.SYSTEM:
                    combined_prompt += f"System: {msg.content}\n\n"
                elif msg.role == ChatRole.USER:
                    combined_prompt += f"User: {msg.content}\n\n"
                elif msg.role == ChatRole.ASSISTANT:
                    combined_prompt += f"Assistant: {msg.content}\n\n"
            
            # Generate response
            response = self.model.generate_content(combined_prompt)
            
            if not response.text:
                logger.warning("Empty response from Gemini API")
                return {"replies": []}
            
            # Create ChatMessage response
            reply = ChatMessage.from_assistant(response.text)
            
            logger.info("Successfully generated response")
            return {"replies": [reply]}
            
        except Exception as e:
            logger.error(f"Error generating response with Gemini: {e}")
            # Return empty response on error
            return {"replies": []}



================================================
FILE: app/tools/tavily_search.py
================================================
"""
Tavily web search integration with document store indexing
"""

import os
import logging
from typing import List, Dict, Any, Optional
import time

from tavily import TavilyClient
from haystack import Document
from haystack.document_stores.in_memory import InMemoryDocumentStore

from app.rag.core import GeminiEmbedder, WebDisabled
from app.llm.gemini import chat

logger = logging.getLogger(__name__)

def web_search_into_docstore(
    docstore: InMemoryDocumentStore,
    embedder: GeminiEmbedder,
    query: str,
    max_results: int = 5
) -> List[Document]:
    """
    Perform web search with Tavily and add results to document store
    
    Args:
        docstore: Haystack document store to add results to
        embedder: Gemini embedder for generating embeddings
        query: Search query
        max_results: Maximum number of search results to process
        
    Returns:
        List of newly added Document objects
        
    Raises:
        WebDisabled: If ALLOW_TAVILY is not set to true
    """
    # Check if Tavily is enabled
    if os.getenv("ALLOW_TAVILY", "false").lower() != "true":
        raise WebDisabled("Web search is disabled. Set ALLOW_TAVILY=true to enable.")
    
    # Get Tavily API key
    tavily_api_key = os.getenv("TAVILY_API_KEY")
    if not tavily_api_key:
        raise ValueError("TAVILY_API_KEY environment variable is required when ALLOW_TAVILY=true")
    
    try:
        # Initialize Tavily client
        client = TavilyClient(api_key=tavily_api_key)
        
        # Perform search
        logger.info(f"Performing web search for: {query}")
        search_result = client.search(
            query=query,
            search_depth="basic",
            max_results=max_results,
            include_answer=True,
            include_raw_content=True
        )
        
        # Process search results
        documents = []
        results = search_result.get("results", [])
        
        if not results:
            logger.warning(f"No web search results found for query: {query}")
            return documents
        
        # Process each search result
        for i, result in enumerate(results):
            try:
                title = result.get("title", "")
                url = result.get("url", "")
                content = result.get("content", "")
                raw_content = result.get("raw_content", "")
                
                # Use raw content if available, otherwise use content
                full_content = raw_content if raw_content else content
                
                if not full_content:
                    logger.warning(f"No content found for URL: {url}")
                    continue
                
                # Summarize content using Gemini
                summary = _summarize_web_content(title, full_content, url, query)
                
                # Create document
                doc = Document(
                    content=summary,
                    meta={
                        "source": "web_search",
                        "source_url": url,
                        "title": title,
                        "type": "web_result",
                        "search_query": query,
                        "result_index": i,
                        "original_content_length": len(full_content),
                        "timestamp": time.time()
                    }
                )
                
                documents.append(doc)
                
            except Exception as e:
                logger.error(f"Error processing search result {i}: {e}")
                continue
        
        if not documents:
            logger.warning("No valid documents created from web search results")
            return documents
        
        # Generate embeddings for all documents
        logger.info(f"Generating embeddings for {len(documents)} web search results...")
        texts = [doc.content for doc in documents]
        embeddings = embedder.embed_texts(texts)
        
        # Add embeddings to documents
        for doc, embedding in zip(documents, embeddings):
            doc.embedding = embedding
        
        # Write documents to store
        docstore.write_documents(documents)
        
        logger.info(f"Successfully added {len(documents)} web search results to document store")
        return documents
        
    except WebDisabled:
        raise
    except Exception as e:
        logger.error(f"Error during web search: {e}")
        return []

def _summarize_web_content(title: str, content: str, url: str, query: str) -> str:
    """
    Summarize web content using Gemini chat model
    
    Args:
        title: Page title
        content: Page content
        url: Page URL
        query: Original search query
        
    Returns:
        Summarized content
    """
    try:
        # Truncate content if too long (keep first 3000 characters)
        truncated_content = content[:3000] if len(content) > 3000 else content
        
        # Create summarization prompt
        system_prompt = (
            "You are a helpful assistant that summarizes web content. "
            "Create a concise but informative summary that captures the key information "
            "relevant to the user's search query. Focus on factual content and maintain accuracy."
        )
        
        user_message = f"""
Please summarize the following web content in relation to the search query: "{query}"

Title: {title}
URL: {url}
Content: {truncated_content}

Provide a clear, factual summary that highlights information most relevant to the search query.
Keep the summary concise but comprehensive (2-3 paragraphs maximum).
"""
        
        messages = [
            {"role": "user", "content": user_message}
        ]
        
        # Get summary from Gemini
        summary = chat(messages, system=system_prompt)
        
        # Add source attribution
        attributed_summary = f"{summary}\n\nSource: {title} ({url})"
        
        return attributed_summary
        
    except Exception as e:
        logger.error(f"Error summarizing content from {url}: {e}")
        # Return truncated original content as fallback
        fallback_content = content[:1000] if len(content) > 1000 else content
        return f"Content from {title} ({url}):\n\n{fallback_content}"

def search_and_get_results(query: str, max_results: int = 5) -> List[Dict[str, Any]]:
    """
    Perform web search and return formatted results without adding to docstore
    
    Args:
        query: Search query
        max_results: Maximum number of results
        
    Returns:
        List of formatted search results
        
    Raises:
        WebDisabled: If ALLOW_TAVILY is not set to true
    """
    # Check if Tavily is enabled
    if os.getenv("ALLOW_TAVILY", "false").lower() != "true":
        raise WebDisabled("Web search is disabled. Set ALLOW_TAVILY=true to enable.")
    
    # Get Tavily API key
    tavily_api_key = os.getenv("TAVILY_API_KEY")
    if not tavily_api_key:
        raise ValueError("TAVILY_API_KEY environment variable is required when ALLOW_TAVILY=true")
    
    try:
        # Initialize Tavily client
        client = TavilyClient(api_key=tavily_api_key)
        
        # Perform search
        logger.info(f"Performing web search for: {query}")
        search_result = client.search(
            query=query,
            search_depth="basic",
            max_results=max_results,
            include_answer=True
        )
        
        # Format results
        formatted_results = []
        results = search_result.get("results", [])
        
        for result in results:
            formatted_results.append({
                "title": result.get("title", ""),
                "url": result.get("url", ""),
                "content": result.get("content", ""),
                "score": result.get("score", 0.0)
            })
        
        # Include answer if available
        answer = search_result.get("answer")
        if answer:
            formatted_results.insert(0, {
                "title": "Direct Answer",
                "url": "tavily://answer",
                "content": answer,
                "score": 1.0
            })
        
        logger.info(f"Retrieved {len(formatted_results)} web search results")
        return formatted_results
        
    except WebDisabled:
        raise
    except Exception as e:
        logger.error(f"Error during web search: {e}")
        return []



================================================
FILE: app/ui/index.html
================================================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Synch GenAI PoC</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #4f46e5 0%, #7c3aed 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            font-weight: 700;
        }

        .header p {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .chat-container {
            height: 500px;
            overflow-y: auto;
            padding: 20px;
            background: #f8fafc;
        }

        .message {
            margin-bottom: 20px;
            padding: 15px;
            border-radius: 12px;
            max-width: 80%;
            word-wrap: break-word;
        }

        .message.user {
            background: #4f46e5;
            color: white;
            margin-left: auto;
            text-align: right;
        }

        .message.assistant {
            background: white;
            border: 1px solid #e2e8f0;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        }

        .message.error {
            background: #fee2e2;
            border: 1px solid #fecaca;
            color: #dc2626;
        }

        .sources {
            margin-top: 10px;
            padding-top: 10px;
            border-top: 1px solid #e2e8f0;
            font-size: 0.9rem;
            color: #64748b;
        }

        .sources h4 {
            margin-bottom: 5px;
            color: #374151;
        }

        .sources ul {
            list-style: none;
            padding-left: 0;
        }

        .sources li {
            margin-bottom: 3px;
            padding-left: 15px;
            position: relative;
        }

        .sources li:before {
            content: "‚Ä¢";
            color: #4f46e5;
            position: absolute;
            left: 0;
        }

        .input-container {
            padding: 20px;
            background: white;
            border-top: 1px solid #e2e8f0;
        }

        .input-row {
            display: flex;
            gap: 10px;
            margin-bottom: 10px;
        }

        .query-input {
            flex: 1;
            padding: 12px 16px;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            font-size: 1rem;
            transition: border-color 0.2s;
        }

        .query-input:focus {
            outline: none;
            border-color: #4f46e5;
        }

        .send-button {
            padding: 12px 24px;
            background: #4f46e5;
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            cursor: pointer;
            transition: background-color 0.2s;
        }

        .send-button:hover:not(:disabled) {
            background: #4338ca;
        }

        .send-button:disabled {
            background: #9ca3af;
            cursor: not-allowed;
        }

        .options {
            display: flex;
            align-items: center;
            gap: 15px;
            font-size: 0.9rem;
            color: #64748b;
        }

        .checkbox-container {
            display: flex;
            align-items: center;
            gap: 5px;
        }

        .checkbox-container input[type="checkbox"] {
            margin: 0;
        }

        .status {
            padding: 10px 20px;
            background: #f1f5f9;
            border-top: 1px solid #e2e8f0;
            font-size: 0.9rem;
            color: #64748b;
            text-align: center;
        }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #4f46e5;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-right: 10px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .welcome-message {
            text-align: center;
            color: #64748b;
            font-style: italic;
            margin: 50px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Synch GenAI PoC</h1>
            <p>Intelligent Knowledge Base Assistant</p>
        </div>

        <div class="chat-container" id="chatContainer">
            <div class="welcome-message">
                Welcome! Ask me anything about our policies, contracts, or data. I'll search our knowledge base and provide accurate answers.
            </div>
        </div>

        <div class="input-container">
            <div class="input-row">
                <input 
                    type="text" 
                    id="queryInput" 
                    class="query-input" 
                    placeholder="Ask a question about policies, contracts, or data..."
                    onkeypress="handleKeyPress(event)"
                >
                <button id="sendButton" class="send-button" onclick="sendQuery()">
                    Send
                </button>
            </div>
            <div class="options">
                <div class="checkbox-container">
                    <input type="checkbox" id="tavilyCheckbox">
                    <label for="tavilyCheckbox">Enable web search fallback</label>
                </div>
            </div>
        </div>

        <div class="status" id="status">
            Ready to answer your questions
        </div>
    </div>

    <script>
        let isLoading = false;

        function handleKeyPress(event) {
            if (event.key === 'Enter' && !isLoading) {
                sendQuery();
            }
        }

        async function sendQuery() {
            const queryInput = document.getElementById('queryInput');
            const sendButton = document.getElementById('sendButton');
            const chatContainer = document.getElementById('chatContainer');
            const status = document.getElementById('status');
            const tavilyCheckbox = document.getElementById('tavilyCheckbox');

            const query = queryInput.value.trim();
            if (!query || isLoading) return;

            // Clear welcome message if it exists
            const welcomeMessage = chatContainer.querySelector('.welcome-message');
            if (welcomeMessage) {
                welcomeMessage.remove();
            }

            // Add user message
            addMessage('user', query);

            // Clear input and disable button
            queryInput.value = '';
            isLoading = true;
            sendButton.disabled = true;
            sendButton.innerHTML = '<div class="loading"></div>Thinking...';
            status.innerHTML = '<div class="loading"></div>Processing your query...';

            try {
                const response = await fetch('/api/query', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        query: query,
                        use_tavily: tavilyCheckbox.checked
                    })
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }

                const data = await response.json();
                addMessage('assistant', data.response, data.sources, data.used_tavily);
                
                // Update status
                const method = data.retrieval_method || 'hybrid';
                const docCount = data.retrieved_documents || 0;
                status.textContent = `Retrieved ${docCount} documents using ${method} retrieval${data.used_tavily ? ' with web search' : ''}`;

            } catch (error) {
                console.error('Error:', error);
                addMessage('error', `Sorry, I encountered an error: ${error.message}`);
                status.textContent = 'Error occurred while processing query';
            } finally {
                isLoading = false;
                sendButton.disabled = false;
                sendButton.textContent = 'Send';
                queryInput.focus();
            }
        }

        function addMessage(type, content, sources = [], usedTavily = false) {
            const chatContainer = document.getElementById('chatContainer');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;

            let messageHTML = `<div>${content}</div>`;

            if (sources && sources.length > 0) {
                messageHTML += `
                    <div class="sources">
                        <h4>Sources${usedTavily ? ' (Knowledge Base + Web)' : ' (Knowledge Base)'}:</h4>
                        <ul>
                            ${sources.map(source => `<li>${source}</li>`).join('')}
                        </ul>
                    </div>
                `;
            }

            messageDiv.innerHTML = messageHTML;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        // Check health on page load
        async function checkHealth() {
            try {
                const response = await fetch('/api/health');
                const data = await response.json();
                
                if (data.status === 'healthy') {
                    document.getElementById('status').textContent = 
                        `System ready - ${data.rag_initialized ? 'RAG initialized' : 'RAG not ready'}`;
                } else {
                    document.getElementById('status').textContent = 'System not ready';
                }
            } catch (error) {
                document.getElementById('status').textContent = 'Unable to connect to server';
            }
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            checkHealth();
            document.getElementById('queryInput').focus();
        });
    </script>
</body>
</html>



================================================
FILE: app/ui/modern.html
================================================
<!DOCTYPE html>
<html lang="en" class="h-full">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GenAI Studio (Hackathon PoC)</title>
    <script src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        'teal': {
                            500: '#14b8a6',
                            600: '#0d9488',
                        },
                        'slate': {
                            50: '#f8fafc',
                            100: '#f1f5f9',
                            200: '#e2e8f0',
                            300: '#cbd5e1',
                            400: '#94a3b8',
                            500: '#64748b',
                            600: '#475569',
                            700: '#334155',
                            800: '#1e293b',
                            900: '#0f172a',
                        }
                    }
                }
            }
        }
    </script>
    <style>
        .chat-message {
            animation: slideInUp 0.3s ease-out;
        }
        @keyframes slideInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        .tool-chip {
            transition: all 0.2s ease;
        }
        .tool-chip:hover {
            transform: translateY(-1px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        .redacted-text {
            background: linear-gradient(90deg, #94a3b8 25%, transparent 25%);
            background-size: 8px 1px;
            background-repeat: repeat-x;
            background-position: 0 50%;
            color: transparent;
        }
        .redacted-text:hover::after {
            content: " (Redacted)";
            color: #64748b;
            font-size: 0.75rem;
            background: #1e293b;
            padding: 2px 6px;
            border-radius: 4px;
            margin-left: 4px;
        }
        
        /* Enhanced markdown styles */
        .markdown-content {
            line-height: 1.6;
        }
        
        .markdown-content pre {
            margin: 1rem 0;
            position: relative;
        }
        
        .markdown-content code {
            font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace;
        }
        
        .markdown-content pre code {
            color: #e6ffed !important;
            background: transparent !important;
            padding: 0 !important;
            border-radius: 0 !important;
        }
        
        /* Override highlight.js theme for better visibility */
        .hljs {
            background: #1e293b !important;
            color: #e2e8f0 !important;
        }
        
        .hljs-keyword { color: #f59e0b !important; }
        .hljs-string { color: #10b981 !important; }
        .hljs-comment { color: #6b7280 !important; }
        .hljs-function { color: #3b82f6 !important; }
        .hljs-variable { color: #8b5cf6 !important; }
        .hljs-number { color: #f472b6 !important; }
        .hljs-built_in { color: #06b6d4 !important; }
    </style>
</head>
<body class="h-full bg-slate-50">
    <div id="root" class="h-full"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef } = React;
        const ReactMarkdown = window.ReactMarkdown;
        
        // Custom components for react-markdown
        const markdownComponents = {
            code: ({ node, inline, className, children, ...props }) => {
                const match = /language-(\w+)/.exec(className || '');
                const language = match ? match[1] : '';
                
                return !inline ? (
                    <div className="my-4">
                        {language && (
                            <div className="bg-slate-100 px-3 py-1 text-xs font-mono text-slate-600 border-t border-l border-r border-slate-300 rounded-t">
                                {language}
                            </div>
                        )}
                        <pre className={`bg-slate-900 text-green-400 p-4 rounded${language ? '-b' : ''} overflow-x-auto`}>
                            <code className={className} {...props}>
                                {children}
                            </code>
                        </pre>
                    </div>
                ) : (
                    <code className="bg-slate-100 text-slate-800 px-1.5 py-0.5 rounded text-sm font-mono" {...props}>
                        {children}
                    </code>
                );
            },
            h1: ({ children }) => <h1 className="text-2xl font-bold text-slate-800 mt-8 mb-4">{children}</h1>,
            h2: ({ children }) => <h2 className="text-xl font-bold text-slate-800 mt-6 mb-3">{children}</h2>,
            h3: ({ children }) => <h3 className="text-lg font-semibold text-slate-800 mt-4 mb-2">{children}</h3>,
            p: ({ children }) => <p className="mb-3 leading-relaxed">{children}</p>,
            ul: ({ children }) => <ul className="list-disc list-inside mb-3 space-y-1">{children}</ul>,
            ol: ({ children }) => <ol className="list-decimal list-inside mb-3 space-y-1">{children}</ol>,
            li: ({ children }) => <li className="ml-2">{children}</li>,
            strong: ({ children }) => <strong className="font-semibold text-slate-800">{children}</strong>,
            em: ({ children }) => <em className="italic">{children}</em>,
            blockquote: ({ children }) => (
                <blockquote className="border-l-4 border-slate-300 pl-4 italic text-slate-600 mb-3">
                    {children}
                </blockquote>
            )
        };

        // Agent configurations
        const AGENTS = {
            'smart': {
                name: 'Smart Chat',
                icon: 'fa-brain',
                color: 'text-teal-600',
                example: 'Find a standing desk under ‚Çπ50k with 12-mo 0% APR',
                tooltip: 'AI router - finds the best agent for your query'
            },
            'offerpilot': {
                name: 'OfferPilot',
                icon: 'fa-tags',
                color: 'text-blue-600',
                example: 'Show me laptops under ‚Çπ80k with financing options',
                tooltip: 'Product search with financing pre-qualification'
            },
            'trustshield': {
                name: 'TrustShield',
                icon: 'fa-shield-halved',
                color: 'text-red-600',
                example: 'I got an email asking for gift cards as refund',
                tooltip: 'Fraud detection and PII protection system'
            },
            'dispute': {
                name: 'Dispute',
                icon: 'fa-gavel',
                color: 'text-amber-600',
                example: 'Charged twice for ‚Çπ12,499 at Amazon on Dec 15th',
                tooltip: 'Transaction dispute resolution assistant'
            },
            'collections': {
                name: 'Collections',
                icon: 'fa-handshake',
                color: 'text-green-600',
                example: 'I have ‚Çπ25k balance at 24% APR, need payment options',
                tooltip: 'Hardship and payment plan assistance'
            },
            'contracts': {
                name: 'Contracts',
                icon: 'fa-file-contract',
                color: 'text-purple-600',
                example: 'Review my merchant agreement for key obligations',
                tooltip: 'Contract analysis and obligation tracking'
            },
            'devcopilot': {
                name: 'DevCopilot',
                icon: 'fa-code',
                color: 'text-indigo-600',
                example: 'Generate Python code for payments API integration',
                tooltip: 'Developer tools and API integration help'
            },
            'carecredit': {
                name: 'CareCredit',
                icon: 'fa-heart-pulse',
                color: 'text-pink-600',
                example: 'Dental procedure costs ‚Çπ45k, what are my options?',
                tooltip: 'Healthcare financing and payment plans'
            },
            'narrator': {
                name: 'Narrator',
                icon: 'fa-chart-line',
                color: 'text-orange-600',
                example: 'Why did spend drop after 2025-07-31?',
                tooltip: 'Portfolio analytics and business insights'
            },
            'imagegen': {
                name: 'ImageGen',
                icon: 'fa-image',
                color: 'text-violet-600',
                example: 'Create a futuristic city with flying cars and neon lights',
                tooltip: 'AI-powered image generation from text descriptions'
            }
        };

        // Main App Component
        function App() {
            const [selectedAgent, setSelectedAgent] = useState('smart');
            const [allowTavily, setAllowTavily] = useState(false);
            const [allowLlmKnowledge, setAllowLlmKnowledge] = useState(true);
            const [allowWebSearch, setAllowWebSearch] = useState(false);
            const [messages, setMessages] = useState([]);
            const [inputText, setInputText] = useState('');
            const [isLoading, setIsLoading] = useState(false);
            const [rightPanel, setRightPanel] = useState('citations');
            const [citations, setCitations] = useState([]);
            const [toolTrace, setToolTrace] = useState([]);
            const [uploadedPdfs, setUploadedPdfs] = useState([]);
            const [selectedPdfChunk, setSelectedPdfChunk] = useState(null);
            const messagesEndRef = useRef(null);

            // Auto-scroll to bottom when messages change
            useEffect(() => {
                messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
            }, [messages]);
            
            // Highlight code blocks after messages update
            useEffect(() => {
                if (window.hljs) {
                    setTimeout(() => window.hljs.highlightAll(), 100);
                }
            }, [messages]);

            const sendMessage = async () => {
                if (!inputText.trim()) return;

                const userMessage = {
                    id: Date.now(),
                    type: 'user',
                    content: inputText,
                    timestamp: new Date()
                };

                setMessages(prev => [...prev, userMessage]);
                setIsLoading(true);

                try {
                    const endpoint = selectedAgent === 'smart' ? '/chat' : `/agent/${selectedAgent}`;
                    const payload = selectedAgent === 'smart' 
                        ? { 
                            message: inputText, 
                            allow_tavily: allowTavily,
                            allow_llm_knowledge: allowLlmKnowledge,
                            allow_web_search: allowWebSearch
                        }
                        : selectedAgent === 'imagegen'
                        ? { prompt: inputText, include_text: true, style_hints: [] }
                        : { query: inputText };

                    const response = await fetch(endpoint, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    const data = await response.json();
                    
                    const assistantMessage = {
                        id: Date.now() + 1,
                        type: 'assistant',
                        content: data.response || data,
                        agent: data.agent || selectedAgent,
                        confidence: data.confidence || 1.0,
                        sources: data.sources || [],
                        used_tavily: data.used_tavily || false,
                        timestamp: new Date(),
                        latency: Math.random() * 2000 + 500, // Mock latency
                        image_data: data.image_data,
                        image_format: data.image_format
                    };

                    setMessages(prev => [...prev, assistantMessage]);
                    setCitations(data.sources || []);
                    setToolTrace(prev => [...prev, {
                        tool: selectedAgent,
                        args: payload,
                        result: data,
                        timestamp: new Date()
                    }]);

                } catch (error) {
                    console.error('Error sending message:', error);
                    setMessages(prev => [...prev, {
                        id: Date.now() + 1,
                        type: 'error',
                        content: 'Sorry, there was an error processing your request.',
                        timestamp: new Date()
                    }]);
                }

                setInputText('');
                setIsLoading(false);
            };

            const useExample = (agentKey) => {
                setInputText(AGENTS[agentKey].example);
                setSelectedAgent(agentKey);
            };

            const clearChat = () => {
                setMessages([]);
                setCitations([]);
                setToolTrace([]);
            };

            const uploadPdf = async (file) => {
                const formData = new FormData();
                formData.append('file', file);
                
                try {
                    const response = await fetch('/upload/pdf', {
                        method: 'POST',
                        body: formData
                    });
                    
                    if (!response.ok) {
                        const errorText = await response.text();
                        console.error(`Upload failed with status ${response.status}:`, errorText);
                        throw new Error(`Upload failed: ${response.status} - ${errorText}`);
                    }
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        setUploadedPdfs(prev => [...prev, result]);
                        
                        // Get first page thumbnail for display
                        let thumbnailImage = null;
                        try {
                            const pageResponse = await fetch(`/pdf/${result.pdf_id}/page/0`);
                            if (pageResponse.ok) {
                                const pageData = await pageResponse.json();
                                thumbnailImage = pageData.image_base64;
                            }
                        } catch (error) {
                            console.error('Failed to fetch PDF thumbnail:', error);
                        }
                        
                        // Add upload notification to chat with PDF data
                        const uploadMessage = {
                            id: Date.now(),
                            type: 'pdf_upload',
                            content: `üìÑ Uploaded and processed: ${result.filename} (${result.chunks_extracted} chunks from ${result.total_pages} pages)`,
                            timestamp: new Date(),
                            pdfData: result,
                            thumbnail: thumbnailImage
                        };
                        setMessages(prev => [...prev, uploadMessage]);
                        
                        return result;
                    } else {
                        throw new Error('Upload failed');
                    }
                } catch (error) {
                    console.error('PDF upload error:', error);
                    
                    const errorMessage = {
                        id: Date.now(),
                        type: 'error',
                        content: `Failed to upload PDF: ${error.message}`,
                        timestamp: new Date()
                    };
                    setMessages(prev => [...prev, errorMessage]);
                    
                    throw error;
                }
            };

            const exportJSON = () => {
                const lastMessage = messages[messages.length - 1];
                if (lastMessage && lastMessage.type === 'assistant') {
                    const blob = new Blob([JSON.stringify(lastMessage, null, 2)], 
                        { type: 'application/json' });
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = `genai-response-${Date.now()}.json`;
                    a.click();
                }
            };

            return (
                <div className="h-screen flex flex-col bg-slate-50">
                    {/* Header */}
                    <Header 
                        allowTavily={allowTavily}
                        setAllowTavily={setAllowTavily}
                        allowLlmKnowledge={allowLlmKnowledge}
                        setAllowLlmKnowledge={setAllowLlmKnowledge}
                        allowWebSearch={allowWebSearch}
                        setAllowWebSearch={setAllowWebSearch}
                        onClear={clearChat}
                        onExport={exportJSON}
                    />

                    {/* Main Content */}
                    <div className="flex-1 flex overflow-hidden">
                        {/* Left Rail */}
                        <LeftRail 
                            selectedAgent={selectedAgent}
                            onSelectAgent={setSelectedAgent}
                            onUseExample={useExample}
                        />

                        {/* Chat Pane */}
                        <ChatPane
                            messages={messages}
                            isLoading={isLoading}
                            inputText={inputText}
                            setInputText={setInputText}
                            selectedAgent={selectedAgent}
                            allowTavily={allowTavily}
                            setAllowTavily={setAllowTavily}
                            onSendMessage={sendMessage}
                            messagesEndRef={messagesEndRef}
                            uploadedPdfs={uploadedPdfs}
                            setUploadedPdfs={setUploadedPdfs}
                            uploadPdf={uploadPdf}
                        />

                        {/* Right Inspector */}
                        <RightInspector
                            activePanel={rightPanel}
                            setActivePanel={setRightPanel}
                            citations={citations}
                            toolTrace={toolTrace}
                            uploadedPdfs={uploadedPdfs}
                            selectedPdfChunk={selectedPdfChunk}
                            setSelectedPdfChunk={setSelectedPdfChunk}
                        />
                    </div>
                </div>
            );
        }

        // Header Component
        function Header({ allowTavily, setAllowTavily, allowLlmKnowledge, setAllowLlmKnowledge, allowWebSearch, setAllowWebSearch, onClear, onExport }) {
            return (
                <header className="bg-white border-b border-slate-200 px-6 py-3">
                    <div className="flex items-center justify-between">
                        <div className="flex items-center space-x-4">
                            <h1 className="text-xl font-semibold text-slate-800">
                                GenAI Studio <span className="text-sm font-normal text-slate-500">(Hackathon PoC)</span>
                            </h1>
                            <div className="flex items-center space-x-3">
                                <span className="px-2 py-1 text-xs bg-slate-100 text-slate-600 rounded-md">
                                    Local ‚Ä¢ No DB
                                </span>
                                <div className="space-y-2">
                                    <label className="flex items-center space-x-2 text-sm">
                                        <input
                                            type="checkbox"
                                            checked={allowTavily}
                                            onChange={(e) => setAllowTavily(e.target.checked)}
                                            className="rounded text-teal-600 focus:ring-teal-500"
                                        />
                                        <span className="text-slate-600">Allow Tavily (legacy)</span>
                                    </label>
                                    <label className="flex items-center space-x-2 text-sm">
                                        <input
                                            type="checkbox"
                                            checked={allowLlmKnowledge}
                                            onChange={(e) => setAllowLlmKnowledge(e.target.checked)}
                                            className="rounded text-blue-600 focus:ring-blue-500"
                                        />
                                        <span className="text-slate-600">LLM Knowledge Fallback</span>
                                    </label>
                                    <label className="flex items-center space-x-2 text-sm">
                                        <input
                                            type="checkbox"
                                            checked={allowWebSearch}
                                            onChange={(e) => setAllowWebSearch(e.target.checked)}
                                            className="rounded text-purple-600 focus:ring-purple-500"
                                        />
                                        <span className="text-slate-600">Web Search Fallback</span>
                                    </label>
                                </div>
                            </div>
                        </div>

                        <div className="flex items-center space-x-3">
                            <span className="px-2 py-1 text-xs bg-green-100 text-green-600 rounded-md">
                                PII Redaction ON
                            </span>
                            <button
                                onClick={onClear}
                                className="px-3 py-1 text-sm text-slate-600 hover:text-slate-800"
                            >
                                Clear
                            </button>
                            <button
                                onClick={onExport}
                                className="px-3 py-1 text-sm text-slate-600 hover:text-slate-800"
                            >
                                Export JSON
                            </button>
                            <span className="px-2 py-1 text-xs bg-amber-100 text-amber-700 rounded-md">
                                Demo ‚Äî not legal/credit advice
                            </span>
                        </div>
                    </div>
                </header>
            );
        }

        // Left Rail Component
        function LeftRail({ selectedAgent, onSelectAgent, onUseExample }) {
            return (
                <div className="w-64 bg-white border-r border-slate-200 flex flex-col">
                    <div className="p-4 border-b border-slate-200">
                        <h2 className="font-medium text-slate-800 mb-3">Agents</h2>
                    </div>
                    <div className="flex-1 overflow-y-auto">
                        {Object.entries(AGENTS).map(([key, agent]) => (
                            <AgentItem
                                key={key}
                                agentKey={key}
                                agent={agent}
                                isSelected={selectedAgent === key}
                                onSelect={() => onSelectAgent(key)}
                                onUseExample={() => onUseExample(key)}
                            />
                        ))}
                    </div>
                </div>
            );
        }

        // Agent Item Component
        function AgentItem({ agentKey, agent, isSelected, onSelect, onUseExample }) {
            return (
                <div 
                    className={`p-3 border-b border-slate-100 cursor-pointer hover:bg-slate-50 transition-colors ${
                        isSelected ? 'bg-teal-50 border-r-2 border-teal-500' : ''
                    }`}
                    onClick={onSelect}
                >
                    <div className="flex items-center justify-between">
                        <div className="flex items-center space-x-3">
                            <i className={`fas ${agent.icon} ${agent.color}`}></i>
                            <div>
                                <div className="font-medium text-sm text-slate-800">
                                    {agent.name}
                                </div>
                                <div className="text-xs text-slate-500 mt-1">
                                    {agent.tooltip}
                                </div>
                            </div>
                        </div>
                        <button
                            onClick={(e) => {
                                e.stopPropagation();
                                onUseExample();
                            }}
                            className="text-xs text-teal-600 hover:text-teal-700 p-1"
                            title="Try Example"
                        >
                            <i className="fas fa-play"></i>
                        </button>
                    </div>
                </div>
            );
        }

        // Chat Pane Component
        function ChatPane({ messages, isLoading, inputText, setInputText, selectedAgent, allowTavily, setAllowTavily, onSendMessage, messagesEndRef, uploadedPdfs, setUploadedPdfs, uploadPdf }) {
            const [isDragOver, setIsDragOver] = useState(false);
            
            const handleKeyPress = (e) => {
                if (e.key === 'Enter') {
                    if (e.shiftKey || e.ctrlKey) {
                        // Allow new line on Shift+Enter or Ctrl+Enter
                        return;
                    } else {
                        // Send message on plain Enter
                        e.preventDefault();
                        if (inputText.trim()) {
                            onSendMessage();
                        }
                    }
                }
            };

            const handleDragOver = (e) => {
                e.preventDefault();
                e.stopPropagation();
                setIsDragOver(true);
            };

            const handleDragLeave = (e) => {
                e.preventDefault();
                e.stopPropagation();
                setIsDragOver(false);
            };

            const handleDrop = async (e) => {
                e.preventDefault();
                e.stopPropagation();
                setIsDragOver(false);

                const files = Array.from(e.dataTransfer.files);
                console.log('Dropped files:', files.map(f => ({ name: f.name, type: f.type, size: f.size })));
                
                const pdfFiles = files.filter(file => 
                    file.type === 'application/pdf' || file.name.toLowerCase().endsWith('.pdf')
                );

                if (pdfFiles.length === 0) {
                    alert('Please drop PDF files only.');
                    return;
                }

                console.log('Processing PDF files:', pdfFiles.map(f => f.name));

                // Upload each PDF file
                for (const file of pdfFiles) {
                    try {
                        console.log(`Uploading PDF: ${file.name}`);
                        await uploadPdf(file);
                        console.log(`Successfully uploaded: ${file.name}`);
                    } catch (error) {
                        console.error(`Error uploading PDF ${file.name}:`, error);
                    }
                }
            };

            return (
                <div 
                    className="flex-1 flex flex-col bg-white relative"
                    onDragOver={handleDragOver}
                    onDragLeave={handleDragLeave}
                    onDrop={handleDrop}
                >
                    {/* Chat Header */}
                    <div className="p-4 border-b border-slate-200">
                        <div className="flex items-center justify-between">
                            <div className="flex items-center space-x-2">
                                <i className={`fas ${AGENTS[selectedAgent].icon} ${AGENTS[selectedAgent].color}`}></i>
                                <span className="font-medium text-slate-800">{AGENTS[selectedAgent].name}</span>
                                {selectedAgent !== 'smart' && (
                                    <span className="px-2 py-1 text-xs bg-slate-100 text-slate-600 rounded">
                                        Direct Mode
                                    </span>
                                )}
                            </div>
                            <div className="text-sm text-slate-500">
                                {messages.length} messages
                            </div>
                        </div>
                    </div>

                    {/* Messages */}
                    <div className="flex-1 overflow-y-auto p-4 space-y-4">
                        {messages.length === 0 && (
                            <div className="text-center py-12">
                                <i className={`fas ${AGENTS[selectedAgent].icon} text-4xl ${AGENTS[selectedAgent].color} mb-4`}></i>
                                <h3 className="text-lg font-medium text-slate-800 mb-2">
                                    {AGENTS[selectedAgent].name}
                                </h3>
                                <p className="text-slate-600 mb-4">
                                    {AGENTS[selectedAgent].tooltip}
                                </p>
                                <div className="text-sm text-slate-500">
                                    Try: "{AGENTS[selectedAgent].example}"
                                </div>
                            </div>
                        )}
                        
                        {messages.map((message) => (
                            <ChatMessage key={message.id} message={message} />
                        ))}
                        
                        {isLoading && (
                            <div className="flex justify-center py-4">
                                <div className="flex items-center space-x-2 text-slate-500">
                                    <div className="animate-spin h-4 w-4 border-2 border-teal-500 border-t-transparent rounded-full"></div>
                                    <span>Thinking...</span>
                                </div>
                            </div>
                        )}
                        <div ref={messagesEndRef} />
                    </div>

                    {/* Drag & Drop Overlay */}
                    {isDragOver && (
                        <div className="absolute inset-0 bg-teal-500 bg-opacity-10 border-2 border-dashed border-teal-500 flex items-center justify-center z-50">
                            <div className="bg-white p-6 rounded-lg shadow-lg text-center">
                                <i className="fas fa-file-pdf text-4xl text-teal-600 mb-2"></i>
                                <p className="text-lg font-medium text-slate-800 mb-1">Drop PDF files here</p>
                                <p className="text-sm text-slate-600">Upload documents to analyze and chat about</p>
                            </div>
                        </div>
                    )}

                    {/* Composer */}
                    <div className="border-t border-slate-200 p-4">
                        {/* PDF Upload Area */}
                        {uploadedPdfs.length > 0 && (
                            <div className="mb-3 p-2 bg-slate-50 rounded border border-slate-200">
                                <div className="text-xs text-slate-600 mb-2">üìÑ Attached PDFs:</div>
                                <div className="flex flex-wrap gap-2">
                                    {uploadedPdfs.map((pdf, index) => (
                                        <div key={index} className="flex items-center space-x-2 bg-white px-2 py-1 rounded border text-xs">
                                            <i className="fas fa-file-pdf text-red-600"></i>
                                            <span>{pdf.filename}</span>
                                            <span className="text-slate-500">({pdf.chunks_extracted} chunks)</span>
                                            <button
                                                onClick={() => setUploadedPdfs(prev => prev.filter((_, i) => i !== index))}
                                                className="text-slate-400 hover:text-red-600 ml-1"
                                            >
                                                <i className="fas fa-times"></i>
                                            </button>
                                        </div>
                                    ))}
                                </div>
                            </div>
                        )}

                        {/* Input Container */}
                        <div className="relative bg-white border border-slate-300 rounded-lg focus-within:border-teal-500 focus-within:ring-1 focus-within:ring-teal-500">
                            <div className="flex items-end">
                                {/* Plus Button */}
                                <div className="flex-shrink-0 p-2">
                                    <label className="cursor-pointer text-slate-500 hover:text-slate-700 transition-colors">
                                        <input
                                            type="file"
                                            accept=".pdf"
                                            className="hidden"
                                            onChange={async (e) => {
                                                const file = e.target.files[0];
                                                if (file) {
                                                    try {
                                                        await uploadPdf(file);
                                                    } catch (error) {
                                                        // Error already handled in uploadPdf
                                                    }
                                                    e.target.value = ''; // Reset input
                                                }
                                            }}
                                        />
                                        <div className="w-6 h-6 rounded-full border border-slate-300 flex items-center justify-center hover:bg-slate-50 transition-colors">
                                            <i className="fas fa-plus text-xs"></i>
                                        </div>
                                    </label>
                                </div>

                                {/* Text Input */}
                                <div className="flex-1 min-h-[44px]">
                                    <textarea
                                        value={inputText}
                                        onChange={(e) => setInputText(e.target.value)}
                                        onKeyPress={handleKeyPress}
                                        placeholder={selectedAgent === 'smart' 
                                            ? 'Ask about your documents, shop + finance, dispute, contracts...'
                                            : `Ask ${AGENTS[selectedAgent].name}...`
                                        }
                                        className="w-full px-2 py-2 border-0 bg-transparent resize-none focus:outline-none"
                                        rows={Math.min(inputText.split('\n').length, 4)}
                                        disabled={isLoading}
                                    />
                                </div>

                                {/* Send Button */}
                                <div className="flex-shrink-0 p-2">
                                    <button
                                        onClick={onSendMessage}
                                        disabled={isLoading || !inputText.trim()}
                                        className={`w-8 h-8 rounded-full flex items-center justify-center transition-all ${
                                            inputText.trim() && !isLoading
                                                ? 'bg-teal-600 text-white hover:bg-teal-700'
                                                : 'bg-slate-100 text-slate-400'
                                        }`}
                                    >
                                        <i className="fas fa-paper-plane text-sm"></i>
                                    </button>
                                </div>
                            </div>
                        </div>

                        {/* Footer Info */}
                        <div className="flex items-center justify-between mt-2">
                            <div className="flex items-center space-x-4">
                                {selectedAgent === 'smart' && (
                                    <label className="flex items-center space-x-1 text-xs text-slate-500">
                                        <input
                                            type="checkbox"
                                            checked={allowTavily}
                                            onChange={(e) => setAllowTavily(e.target.checked)}
                                            className="rounded"
                                        />
                                        <span>Use Tavily</span>
                                    </label>
                                )}
                            </div>
                            <div className="text-xs text-slate-400">
                                {inputText.length} chars ‚Ä¢ Enter to send ‚Ä¢ Shift+Enter for new line
                            </div>
                        </div>
                    </div>
                </div>
            );
        }

        // Chat Message Component
        function ChatMessage({ message }) {
            if (message.type === 'user') {
                return (
                    <div className="flex justify-end">
                        <div className="bg-teal-600 text-white px-4 py-2 rounded-lg max-w-md">
                            {message.content}
                        </div>
                    </div>
                );
            }

            if (message.type === 'error') {
                return (
                    <div className="flex">
                        <div className="bg-red-100 text-red-700 px-4 py-2 rounded-lg max-w-md">
                            <i className="fas fa-exclamation-triangle mr-2"></i>
                            {message.content}
                        </div>
                    </div>
                );
            }

            if (message.type === 'pdf_upload') {
                return (
                    <div className="flex">
                        <div className="bg-blue-50 border border-blue-200 px-4 py-3 rounded-lg max-w-md">
                            <div className="flex items-start space-x-3">
                                {message.thumbnail && (
                                    <div className="flex-shrink-0">
                                        <img 
                                            src={`data:image/png;base64,${message.thumbnail}`} 
                                            alt="PDF Thumbnail"
                                            className="w-16 h-20 object-cover rounded border border-slate-200 shadow-sm"
                                        />
                                    </div>
                                )}
                                <div className="flex-1">
                                    <div className="flex items-center space-x-2 mb-1">
                                        <i className="fas fa-file-pdf text-red-600"></i>
                                        <span className="font-medium text-sm text-slate-800">
                                            {message.pdfData?.filename}
                                        </span>
                                    </div>
                                    <div className="text-xs text-slate-600 space-y-1">
                                        <div>üìÑ {message.pdfData?.total_pages} pages</div>
                                        <div>üß© {message.pdfData?.chunks_extracted} chunks extracted</div>
                                        <div>‚ö° Processed in {message.pdfData?.processing_time?.toFixed(2)}s</div>
                                    </div>
                                    <div className="text-xs text-slate-500 mt-2">
                                        Ready for questions about this document
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                );
            }

            return (
                <div className="chat-message">
                    <div className="flex items-start space-x-3">
                        <div className={`w-8 h-8 rounded-full bg-slate-100 flex items-center justify-center`}>
                            <i className={`fas ${AGENTS[message.agent]?.icon || 'fa-robot'} text-slate-600`}></i>
                        </div>
                        <div className="flex-1">
                            {/* Message Header */}
                            <div className="flex items-center space-x-2 mb-2">
                                <span className="font-medium text-sm text-slate-800">
                                    {AGENTS[message.agent]?.name || message.agent}
                                </span>
                                <span className="text-xs text-slate-500">
                                    {message.timestamp.toLocaleTimeString()}
                                </span>
                                {message.latency && (
                                    <span className="text-xs text-slate-400">
                                        {Math.round(message.latency)}ms
                                    </span>
                                )}
                                {message.confidence && (
                                    <span className={`text-xs px-1 py-0.5 rounded ${
                                        message.confidence > 0.8 ? 'bg-green-100 text-green-600' :
                                        message.confidence > 0.6 ? 'bg-yellow-100 text-yellow-600' :
                                        'bg-red-100 text-red-600'
                                    }`}>
                                        {Math.round(message.confidence * 100)}%
                                    </span>
                                )}
                                {message.used_tavily && (
                                    <span className="text-xs bg-blue-100 text-blue-600 px-2 py-0.5 rounded">
                                        <i className="fas fa-globe mr-1"></i>
                                        Web Enhanced
                                    </span>
                                )}
                            </div>

                            {/* Message Content */}
                            <div className="prose prose-sm max-w-none text-slate-700">
                                {typeof message.content === 'string' ? (
                                    <ReactMarkdown 
                                        components={markdownComponents}
                                        className="markdown-content"
                                    >
                                        {message.content.replace(/\[REDACTED[^\]]*\]/g, '‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà')}
                                    </ReactMarkdown>
                                ) : (
                                    <pre className="text-sm bg-slate-50 p-3 rounded border overflow-x-auto">
                                        {JSON.stringify(message.content, null, 2)}
                                    </pre>
                                )}
                            </div>

                            {/* Generated Image Display */}
                            {message.image_data && (
                                <div className="mt-4">
                                    <div className="border border-slate-200 rounded-lg overflow-hidden bg-slate-50">
                                        <div className="p-3 bg-slate-100 border-b border-slate-200">
                                            <div className="flex items-center justify-between text-sm">
                                                <div className="flex items-center space-x-2">
                                                    <i className="fas fa-image text-violet-600"></i>
                                                    <span className="font-medium text-slate-800">Generated Image</span>
                                                    <span className="px-2 py-1 text-xs bg-violet-100 text-violet-700 rounded">
                                                        {message.image_format || 'PNG'}
                                                    </span>
                                                </div>
                                                <button
                                                    onClick={() => {
                                                        const link = document.createElement('a');
                                                        link.download = `generated-image-${Date.now()}.${(message.image_format || 'PNG').toLowerCase()}`;
                                                        link.href = `data:image/${(message.image_format || 'png').toLowerCase()};base64,${message.image_data}`;
                                                        link.click();
                                                    }}
                                                    className="text-slate-500 hover:text-slate-700"
                                                    title="Download Image"
                                                >
                                                    <i className="fas fa-download"></i>
                                                </button>
                                            </div>
                                        </div>
                                        <div className="p-4">
                                            <img
                                                src={`data:image/${(message.image_format || 'png').toLowerCase()};base64,${message.image_data}`}
                                                alt="Generated image"
                                                className="max-w-full h-auto rounded border border-slate-200 shadow-sm hover:shadow-md transition-shadow cursor-pointer"
                                                style={{ maxHeight: '400px', objectFit: 'contain' }}
                                                onClick={() => {
                                                    // Open full-size image in new window
                                                    const newWindow = window.open();
                                                    newWindow.document.write(`
                                                        <html>
                                                            <head><title>Generated Image</title></head>
                                                            <body style="margin:0; background:#000; display:flex; justify-content:center; align-items:center; min-height:100vh;">
                                                                <img src="data:image/${(message.image_format || 'png').toLowerCase()};base64,${message.image_data}" style="max-width:100%; max-height:100%; object-fit:contain;" />
                                                            </body>
                                                        </html>
                                                    `);
                                                }}
                                            />
                                        </div>
                                    </div>
                                </div>
                            )}

                            {/* Sources */}
                            {message.sources && message.sources.length > 0 && (
                                <div className="mt-3 flex flex-wrap gap-1">
                                    {message.sources.slice(0, 5).map((source, index) => (
                                        <button
                                            key={index}
                                            className="tool-chip text-xs bg-slate-100 hover:bg-slate-200 text-slate-600 px-2 py-1 rounded-md"
                                            title={source}
                                        >
                                            <i className="fas fa-quote-left mr-1"></i>
                                            ({index + 1})
                                        </button>
                                    ))}
                                </div>
                            )}
                            
                            {/* Fallback Information */}
                            {message.fallback_used && (
                                <div className="mt-2 px-3 py-2 bg-blue-50 border border-blue-200 rounded-lg">
                                    <div className="flex items-center space-x-2 text-sm">
                                        <i className="fas fa-route text-blue-600"></i>
                                        <span className="font-medium text-blue-800">
                                            Fallback Used: {message.fallback_used.replace('_', ' ')}
                                        </span>
                                    </div>
                                    {message.document_assessment && (
                                        <div className="mt-1 text-xs text-blue-700">
                                            <div>Quality Score: {(message.document_assessment.document_quality_score * 100).toFixed(0)}%</div>
                                            <div>Assessment: {message.document_assessment.reason}</div>
                                        </div>
                                    )}
                                </div>
                            )}
                        </div>
                    </div>
                </div>
            );
        }

        // Right Inspector Component
        function RightInspector({ activePanel, setActivePanel, citations, toolTrace, uploadedPdfs, selectedPdfChunk, setSelectedPdfChunk }) {
            return (
                <div className="w-80 bg-white border-l border-slate-200 flex flex-col">
                    {/* Panel Tabs */}
                    <div className="border-b border-slate-200">
                        <div className="flex">
                            {[
                                { id: 'citations', label: 'Citations', icon: 'fa-quote-left' },
                                { id: 'trace', label: 'Tool Trace', icon: 'fa-code' },
                                { id: 'docs', label: 'Doc Viewer', icon: 'fa-file-text' }
                            ].map(tab => (
                                <button
                                    key={tab.id}
                                    onClick={() => setActivePanel(tab.id)}
                                    className={`flex-1 px-3 py-2 text-sm font-medium border-b-2 ${
                                        activePanel === tab.id
                                            ? 'border-teal-500 text-teal-600'
                                            : 'border-transparent text-slate-500 hover:text-slate-700'
                                    }`}
                                >
                                    <i className={`fas ${tab.icon} mr-1`}></i>
                                    {tab.label}
                                </button>
                            ))}
                        </div>
                    </div>

                    {/* Panel Content */}
                    <div className="flex-1 overflow-y-auto p-4">
                        {activePanel === 'citations' && (
                            <CitationsPanel 
                                citations={citations} 
                                onPdfChunkClick={(filename, chunkId) => {
                                    // Switch to docs panel
                                    setActivePanel('docs');
                                    setSelectedPdfChunk(chunkId);
                                    
                                    // Find and auto-select the PDF by filename
                                    const matchingPdf = uploadedPdfs.find(pdf => 
                                        pdf.filename === filename
                                    );
                                    
                                    if (matchingPdf) {
                                        // This will be handled by the DocViewerPanel
                                        console.log(`Navigating to PDF: ${filename}, Chunk: ${chunkId}`);
                                    }
                                }}
                            />
                        )}
                        {activePanel === 'trace' && (
                            <ToolTracePanel toolTrace={toolTrace} />
                        )}
                        {activePanel === 'docs' && (
                            <DocViewerPanel 
                                uploadedPdfs={uploadedPdfs}
                                selectedPdfChunk={selectedPdfChunk}
                                setSelectedPdfChunk={setSelectedPdfChunk}
                            />
                        )}
                    </div>
                </div>
            );
        }

        // Citations Panel
        function CitationsPanel({ citations, onPdfChunkClick }) {
            if (citations.length === 0) {
                return (
                    <div className="text-center py-8 text-slate-500">
                        <i className="fas fa-quote-left text-2xl mb-2"></i>
                        <p>No citations yet</p>
                        <p className="text-xs mt-1">Sources will appear here</p>
                    </div>
                );
            }

            return (
                <div className="space-y-3">
                    {citations.map((citation, index) => {
                        // Parse different citation formats
                        let sourceName = citation;
                        let score = null;
                        let type = 'source';
                        let icon = 'fa-file-text';
                        
                        // Handle routing info (first citation)
                        if (citation.includes('üéØ Routed to:')) {
                            const match = citation.match(/üéØ Routed to: (\w+) \((\d+\.?\d*)% confidence\)/);
                            if (match) {
                                sourceName = `Routed to ${match[1]}`;
                                score = `${match[2]}% confidence`;
                                type = 'routing';
                                icon = 'fa-route';
                            }
                        }
                        // Handle score-based citations
                        else if (citation.includes(' - Score:')) {
                            const parts = citation.split(' - Score:');
                            sourceName = parts[0].trim();
                            score = `Score: ${parts[1].trim()}`;
                            type = 'document';
                            icon = 'fa-file-text';
                        }
                        // Handle PDF citations with chunk IDs
                        else if (citation.includes('.pdf') || citation.includes('pdf_') || citation.includes('chunk_')) {
                            type = 'pdf';
                            icon = 'fa-file-pdf';
                            
                            // Try to extract PDF filename and chunk ID
                            const pdfMatch = citation.match(/([^\/]+\.pdf)/);
                            const chunkMatch = citation.match(/(chunk_\w+|para_\d+|page_\d+)/);
                            
                            if (pdfMatch) {
                                sourceName = pdfMatch[1];
                                if (chunkMatch) {
                                    score = `Chunk: ${chunkMatch[1]}`;
                                    // Store chunk info for click handler
                                    citation.chunkId = chunkMatch[1];
                                    citation.filename = pdfMatch[1];
                                }
                            }
                        }
                        // Handle other citation formats
                        else if (citation.includes('.md')) {
                            type = 'document';
                            icon = 'fa-file-text';
                        }
                        else if (citation.includes('Web Enhanced') || citation.includes('Tavily')) {
                            type = 'web';
                            icon = 'fa-globe';
                        }
                        
                        return (
                            <div key={index} className={`border rounded-md p-3 ${
                                type === 'routing' ? 'border-teal-200 bg-teal-50' :
                                type === 'web' ? 'border-blue-200 bg-blue-50' :
                                type === 'pdf' ? 'border-red-200 bg-red-50' :
                                'border-slate-200'
                            }`}>
                                <div className="flex items-start justify-between mb-2">
                                    <div className="flex items-start space-x-2">
                                        <i className={`fas ${icon} text-sm mt-0.5 ${
                                            type === 'routing' ? 'text-teal-600' :
                                            type === 'web' ? 'text-blue-600' :
                                            type === 'pdf' ? 'text-red-600' :
                                            'text-slate-600'
                                        }`}></i>
                                        <div>
                                            <div className="text-sm font-medium text-slate-800">
                                                {sourceName}
                                            </div>
                                            {score && (
                                                <div className={`text-xs mt-1 ${
                                                    type === 'routing' ? 'text-teal-600' :
                                                    type === 'web' ? 'text-blue-600' :
                                                    type === 'pdf' ? 'text-red-600' :
                                                    'text-slate-500'
                                                }`}>
                                                    {score}
                                                </div>
                                            )}
                                        </div>
                                    </div>
                                    <span className={`text-xs px-2 py-1 rounded ${
                                        type === 'routing' ? 'bg-teal-100 text-teal-700' :
                                        type === 'web' ? 'bg-blue-100 text-blue-700' :
                                        'bg-slate-100 text-slate-600'
                                    }`}>
                                        ({index + 1})
                                    </span>
                                </div>
                                {type === 'document' && (
                                    <button className="text-xs text-slate-600 hover:text-slate-800">
                                        <i className="fas fa-eye mr-1"></i>
                                        View source
                                    </button>
                                )}
                                {type === 'pdf' && citation.chunkId && (
                                    <button 
                                        onClick={() => {
                                            // Switch to docs panel
                                            onPdfChunkClick(citation.filename, citation.chunkId);
                                        }}
                                        className="text-xs text-red-600 hover:text-red-800 transition-colors"
                                    >
                                        <i className="fas fa-external-link-alt mr-1"></i>
                                        View in PDF
                                    </button>
                                )}
                                {type === 'web' && (
                                    <div className="text-xs text-blue-600">
                                        <i className="fas fa-external-link-alt mr-1"></i>
                                        External source
                                    </div>
                                )}
                            </div>
                        );
                    })}
                </div>
            );
        }

        // Tool Trace Panel
        function ToolTracePanel({ toolTrace }) {
            if (toolTrace.length === 0) {
                return (
                    <div className="text-center py-8 text-slate-500">
                        <i className="fas fa-code text-2xl mb-2"></i>
                        <p>No trace yet</p>
                        <p className="text-xs mt-1">Tool calls will appear here</p>
                    </div>
                );
            }

            return (
                <div className="space-y-3">
                    {toolTrace.map((trace, index) => (
                        <div key={index} className="border border-slate-200 rounded-md">
                            <div className="p-3 border-b border-slate-100">
                                <div className="flex items-center justify-between">
                                    <span className="font-medium text-sm text-slate-800">
                                        {trace.tool}
                                    </span>
                                    <span className="text-xs text-slate-500">
                                        {trace.timestamp.toLocaleTimeString()}
                                    </span>
                                </div>
                            </div>
                            <div className="p-3">
                                <details className="text-xs">
                                    <summary className="cursor-pointer text-slate-600 mb-2">
                                        View details
                                    </summary>
                                    <pre className="bg-slate-50 p-2 rounded text-slate-700 overflow-x-auto">
                                        {JSON.stringify(trace.result, null, 2).slice(0, 500)}...
                                    </pre>
                                </details>
                            </div>
                        </div>
                    ))}
                </div>
            );
        }

        // Doc Viewer Panel  
        function DocViewerPanel({ uploadedPdfs, selectedPdfChunk, setSelectedPdfChunk }) {
            const [selectedPdf, setSelectedPdf] = useState(null);
            const [currentPage, setCurrentPage] = useState(0);
            const [pageData, setPageData] = useState(null);
            const [loading, setLoading] = useState(false);
            const [imgLoaded, setImgLoaded] = useState(null);
            const imgRef = useRef(null);
            
            useEffect(() => {
                if (selectedPdf && currentPage !== null) {
                    loadPageData();
                }
            }, [selectedPdf, currentPage]);
            
            // Auto-select PDF when chunk is selected from citations
            useEffect(() => {
                if (selectedPdfChunk && uploadedPdfs.length > 0 && !selectedPdf) {
                    // Find which PDF contains this chunk
                    const findPdfWithChunk = async () => {
                        for (const pdf of uploadedPdfs) {
                            try {
                                const response = await fetch(`/pdf/${pdf.pdf_id}/info`);
                                const pdfInfo = await response.json();
                                
                                // Check if this PDF has the selected chunk
                                const hasChunk = pdfInfo.chunks && pdfInfo.chunks.some(chunk => 
                                    chunk.chunk_id === selectedPdfChunk
                                );
                                
                                if (hasChunk) {
                                    setSelectedPdf(pdf);
                                    
                                    // Find the page containing this chunk
                                    const matchingChunk = pdfInfo.chunks.find(chunk => 
                                        chunk.chunk_id === selectedPdfChunk
                                    );
                                    
                                    if (matchingChunk) {
                                        setCurrentPage(matchingChunk.page_number || 0);
                                    }
                                    break;
                                }
                            } catch (error) {
                                console.error(`Error checking PDF ${pdf.filename}:`, error);
                            }
                        }
                    };
                    
                    findPdfWithChunk();
                }
            }, [selectedPdfChunk, uploadedPdfs]);
            
            const loadPageData = async () => {
                if (!selectedPdf) return;
                
                setLoading(true);
                try {
                    const response = await fetch(`/pdf/${selectedPdf.pdf_id}/page/${currentPage}`);
                    const data = await response.json();
                    setPageData(data);
                } catch (error) {
                    console.error('Error loading page data:', error);
                } finally {
                    setLoading(false);
                }
            };

            if (uploadedPdfs.length === 0) {
                return (
                    <div className="text-center py-8 text-slate-500">
                        <i className="fas fa-file-pdf text-2xl mb-2"></i>
                        <p>No PDFs uploaded</p>
                        <p className="text-xs mt-1">Upload a PDF to view it here</p>
                    </div>
                );
            }

            if (!selectedPdf) {
                return (
                    <div>
                        <h3 className="font-medium text-slate-800 mb-3">Uploaded PDFs</h3>
                        <div className="space-y-2">
                            {uploadedPdfs.map((pdf, index) => (
                                <button
                                    key={index}
                                    onClick={() => {
                                        setSelectedPdf(pdf);
                                        setCurrentPage(0);
                                    }}
                                    className="w-full p-3 text-left bg-slate-50 hover:bg-slate-100 rounded border border-slate-200"
                                >
                                    <div className="flex items-center space-x-2">
                                        <i className="fas fa-file-pdf text-red-600"></i>
                                        <div className="flex-1 min-w-0">
                                            <div className="font-medium text-sm text-slate-800 truncate">
                                                {pdf.filename}
                                            </div>
                                            <div className="text-xs text-slate-500">
                                                {pdf.total_pages} pages ‚Ä¢ {pdf.chunks_extracted} chunks
                                            </div>
                                        </div>
                                    </div>
                                </button>
                            ))}
                        </div>
                    </div>
                );
            }

            return (
                <div>
                    {/* PDF Header */}
                    <div className="border-b border-slate-200 pb-3 mb-3">
                        <div className="flex items-center justify-between">
                            <button 
                                onClick={() => setSelectedPdf(null)}
                                className="text-slate-500 hover:text-slate-700"
                            >
                                <i className="fas fa-arrow-left"></i>
                            </button>
                            <div className="text-sm font-medium text-slate-800 truncate">
                                {selectedPdf.filename}
                            </div>
                            <div className="text-xs text-slate-500">
                                {currentPage + 1}/{selectedPdf.total_pages}
                            </div>
                        </div>
                    </div>

                    {/* Page Navigation */}
                    <div className="flex items-center justify-center space-x-2 mb-3">
                        <button
                            onClick={() => setCurrentPage(Math.max(0, currentPage - 1))}
                            disabled={currentPage === 0}
                            className="px-2 py-1 text-xs bg-slate-100 hover:bg-slate-200 disabled:opacity-50 rounded"
                        >
                            <i className="fas fa-chevron-left"></i>
                        </button>
                        <span className="text-xs text-slate-600">
                            Page {currentPage + 1}
                        </span>
                        <button
                            onClick={() => setCurrentPage(Math.min(selectedPdf.total_pages - 1, currentPage + 1))}
                            disabled={currentPage >= selectedPdf.total_pages - 1}
                            className="px-2 py-1 text-xs bg-slate-100 hover:bg-slate-200 disabled:opacity-50 rounded"
                        >
                            <i className="fas fa-chevron-right"></i>
                        </button>
                    </div>

                    {/* PDF Page Viewer */}
                    <div className="relative">
                        {loading ? (
                            <div className="flex items-center justify-center py-8">
                                <div className="animate-spin h-6 w-6 border-2 border-teal-500 border-t-transparent rounded-full"></div>
                            </div>
                        ) : pageData ? (
                            <div className="relative border border-slate-200 rounded overflow-hidden">
                                <img
                                    ref={imgRef}
                                    src={`data:image/png;base64,${pageData.image_base64}`}
                                    alt={`Page ${currentPage + 1}`}
                                    className="w-full h-auto"
                                    onLoad={() => {
                                        // Force re-render of bounding boxes when image loads
                                        setImgLoaded(Date.now());
                                    }}
                                />
                                
                                {/* Bounding Box Overlays */}
                                {imgLoaded && pageData.chunks.map((chunk, index) => {
                                    // Calculate scale factor based on actual image display size
                                    const imgElement = imgRef.current;
                                    if (!imgElement) return null;
                                    
                                    // Get the natural (original) dimensions of the rendered image
                                    const naturalWidth = imgElement.naturalWidth;
                                    const naturalHeight = imgElement.naturalHeight;
                                    
                                    // Get the displayed dimensions
                                    const displayWidth = imgElement.offsetWidth;
                                    const displayHeight = imgElement.offsetHeight;
                                    
                                    // Our coordinates are based on the natural image size
                                    // We need to scale them to the displayed size
                                    const scaleX = displayWidth / naturalWidth;
                                    const scaleY = displayHeight / naturalHeight;
                                    
                                    return (
                                        <div
                                            key={chunk.chunk_id}
                                            className={`absolute border-2 cursor-pointer transition-all ${
                                                selectedPdfChunk === chunk.chunk_id 
                                                    ? 'border-teal-500 bg-teal-500 bg-opacity-20' 
                                                    : 'border-blue-500 bg-blue-500 bg-opacity-10 hover:bg-opacity-20'
                                            }`}
                                            style={{
                                                left: `${chunk.bbox.x * scaleX}px`,
                                                top: `${chunk.bbox.y * scaleY}px`, 
                                                width: `${chunk.bbox.width * scaleX}px`,
                                                height: `${chunk.bbox.height * scaleY}px`
                                            }}
                                            onClick={() => setSelectedPdfChunk(
                                                selectedPdfChunk === chunk.chunk_id ? null : chunk.chunk_id
                                            )}
                                            title={chunk.text}
                                        >
                                            <div className="absolute -top-5 -left-0.5 bg-blue-500 text-white text-xs px-1 rounded">
                                                {index + 1}
                                            </div>
                                        </div>
                                    );
                                })}
                            </div>
                        ) : null}
                    </div>

                    {/* Chunk Details */}
                    {selectedPdfChunk && pageData && (
                        <div className="mt-3 p-3 bg-slate-50 rounded border border-slate-200">
                            <h4 className="text-sm font-medium text-slate-800 mb-2">Selected Chunk</h4>
                            {(() => {
                                const chunk = pageData.chunks.find(c => c.chunk_id === selectedPdfChunk);
                                return chunk ? (
                                    <div>
                                        <div className="text-xs text-slate-600 mb-1">
                                            ID: {chunk.chunk_id} ‚Ä¢ Confidence: {(chunk.confidence * 100).toFixed(1)}%
                                        </div>
                                        <div className="text-sm text-slate-700 max-h-32 overflow-y-auto">
                                            {chunk.text}
                                        </div>
                                    </div>
                                ) : null;
                            })()}
                        </div>
                    )}
                </div>
            );
        }

        // Render the app
        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>


================================================
FILE: app/utils/tracer.py
================================================
"""
Agent execution tracer for Agent Theater feature
Collects display-safe execution traces without performance impact
"""

import time
import uuid
import logging
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from contextlib import contextmanager

logger = logging.getLogger(__name__)


@dataclass
class ToolCall:
    """Represents a tool call within an agent execution"""
    tool_name: str
    duration_ms: int
    status: str  # 'success', 'error', 'timeout'
    input_summary: Optional[str] = None
    output_summary: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AgentExecution:
    """Represents a single agent's execution"""
    agent_name: str
    display_name: str
    started_at: int  # timestamp in ms
    duration_ms: int = 0
    status: str = 'success'  # 'success', 'error', 'timeout'
    tool_calls: List[ToolCall] = field(default_factory=list)
    input_summary: Optional[str] = None
    output_summary: Optional[str] = None
    confidence: Optional[float] = None
    sources_used: List[str] = field(default_factory=list)


@dataclass
class AgentTrace:
    """Complete trace of multi-agent execution"""
    execution_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    total_duration_ms: int = 0
    agent_executions: List[AgentExecution] = field(default_factory=list)
    routing_decision: Optional[Dict[str, Any]] = None


class AgentTracer:
    """
    Lightweight tracer for collecting agent execution information
    Designed to have minimal performance impact on the system
    """
    
    def __init__(self):
        self.current_trace: Optional[AgentTrace] = None
        self.current_execution: Optional[AgentExecution] = None
        self._start_time: Optional[int] = None
    
    def start_trace(self) -> str:
        """Start a new trace session"""
        self.current_trace = AgentTrace()
        self._start_time = int(time.time() * 1000)
        logger.debug(f"Started trace: {self.current_trace.execution_id}")
        return self.current_trace.execution_id
    
    def set_routing_decision(self, primary_agent: str, confidence: float, fallback_used: Optional[str] = None):
        """Record the routing decision"""
        if not self.current_trace:
            return
            
        self.current_trace.routing_decision = {
            "primary_agent": primary_agent,
            "confidence": confidence,
            "fallback_used": fallback_used
        }
    
    @contextmanager
    def trace_agent(self, agent_name: str, display_name: str):
        """Context manager to trace an agent execution"""
        if not self.current_trace:
            yield None
            return
        
        # Map agent names to display names
        display_name_mapping = {
            'smart': 'Smart Chat',
            'offerpilot': 'OfferPilot', 
            'trustshield': 'TrustShield',
            'dispute': 'Dispute Copilot',
            'collections': 'Collections',
            'contracts': 'Contracts',
            'devcopilot': 'DevCopilot',
            'carecredit': 'WeCare',
            'narrator': 'Narrator',
            'imagegen': 'ImageGen',
            'rag': 'RAG System',
            'search': 'Web Search'
        }
        
        execution = AgentExecution(
            agent_name=agent_name,
            display_name=display_name_mapping.get(agent_name, display_name),
            started_at=int(time.time() * 1000)
        )
        
        self.current_execution = execution
        start_time = time.time()
        
        try:
            yield execution
            execution.status = 'success'
        except Exception as e:
            execution.status = 'error'
            logger.warning(f"Agent {agent_name} execution failed: {e}")
        finally:
            execution.duration_ms = int((time.time() - start_time) * 1000)
            self.current_trace.agent_executions.append(execution)
            self.current_execution = None
    
    @contextmanager
    def trace_tool(self, tool_name: str, input_data: Any = None):
        """Context manager to trace a tool call"""
        if not self.current_execution:
            yield None
            return
        
        tool_call = ToolCall(
            tool_name=tool_name,
            duration_ms=0,
            status='success'
        )
        
        # Create safe input summary (remove sensitive data)
        if input_data:
            tool_call.input_summary = self._create_safe_summary(input_data, max_length=100)
        
        start_time = time.time()
        
        try:
            result = yield tool_call
            tool_call.status = 'success'
            
            # Create safe output summary
            if result:
                tool_call.output_summary = self._create_safe_summary(result, max_length=100)
                
        except Exception as e:
            tool_call.status = 'error'
            logger.warning(f"Tool {tool_name} failed: {e}")
        finally:
            tool_call.duration_ms = int((time.time() - start_time) * 1000)
            self.current_execution.tool_calls.append(tool_call)
    
    def set_agent_confidence(self, confidence: float):
        """Set confidence score for current agent execution"""
        if self.current_execution:
            self.current_execution.confidence = confidence
    
    def add_sources(self, sources: List[str]):
        """Add sources used by current agent"""
        if self.current_execution:
            # Only keep filenames/short identifiers to avoid clutter
            safe_sources = []
            for source in sources:
                if isinstance(source, str):
                    # Extract just filename or short identifier
                    if '/' in source:
                        safe_sources.append(source.split('/')[-1])
                    else:
                        safe_sources.append(source[:50])  # Truncate long sources
                        
            self.current_execution.sources_used.extend(safe_sources)
    
    def set_agent_summaries(self, input_summary: str = None, output_summary: str = None):
        """Set input/output summaries for current agent"""
        if self.current_execution:
            if input_summary:
                self.current_execution.input_summary = self._create_safe_summary(input_summary, max_length=200)
            if output_summary:
                self.current_execution.output_summary = self._create_safe_summary(output_summary, max_length=200)
    
    def finish_trace(self) -> Optional[AgentTrace]:
        """Finish the current trace and return it"""
        if not self.current_trace or not self._start_time:
            return None
        
        self.current_trace.total_duration_ms = int(time.time() * 1000) - self._start_time
        
        # Log trace summary
        logger.info(f"Trace {self.current_trace.execution_id} completed: "
                   f"{len(self.current_trace.agent_executions)} agents, "
                   f"{self.current_trace.total_duration_ms}ms total")
        
        trace = self.current_trace
        self.current_trace = None
        self.current_execution = None
        self._start_time = None
        
        return trace
    
    def _create_safe_summary(self, data: Any, max_length: int = 100) -> str:
        """Create a safe, truncated summary of data for display"""
        if data is None:
            return ""
        
        # Convert to string
        if isinstance(data, dict):
            # For dicts, show key structure without values
            keys = list(data.keys())[:3]  # First 3 keys only
            summary = f"{{keys: {keys}"
            if len(data) > 3:
                summary += f", +{len(data)-3} more"
            summary += "}"
        elif isinstance(data, list):
            summary = f"[{len(data)} items]"
        elif isinstance(data, str):
            # Remove potential PII patterns and truncate
            summary = self._sanitize_string(data)
        else:
            summary = str(type(data).__name__)
        
        # Truncate to max length
        if len(summary) > max_length:
            summary = summary[:max_length-3] + "..."
        
        return summary
    
    def _sanitize_string(self, text: str) -> str:
        """Remove potential PII from string summaries"""
        import re
        
        # Remove credit card patterns
        text = re.sub(r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b', '[CARD]', text)
        # Remove SSN patterns  
        text = re.sub(r'\b\d{3}-?\d{2}-?\d{4}\b', '[SSN]', text)
        # Remove email patterns
        text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[EMAIL]', text)
        # Remove phone patterns
        text = re.sub(r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b', '[PHONE]', text)
        
        return text.strip()


# Global tracer instance
tracer = AgentTracer()


def get_tracer() -> AgentTracer:
    """Get the global tracer instance"""
    return tracer


================================================
FILE: metrics/credit_metrics.csv
================================================
date,product,outstanding_balance,utilization_rate,payment_rate,net_charge_offs,provision_expense,yield
2025-01-31,CareCredit,2500000000.00,0.65,0.88,15000000.00,18000000.00,0.142
2025-01-31,Synchrony_Store_Card,4200000000.00,0.72,0.85,28000000.00,32000000.00,0.168
2025-01-31,PayPal_Credit,1800000000.00,0.58,0.90,8500000.00,10500000.00,0.135
2025-02-28,CareCredit,2520000000.00,0.66,0.87,15500000.00,18500000.00,0.144
2025-02-28,Synchrony_Store_Card,4250000000.00,0.73,0.84,29000000.00,33000000.00,0.170
2025-02-28,PayPal_Credit,1820000000.00,0.59,0.89,8800000.00,10800000.00,0.137
2025-03-31,CareCredit,2540000000.00,0.64,0.89,14800000.00,17800000.00,0.141
2025-03-31,Synchrony_Store_Card,4300000000.00,0.71,0.86,27500000.00,31500000.00,0.166
2025-03-31,PayPal_Credit,1840000000.00,0.57,0.91,8200000.00,10200000.00,0.133
2025-04-30,CareCredit,2580000000.00,0.67,0.86,16200000.00,19200000.00,0.146
2025-04-30,Synchrony_Store_Card,4380000000.00,0.74,0.83,30500000.00,34500000.00,0.172
2025-04-30,PayPal_Credit,1870000000.00,0.60,0.88,9100000.00,11100000.00,0.139
2025-05-31,CareCredit,2600000000.00,0.65,0.88,15800000.00,18800000.00,0.143
2025-05-31,Synchrony_Store_Card,4420000000.00,0.72,0.85,29800000.00,33800000.00,0.169
2025-05-31,PayPal_Credit,1890000000.00,0.58,0.90,8900000.00,10900000.00,0.136
2025-06-30,CareCredit,2650000000.00,0.68,0.85,16800000.00,19800000.00,0.148
2025-06-30,Synchrony_Store_Card,4480000000.00,0.75,0.82,31200000.00,35200000.00,0.174
2025-06-30,PayPal_Credit,1920000000.00,0.61,0.87,9400000.00,11400000.00,0.141
2025-07-31,CareCredit,2680000000.00,0.66,0.87,16200000.00,19200000.00,0.145
2025-07-31,Synchrony_Store_Card,4520000000.00,0.73,0.84,30800000.00,34800000.00,0.171
2025-07-31,PayPal_Credit,1950000000.00,0.59,0.89,9200000.00,11200000.00,0.138


================================================
FILE: metrics/delinquency_rates.csv
================================================
month,segment,vintage,total_accounts,delinq_30,delinq_60,delinq_90,charge_off_rate
2025-01-31,PRIME,2024Q1,45000,0.025,0.012,0.008,0.003
2025-01-31,PRIME,2024Q2,52000,0.022,0.010,0.007,0.002
2025-01-31,NEAR_PRIME,2024Q1,38000,0.045,0.025,0.018,0.008
2025-01-31,NEAR_PRIME,2024Q2,41000,0.042,0.023,0.016,0.007
2025-01-31,SUBPRIME,2024Q1,28000,0.085,0.055,0.042,0.025
2025-01-31,SUBPRIME,2024Q2,31000,0.082,0.052,0.039,0.023
2025-02-28,PRIME,2024Q1,44800,0.028,0.014,0.009,0.004
2025-02-28,PRIME,2024Q2,51800,0.024,0.012,0.008,0.003
2025-02-28,NEAR_PRIME,2024Q1,37900,0.048,0.027,0.020,0.009
2025-02-28,NEAR_PRIME,2024Q2,40800,0.045,0.025,0.018,0.008
2025-02-28,SUBPRIME,2024Q1,27800,0.088,0.058,0.045,0.027
2025-02-28,SUBPRIME,2024Q2,30900,0.085,0.055,0.042,0.025
2025-03-31,PRIME,2024Q1,44600,0.026,0.013,0.008,0.003
2025-03-31,PRIME,2024Q2,51600,0.023,0.011,0.007,0.002
2025-03-31,NEAR_PRIME,2024Q1,37750,0.046,0.026,0.019,0.008
2025-03-31,NEAR_PRIME,2024Q2,40650,0.043,0.024,0.017,0.007
2025-03-31,SUBPRIME,2024Q1,27650,0.086,0.056,0.043,0.026
2025-03-31,SUBPRIME,2024Q2,30750,0.083,0.053,0.040,0.024
2025-04-30,PRIME,2024Q1,44400,0.029,0.015,0.010,0.005
2025-04-30,PRIME,2024Q2,51400,0.026,0.013,0.009,0.004
2025-04-30,NEAR_PRIME,2024Q1,37600,0.049,0.028,0.021,0.010
2025-04-30,NEAR_PRIME,2024Q2,40500,0.046,0.026,0.019,0.009
2025-04-30,SUBPRIME,2024Q1,27500,0.089,0.059,0.046,0.028
2025-04-30,SUBPRIME,2024Q2,30600,0.086,0.056,0.043,0.026
2025-05-31,PRIME,2024Q1,44200,0.027,0.014,0.009,0.004
2025-05-31,PRIME,2024Q2,51200,0.024,0.012,0.008,0.003
2025-05-31,NEAR_PRIME,2024Q1,37450,0.047,0.027,0.020,0.009
2025-05-31,NEAR_PRIME,2024Q2,40350,0.044,0.025,0.018,0.008
2025-05-31,SUBPRIME,2024Q1,27350,0.087,0.057,0.044,0.027
2025-05-31,SUBPRIME,2024Q2,30450,0.084,0.054,0.041,0.025
2025-06-30,PRIME,2024Q1,44000,0.030,0.016,0.011,0.006
2025-06-30,PRIME,2024Q2,51000,0.027,0.014,0.010,0.005
2025-06-30,NEAR_PRIME,2024Q1,37300,0.050,0.029,0.022,0.011
2025-06-30,NEAR_PRIME,2024Q2,40200,0.047,0.027,0.020,0.010
2025-06-30,SUBPRIME,2024Q1,27200,0.090,0.060,0.047,0.029
2025-06-30,SUBPRIME,2024Q2,30300,0.087,0.057,0.044,0.027
2025-07-31,PRIME,2024Q1,43800,0.025,0.012,0.008,0.003
2025-07-31,PRIME,2024Q2,50800,0.022,0.010,0.007,0.002
2025-07-31,NEAR_PRIME,2024Q1,37150,0.044,0.024,0.017,0.007
2025-07-31,NEAR_PRIME,2024Q2,40050,0.041,0.022,0.015,0.006
2025-07-31,SUBPRIME,2024Q1,27050,0.084,0.053,0.040,0.024
2025-07-31,SUBPRIME,2024Q2,30150,0.081,0.050,0.037,0.022


================================================
FILE: metrics/portfolio_spend.csv
================================================
date,merchant,promo_type,spend_amount,transaction_count,avg_ticket,new_customers
2025-07-01,HomeDepot,0_APR_12_MONTH,2450000.50,1200,2041.67,85
2025-07-01,HomeDepot,STANDARD,890000.25,890,1000.00,45
2025-07-01,Amazon,0_APR_6_MONTH,3200000.75,2400,1333.33,120
2025-07-01,Amazon,STANDARD,1800000.00,1800,1000.00,90
2025-07-01,BestBuy,0_APR_18_MONTH,1850000.00,925,2000.00,78
2025-07-02,HomeDepot,0_APR_12_MONTH,2380000.00,1190,2000.00,82
2025-07-02,HomeDepot,STANDARD,920000.00,920,1000.00,48
2025-07-02,Amazon,0_APR_6_MONTH,3150000.00,2300,1369.57,118
2025-07-02,Amazon,STANDARD,1750000.00,1750,1000.00,88
2025-07-02,BestBuy,0_APR_18_MONTH,1900000.00,950,2000.00,80
2025-07-15,HomeDepot,0_APR_12_MONTH,2600000.00,1300,2000.00,95
2025-07-15,HomeDepot,STANDARD,950000.00,950,1000.00,52
2025-07-15,Amazon,0_APR_6_MONTH,3400000.00,2550,1333.33,135
2025-07-15,Amazon,STANDARD,1900000.00,1900,1000.00,95
2025-07-15,BestBuy,0_APR_18_MONTH,2100000.00,1050,2000.00,88
2025-07-30,HomeDepot,0_APR_12_MONTH,2800000.00,1400,2000.00,105
2025-07-30,HomeDepot,STANDARD,980000.00,980,1000.00,55
2025-07-30,Amazon,0_APR_6_MONTH,3600000.00,2700,1333.33,145
2025-07-30,Amazon,STANDARD,2000000.00,2000,1000.00,100
2025-07-30,BestBuy,0_APR_18_MONTH,2200000.00,1100,2000.00,92
2025-07-31,HomeDepot,0_APR_12_MONTH,2750000.00,1375,2000.00,102
2025-07-31,HomeDepot,STANDARD,975000.00,975,1000.00,54
2025-07-31,Amazon,0_APR_6_MONTH,3550000.00,2665,1332.08,142
2025-07-31,Amazon,STANDARD,1950000.00,1950,1000.00,98
2025-07-31,BestBuy,0_APR_18_MONTH,2150000.00,1075,2000.00,90
2025-08-01,HomeDepot,0_APR_12_MONTH,1200000.00,600,2000.00,45
2025-08-01,HomeDepot,STANDARD,880000.00,880,1000.00,42
2025-08-01,Amazon,0_APR_6_MONTH,1500000.00,1125,1333.33,68
2025-08-01,Amazon,STANDARD,1650000.00,1650,1000.00,85
2025-08-01,BestBuy,0_APR_18_MONTH,1850000.00,925,2000.00,78
2025-08-02,HomeDepot,0_APR_12_MONTH,1180000.00,590,2000.00,44
2025-08-02,HomeDepot,STANDARD,860000.00,860,1000.00,41
2025-08-02,Amazon,0_APR_6_MONTH,1480000.00,1110,1333.33,67
2025-08-02,Amazon,STANDARD,1620000.00,1620,1000.00,83
2025-08-02,BestBuy,0_APR_18_MONTH,1800000.00,900,2000.00,76
2025-08-05,HomeDepot,0_APR_12_MONTH,1150000.00,575,2000.00,43
2025-08-05,HomeDepot,STANDARD,840000.00,840,1000.00,40
2025-08-05,Amazon,0_APR_6_MONTH,1450000.00,1087,1333.95,65
2025-08-05,Amazon,STANDARD,1580000.00,1580,1000.00,81
2025-08-05,BestBuy,0_APR_18_MONTH,1750000.00,875,2000.00,74


================================================
FILE: metrics/promo_performance.csv
================================================
date,promo_id,promo_name,start_date,end_date,applications,approvals,approval_rate,activation_rate,spend_per_approval
2025-07-01,PROMO_HD_001,HomeDepot Summer Sale,2025-06-15,2025-07-31,1500,1200,0.80,0.85,2250.50
2025-07-01,PROMO_AMZ_001,Amazon Prime Day,2025-07-10,2025-07-20,2800,2240,0.80,0.90,1850.25
2025-07-01,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,950,760,0.80,0.88,2150.75
2025-07-02,PROMO_HD_001,HomeDepot Summer Sale,2025-06-15,2025-07-31,1480,1184,0.80,0.86,2200.00
2025-07-02,PROMO_AMZ_001,Amazon Prime Day,2025-07-10,2025-07-20,2750,2200,0.80,0.91,1825.50
2025-07-02,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,970,776,0.80,0.87,2175.25
2025-07-15,PROMO_HD_001,HomeDepot Summer Sale,2025-06-15,2025-07-31,1650,1320,0.80,0.87,2300.75
2025-07-15,PROMO_AMZ_001,Amazon Prime Day,2025-07-10,2025-07-20,3200,2560,0.80,0.92,1950.00
2025-07-15,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1100,880,0.80,0.89,2225.50
2025-07-30,PROMO_HD_001,HomeDepot Summer Sale,2025-06-15,2025-07-31,1750,1400,0.80,0.88,2400.25
2025-07-30,PROMO_AMZ_001,Amazon Prime Day,2025-07-10,2025-07-20,3400,2720,0.80,0.93,2050.75
2025-07-30,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1150,920,0.80,0.90,2275.00
2025-07-31,PROMO_HD_001,HomeDepot Summer Sale,2025-06-15,2025-07-31,1800,1440,0.80,0.89,2450.50
2025-07-31,PROMO_AMZ_001,Amazon Prime Day,2025-07-10,2025-07-20,3500,2800,0.80,0.94,2100.25
2025-07-31,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1200,960,0.80,0.91,2300.75
2025-08-01,PROMO_HD_002,HomeDepot Fall Prep,2025-08-01,2025-08-31,800,640,0.80,0.75,1850.00
2025-08-01,PROMO_AMZ_002,Amazon Back to School,2025-08-01,2025-08-15,1200,960,0.80,0.82,1650.25
2025-08-01,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1180,944,0.80,0.89,2275.50
2025-08-02,PROMO_HD_002,HomeDepot Fall Prep,2025-08-01,2025-08-31,820,656,0.80,0.76,1875.25
2025-08-02,PROMO_AMZ_002,Amazon Back to School,2025-08-01,2025-08-15,1180,944,0.80,0.83,1675.00
2025-08-02,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1160,928,0.80,0.88,2250.75
2025-08-05,PROMO_HD_002,HomeDepot Fall Prep,2025-08-01,2025-08-31,850,680,0.80,0.77,1900.50
2025-08-05,PROMO_AMZ_002,Amazon Back to School,2025-08-01,2025-08-15,1150,920,0.80,0.84,1700.75
2025-08-05,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1140,912,0.80,0.87,2225.25


================================================
FILE: src/App.tsx
================================================
import React, { useState, useEffect, useRef } from 'react';
import { Message, ChatRequest, ChatResponse, UploadedPdf, UserType, PersonaDetectionResponse, ChatHistory } from './types';
import { AGENTS } from './config/agents';
import Header from './components/Header';
import LeftRail from './components/LeftRail';
import ChatPane from './components/ChatPane';
import RightInspector from './components/RightInspector';

function App() {
  // Chat History Management
  const [chatHistories, setChatHistories] = useState<ChatHistory[]>([]);
  const [currentChatId, setCurrentChatId] = useState<string | null>(null);
  const [rightPanelCollapsed, setRightPanelCollapsed] = useState(false);
  
  // Current Chat State
  const [userType, setUserType] = useState<UserType>('consumer');
  const [selectedAgent, setSelectedAgent] = useState('smart');
  const [availableAgents, setAvailableAgents] = useState<string[]>([]);
  const [personaDetected, setPersonaDetected] = useState(false);
  const [personaConfidence, setPersonaConfidence] = useState(0);
  const [allowTavily, setAllowTavily] = useState(false);
  const [allowLlmKnowledge, setAllowLlmKnowledge] = useState(true);
  const [allowWebSearch, setAllowWebSearch] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputText, setInputText] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [rightPanel, setRightPanel] = useState('citations');
  const [citations, setCitations] = useState<string[]>([]);
  const [toolTrace, setToolTrace] = useState<any[]>([]);
  const [agentTrace, setAgentTrace] = useState<any>(null);
  const [uploadedPdfs, setUploadedPdfs] = useState<UploadedPdf[]>([]);
  const [selectedPdfChunk, setSelectedPdfChunk] = useState(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // Get current chat
  const currentChat = currentChatId ? chatHistories.find(chat => chat.id === currentChatId) : null;

  // Auto-scroll to bottom when messages change
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  // Load chat history from localStorage on mount
  useEffect(() => {
    const saved = localStorage.getItem('chatHistories');
    if (saved) {
      try {
        const parsed = JSON.parse(saved);
        const histories = parsed.map((h: any) => ({
          ...h,
          createdAt: new Date(h.createdAt),
          updatedAt: new Date(h.updatedAt),
          messages: h.messages.map((m: any) => ({
            ...m,
            timestamp: new Date(m.timestamp)
          }))
        }));
        setChatHistories(histories);
      } catch (e) {
        console.error('Failed to load chat histories:', e);
      }
    }
  }, []);

  // Save chat histories to localStorage whenever they change
  useEffect(() => {
    if (chatHistories.length > 0) {
      localStorage.setItem('chatHistories', JSON.stringify(chatHistories));
    }
  }, [chatHistories]);

  // Update current chat messages when messages change
  useEffect(() => {
    if (currentChatId && messages.length > 0) {
      setChatHistories(prev => prev.map(chat => 
        chat.id === currentChatId 
          ? { ...chat, messages: [...messages], updatedAt: new Date() }
          : chat
      ));
    }
  }, [messages, currentChatId]);

  // Update chat history persona when userType changes
  useEffect(() => {
    if (currentChatId && personaDetected) {
      setChatHistories(prev => prev.map(chat => 
        chat.id === currentChatId 
          ? { ...chat, persona: userType, updatedAt: new Date() }
          : chat
      ));
    }
  }, [userType, currentChatId, personaDetected]);

  // Chat Management Functions
  const createNewChat = () => {
    const newChatId = Date.now().toString();
    const newChat: ChatHistory = {
      id: newChatId,
      title: 'New Chat',
      messages: [],
      createdAt: new Date(),
      updatedAt: new Date(),
      persona: userType
    };
    
    setChatHistories(prev => [newChat, ...prev]);
    setCurrentChatId(newChatId);
    
    // Reset current chat state
    setMessages([]);
    setCitations([]);
    setToolTrace([]);
    setAgentTrace(null);
    setPersonaDetected(false);
    setPersonaConfidence(0);
    setAvailableAgents([]);
  };

  const selectChat = (chatId: string) => {
    const chat = chatHistories.find(c => c.id === chatId);
    if (chat) {
      setCurrentChatId(chatId);
      setMessages(chat.messages);
      setUserType(chat.persona || 'consumer');
      
      // Reset other state
      setCitations([]);
      setToolTrace([]);
      setAgentTrace(null);
      
      // Extract citations and traces from last message if available
      const lastMessage = chat.messages[chat.messages.length - 1];
      if (lastMessage?.role === 'assistant') {
        setCitations(lastMessage.sources || []);
        setAgentTrace(lastMessage.agent_trace || null);
      }
    }
  };

  const deleteChat = (chatId: string) => {
    setChatHistories(prev => prev.filter(chat => chat.id !== chatId));
    if (currentChatId === chatId) {
      setCurrentChatId(null);
      setMessages([]);
      setCitations([]);
      setToolTrace([]);
      setAgentTrace(null);
    }
  };

  const updateChatTitle = (chatId: string, title: string) => {
    setChatHistories(prev => prev.map(chat => 
      chat.id === chatId 
        ? { ...chat, title, updatedAt: new Date() }
        : chat
    ));
  };

  const generateChatTitle = async (message: string, chatId: string) => {
    try {
      const response = await fetch('/generate-chat-title', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message })
      });

      if (response.ok) {
        const result = await response.json();
        updateChatTitle(chatId, result.title);
      } else {
        // Fallback to truncated message
        const fallbackTitle = message.length > 50 ? message.substring(0, 47) + '...' : message;
        updateChatTitle(chatId, fallbackTitle);
      }
    } catch (error) {
      console.error('Failed to generate chat title:', error);
      // Fallback to truncated message
      const fallbackTitle = message.length > 50 ? message.substring(0, 47) + '...' : message;
      updateChatTitle(chatId, fallbackTitle);
    }
  };

  const sendMessage = async () => {
    if (!inputText.trim()) return;

    // Create new chat if none exists
    if (!currentChatId) {
      createNewChat();
    }

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: inputText,
      agent: 'user',
      timestamp: new Date()
    };

    // Auto-generate chat title from first message using LLM
    if (messages.length === 0 && currentChatId) {
      generateChatTitle(inputText, currentChatId);
    }

    setMessages(prev => [...prev, userMessage]);
    setInputText('');
    setIsLoading(true);

    try {
      // Detect persona if not already detected
      if (!personaDetected && messages.length === 0) {
        try {
          const personaResponse = await fetch('/detect-persona-and-agents', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              message: inputText,
              allow_tavily: allowTavily,
              allow_llm_knowledge: allowLlmKnowledge,
              allow_web_search: allowWebSearch,
              user_type: userType
            })
          });

          if (personaResponse.ok) {
            const personaData: PersonaDetectionResponse = await personaResponse.json();
            setUserType(personaData.persona);
            setAvailableAgents(personaData.available_agents);
            setPersonaDetected(true);
            setPersonaConfidence(personaData.confidence);
          }
        } catch (personaError) {
          console.warn('Persona detection failed:', personaError);
          // Continue with default settings
        }
      }
      const endpoint = selectedAgent === 'smart' ? '/chat' : `/agent/${selectedAgent}`;
      const payload: ChatRequest | any = selectedAgent === 'smart' 
        ? { 
            message: inputText, 
            allow_tavily: allowTavily,
            allow_llm_knowledge: allowLlmKnowledge,
            allow_web_search: allowWebSearch,
            user_type: userType
          }
        : selectedAgent === 'imagegen'
        ? { prompt: inputText, include_text: true, style_hints: [], user_type: userType }
        : { query: inputText, user_type: userType };

      const response = await fetch(endpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload)
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const result: ChatResponse = await response.json();
      
      const aiMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: result.response,
        agent: result.agent,
        confidence: result.confidence,
        sources: result.sources,
        used_tavily: result.used_tavily,
        fallback_used: result.fallback_used,
        document_assessment: result.document_assessment,
        image_data: result.image_data,
        image_format: result.image_format,
        agent_trace: result.agent_trace,  // üé≠ Add the missing agent_trace!
        timestamp: new Date()
      };

      setMessages(prev => [...prev, aiMessage]);
      setCitations(result.sources || []);
      setAgentTrace(result.agent_trace || null);
      
      // Auto-switch to Tool Trace if agent trace exists
      if (result.agent_trace && result.agent_trace.agent_executions?.length > 1) {
        setRightPanel('tools');
      }
    } catch (error) {
      console.error('Error sending message:', error);
      const errorMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: `Error: ${error instanceof Error ? error.message : 'Unknown error occurred'}`,
        agent: 'system',
        timestamp: new Date()
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  const uploadPdf = async (file: File) => {
    const formData = new FormData();
    formData.append('file', file);

    try {
      const response = await fetch('/upload/pdf', {
        method: 'POST',
        body: formData
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`Upload failed with status ${response.status}:`, errorText);
        throw new Error(`Upload failed: ${response.status} - ${errorText}`);
      }

      const result = await response.json();
      
      // Add PDF upload message
      const pdfMessage: Message = {
        id: Date.now().toString(),
        role: 'user',
        content: `Uploaded PDF: ${file.name}`,
        agent: 'user',
        timestamp: new Date(),
        pdfData: {
          filename: result.filename,
          total_pages: result.total_pages,
          chunks_extracted: result.chunks_extracted,
          processing_time: result.processing_time,
          file_size: result.file_size
        }
      };

      setMessages(prev => [...prev, pdfMessage]);
      setUploadedPdfs(prev => [...prev, {
        pdf_id: result.pdf_id,
        filename: result.filename,
        total_pages: result.total_pages,
        chunks: result.chunks_extracted,
        processing_time: result.processing_time
      }]);
    } catch (error) {
      console.error('PDF upload error:', error);
    }
  };

  const handleSelectAgent = (agent: string) => {
    setSelectedAgent(agent);
  };

  const handleUseExample = (agent: string) => {
    setSelectedAgent(agent);
    setInputText(AGENTS[agent]?.example || '');
  };

  const clearChat = () => {
    createNewChat();
  };

  const exportJSON = () => {
    const lastMessage = messages[messages.length - 1];
    if (lastMessage && lastMessage.role === 'assistant') {
      const blob = new Blob([JSON.stringify(lastMessage, null, 2)], { type: 'application/json' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `genai-response-${Date.now()}.json`;
      a.click();
      URL.revokeObjectURL(url);
    }
  };

  const handleResetPersona = () => {
    setUserType('consumer');
    setAvailableAgents([]);
    setPersonaDetected(false);
    setPersonaConfidence(0);
    setMessages([]);
    setCitations([]);
    setToolTrace([]);
    setAgentTrace(null);
  };

  // Auto-detect persona from context instead of manual selection
  // No landing page needed - context-based routing handles persona detection

  return (
    <div className="h-screen flex flex-col bg-slate-50">
      {/* Header */}
      <Header 
        allowTavily={allowTavily}
        setAllowTavily={setAllowTavily}
        allowLlmKnowledge={allowLlmKnowledge}
        setAllowLlmKnowledge={setAllowLlmKnowledge}
        allowWebSearch={allowWebSearch}
        setAllowWebSearch={setAllowWebSearch}
        onClear={clearChat}
        onExport={exportJSON}
        onResetPersona={handleResetPersona}
      />

      {/* Main Content */}
      <div className="flex-1 flex overflow-hidden">
        {/* Left Rail */}
        <LeftRail 
          chatHistories={chatHistories}
          currentChatId={currentChatId}
          onSelectChat={selectChat}
          onCreateNewChat={createNewChat}
          onDeleteChat={deleteChat}
          onUpdateChatTitle={updateChatTitle}
          userType={userType}
        />

        {/* Chat Pane */}
        <ChatPane 
          messages={messages}
          isLoading={isLoading}
          inputText={inputText}
          setInputText={setInputText}
          selectedAgent={selectedAgent}
          onSendMessage={sendMessage}
          messagesEndRef={messagesEndRef}
          uploadPdf={uploadPdf}
          currentChatTitle={currentChat?.title || 'New Chat'}
        />

        {/* Right Inspector */}
        <RightInspector 
          activePanel={rightPanel}
          setActivePanel={setRightPanel}
          citations={citations}
          toolTrace={toolTrace}
          agentTrace={agentTrace}
          uploadedPdfs={uploadedPdfs}
          selectedPdfChunk={selectedPdfChunk}
          setSelectedPdfChunk={setSelectedPdfChunk}
          isCollapsed={rightPanelCollapsed}
          onToggleCollapse={() => setRightPanelCollapsed(!rightPanelCollapsed)}
        />
      </div>
    </div>
  );
}

export default App;


================================================
FILE: src/index.css
================================================
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  html, body {
    @apply h-full;
  }
}

@layer components {
  .tool-chip {
    @apply transition-all duration-200 ease-in-out;
  }
  
  .tool-chip:hover {
    @apply transform -translate-y-1 shadow-md;
  }
  
  .redacted-text {
    @apply bg-slate-800 text-slate-800 px-2 py-1 rounded select-none;
    background-image: repeating-linear-gradient(45deg, transparent, transparent 2px, rgba(255,255,255,.1) 2px, rgba(255,255,255,.1) 4px);
    background-repeat: repeat-x;
    background-position: 0 50%;
    color: transparent;
  }
  
  .redacted-text:hover::after {
    content: " (Redacted)";
    @apply text-slate-400 text-xs bg-slate-700 px-1.5 py-0.5 rounded ml-1;
  }
  
  .markdown-content {
    @apply leading-relaxed;
  }
  
  .markdown-content pre {
    @apply my-4 relative;
  }
  
  .markdown-content code {
    @apply font-mono;
  }
  
  .markdown-content pre code {
    @apply text-slate-100 bg-transparent p-0 rounded-none;
  }
  
  /* Agent Theater Animations */
  .agent-theater {
    animation: slideInUp 0.4s ease-out;
  }
  
  @keyframes slideInUp {
    from {
      opacity: 0;
      transform: translateY(20px);
    }
    to {
      opacity: 1;
      transform: translateY(0);
    }
  }
  
  @keyframes fadeIn {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }
  
  .animate-fade-in {
    animation: fadeIn 0.3s ease-out;
  }
  
  @keyframes pulse {
    0%, 100% {
      opacity: 0.8;
      transform: scale(1);
    }
    50% {
      opacity: 0.3;
      transform: scale(1.05);
    }
  }
  
  @keyframes slideDown {
    from {
      opacity: 0;
      transform: translateY(-10px);
    }
    to {
      opacity: 1;
      transform: translateY(0);
    }
  }
  
  .animate-slideDown {
    animation: slideDown 0.3s ease-out;
  }
}

/* Syntax highlighting overrides */
.hljs {
  @apply bg-slate-900 text-slate-100 !important;
}

.hljs-keyword { @apply text-amber-400 !important; }
.hljs-string { @apply text-emerald-400 !important; }
.hljs-comment { @apply text-slate-500 !important; }
.hljs-function { @apply text-blue-400 !important; }
.hljs-variable { @apply text-purple-400 !important; }
.hljs-number { @apply text-pink-400 !important; }
.hljs-built_in { @apply text-cyan-400 !important; }


================================================
FILE: src/main.tsx
================================================
import React from 'react'
import ReactDOM from 'react-dom/client'
import App from './App.tsx'
import './index.css'

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>,
)


================================================
FILE: src/types.ts
================================================
export interface Agent {
  name: string;
  icon: string;
  color: string;
  example: string;
  tooltip: string;
}

export interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  agent: string;
  confidence?: number;
  sources?: string[];
  used_tavily?: boolean;
  fallback_used?: string | null;
  document_assessment?: DocumentAssessment | null;
  image_data?: string | null;
  image_format?: string | null;
  timestamp: Date;
  pdfData?: PdfData;
  agent_trace?: AgentTrace;
}

export interface DocumentAssessment {
  sufficient: boolean;
  confidence: number;
  reason: string;
  document_quality_score: number;
  semantic_relevance: number;
  coverage_score: number;
  answer_sufficiency: number;
}

export interface PdfData {
  filename: string;
  total_pages: number;
  chunks_extracted: number;
  processing_time: number;
  file_size: number;
}

export interface ChatRequest {
  message: string;
  allow_tavily?: boolean;
  allow_llm_knowledge?: boolean;
  allow_web_search?: boolean;
  user_type?: UserType;
}

export interface ChatResponse {
  response: string;
  agent: string;
  confidence: number;
  sources: string[];
  used_tavily: boolean;
  fallback_used?: string | null;
  document_assessment?: DocumentAssessment | null;
  image_data?: string | null;
  image_format?: string | null;
  agent_trace?: AgentTrace;
}

export interface UploadedPdf {
  pdf_id: string;
  filename: string;
  total_pages: number;
  chunks: number;
  processing_time: number;
}

export type UserType = 'consumer' | 'partner';

export interface PersonaDetectionResponse {
  persona: UserType;
  confidence: number;
  reasoning: string;
  available_agents: string[];
  is_confident: boolean;
  error?: string;
}

export interface ChatHistory {
  id: string;
  title: string;
  messages: Message[];
  createdAt: Date;
  updatedAt: Date;
  persona?: UserType;
}

// Agent Theater Types
export interface ToolCall {
  tool_name: string;
  duration_ms: number;
  status: 'success' | 'error' | 'timeout';
  input_summary?: string;
  output_summary?: string;
  metadata?: Record<string, any>;
}

export interface AgentExecution {
  agent_name: string;
  display_name: string;
  started_at: number;
  duration_ms: number;
  status: 'success' | 'error' | 'timeout';
  tool_calls: ToolCall[];
  input_summary?: string;
  output_summary?: string;
  confidence?: number;
  sources_used?: string[];
}

export interface AgentTrace {
  execution_id: string;
  total_duration_ms: number;
  agent_executions: AgentExecution[];
  routing_decision?: {
    primary_agent: string;
    confidence: number;
    fallback_used?: string;
  };
}


================================================
FILE: src/components/AgentTheater.tsx
================================================
import React, { useState, useEffect } from 'react';
import { AgentTrace, AgentExecution, ToolCall } from '../types';
import { AGENTS } from '../config/agents';

interface AgentTheaterProps {
  trace: AgentTrace;
  isVisible: boolean;
  compact?: boolean;
  onExpandToPanel?: () => void;
}

const AgentTheater: React.FC<AgentTheaterProps> = ({ 
  trace, 
  isVisible, 
  compact = false,
  onExpandToPanel 
}) => {
  const [expandedAgent, setExpandedAgent] = useState<string | null>(null);
  const [animationStage, setAnimationStage] = useState<number>(0);

  // Animation effect to show agents appearing in sequence
  useEffect(() => {
    if (!isVisible) {
      setAnimationStage(0);
      return;
    }

    const totalAgents = trace.agent_executions.length;
    let currentStage = 0;

    const interval = setInterval(() => {
      currentStage++;
      setAnimationStage(currentStage);
      
      if (currentStage >= totalAgents) {
        clearInterval(interval);
      }
    }, 200); // Faster animation for compact view

    return () => clearInterval(interval);
  }, [isVisible, trace.agent_executions.length]);

  if (!isVisible || !trace.agent_executions.length) return null;

  const formatDuration = (ms: number): string => {
    if (ms < 1000) return `${ms}ms`;
    if (ms < 60000) return `${(ms / 1000).toFixed(1)}s`;
    return `${Math.floor(ms / 60000)}m ${Math.floor((ms % 60000) / 1000)}s`;
  };

  const getStatusColor = (status: string): string => {
    switch (status) {
      case 'success': return 'text-emerald-500';
      case 'error': return 'text-red-500';
      case 'timeout': return 'text-amber-500';
      default: return 'text-slate-400';
    }
  };

  const getStatusIcon = (status: string): string => {
    switch (status) {
      case 'success': return 'fa-check-circle';
      case 'error': return 'fa-exclamation-circle';
      case 'timeout': return 'fa-clock';
      default: return 'fa-circle';
    }
  };

  // Compact inline version
  if (compact) {
    return (
      <div className="agent-theater-compact mb-3">
        <div className="flex items-center justify-between mb-2">
          <div className="flex items-center space-x-2">
            <div className="w-5 h-5 bg-gradient-to-r from-purple-500 to-blue-500 rounded-full flex items-center justify-center">
              <i className="fas fa-route text-white text-xs"></i>
            </div>
            <span className="text-sm font-medium text-slate-700">Multi-Agent Execution</span>
            <span className="text-xs text-slate-500">
              ({formatDuration(trace.total_duration_ms)})
            </span>
          </div>
          {onExpandToPanel && (
            <button
              onClick={onExpandToPanel}
              className="text-xs text-blue-600 hover:text-blue-800 hover:underline"
            >
              View Details ‚Üí
            </button>
          )}
        </div>

        {/* Agent Flow - Compact horizontal layout */}
        <div className="flex items-center space-x-1 overflow-x-auto pb-1">
          {trace.agent_executions.map((execution, index) => {
            const agent = AGENTS[execution.agent_name];
            const isVisible = index < animationStage;

            return (
              <React.Fragment key={execution.agent_name}>
                {/* Agent Badge */}
                <div
                  className={`
                    flex items-center space-x-1 px-2 py-1 rounded-full text-xs
                    transition-all duration-300 bg-white border
                    ${isVisible ? 'opacity-100 translate-x-0' : 'opacity-0 translate-x-2'}
                    ${execution.status === 'success' ? 'border-emerald-200 bg-emerald-50' : 'border-slate-200'}
                  `}
                  title={`${execution.display_name}: ${formatDuration(execution.duration_ms)}`}
                >
                  <i className={`fas ${agent?.icon || 'fa-robot'} ${agent?.color || 'text-slate-500'} text-xs`}></i>
                  <span className="font-medium text-slate-700">{execution.display_name}</span>
                  <span className="text-slate-500">{formatDuration(execution.duration_ms)}</span>
                  <i className={`fas ${getStatusIcon(execution.status)} ${getStatusColor(execution.status)} text-xs`}></i>
                  
                  {/* Tool call indicator */}
                  {execution.tool_calls.length > 0 && (
                    <div className="w-4 h-4 bg-blue-500 text-white rounded-full flex items-center justify-center text-xs">
                      {execution.tool_calls.length}
                    </div>
                  )}
                </div>

                {/* Arrow between agents */}
                {index < trace.agent_executions.length - 1 && (
                  <i className={`
                    fas fa-arrow-right text-slate-300 text-xs
                    transition-opacity duration-300
                    ${index < animationStage - 1 ? 'opacity-100' : 'opacity-0'}
                  `}></i>
                )}
              </React.Fragment>
            );
          })}
        </div>
      </div>
    );
  }

  // Full detailed version (for right panel)
  return (
    <div className="space-y-4 p-1">
      {/* Header */}
      <div className="flex items-center space-x-2 mb-3">
        <div className="w-5 h-5 bg-gradient-to-r from-purple-500 to-blue-500 rounded-full flex items-center justify-center">
          <i className="fas fa-route text-white text-xs"></i>
        </div>
        <div className="flex-1">
          <h3 className="text-sm font-medium text-slate-800">Execution Trace</h3>
          <p className="text-xs text-slate-500">{trace.agent_executions.length} agents ‚Ä¢ {formatDuration(trace.total_duration_ms)}</p>
        </div>
      </div>

      {/* Agent Flow */}
      <div className="space-y-2">
        {trace.agent_executions.map((execution, index) => {
          const agent = AGENTS[execution.agent_name];
          const isVisible = index < animationStage;
          const isExpanded = expandedAgent === execution.agent_name;

          return (
            <div
              key={execution.agent_name}
              className={`transition-all duration-500 ${isVisible ? 'opacity-100 translate-y-0' : 'opacity-0 translate-y-4'}`}
            >
              {/* Agent Row */}
              <div
                className={`
                  flex items-start space-x-3 p-3 rounded-lg cursor-pointer transition-all duration-200
                  ${isExpanded ? 'bg-blue-50 border border-blue-200' : 'bg-slate-50 hover:bg-slate-100'}
                `}
                onClick={() => setExpandedAgent(isExpanded ? null : execution.agent_name)}
              >
                {/* Agent Avatar */}
                <div className={`
                  w-7 h-7 rounded-md flex items-center justify-center relative flex-shrink-0 mt-0.5
                  ${agent?.color.replace('text-', 'bg-').replace('-600', '-100') || 'bg-slate-100'}
                `}>
                  <i className={`fas ${agent?.icon || 'fa-robot'} ${agent?.color || 'text-slate-600'} text-sm`}></i>
                  <div className={`
                    absolute -top-1 -right-1 w-3 h-3 rounded-full border-2 border-white
                    ${execution.status === 'success' ? 'bg-emerald-500' : 'bg-slate-400'}
                  `}></div>
                </div>

                {/* Agent Info */}
                <div className="flex-1 min-w-0">
                  <div className="flex items-start justify-between mb-1">
                    <span className="text-sm font-medium text-slate-800 leading-tight">{execution.display_name}</span>
                    <div className="flex items-center space-x-2 text-xs text-slate-500 flex-shrink-0 ml-3">
                      <span className="whitespace-nowrap">{formatDuration(execution.duration_ms)}</span>
                      {execution.tool_calls.length > 0 && (
                        <div className="w-5 h-5 bg-blue-500 text-white rounded-full flex items-center justify-center text-xs">
                          {execution.tool_calls.length}
                        </div>
                      )}
                      <i className={`fas fa-chevron-${isExpanded ? 'up' : 'down'} text-xs`}></i>
                    </div>
                  </div>
                  
                  {execution.input_summary && (
                    <p className="text-xs text-slate-500 line-clamp-2 leading-relaxed">{execution.input_summary}</p>
                  )}
                </div>
              </div>

              {/* Expanded Details */}
              {isExpanded && (
                <div className="mt-2 ml-10 p-3 bg-white rounded-lg border border-slate-200 animate-slideDown">
                  {/* Tool Calls */}
                  {execution.tool_calls.length > 0 && (
                    <div className="mb-3">
                      <div className="text-xs font-medium text-slate-700 mb-2 flex items-center">
                        <i className="fas fa-wrench mr-1"></i>
                        Tools Used:
                      </div>
                      <div className="space-y-2">
                        {execution.tool_calls.map((toolCall, idx) => (
                          <div key={idx} className="flex items-center justify-between p-2 bg-slate-50 rounded text-xs">
                            <div className="flex items-center space-x-2 flex-1 min-w-0">
                              <i className={`fas ${getStatusIcon(toolCall.status)} ${getStatusColor(toolCall.status)} flex-shrink-0`}></i>
                              <span className="font-medium truncate">{toolCall.tool_name}</span>
                            </div>
                            <span className="text-slate-500 flex-shrink-0 ml-2">{formatDuration(toolCall.duration_ms)}</span>
                          </div>
                        ))}
                      </div>
                    </div>
                  )}

                  {/* Input/Output */}
                  {execution.input_summary && (
                    <div className="mb-3">
                      <div className="text-xs font-medium text-slate-700 mb-1">Input:</div>
                      <div className="text-xs text-slate-600 bg-slate-50 p-2 rounded-md leading-relaxed break-words max-h-20 overflow-y-auto">{execution.input_summary}</div>
                    </div>
                  )}

                  {execution.output_summary && (
                    <div className="mb-3">
                      <div className="text-xs font-medium text-slate-700 mb-1">Output:</div>
                      <div className="text-xs text-slate-600 bg-slate-50 p-2 rounded-md leading-relaxed break-words max-h-20 overflow-y-auto">{execution.output_summary}</div>
                    </div>
                  )}

                  {/* Confidence bar */}
                  {execution.confidence !== undefined && (
                    <div className="flex items-center space-x-3">
                      <span className="text-xs font-medium text-slate-700 flex-shrink-0">Confidence:</span>
                      <div className="flex-1 bg-slate-200 rounded-full h-2">
                        <div 
                          className="bg-gradient-to-r from-blue-500 to-blue-600 h-2 rounded-full transition-all duration-500"
                          style={{ width: `${execution.confidence * 100}%` }}
                        ></div>
                      </div>
                      <span className="text-xs text-slate-600 flex-shrink-0 font-medium">{(execution.confidence * 100).toFixed(0)}%</span>
                    </div>
                  )}
                </div>
              )}
            </div>
          );
        })}
      </div>

      {/* Routing Info */}
      {trace.routing_decision && (
        <div className="mt-2 p-2 bg-blue-50 rounded border border-blue-200">
          <div className="flex items-center space-x-1 text-xs">
            <i className="fas fa-route text-blue-600"></i>
            <span className="font-medium text-blue-800">
              Routed to <strong>{trace.routing_decision.primary_agent}</strong>
            </span>
            {trace.routing_decision.confidence && (
              <span className="text-blue-700">
                ({(trace.routing_decision.confidence * 100).toFixed(0)}%)
              </span>
            )}
          </div>
          {trace.routing_decision.fallback_used && (
            <div className="mt-0.5 text-xs text-blue-700">
              Fallback: {trace.routing_decision.fallback_used}
            </div>
          )}
        </div>
      )}
    </div>
  );
};

export default AgentTheater;


================================================
FILE: src/components/ChatMessage.tsx
================================================
import React from 'react';
import { Message } from '../types';
import { AGENTS } from '../config/agents';
import MarkdownRenderer from './MarkdownRenderer';
import AgentTheater from './AgentTheater';

interface ChatMessageProps {
  message: Message;
}

const ChatMessage: React.FC<ChatMessageProps> = ({ message }) => {
  if (message.role === 'user') {
    return (
      <div className="chat-message animate-fade-in">
        <div className="flex items-start space-x-3 justify-end">
          <div className="max-w-3xl">
            <div className="bg-teal-600 text-white px-4 py-2 rounded-2xl rounded-tr-sm">
              <p className="text-sm leading-relaxed whitespace-pre-wrap">{message.content}</p>
            </div>
            {message.pdfData && (
              <div className="mt-2 p-3 bg-red-50 border border-red-200 rounded-lg max-w-sm">
                <div className="flex items-center space-x-2">
                  <div className="w-8 h-8 bg-red-100 rounded flex items-center justify-center flex-shrink-0">
                    <i className="fas fa-file-pdf text-red-600"></i>
                  </div>
                  <div className="flex-1">
                    <div className="flex items-center space-x-2 mb-1">
                      <i className="fas fa-file-pdf text-red-600"></i>
                      <span className="font-medium text-sm text-slate-800">
                        {message.pdfData.filename}
                      </span>
                    </div>
                    <div className="text-xs text-slate-600 space-y-1">
                      <div>üìÑ {message.pdfData.total_pages} pages</div>
                      <div>üß© {message.pdfData.chunks_extracted} chunks extracted</div>
                      <div>‚ö° Processed in {message.pdfData.processing_time?.toFixed(2)}s</div>
                    </div>
                    <div className="text-xs text-slate-500 mt-2">
                      Ready for questions about this document
                    </div>
                  </div>
                </div>
              </div>
            )}
          </div>
          <div className="w-8 h-8 rounded-full bg-teal-600 flex items-center justify-center text-white flex-shrink-0">
            <i className="fas fa-user text-sm"></i>
          </div>
        </div>
      </div>
    );
  }

  return (
    <div className="chat-message animate-fade-in">
      <div className="flex items-start space-x-4">
        {/* Agent Avatar with Color Ring */}
        <div className="relative flex-shrink-0">
          <div className={`w-10 h-10 rounded-full ${AGENTS[message.agent]?.color?.replace('text-', 'bg-') || 'bg-slate-500'} bg-opacity-10 flex items-center justify-center ring-2 ring-white shadow-sm`}>
            <i className={`fas ${AGENTS[message.agent]?.icon || 'fa-robot'} ${AGENTS[message.agent]?.color || 'text-slate-600'} text-lg`}></i>
          </div>
          {message.confidence !== undefined && (
            <div className="absolute -bottom-1 -right-1 w-6 h-6 bg-white rounded-full flex items-center justify-center shadow-sm border border-slate-200">
              <span className="text-xs font-medium text-slate-600">
                {(message.confidence * 100).toFixed(0)}%
              </span>
            </div>
          )}
        </div>

        <div className="flex-1 max-w-4xl">
          {/* Enhanced Message Header */}
          <div className="bg-white rounded-lg shadow-sm border border-slate-200 overflow-hidden">
            <div className={`px-4 py-3 ${AGENTS[message.agent]?.color?.replace('text-', 'bg-') || 'bg-slate-500'} bg-opacity-5 border-b border-slate-100`}>
              <div className="flex items-center justify-between">
                <div className="flex items-center space-x-3">
                  <span className="font-semibold text-slate-800">
                    {AGENTS[message.agent]?.name || 'AI Assistant'}
                  </span>
                  <span className="text-xs text-slate-500">
                    {new Date(message.timestamp).toLocaleTimeString()}
                  </span>
                </div>
                {message.fallback_used && (
                  <div className="flex items-center space-x-2">
                    <i className="fas fa-route text-amber-600"></i>
                    <span className="text-xs text-amber-700 font-medium">
                      Fallback: {message.fallback_used.replace('_', ' ')}
                    </span>
                  </div>
                )}
              </div>
              
              {/* Agent Theater - Show execution trace in header */}
              {message.agent_trace && (
                <div className="mt-2">
                  <AgentTheater 
                    trace={message.agent_trace} 
                    isVisible={true} 
                    compact={true}
                    onExpandToPanel={() => {
                      console.log('Switch to Agent Theater panel');
                    }}
                  />
                </div>
              )}
            </div>

            {/* Enhanced Message Content */}
            <div className="px-4 py-4">
              <div className="prose prose-slate max-w-none">
                <MarkdownRenderer content={message.content} />
              </div>
            </div>

            {/* Image Display */}
            {message.image_data && (
              <div className="px-4 pb-4">
                <div className="border border-slate-200 rounded-lg overflow-hidden bg-slate-50">
                  <div className="px-3 py-2 border-b border-slate-200 bg-white">
                    <span className="text-sm text-slate-600 flex items-center font-medium">
                      <i className="fas fa-image mr-2 text-purple-600"></i>
                      Generated Image ({message.image_format})
                    </span>
                  </div>
                  <div className="p-4">
                    <img
                      src={`data:image/${message.image_format};base64,${message.image_data}`}
                      alt="Generated content"
                      className="max-w-full h-auto rounded shadow-sm"
                    />
                  </div>
                </div>
              </div>
            )}

            {/* Footer with Sources and Metadata */}
            <div className="px-4 py-3 bg-slate-50 border-t border-slate-100">
              <div className="flex items-center justify-between">
                {/* Sources */}
                {message.sources && message.sources.length > 0 ? (
                  <div className="flex flex-wrap gap-1">
                    <span className="text-xs text-slate-600 mr-2">Sources:</span>
                    {message.sources.slice(0, 3).map((source, index) => (
                      <button
                        key={index}
                        className="text-xs bg-white hover:bg-slate-100 text-slate-600 px-2 py-1 rounded-md border border-slate-200 transition-colors"
                        title={source}
                      >
                        <i className="fas fa-quote-left mr-1"></i>
                        {index + 1}
                      </button>
                    ))}
                    {message.sources.length > 3 && (
                      <span className="text-xs text-slate-500">
                        +{message.sources.length - 3} more
                      </span>
                    )}
                  </div>
                ) : (
                  <div className="text-xs text-slate-500">
                    <i className="fas fa-brain mr-1"></i>
                    AI Knowledge
                  </div>
                )}
                
                {/* Document Assessment */}
                {message.document_assessment && (
                  <div className="text-xs text-slate-500">
                    Quality: {(message.document_assessment.document_quality_score * 100).toFixed(0)}%
                  </div>
                )}
                
                {/* Used Tavily indicator */}
                {message.used_tavily && (
                  <div className="flex items-center space-x-1 text-xs text-blue-600">
                    <i className="fas fa-search"></i>
                    <span>Web Search</span>
                  </div>
                )}
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
};

export default ChatMessage;


================================================
FILE: src/components/ChatPane.tsx
================================================
import React, { useState, useRef } from 'react';
import { Message } from '../types';
import { AGENTS } from '../config/agents';
import ChatMessage from './ChatMessage';

interface ChatPaneProps {
  messages: Message[];
  isLoading: boolean;
  inputText: string;
  setInputText: (text: string) => void;
  selectedAgent: string;
  onSendMessage: () => void;
  messagesEndRef: React.RefObject<HTMLDivElement>;
  uploadPdf: (file: File) => void;
  currentChatTitle: string;
}

const ChatPane: React.FC<ChatPaneProps> = ({
  messages,
  isLoading,
  inputText,
  setInputText,
  selectedAgent,
  onSendMessage,
  messagesEndRef,
  uploadPdf,
  currentChatTitle
}) => {
  const [isDragOver, setIsDragOver] = useState(false);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter') {
      if (e.shiftKey || e.ctrlKey) {
        // Allow new line on Shift+Enter or Ctrl+Enter
        return;
      } else {
        // Send message on plain Enter
        e.preventDefault();
        if (inputText.trim()) {
          onSendMessage();
        }
      }
    }
  };

  const handleDragOver = (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragOver(true);
  };

  const handleDragLeave = (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragOver(false);
  };

  const handleDrop = async (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragOver(false);

    const files = Array.from(e.dataTransfer.files);
    console.log('Dropped files:', files.map(f => ({ name: f.name, type: f.type, size: f.size })));
    
    const pdfFiles = files.filter(file => 
      file.type === 'application/pdf' || file.name.toLowerCase().endsWith('.pdf')
    );

    if (pdfFiles.length === 0) {
      alert('Please drop PDF files only.');
      return;
    }

    // Upload each PDF file
    for (const file of pdfFiles) {
      try {
        console.log(`Uploading PDF: ${file.name}`);
        await uploadPdf(file);
        console.log(`Successfully uploaded: ${file.name}`);
      } catch (error) {
        console.error(`Error uploading PDF ${file.name}:`, error);
      }
    }
  };

  const handleFileUpload = () => {
    fileInputRef.current?.click();
  };

  const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file && file.type === 'application/pdf') {
      uploadPdf(file);
    }
  };

  return (
    <div 
      className="flex-1 flex flex-col bg-white relative"
      onDragOver={handleDragOver}
      onDragLeave={handleDragLeave}
      onDrop={handleDrop}
    >
      {/* Drag overlay */}
      {isDragOver && (
        <div className="absolute inset-0 bg-teal-50 border-2 border-dashed border-teal-300 flex items-center justify-center z-10">
          <div className="text-center">
            <i className="fas fa-file-pdf text-4xl text-teal-600 mb-4"></i>
            <p className="text-teal-800 font-medium">Drop PDF files here</p>
          </div>
        </div>
      )}

      {/* Chat Header */}
      <div className="bg-white border-b border-slate-200 px-6 py-4 flex items-center justify-between">
        <div className="flex items-center space-x-4">
          <div className="flex items-center space-x-3">
            <i className="fas fa-comments text-blue-600 text-xl"></i>
            <span className="font-semibold text-lg text-slate-800">{currentChatTitle}</span>
          </div>
          <span className="px-3 py-1 text-sm bg-slate-100 text-slate-600 rounded-full font-medium">
            {messages.length} messages
          </span>
        </div>
        <div className="flex items-center space-x-2 text-sm text-slate-500">
          <i className="fas fa-circle text-green-500"></i>
          <span className="font-medium">AI Assistant</span>
        </div>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto bg-gradient-to-b from-slate-50 to-white">
        <div className="p-6 space-y-6">
        {messages.length === 0 ? (
          <div className="text-center py-16">
            <div className="w-20 h-20 bg-slate-100 rounded-full flex items-center justify-center mx-auto mb-6">
              <i className="fas fa-comments text-slate-400 text-3xl"></i>
            </div>
            <h3 className="text-xl font-semibold text-slate-800 mb-3">
              Start a New Conversation
            </h3>
            <p className="text-base text-slate-600 max-w-lg mx-auto mb-6 leading-relaxed">
              Ask me anything about financial services, healthcare financing, or business partnerships. I'll route your question to the right specialist.
            </p>
            <div className="bg-slate-50 rounded-xl p-4 max-w-md mx-auto">
              <p className="text-sm text-slate-500 mb-2 font-medium">Try asking:</p>
              <p className="text-sm text-slate-700 italic">"I need help financing a dental procedure for $3,500"</p>
            </div>
          </div>
        ) : (
          messages.map((message) => (
            <ChatMessage key={message.id} message={message} />
          ))
        )}
        
        {isLoading && (
          <div className="flex items-start space-x-4 animate-fade-in">
            <div className="w-10 h-10 rounded-full bg-slate-100 flex items-center justify-center animate-pulse">
              <i className={`fas ${AGENTS[selectedAgent]?.icon || 'fa-robot'} ${AGENTS[selectedAgent]?.color || 'text-slate-600'}`}></i>
            </div>
            <div className="flex-1">
              <div className="bg-white border border-slate-200 rounded-lg shadow-sm overflow-hidden">
                <div className="px-4 py-3 bg-slate-50 border-b border-slate-100">
                  <span className="font-semibold text-slate-700">
                    {AGENTS[selectedAgent]?.name || 'AI Assistant'}
                  </span>
                </div>
                <div className="px-4 py-4">
                  <div className="flex items-center space-x-3">
                    <div className="flex space-x-1">
                      <div className="w-2 h-2 bg-slate-400 rounded-full animate-bounce"></div>
                      <div className="w-2 h-2 bg-slate-400 rounded-full animate-bounce" style={{animationDelay: '0.1s'}}></div>
                      <div className="w-2 h-2 bg-slate-400 rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
                    </div>
                    <span className="text-sm text-slate-500">
                      Analyzing your request...
                    </span>
                  </div>
                </div>
              </div>
            </div>
          </div>
        )}
        <div ref={messagesEndRef} />
        </div>
      </div>

      {/* Input */}
      <div className="bg-white border-t border-slate-200 p-6">
        <div className="flex items-end space-x-4">
          <button
            onClick={handleFileUpload}
            className="p-3 text-slate-600 hover:text-slate-800 hover:bg-slate-100 rounded-xl transition-colors"
            title="Upload PDF"
          >
            <i className="fas fa-plus text-xl"></i>
          </button>
          
          <div className="flex-1">
            <textarea
              value={inputText}
              onChange={(e) => setInputText(e.target.value)}
              onKeyDown={handleKeyPress}
              placeholder={`Ask ${AGENTS[selectedAgent]?.name || 'AI Assistant'}...`}
              className="w-full px-5 py-4 text-base border border-slate-300 rounded-xl resize-none focus:outline-none focus:ring-2 focus:ring-teal-500 focus:border-transparent placeholder-slate-400"
              rows={1}
              disabled={isLoading}
            />
          </div>
          
          <button
            onClick={onSendMessage}
            disabled={!inputText.trim() || isLoading}
            className="px-5 py-4 bg-teal-600 text-white rounded-xl hover:bg-teal-700 disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
          >
            <i className="fas fa-paper-plane text-base"></i>
          </button>
        </div>
        <div className="mt-3 flex items-center justify-between text-sm text-slate-500">
          <span className="font-medium">Press Enter to send ‚Ä¢ Shift+Enter for new line</span>
          <span className="font-medium">{inputText.length} characters</span>
        </div>
      </div>

      {/* Hidden file input */}
      <input
        ref={fileInputRef}
        type="file"
        accept=".pdf"
        onChange={handleFileChange}
        className="hidden"
      />
    </div>
  );
};

export default ChatPane;


================================================
FILE: src/components/Header.tsx
================================================
import React from 'react';

interface HeaderProps {
  allowTavily: boolean;
  setAllowTavily: (value: boolean) => void;
  allowLlmKnowledge: boolean;
  setAllowLlmKnowledge: (value: boolean) => void;
  allowWebSearch: boolean;
  setAllowWebSearch: (value: boolean) => void;
  onClear: () => void;
  onExport: () => void;
  onResetPersona?: () => void;
}

const Header: React.FC<HeaderProps> = ({
  allowTavily,
  setAllowTavily,
  allowLlmKnowledge,
  setAllowLlmKnowledge,
  allowWebSearch,
  setAllowWebSearch,
  onClear,
  onExport,
  onResetPersona
}) => {
  return (
    <header className="bg-white border-b border-slate-200 px-6 py-3">
      <div className="flex items-center justify-between">
        <div className="flex items-center space-x-6">
          <h1 className="text-xl font-semibold text-slate-800">
            GenAI Studio <span className="text-sm font-normal text-slate-500">(Hackathon PoC)</span>
          </h1>
          <div className="flex items-center space-x-4">
            <span className="px-2 py-1 text-xs bg-slate-100 text-slate-600 rounded-md">
              Local ‚Ä¢ No DB
            </span>
            <div className="flex items-center space-x-2">
              <span className="px-3 py-1 text-xs bg-green-100 text-green-700 rounded-md font-medium">
                ü§ñ Auto-detect persona
              </span>
              {onResetPersona && (
                <button
                  onClick={onResetPersona}
                  className="px-2 py-1 text-xs text-slate-500 hover:text-slate-700 hover:bg-slate-100 rounded transition-colors"
                  title="Reset to consumer view"
                >
                  <i className="fas fa-refresh"></i>
                </button>
              )}
            </div>
            
            {/* Elegant Toggle Switches */}
            <div className="flex items-center space-x-6 ml-4">
              {/* Tavily Toggle */}
              <div className="flex items-center space-x-2">
                <label className="relative inline-flex items-center cursor-pointer">
                  <input
                    type="checkbox"
                    checked={allowTavily}
                    onChange={(e) => setAllowTavily(e.target.checked)}
                    className="sr-only peer"
                  />
                  <div className="w-9 h-5 bg-slate-200 peer-focus:outline-none peer-focus:ring-2 peer-focus:ring-teal-300 rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:rounded-full after:h-4 after:w-4 after:transition-all peer-checked:bg-teal-500"></div>
                </label>
                <span className="text-xs text-slate-600 font-medium">
                  Tavily <span className="text-slate-400">(legacy)</span>
                </span>
              </div>

              {/* LLM Knowledge Toggle */}
              <div className="flex items-center space-x-2">
                <label className="relative inline-flex items-center cursor-pointer">
                  <input
                    type="checkbox"
                    checked={allowLlmKnowledge}
                    onChange={(e) => setAllowLlmKnowledge(e.target.checked)}
                    className="sr-only peer"
                  />
                  <div className="w-9 h-5 bg-slate-200 peer-focus:outline-none peer-focus:ring-2 peer-focus:ring-blue-300 rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:rounded-full after:h-4 after:w-4 after:transition-all peer-checked:bg-blue-500"></div>
                </label>
                <span className="text-xs text-slate-600 font-medium flex items-center space-x-1">
                  <i className="fas fa-brain text-blue-500"></i>
                  <span>LLM Knowledge</span>
                </span>
              </div>

              {/* Web Search Toggle */}
              <div className="flex items-center space-x-2">
                <label className="relative inline-flex items-center cursor-pointer">
                  <input
                    type="checkbox"
                    checked={allowWebSearch}
                    onChange={(e) => setAllowWebSearch(e.target.checked)}
                    className="sr-only peer"
                  />
                  <div className="w-9 h-5 bg-slate-200 peer-focus:outline-none peer-focus:ring-2 peer-focus:ring-purple-300 rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:rounded-full after:h-4 after:w-4 after:transition-all peer-checked:bg-purple-500"></div>
                </label>
                <span className="text-xs text-slate-600 font-medium flex items-center space-x-1">
                  <i className="fas fa-search text-purple-500"></i>
                  <span>Web Search</span>
                </span>
              </div>
            </div>
          </div>
        </div>

        <div className="flex items-center space-x-3">
          <span className="px-2 py-1 text-xs bg-green-100 text-green-600 rounded-md">
            PII Redaction ON
          </span>
          <button
            onClick={onClear}
            className="px-3 py-1 text-sm text-slate-600 hover:text-slate-800"
          >
            Clear
          </button>
          <button
            onClick={onExport}
            className="px-3 py-1 text-sm text-slate-600 hover:text-slate-800"
          >
            Export
          </button>
        </div>
      </div>
    </header>
  );
};

export default Header;


================================================
FILE: src/components/LandingPage.tsx
================================================
import React from 'react';

interface LandingPageProps {
  onUserTypeSelect: (userType: 'consumer' | 'partner') => void;
}

const LandingPage: React.FC<LandingPageProps> = ({ onUserTypeSelect }) => {
  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 to-indigo-100 flex items-center justify-center p-4">
      <div className="max-w-4xl w-full">
        <div className="text-center mb-12">
          <h1 className="text-5xl font-bold text-gray-900 mb-4">
            Welcome to Synch GenAI
          </h1>
          <p className="text-xl text-gray-600 mb-8">
            AI-powered financial services platform
          </p>
          <p className="text-lg text-gray-500">
            Choose your role to get started with the right set of tools
          </p>
        </div>

        <div className="grid md:grid-cols-2 gap-8 max-w-3xl mx-auto">
          {/* Consumer Option */}
          <div 
            onClick={() => onUserTypeSelect('consumer')}
            className="bg-white rounded-2xl p-8 shadow-lg hover:shadow-xl transition-all duration-300 cursor-pointer border-2 border-transparent hover:border-blue-500 group"
          >
            <div className="text-center">
              <div className="w-20 h-20 bg-blue-100 rounded-full flex items-center justify-center mx-auto mb-6 group-hover:bg-blue-200 transition-colors">
                <i className="fas fa-user text-3xl text-blue-600"></i>
              </div>
              <h2 className="text-2xl font-bold text-gray-900 mb-4">Consumer</h2>
              <p className="text-gray-600 mb-6">
                Access personal financial services, manage your accounts, and get help with transactions
              </p>
              <div className="space-y-2 text-sm text-gray-500">
                <div className="flex items-center justify-center">
                  <i className="fas fa-check text-green-500 mr-2"></i>
                  Account Management
                </div>
                <div className="flex items-center justify-center">
                  <i className="fas fa-check text-green-500 mr-2"></i>
                  Transaction Support
                </div>
                <div className="flex items-center justify-center">
                  <i className="fas fa-check text-green-500 mr-2"></i>
                  Financial Products
                </div>
              </div>
            </div>
          </div>

          {/* Partner Option */}
          <div 
            onClick={() => onUserTypeSelect('partner')}
            className="bg-white rounded-2xl p-8 shadow-lg hover:shadow-xl transition-all duration-300 cursor-pointer border-2 border-transparent hover:border-purple-500 group"
          >
            <div className="text-center">
              <div className="w-20 h-20 bg-purple-100 rounded-full flex items-center justify-center mx-auto mb-6 group-hover:bg-purple-200 transition-colors">
                <i className="fas fa-handshake text-3xl text-purple-600"></i>
              </div>
              <h2 className="text-2xl font-bold text-gray-900 mb-4">Partner</h2>
              <p className="text-gray-600 mb-6">
                Access business tools, analytics, and partner-specific services for your organization
              </p>
              <div className="space-y-2 text-sm text-gray-500">
                <div className="flex items-center justify-center">
                  <i className="fas fa-check text-green-500 mr-2"></i>
                  Business Analytics
                </div>
                <div className="flex items-center justify-center">
                  <i className="fas fa-check text-green-500 mr-2"></i>
                  Developer Tools
                </div>
                <div className="flex items-center justify-center">
                  <i className="fas fa-check text-green-500 mr-2"></i>
                  Portfolio Insights
                </div>
              </div>
            </div>
          </div>
        </div>

        <div className="text-center mt-12">
          <p className="text-sm text-gray-400">
            Powered by AI ‚Ä¢ Secure ‚Ä¢ Real-time
          </p>
        </div>
      </div>
    </div>
  );
};

export default LandingPage;


================================================
FILE: src/components/LeftRail.tsx
================================================
import React, { useState } from 'react';
import { ChatHistory, UserType } from '../types';

interface LeftRailProps {
  chatHistories: ChatHistory[];
  currentChatId: string | null;
  onSelectChat: (chatId: string) => void;
  onCreateNewChat: () => void;
  onDeleteChat: (chatId: string) => void;
  onUpdateChatTitle: (chatId: string, title: string) => void;
  userType: UserType;
}

interface ChatHistoryItemProps {
  chat: ChatHistory;
  isSelected: boolean;
  onSelect: () => void;
  onDelete: () => void;
  onUpdateTitle: (title: string) => void;
}

const ChatHistoryItem: React.FC<ChatHistoryItemProps> = ({ 
  chat, 
  isSelected, 
  onSelect, 
  onDelete, 
  onUpdateTitle 
}) => {
  const [isEditing, setIsEditing] = useState(false);
  const [editTitle, setEditTitle] = useState(chat.title);

  const handleSaveTitle = () => {
    if (editTitle.trim() && editTitle !== chat.title) {
      onUpdateTitle(editTitle.trim());
    }
    setIsEditing(false);
  };

  const handleKeyDown = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter') {
      handleSaveTitle();
    } else if (e.key === 'Escape') {
      setEditTitle(chat.title);
      setIsEditing(false);
    }
  };

  return (
    <div className="border-b border-slate-100 last:border-0">
      <div
        className={`group p-3 cursor-pointer transition-all hover:bg-slate-50 ${
          isSelected 
            ? 'bg-blue-50 border-r-2 border-blue-500' 
            : 'hover:bg-slate-50'
        }`}
        onClick={onSelect}
      >
        <div className="flex items-start justify-between">
          <div className="flex-1 min-w-0">
            {isEditing ? (
              <input
                type="text"
                value={editTitle}
                onChange={(e) => setEditTitle(e.target.value)}
                onBlur={handleSaveTitle}
                onKeyDown={handleKeyDown}
                className="w-full text-sm font-medium bg-transparent border-none outline-none focus:ring-1 focus:ring-blue-500 rounded px-1"
                autoFocus
                onClick={(e) => e.stopPropagation()}
              />
            ) : (
              <h3 className={`font-medium ${isSelected ? 'text-blue-700' : 'text-slate-700'} text-sm truncate`}>
                {chat.title}
              </h3>
            )}
            <div className="flex items-center justify-between mt-1">
              <p className="text-xs text-slate-500">
                {chat.messages.length} messages
              </p>
              <p className="text-xs text-slate-400">
                {new Date(chat.updatedAt).toLocaleDateString()}
              </p>
            </div>
            {chat.persona && (
              <span className={`inline-block mt-1 px-2 py-0.5 text-xs rounded-full ${
                chat.persona === 'consumer' 
                  ? 'bg-green-100 text-green-700' 
                  : 'bg-purple-100 text-purple-700'
              }`}>
                {chat.persona}
              </span>
            )}
          </div>
          <div className="opacity-0 group-hover:opacity-100 transition-opacity flex items-center space-x-1 ml-2">
            <button
              onClick={(e) => { 
                e.stopPropagation(); 
                setIsEditing(true);
              }}
              className="p-1 hover:bg-slate-200 rounded"
              title="Edit title"
            >
              <i className="fas fa-edit text-xs text-slate-400"></i>
            </button>
            <button
              onClick={(e) => { 
                e.stopPropagation(); 
                if (confirm('Delete this chat?')) onDelete();
              }}
              className="p-1 hover:bg-red-100 rounded"
              title="Delete chat"
            >
              <i className="fas fa-trash text-xs text-red-400"></i>
            </button>
          </div>
        </div>
      </div>
    </div>
  );
}

const LeftRail: React.FC<LeftRailProps> = ({ 
  chatHistories,
  currentChatId,
  onSelectChat,
  onCreateNewChat,
  onDeleteChat,
  onUpdateChatTitle,
  userType
}) => {
  
  return (
    <div className="w-72 bg-white border-r border-slate-200 flex flex-col">
      <div className="p-4 border-b border-slate-200">
        <div className="flex items-center justify-between mb-4">
          <h2 className="text-lg font-semibold text-slate-800">Chat History</h2>
          <button
            onClick={onCreateNewChat}
            className="p-2 bg-blue-600 hover:bg-blue-700 text-white rounded-lg transition-colors"
            title="New Chat"
          >
            <i className="fas fa-plus text-sm"></i>
          </button>
        </div>
        <div className="text-xs text-slate-400 bg-slate-50 px-2 py-1 rounded">
          {userType} persona
        </div>
      </div>
      
      <div className="flex-1 overflow-y-auto">
        {chatHistories.length === 0 ? (
          <div className="p-6 text-center">
            <div className="w-16 h-16 bg-slate-100 rounded-full flex items-center justify-center mx-auto mb-4">
              <i className="fas fa-comments text-slate-400 text-xl"></i>
            </div>
            <h3 className="font-medium text-slate-700 mb-2">No chats yet</h3>
            <p className="text-sm text-slate-500 mb-4">Start a new conversation to see your chat history</p>
            <button
              onClick={onCreateNewChat}
              className="px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white text-sm rounded-lg transition-colors"
            >
              Start New Chat
            </button>
          </div>
        ) : (
          chatHistories.map((chat) => (
            <ChatHistoryItem
              key={chat.id}
              chat={chat}
              isSelected={chat.id === currentChatId}
              onSelect={() => onSelectChat(chat.id)}
              onDelete={() => onDeleteChat(chat.id)}
              onUpdateTitle={(title) => onUpdateChatTitle(chat.id, title)}
            />
          ))
        )}
      </div>
      
      <div className="p-3 border-t border-slate-100 bg-slate-50">
        <p className="text-xs text-slate-500 text-center">
          {chatHistories.length} chat{chatHistories.length !== 1 ? 's' : ''} saved
        </p>
      </div>
    </div>
  );
};

export default LeftRail;


================================================
FILE: src/components/MarkdownRenderer.tsx
================================================
import React from 'react';
import ReactMarkdown from 'react-markdown';
import rehypeHighlight from 'rehype-highlight';
import remarkGfm from 'remark-gfm';
import 'highlight.js/styles/github.css';

interface MarkdownRendererProps {
  content: string;
  className?: string;
}

const MarkdownRenderer: React.FC<MarkdownRendererProps> = ({ content, className = '' }) => {
  // Only process redacted text - preserve all markdown formatting
  const processedContent = content.replace(/\[REDACTED[^\]]*\]/g, '‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà');

  return (
    <div className={`prose prose-slate max-w-none ${className}`}>
      <ReactMarkdown
        rehypePlugins={[rehypeHighlight]}
        remarkPlugins={[remarkGfm]}
      >
        {processedContent}
      </ReactMarkdown>
    </div>
  );
};

export default MarkdownRenderer;


================================================
FILE: src/components/RightInspector.tsx
================================================
import React, { useState, useEffect, useRef } from 'react';
import { UploadedPdf, AgentTrace } from '../types';
import AgentTheater from './AgentTheater';

interface RightInspectorProps {
  activePanel: string;
  setActivePanel: (panel: string) => void;
  citations: string[];
  toolTrace: any[];
  agentTrace: AgentTrace | null;
  uploadedPdfs: UploadedPdf[];
  selectedPdfChunk: any;
  setSelectedPdfChunk: (chunk: any) => void;
  isCollapsed: boolean;
  onToggleCollapse: () => void;
}

const RightInspector: React.FC<RightInspectorProps> = ({
  activePanel,
  setActivePanel,
  citations,
  toolTrace,
  agentTrace,
  uploadedPdfs,
  selectedPdfChunk,
  setSelectedPdfChunk,
  isCollapsed,
  onToggleCollapse
}) => {
  if (isCollapsed) {
    return (
      <div className="w-12 bg-white border-l border-slate-200 flex flex-col">
        <div className="p-3 border-b border-slate-200">
          <button
            onClick={onToggleCollapse}
            className="w-full p-2 text-slate-600 hover:text-slate-800 hover:bg-slate-100 rounded transition-colors"
            title="Expand panel"
          >
            <i className="fas fa-chevron-left"></i>
          </button>
        </div>
        <div className="flex-1 flex flex-col items-center justify-center space-y-4 py-4">
          <button
            onClick={() => { setActivePanel('citations'); onToggleCollapse(); }}
            className={`p-2 rounded transition-colors ${
              activePanel === 'citations' 
                ? 'bg-blue-100 text-blue-600' 
                : 'text-slate-400 hover:text-slate-600 hover:bg-slate-100'
            }`}
            title="Citations"
          >
            <i className="fas fa-quote-left"></i>
          </button>
          <button
            onClick={() => { setActivePanel('tools'); onToggleCollapse(); }}
            className={`p-2 rounded transition-colors ${
              activePanel === 'tools' 
                ? 'bg-blue-100 text-blue-600' 
                : 'text-slate-400 hover:text-slate-600 hover:bg-slate-100'
            }`}
            title="Tools"
          >
            <i className="fas fa-route"></i>
          </button>
          <button
            onClick={() => { setActivePanel('pdfs'); onToggleCollapse(); }}
            className={`p-2 rounded transition-colors ${
              activePanel === 'pdfs' 
                ? 'bg-blue-100 text-blue-600' 
                : 'text-slate-400 hover:text-slate-600 hover:bg-slate-100'
            }`}
            title="PDFs"
          >
            <i className="fas fa-file-pdf"></i>
          </button>
        </div>
      </div>
    );
  }

  return (
    <div className="w-80 bg-white border-l border-slate-200 flex flex-col">
      {/* Header with collapse button */}
      <div className="flex items-center justify-between p-3 border-b border-slate-200">
        <h3 className="font-semibold text-slate-700">Inspector</h3>
        <button
          onClick={onToggleCollapse}
          className="p-1 text-slate-500 hover:text-slate-700 hover:bg-slate-100 rounded transition-colors"
          title="Collapse panel"
        >
          <i className="fas fa-chevron-right"></i>
        </button>
      </div>
      
      {/* Tabs */}
      <div className="border-b border-slate-200">
        <div className="flex">
          <button
            onClick={() => setActivePanel('citations')}
            className={`flex-1 px-4 py-3 text-sm font-medium border-b-2 ${
              activePanel === 'citations'
                ? 'text-teal-600 border-teal-500'
                : 'text-slate-500 border-transparent hover:text-slate-700 hover:border-slate-300'
            }`}
          >
            <i className="fas fa-quote-left mr-2"></i>
            Citations
          </button>
          <button
            onClick={() => setActivePanel('tools')}
            className={`flex-1 px-4 py-3 text-sm font-medium border-b-2 relative ${
              activePanel === 'tools'
                ? 'text-teal-600 border-teal-500'
                : 'text-slate-500 border-transparent hover:text-slate-700 hover:border-slate-300'
            }`}
          >
            <i className="fas fa-route mr-2"></i>
            Agent Theater
            {agentTrace && agentTrace.agent_executions?.length > 1 && (
              <span className="absolute -top-1 -right-1 w-5 h-5 bg-purple-500 text-white text-xs rounded-full flex items-center justify-center">
                {agentTrace.agent_executions.length}
              </span>
            )}
          </button>
          <button
            onClick={() => setActivePanel('pdfs')}
            className={`flex-1 px-4 py-3 text-sm font-medium border-b-2 relative ${
              activePanel === 'pdfs'
                ? 'text-teal-600 border-teal-500'
                : 'text-slate-500 border-transparent hover:text-slate-700 hover:border-slate-300'
            }`}
          >
            <i className="fas fa-file-pdf mr-2"></i>
            Doc Viewer
            {uploadedPdfs.length > 0 && (
              <span className="absolute -top-1 -right-1 w-5 h-5 bg-red-500 text-white text-xs rounded-full flex items-center justify-center">
                {uploadedPdfs.length}
              </span>
            )}
          </button>
        </div>
      </div>

      {/* Content */}
      <div className="flex-1 overflow-y-auto">
        {activePanel === 'citations' && (
          <div className="p-6">
            <h3 className="text-lg font-semibold text-slate-800 mb-6">Sources & Citations</h3>
            {citations.length > 0 ? (
              <div className="space-y-4">
                {citations.map((citation, index) => (
                  <div key={index} className="p-4 bg-slate-50 rounded-xl border border-slate-200 hover:border-slate-300 transition-colors">
                    <div className="flex items-start space-x-3">
                      <span className="flex-shrink-0 w-7 h-7 bg-teal-100 text-teal-700 rounded-full text-sm font-semibold flex items-center justify-center">
                        {index + 1}
                      </span>
                      <div className="text-base text-slate-700 leading-relaxed font-medium">
                        {citation}
                      </div>
                    </div>
                  </div>
                ))}
              </div>
            ) : (
              <div className="text-center py-12">
                <i className="fas fa-quote-left text-4xl text-slate-300 mb-4"></i>
                <p className="text-slate-500 text-base font-medium">No citations yet</p>
                <p className="text-sm text-slate-400 mt-2">Citations will appear here when you chat with agents</p>
              </div>
            )}
          </div>
        )}

        {activePanel === 'tools' && (
          <div className="p-3">
            {agentTrace && agentTrace.agent_executions?.length > 0 ? (
              <AgentTheater 
                trace={agentTrace} 
                isVisible={true} 
                compact={false}
              />
            ) : (
              <div className="text-center py-12">
                <div className="w-16 h-16 mx-auto mb-4 bg-gradient-to-r from-purple-100 to-blue-100 rounded-full flex items-center justify-center">
                  <i className="fas fa-route text-2xl text-purple-600"></i>
                </div>
                <p className="text-slate-500 text-base font-medium">No agent executions yet</p>
                <p className="text-sm text-slate-400 mt-2">Multi-agent execution traces will appear here when multiple agents collaborate</p>
              </div>
            )}
          </div>
        )}

        {activePanel === 'pdfs' && (
          <DocViewerPanel 
            uploadedPdfs={uploadedPdfs}
            selectedPdfChunk={selectedPdfChunk}
            setSelectedPdfChunk={setSelectedPdfChunk}
          />
        )}
      </div>
    </div>
  );
};

// Doc Viewer Panel Component
function DocViewerPanel({ uploadedPdfs, selectedPdfChunk, setSelectedPdfChunk }: {
  uploadedPdfs: UploadedPdf[];
  selectedPdfChunk: any;
  setSelectedPdfChunk: (chunk: any) => void;
}) {
  const [selectedPdf, setSelectedPdf] = useState<UploadedPdf | null>(null);
  const [currentPage, setCurrentPage] = useState(0);
  const [pageData, setPageData] = useState<any>(null);
  const [loading, setLoading] = useState(false);
  const [imgLoaded, setImgLoaded] = useState<boolean | null>(null);
  const imgRef = useRef<HTMLImageElement>(null);

  useEffect(() => {
    if (selectedPdf && currentPage !== null) {
      loadPageData();
    }
  }, [selectedPdf, currentPage]);

  // Auto-select PDF when chunk is selected from citations
  useEffect(() => {
    if (selectedPdfChunk && uploadedPdfs.length > 0 && !selectedPdf) {
      // Find which PDF contains this chunk
      const findPdfWithChunk = async () => {
        for (const pdf of uploadedPdfs) {
          try {
            const response = await fetch(`/pdf/${pdf.pdf_id}/info`);
            const pdfInfo = await response.json();
            
            // Check if this PDF has the selected chunk
            const hasChunk = pdfInfo.chunks && pdfInfo.chunks.some((chunk: any) => 
              chunk.chunk_id === selectedPdfChunk
            );
            
            if (hasChunk) {
              setSelectedPdf(pdf);
              
              // Find the page containing this chunk
              const matchingChunk = pdfInfo.chunks.find((chunk: any) => 
                chunk.chunk_id === selectedPdfChunk
              );
              
              if (matchingChunk) {
                setCurrentPage(matchingChunk.page_number || 0);
              }
              break;
            }
          } catch (error) {
            console.error(`Error checking PDF ${pdf.filename}:`, error);
          }
        }
      };
      
      findPdfWithChunk();
    }
  }, [selectedPdfChunk, uploadedPdfs, selectedPdf]);

  const loadPageData = async () => {
    if (!selectedPdf) return;
    
    setLoading(true);
    try {
      const response = await fetch(`/pdf/${selectedPdf.pdf_id}/page/${currentPage}`);
      const data = await response.json();
      setPageData(data);
    } catch (error) {
      console.error('Error loading page data:', error);
      setPageData(null);
    }
    setLoading(false);
  };

  const handlePdfSelect = (pdf: UploadedPdf) => {
    setSelectedPdf(pdf);
    setCurrentPage(0);
    setPageData(null);
  };

  const nextPage = () => {
    if (selectedPdf && currentPage < selectedPdf.total_pages - 1) {
      setCurrentPage(currentPage + 1);
    }
  };

  const prevPage = () => {
    if (currentPage > 0) {
      setCurrentPage(currentPage - 1);
    }
  };

  return (
    <div className="p-6">
      <h3 className="text-lg font-semibold text-slate-800 mb-6">Document Viewer</h3>
      
      {uploadedPdfs.length === 0 ? (
        <div className="text-center py-12">
          <i className="fas fa-file-pdf text-4xl text-slate-300 mb-4"></i>
          <p className="text-slate-500 text-base font-medium">No PDFs uploaded</p>
          <p className="text-sm text-slate-400 mt-2">Drag & drop PDF files to analyze them</p>
        </div>
      ) : !selectedPdf ? (
        <div className="space-y-4">
          {uploadedPdfs.map((pdf) => (
            <div 
              key={pdf.pdf_id} 
              className="p-4 bg-slate-50 rounded-xl border border-slate-200 cursor-pointer hover:bg-slate-100 hover:border-slate-300 transition-all"
              onClick={() => handlePdfSelect(pdf)}
            >
              <div className="flex items-center space-x-4">
                <i className="fas fa-file-pdf text-red-500 text-xl"></i>
                <div className="flex-1">
                  <div className="font-semibold text-base text-slate-800 truncate mb-2">
                    {pdf.filename}
                  </div>
                  <div className="text-sm text-slate-600 space-y-1">
                    <div className="flex items-center space-x-4">
                      <span>üìÑ {pdf.total_pages} pages</span>
                      <span>üß© {pdf.chunks} chunks</span>
                      <span>‚ö° {pdf.processing_time.toFixed(2)}s</span>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          ))}
        </div>
      ) : (
        <div className="space-y-6">
          {/* PDF Header */}
          <div className="flex items-center justify-between">
            <button
              onClick={() => setSelectedPdf(null)}
              className="text-teal-600 hover:text-teal-700 text-sm font-medium flex items-center space-x-2 px-3 py-2 rounded-lg hover:bg-teal-50 transition-colors"
            >
              <i className="fas fa-arrow-left"></i>
              <span>Back to list</span>
            </button>
            <div className="text-sm text-slate-600 font-medium bg-slate-100 px-3 py-1 rounded-full">
              {selectedPdf.filename}
            </div>
          </div>

          {/* Page Navigation */}
          <div className="flex items-center justify-between py-3 px-4 bg-slate-50 rounded-xl border border-slate-200">
            <button
              onClick={prevPage}
              disabled={currentPage === 0}
              className="p-2 text-slate-600 hover:text-slate-800 disabled:opacity-30 disabled:cursor-not-allowed hover:bg-white rounded-lg transition-colors"
            >
              <i className="fas fa-chevron-left text-base"></i>
            </button>
            <span className="text-base font-medium text-slate-700">
              Page {currentPage + 1} of {selectedPdf.total_pages}
            </span>
            <button
              onClick={nextPage}
              disabled={currentPage >= selectedPdf.total_pages - 1}
              className="p-2 text-slate-600 hover:text-slate-800 disabled:opacity-30 disabled:cursor-not-allowed hover:bg-white rounded-lg transition-colors"
            >
              <i className="fas fa-chevron-right text-base"></i>
            </button>
          </div>

          {/* PDF Page Viewer */}
          <div className="relative">
            {loading ? (
              <div className="flex items-center justify-center py-8">
                <div className="animate-spin h-6 w-6 border-2 border-teal-500 border-t-transparent rounded-full"></div>
              </div>
            ) : pageData ? (
              <div className="relative border border-slate-200 rounded overflow-hidden">
                <img
                  ref={imgRef}
                  src={`data:image/png;base64,${pageData.image_base64}`}
                  alt={`Page ${currentPage + 1}`}
                  className="w-full h-auto"
                  onLoad={() => setImgLoaded(true)}
                  onError={() => setImgLoaded(false)}
                />
                
                {/* Chunk overlays */}
                {imgLoaded && pageData.chunks && imgRef.current && (() => {
                  const img = imgRef.current;
                  const scaleX = img.offsetWidth / img.naturalWidth;
                  const scaleY = img.offsetHeight / img.naturalHeight;
                  
                  return pageData.chunks.map((chunk: any, index: number) => {
                    if (!chunk.bbox) return null;
                    
                    return (
                      <div
                        key={chunk.chunk_id}
                        className={`absolute border-2 cursor-pointer transition-all ${
                          selectedPdfChunk === chunk.chunk_id 
                            ? 'border-teal-500 bg-teal-500 bg-opacity-20' 
                            : 'border-blue-500 bg-blue-500 bg-opacity-10 hover:bg-opacity-20'
                        }`}
                        style={{
                          left: `${chunk.bbox.x * scaleX}px`,
                          top: `${chunk.bbox.y * scaleY}px`, 
                          width: `${chunk.bbox.width * scaleX}px`,
                          height: `${chunk.bbox.height * scaleY}px`
                        }}
                        onClick={() => setSelectedPdfChunk(
                          selectedPdfChunk === chunk.chunk_id ? null : chunk.chunk_id
                        )}
                        title={chunk.text}
                      >
                        <div className="absolute -top-5 -left-0.5 bg-blue-500 text-white text-xs px-1 rounded">
                          {index + 1}
                        </div>
                      </div>
                    );
                  });
                })()}
              </div>
            ) : (
              <div className="flex items-center justify-center py-8 text-slate-500">
                <i className="fas fa-exclamation-triangle mr-2"></i>
                Failed to load page
              </div>
            )}
          </div>

          {/* Chunk Details */}
          {selectedPdfChunk && pageData && (
            <div className="mt-3 p-3 bg-slate-50 rounded border border-slate-200">
              <h4 className="text-sm font-medium text-slate-800 mb-2">Selected Chunk</h4>
              {(() => {
                const chunk = pageData.chunks.find((c: any) => c.chunk_id === selectedPdfChunk);
                return chunk ? (
                  <div>
                    <div className="text-xs text-slate-600 mb-1">
                      ID: {chunk.chunk_id} ‚Ä¢ Confidence: {(chunk.confidence * 100).toFixed(1)}%
                    </div>
                    <div className="text-sm text-slate-700 max-h-32 overflow-y-auto">
                      {chunk.text}
                    </div>
                  </div>
                ) : null;
              })()}
            </div>
          )}
        </div>
      )}
    </div>
  );
}

export default RightInspector;


================================================
FILE: src/config/agents.ts
================================================
import { Agent, UserType } from '../types';

export const AGENTS: Record<string, Agent> = {
  smart: {
    name: 'Smart Chat',
    icon: 'fa-brain',
    color: 'text-teal-600',
    example: 'Find a standing desk under ‚Çπ50k with 12-mo 0% APR',
    tooltip: 'AI router - finds the best agent for your query'
  },
  offerpilot: {
    name: 'OfferPilot',
    icon: 'fa-tags',
    color: 'text-blue-600',
    example: 'Show me laptops under ‚Çπ80k with financing options',
    tooltip: 'Product search with financing pre-qualification'
  },
  trustshield: {
    name: 'TrustShield',
    icon: 'fa-shield-halved',
    color: 'text-red-600',
    example: 'I got an email asking for gift cards as refund',
    tooltip: 'Fraud detection and PII protection system'
  },
  dispute: {
    name: 'Dispute',
    icon: 'fa-gavel',
    color: 'text-amber-600',
    example: 'Charged twice for ‚Çπ12,499 at Amazon on Dec 15th',
    tooltip: 'Transaction dispute resolution assistant'
  },
  collections: {
    name: 'Collections',
    icon: 'fa-handshake',
    color: 'text-green-600',
    example: 'I have ‚Çπ25k balance at 24% APR, need payment options',
    tooltip: 'Hardship and payment plan assistance'
  },
  contracts: {
    name: 'Contracts',
    icon: 'fa-file-contract',
    color: 'text-purple-600',
    example: 'Review my merchant agreement for key obligations',
    tooltip: 'Contract analysis and obligation tracking'
  },
  devcopilot: {
    name: 'DevCopilot',
    icon: 'fa-code',
    color: 'text-indigo-600',
    example: 'Generate Python code for payments API integration',
    tooltip: 'Developer tools and API integration help'
  },
  carecredit: {
    name: 'WeCare',
    icon: 'fa-heart-pulse',
    color: 'text-pink-600',
    example: 'Analyze this dental treatment estimate',
    tooltip: 'Medical/dental expense analysis'
  },
  narrator: {
    name: 'Narrator',
    icon: 'fa-chart-line',
    color: 'text-orange-600',
    example: 'Why did spend drop after 2025-07-31?',
    tooltip: 'Portfolio analytics and business insights'
  },
  imagegen: {
    name: 'ImageGen',
    icon: 'fa-image',
    color: 'text-violet-600',
    example: 'Create a futuristic city with flying cars and neon lights',
    tooltip: 'AI-powered image generation from text descriptions'
  }
};

// Define which agents are available for each persona (matching backend initialization)
export const PERSONA_AGENTS: Record<UserType, string[]> = {
  consumer: ['smart', 'offerpilot', 'dispute', 'collections', 'contracts', 'carecredit', 'narrator'],
  partner: ['smart', 'devcopilot', 'narrator', 'imagegen', 'contracts', 'offerpilot', 'carecredit'] // Core + Contextual
};

// Partner-specific agent categories
export const PARTNER_AGENT_CATEGORIES = {
  'always_on': ['trustshield'], // Runs as middleware, not selectable
  'core': ['devcopilot', 'narrator', 'imagegen', 'contracts'],
  'contextual': ['offerpilot', 'carecredit'] // Available when specifically requested
};

// Partner-specific descriptions
export const PARTNER_AGENT_DESCRIPTIONS: Record<string, string> = {
  devcopilot: 'Partner onboarding, widget/APIs, webhooks, POS integration',
  narrator: 'Portfolio analytics, campaign metrics, funnel diagnostics', 
  imagegen: 'Co-branded creative with compliant promo copy',
  contracts: 'Partner terms, data sharing, promo obligations',
  offerpilot: 'Promo structuring and assortment checks for campaigns',
  carecredit: 'Provider enrollment checks and eligibility language'
};

// Helper function to get initial agents (only Smart Chat)
export const getInitialAgents = (): Record<string, Agent> => {
  return {
    smart: AGENTS.smart
  };
};

// Helper function to get available agents for a persona
export const getAvailableAgents = (userType: UserType, availableAgentKeys?: string[]): Record<string, Agent> => {
  // If no specific agents provided, show only smart chat initially
  if (!availableAgentKeys || availableAgentKeys.length === 0) {
    return getInitialAgents();
  }
  
  const filteredAgents: Record<string, Agent> = {};
  
  availableAgentKeys.forEach(key => {
    if (AGENTS[key]) {
      // Use Partner-specific description if available
      const agentCopy = { ...AGENTS[key] };
      if (userType === 'partner' && PARTNER_AGENT_DESCRIPTIONS[key]) {
        agentCopy.tooltip = PARTNER_AGENT_DESCRIPTIONS[key];
      }
      filteredAgents[key] = agentCopy;
    }
  });
  
  return filteredAgents;
};


================================================
FILE: synchrony-demo-rules-repo/README.md
================================================
# Synchrony Demo Rules & Fixtures Repository

**Purpose:** Provide a complete, rules-ready scaffold and rich dummy content to power a
Synchrony-style multi-agent demo (OfferPilot, TrustShield, Dispute, Collections, Contracts,
DevCopilot, CareCredit, Narrator, ImageGen) across **Consumer** and **Partner** personas.

- This kit is **rules-agnostic** by default. Flip flags in `flags.json` to opt into real rules later.
- All legal/financial texts are **non-binding demo content**.

## Structure
- `flags.json` ‚Äî feature flags (`demo_no_rules`, etc.).
- `rules/` ‚Äî declarative rule sets (promos, disclosures, risk, disputes, contracts lexicons, carecredit, narrator metrics, imagegen templates, collections, routing).
- `fixtures/` ‚Äî demo data for merchants, products, users, transactions, estimates, providers, contracts, marketing templates, dev docs, narrator metrics.
- `golden_tests/` ‚Äî sample inputs & expected substrings for end-to-end checks.
- `VERSION.txt` ‚Äî repo version/date.

## Personas
- **Consumer**: offer, dispute, collections, contracts, carecredit (+ narrator-lite). TrustShield runs globally.
- **Partner**: devcopilot, narrator (full), imagegen, contracts (+ offer for promo design). TrustShield runs globally.

## Use
1. Load flags & rules into your app at boot.
2. Use fixtures for offline demo mode to avoid flaky networks.
3. Run golden tests to assert deterministic copy and disclosures.



================================================
FILE: synchrony-demo-rules-repo/flags.json
================================================
{
  "demo_no_rules": true,
  "disclosures_required": true,
  "trustshield_enabled": true,
  "allow_parallel_execution": true,
  "offline_mode": true
}



================================================
FILE: synchrony-demo-rules-repo/VERSION.txt
================================================
v0.1.0-demo (2025-08-14)



================================================
FILE: synchrony-demo-rules-repo/fixtures/merchants.json
================================================
[
  {
    "partner_id": "urbanliving",
    "name": "UrbanLiving",
    "categories": [
      "furniture",
      "home_decor"
    ]
  },
  {
    "partner_id": "homearc",
    "name": "HomeArc",
    "categories": [
      "furniture",
      "appliances"
    ]
  },
  {
    "partner_id": "wheelworks",
    "name": "WheelWorks",
    "categories": [
      "tires",
      "auto"
    ]
  }
]



================================================
FILE: synchrony-demo-rules-repo/fixtures/products.json
================================================
[
  {
    "sku": "UL-RECLINER-60K",
    "title": "UrbanLiving Recliner",
    "category": "furniture",
    "price": 60000,
    "partner_id": "urbanliving"
  },
  {
    "sku": "HA-SOFA-85K",
    "title": "HomeArc Plush Sofa",
    "category": "furniture",
    "price": 85000,
    "partner_id": "homearc"
  },
  {
    "sku": "WW-TIRE-20K",
    "title": "WheelWorks All-Season Tire Set",
    "category": "tires",
    "price": 20000,
    "partner_id": "wheelworks"
  }
]



================================================
FILE: synchrony-demo-rules-repo/fixtures/providers.json
================================================
{
  "providers": [
    {
      "provider_id": "prov_dent_01",
      "name": "SmileCraft Dental",
      "city": "Bengaluru",
      "specialty": "dental",
      "enrolled": true,
      "address": "MG Road, Bengaluru 560001",
      "phone": "+91 80 2555 0123",
      "accepts_carecredit": true,
      "next_appt_days": 3
    },
    {
      "provider_id": "prov_dent_02", 
      "name": "Indira Dental Care",
      "city": "Bengaluru",
      "specialty": "dental",
      "enrolled": true,
      "address": "Koramangala, Bengaluru 560034",
      "phone": "+91 80 2555 0456",
      "accepts_carecredit": true,
      "next_appt_days": 7
    },
    {
      "provider_id": "prov_derm_01",
      "name": "SkinGlow Clinic", 
      "city": "Bengaluru",
      "specialty": "dermatology",
      "enrolled": true,
      "address": "Brigade Road, Bengaluru 560001",
      "phone": "+91 80 2555 0789",
      "accepts_carecredit": true,
      "next_appt_days": 14
    },
    {
      "provider_id": "prov_dent_03",
      "name": "Manhattan Dental Group",
      "city": "New York",
      "specialty": "dental",
      "enrolled": true,
      "address": "123 Park Ave, New York, NY 10001",
      "phone": "(212) 555-0123",
      "accepts_carecredit": true,
      "next_appt_days": 5
    },
    {
      "provider_id": "prov_derm_02",
      "name": "Chicago Dermatology Center",
      "city": "Chicago", 
      "specialty": "dermatology",
      "enrolled": true,
      "address": "321 Michigan Ave, Chicago, IL 60601",
      "phone": "(312) 555-0321",
      "accepts_carecredit": true,
      "next_appt_days": 10
    },
    {
      "provider_id": "prov_vet_01",
      "name": "Phoenix Animal Hospital",
      "city": "Phoenix",
      "specialty": "veterinary",
      "enrolled": true,
      "address": "111 Desert Blvd, Phoenix, AZ 85001",
      "phone": "(602) 555-0111",
      "accepts_carecredit": true,
      "next_appt_days": 2
    }
  ],
  "specialties": {
    "dental": ["dental", "tooth", "teeth", "crown", "filling", "cleaning", "root canal", "extraction", "oral", "periodontal", "orthodontic"],
    "dermatology": ["skin", "mole", "dermatology", "acne", "rash", "lesion", "biopsy", "cosmetic", "botox", "laser"],
    "veterinary": ["pet", "dog", "cat", "animal", "veterinary", "vet", "vaccination", "spay", "neuter", "emergency"],
    "ophthalmology": ["eye", "vision", "glasses", "contact", "cataract", "lasik", "glaucoma", "retinal", "ophthalmology"]
  },
  "procedure_mappings": {
    "D0120": {"specialty": "dental", "name": "Periodic oral evaluation"},
    "D1110": {"specialty": "dental", "name": "Prophylaxis cleaning"}, 
    "D0274": {"specialty": "dental", "name": "Bitewing X-rays"},
    "D2140": {"specialty": "dental", "name": "Amalgam filling"},
    "D2750": {"specialty": "dental", "name": "Crown - porcelain"},
    "99213": {"specialty": "dermatology", "name": "Office visit - established patient"},
    "11100": {"specialty": "dermatology", "name": "Biopsy of skin lesion"},
    "17000": {"specialty": "dermatology", "name": "Destruction of lesion"}
  }
}



================================================
FILE: synchrony-demo-rules-repo/fixtures/transactions.json
================================================
[
  {
    "tx_id": "t1",
    "merchant": "Amazon",
    "amount": 12499,
    "date": "2025-12-15",
    "posting_date": "2025-12-16",
    "card_last4": "1111"
  },
  {
    "tx_id": "t2",
    "merchant": "Amazon",
    "amount": 12499,
    "date": "2025-12-15",
    "posting_date": "2025-12-16",
    "card_last4": "1111"
  },
  {
    "tx_id": "t3",
    "merchant": "UrbanLiving",
    "amount": 60000,
    "date": "2025-12-10",
    "posting_date": "2025-12-12",
    "card_last4": "1111"
  }
]



================================================
FILE: synchrony-demo-rules-repo/fixtures/users.json
================================================
[
  {
    "user_id": "u_consumer_01",
    "name": "Asha",
    "persona": "consumer",
    "city": "Bengaluru"
  },
  {
    "user_id": "u_partner_01",
    "name": "Ravi",
    "persona": "partner",
    "company": "HomeArc"
  }
]



================================================
FILE: synchrony-demo-rules-repo/fixtures/contracts/card_terms_urbanliving_v1.md
================================================
# UrbanLiving Card Terms (Demo)

**APR:** The APR (Annual Percentage Rate) for purchases is 29.99%. Finance charges may apply.

**Promotional Terms:** Equal Payment plan or Deferred Interest offers may be available. No interest if paid in full within the promo period. If not paid in full, interest accrues from purchase date.

**Late Fees:** A late fee may be assessed if a minimum payment is not made by the due date. Returned payment fees may apply.

**Dispute Resolution:** Binding arbitration is required, except claims eligible for small claims court. Class action waiver applies.

**Data Sharing:** We may share information with marketing partners; you can opt out by contacting support.



================================================
FILE: synchrony-demo-rules-repo/fixtures/contracts/carecredit_terms_v1.md
================================================
# CareCredit Promotional Terms (Demo)

Promotional financing is subject to credit approval and may require a minimum purchase. Equal Payment and Deferred Interest options are offered by participating providers.



================================================
FILE: synchrony-demo-rules-repo/fixtures/contracts/partner_agreement_lifestyle_v1.md
================================================
# Lifestyle Partner Agreement (Demo Excerpt)

Partner agrees to display required legal footers on all promotional materials. Data sharing with Synchrony is limited to transaction and campaign performance events. Chargeback handling follows the brand's standard playbook.



================================================
FILE: synchrony-demo-rules-repo/fixtures/dev_docs/dispute_status.md
================================================
# Dispute Status Payload Example
{
  "dispute_id":"d-1001",
  "status":"under_review",
  "next_milestone":"2025-09-01"
}



================================================
FILE: synchrony-demo-rules-repo/fixtures/dev_docs/error_handling.md
================================================
# Error Handling
Use idempotency keys for retries. Log and alert on non-2xx webhook responses.



================================================
FILE: synchrony-demo-rules-repo/fixtures/dev_docs/logging.md
================================================
# Logging & Observability
Emit a run ledger per interaction: persona, platform, agents, strategy, latency, confidence, risk, disclosures.



================================================
FILE: synchrony-demo-rules-repo/fixtures/dev_docs/onboarding.md
================================================
# Partner Onboarding (Demo)
1) Request sandbox keys
2) Embed prequalification widget
3) Handle callbacks and store outcomes



================================================
FILE: synchrony-demo-rules-repo/fixtures/dev_docs/webhooks.md
================================================
# Webhooks ‚Äî Dispute Status
POST JSON to your endpoint on status changes: `intake|compiled|ready_to_submit|submitted|under_review`.



================================================
FILE: synchrony-demo-rules-repo/fixtures/dev_docs/widget_embed.md
================================================
# Prequalification Widget Embed
Drop-in script with `onStart` and `onComplete` events. Pass minimal context (amount, partner_id).



================================================
FILE: synchrony-demo-rules-repo/fixtures/disputes/sample_intake_duplicate.md
================================================
### Dispute Intake ‚Äî Duplicate Charge
User: Asha (u_consumer_01)
Merchant: Amazon
Allegation: Duplicate charge for ‚Çπ12,499 on Dec 15
Evidence: Statement screenshot (2 entries), order ID #AMZ-9912, chat attempt on Dec 16
Requested outcome: Reverse duplicate charge



================================================
FILE: synchrony-demo-rules-repo/fixtures/disputes/sample_intake_not_received.md
================================================
### Dispute Intake ‚Äî Item Not Received
User: Asha (u_consumer_01)
Merchant: UrbanLiving
Allegation: Recliner not delivered
Evidence: Order confirmation #UL-2231, expected delivery Dec 20, merchant contact Dec 22
Requested outcome: Refund or delivery



================================================
FILE: synchrony-demo-rules-repo/fixtures/estimates/dental_implant_estimate_01.txt
================================================
Clinic: SmileCraft Dental
City: Bengaluru

Items:
- CBCT Scan (D0367): ‚Çπ3,500
- Surgical Placement of Implant (D6010): ‚Çπ48,000
- Abutment (D6056): ‚Çπ12,000
- Crown (D6065): ‚Çπ22,500

Notes: Self-pay. Wants 12-month 0% if available.



================================================
FILE: synchrony-demo-rules-repo/fixtures/estimates/dermatology_laser_01.txt
================================================
Clinic: SkinGlow
City: Bengaluru

Items:
- Laser resurfacing session: ‚Çπ18,000
- Follow-up consultation: ‚Çπ1,500

Notes: Inquire about 6-month equal payments.



================================================
FILE: synchrony-demo-rules-repo/fixtures/marketing/email_templates/header_equal_payment.md
================================================
# Template: Email Header ‚Äî Equal Payment
Headline: Make it yours with easy monthly payments
Legal Footer: {DISCLOSURE(equal_payment_generic)}



================================================
FILE: synchrony-demo-rules-repo/fixtures/marketing/signage_templates/a4_deferred_interest.md
================================================
# Template: A4 In-Store ‚Äî Deferred Interest
Headline: No interest if paid in full in {MONTHS} months
Subhead: Available on qualifying purchases
CTA: Ask a store associate
Footer (legal): {DISCLOSURE(deferred_interest_generic)}



================================================
FILE: synchrony-demo-rules-repo/fixtures/marketing/signage_templates/a4_equal_payment.md
================================================
# Template: A4 In-Store ‚Äî Equal Payment
Headline: Upgrade today with easy monthly payments
Subhead: Spread your purchase over {MONTHS} months
CTA: Apply in-store or online
Footer (legal): {DISCLOSURE(equal_payment_generic)}



================================================
FILE: synchrony-demo-rules-repo/fixtures/marketing/social_templates/square_equal_payment.md
================================================
# Template: Social Square ‚Äî Equal Payment
Caption: Equal monthly payments for {MONTHS} months. Subject to credit approval.
Legal: {DISCLOSURE(equal_payment_generic)}



================================================
FILE: synchrony-demo-rules-repo/fixtures/narrator/kpi_definitions.md
================================================
# KPI Definitions (Demo)
- Approval Rate = approved_apps / total_apps
- Promo Uptake = promo_txn / total_txn
- Revolve Rate = balance_revolving / total_balance
- Charge-off Rate = charge_offs / total_accounts
- Funnel Conversion = completed / started



================================================
FILE: synchrony-demo-rules-repo/fixtures/narrator/mock_portfolio_metrics.json
================================================
{
  "date": "2025-08-14",
  "previous_date": "2025-08-07",
  "segments": [
    {
      "platform": "digital",
      "approval_rate": 0.42,
      "promo_uptake": 0.31,
      "revolve_rate": 0.55,
      "charge_off_rate": 0.023,
      "funnel_conversion": 0.18,
      "acquisition_cost": 125.50,
      "portfolio_yield": 0.21,
      "total_apps": 15420,
      "approved_apps": 6476,
      "promo_txn": 2845,
      "total_txn": 9178,
      "balance_revolving": 42500000,
      "total_balance": 77270000,
      "charge_offs": 354,
      "total_accounts": 15420,
      "completed": 2777,
      "started": 15420,
      "marketing_spend": 1935210,
      "new_accounts": 15420,
      "interest_revenue": 16226700,
      "avg_balance": 77270000,
      "previous_values": {
        "approval_rate": 0.45,
        "promo_uptake": 0.28,
        "revolve_rate": 0.52,
        "charge_off_rate": 0.021
      }
    },
    {
      "platform": "carecredit",
      "approval_rate": 0.58,
      "promo_uptake": 0.47,
      "revolve_rate": 0.28,
      "charge_off_rate": 0.012,
      "funnel_conversion": 0.35,
      "acquisition_cost": 87.25,
      "portfolio_yield": 0.19,
      "total_apps": 8750,
      "approved_apps": 5075,
      "promo_txn": 2386,
      "total_txn": 5075,
      "balance_revolving": 14210000,
      "total_balance": 50750000,
      "charge_offs": 105,
      "total_accounts": 8750,
      "completed": 3063,
      "started": 8750,
      "marketing_spend": 763437,
      "new_accounts": 8750,
      "interest_revenue": 9642500,
      "avg_balance": 50750000,
      "previous_values": {
        "approval_rate": 0.55,
        "promo_uptake": 0.43,
        "revolve_rate": 0.31,
        "charge_off_rate": 0.015
      }
    },
    {
      "platform": "home_auto",
      "approval_rate": 0.49,
      "promo_uptake": 0.36,
      "revolve_rate": 0.41,
      "charge_off_rate": 0.018,
      "funnel_conversion": 0.28,
      "acquisition_cost": 95.75,
      "portfolio_yield": 0.23,
      "total_apps": 12100,
      "approved_apps": 5929,
      "promo_txn": 2134,
      "total_txn": 5929,
      "balance_revolving": 24895000,
      "total_balance": 60720000,
      "charge_offs": 218,
      "total_accounts": 12100,
      "completed": 3388,
      "started": 12100,
      "marketing_spend": 1158575,
      "new_accounts": 12100,
      "interest_revenue": 13965600,
      "avg_balance": 60720000,
      "previous_values": {
        "approval_rate": 0.52,
        "promo_uptake": 0.33,
        "revolve_rate": 0.38,
        "charge_off_rate": 0.016
      }
    }
  ]
}



================================================
FILE: synchrony-demo-rules-repo/golden_tests/collections_plan_demo.json
================================================
{
  "input": "I can't pay this month \u2014 what can I do?",
  "expect_contains": [
    "recommended plan",
    "schedule",
    "total cost",
    "disclosures"
  ]
}



================================================
FILE: synchrony-demo-rules-repo/golden_tests/contracts_detection_demo.json
================================================
{
  "input": "Explain the promo and late fee rules from this T&C",
  "expect_contains": [
    "Promotional Terms",
    "Late Fees",
    "clause",
    "ask legal"
  ]
}



================================================
FILE: synchrony-demo-rules-repo/golden_tests/devcopilot_widget_embed_demo.json
================================================
{
  "input": "How do I embed the prequal widget?",
  "expect_contains": [
    "3-step",
    "onComplete",
    "sandbox",
    "anchored citation"
  ]
}



================================================
FILE: synchrony-demo-rules-repo/golden_tests/dispute_duplicate_charge_demo.json
================================================
{
  "input": "I was charged twice for \u20b912,499 at Amazon on Dec 15",
  "expect_contains": [
    "Duplicate charge",
    "eligibility window",
    "evidence",
    "status",
    "next update"
  ]
}



================================================
FILE: synchrony-demo-rules-repo/golden_tests/imagegen_marketing_flyer_demo.json
================================================
{
  "input": "Create an A4 in-store flyer for 12-mo equal payments",
  "expect_contains": [
    "preview",
    "headline",
    "CTA",
    "legal",
    "equal_payment_generic"
  ]
}



================================================
FILE: synchrony-demo-rules-repo/golden_tests/offerpilot_carecredit_demo.json
================================================
{
  "input": "Here is my dental implant estimate. Can I do 12-month 0%?",
  "expect_contains": [
    "items",
    "12-month",
    "Equal monthly payments",
    "No interest if paid in full",
    "Disclosure"
  ]
}



================================================
FILE: synchrony-demo-rules-repo/rules/carecredit.yml
================================================
procedures:
  dental_implant:
    typical_cost_range: [60000, 200000]
    min_purchase_for_promo: 20000
    specialty: "dental"
  orthodontics:
    typical_cost_range: [30000, 120000]
    min_purchase_for_promo: 15000
    specialty: "dental"
  dermatology_laser:
    typical_cost_range: [15000, 80000]
    min_purchase_for_promo: 10000
    specialty: "derm"

oop_estimator:
  deductible_default: 1500.00
  coinsurance_default: 0.20
  caveat: "Illustrative only ‚Äî confirm with insurer and provider."

oopp_defaults:
  deductible:
    individual: 1500.00
    family: 3000.00
  coinsurance:
    in_network: 0.20
    out_network: 0.40
  copay:
    primary_care: 25.00
    specialist: 50.00
    emergency: 150.00

financing_options:
  equal_payment:
    terms: [6, 12, 18, 24, 36, 48, 60]
    min_amount: 200.00
    max_amount: 25000.00
    apr_range:
      promotional: 0.00
      standard: [14.90, 26.99]
  deferred_interest:
    terms: [6, 12, 18, 24]
    min_amount: 200.00
    max_amount: 25000.00
    promo_periods: [6, 12, 18, 24]
    standard_apr: 26.99

disclosures:
  carecredit_generic: "CareCredit healthcare financing subject to credit approval. Minimum monthly payments required. See carecredit.com for details."
  equal_payment_generic: "Equal monthly payments required. Subject to credit approval. See terms and conditions."
  deferred_interest_generic: "If promotional balance is not paid in full by end of promotional period, interest will be charged from purchase date. Subject to credit approval."

provider_search:
  max_results: 3
  search_radius_miles: 25
  appointment_priority_weight: 0.6
  distance_priority_weight: 0.4

specialty_mappings:
  dental: ["dental", "oral", "tooth", "teeth"]
  dermatology: ["skin", "derm", "cosmetic"]
  veterinary: ["pet", "animal", "vet"]
  ophthalmology: ["eye", "vision", "optical"]
  plastic_surgery: ["plastic", "cosmetic", "aesthetic"]



================================================
FILE: synchrony-demo-rules-repo/rules/collections.yml
================================================
plans:
  interest_only:
    name: "Interest-Only Payments"
    duration_months: 3
    description: "Pay only interest charges for a temporary period"
    payment_type: "interest_only"
    min_payment_percent: 0.02  # 2% of balance
    disclosure_key: "collections_generic"
    eligibility:
      min_balance: 100.00
      max_balance: 10000.00
  short_deferral:
    name: "Short-Term Deferral"
    duration_months: 2
    description: "Skip payments temporarily, with interest accruing"
    payment_type: "deferred"
    min_payment_percent: 0.00  # No payments during deferral
    disclosure_key: "collections_generic"
    eligibility:
      min_balance: 50.00
      max_balance: 5000.00
  re_age:
    name: "Account Re-Aging"
    duration_months: 6
    description: "Restart payment schedule with reduced amounts"
    payment_type: "reduced"
    min_payment_percent: 0.015  # 1.5% of balance
    disclosure_key: "collections_generic"
    eligibility:
      min_balance: 200.00
      max_balance: 25000.00
  fixed_term:
    name: "Fixed Payment Plan"
    duration_months: 12
    description: "Fixed monthly payments to resolve balance"
    payment_type: "fixed"
    min_payment_percent: 0.025  # 2.5% of balance minimum
    disclosure_key: "collections_generic"
    eligibility:
      min_balance: 300.00
      max_balance: 50000.00

scoring:
  weights:
    affordability: 0.4    # Customer's ability to pay
    bank_npv: 0.3        # Bank's net present value
    cure_probability: 0.3 # Likelihood of successful resolution

simulation_params:
  demo_apr: 0.2399  # 23.99% APR for simulations
  late_fee: 39.00
  processing_fee: 0.00
  discount_rate: 0.08  # For NPV calculations

disclosures:
  collections_generic: "Payment plan terms subject to approval. Interest and fees may apply. Contact us for full terms and conditions."



================================================
FILE: synchrony-demo-rules-repo/rules/contracts_lexicon.yml
================================================
clauses:
  apr:
    keywords: ["APR", "annual percentage", "interest rate", "finance charge"]
  promotional_terms:
    keywords: ["equal payment", "deferred interest", "paid in full", "promo period", "no interest"]
  late_fees:
    keywords: ["late fee", "returned payment", "penalty", "grace period"]
  dispute_resolution:
    keywords: ["arbitration", "binding", "small claims", "waiver", "class action"]
  data_sharing:
    keywords: ["share", "third party", "marketing partners", "opt out", "sell"]
risk_flags:
  missing_clause: "Key clause not found"
  conflicting_numbers: "Conflicting numerical terms detected"
  promo_ambiguity: "Promotional wording lacks 'paid in full' condition"
ask_legal_triggers:
  - "conflicting_numbers"
  - "promo_ambiguity"
  - "missing_clause"



================================================
FILE: synchrony-demo-rules-repo/rules/disclosures.yml
================================================
disclosures:
  equal_payment_generic: |
    Equal monthly payments required for the promo period. Taxes and fees may apply.
    Missing or late payments may incur fees. Demo copy ‚Äî consult actual issuer terms.
  deferred_interest_generic: |
    No interest if paid in full within the promo period. If not paid in full, interest
    accrues from the purchase date at the standard rate. Demo copy ‚Äî confirm actual terms.
  collections_generic: |
    Payment plan availability is subject to eligibility. Illustrative figures only for demo.
  carecredit_generic: |
    Subject to credit approval. Minimum purchase may be required for promotional financing.
    Ask your provider for details. Demo copy.
  marketing_generic: |
    Offers subject to credit approval and change. Demo assets; not for production use.
keys:
  - equal_payment_generic
  - deferred_interest_generic
  - collections_generic
  - carecredit_generic
  - marketing_generic



================================================
FILE: synchrony-demo-rules-repo/rules/dispute.yml
================================================
categories:
  duplicate_charge:
    required_evidence: ["statement_screenshot", "merchant_name", "date", "amount"]
    narrative_hint: "Two identical charges in close proximity without a second purchase."
  item_not_received:
    required_evidence: ["order_confirmation", "expected_delivery", "merchant_contact_attempt"]
    narrative_hint: "Order not delivered by expected date; merchant contact unsuccessful."
  wrong_amount:
    required_evidence: ["receipt", "statement_screenshot", "correct_amount"]
    narrative_hint: "Charged higher than agreed."
  canceled_but_charged:
    required_evidence: ["cancellation_confirmation", "statement_screenshot"]
    narrative_hint: "Charge posted after cancellation."
demo_clocks:
  posting_window_days: 60
  purchase_window_days: 90
status_pipeline: ["intake", "compiled", "ready_to_submit", "submitted", "under_review"]
likelihood_buckets: ["low", "medium", "high"]



================================================
FILE: synchrony-demo-rules-repo/rules/imagegen.yml
================================================
templates:
  a4_instore:
    format: "A4"
    dimensions: "8.5x11"
    orientation: "portrait"
    layout: ["headline", "subhead", "price_callout", "cta", "legal_footer"]
    brand_placement: "top_left"
  a4_counter:
    format: "A4" 
    dimensions: "8.5x11"
    orientation: "landscape"
    layout: ["headline", "body", "cta", "legal_footer"]
    brand_placement: "top_center"
  social_square:
    format: "square"
    dimensions: "1080x1080"
    orientation: "square"
    layout: ["headline", "caption_with_legal"]
    brand_placement: "bottom_right"
  social_story:
    format: "story"
    dimensions: "1080x1920"
    orientation: "portrait"
    layout: ["headline", "body", "cta", "legal_footer"]
    brand_placement: "top_center"
  email_header:
    format: "email"
    dimensions: "1200x400" 
    orientation: "landscape"
    layout: ["headline", "cta", "legal_footer"]
    brand_placement: "left_side"

co_brand_settings:
  default_hex: "#2E86DE"
  placeholder_style: "initials_in_circle"
  brand_positions:
    - "top_left"
    - "top_center"
    - "top_right" 
    - "bottom_left"
    - "bottom_right"
    - "left_side"

dynamic_disclosures:
  equal_payment:
    triggers: ["equal payment", "equal monthly", "same payment", "fixed payment"]
    disclosure_id: "equal_payment_generic"
  deferred_interest:
    triggers: ["no interest", "deferred interest", "0% interest", "interest-free"]
    disclosure_id: "deferred_interest_generic"
  promotional_rate:
    triggers: ["promotional rate", "intro rate", "special rate", "limited time"]
    disclosure_id: "promotional_rate_generic"

banned_phrases:
  guaranteed_approval:
    phrases: ["guaranteed approval", "guaranteed financing", "everyone approved"]
    replacement: "subject to credit approval"
    severity: "high"
  instant_decision:
    phrases: ["instant approval", "immediate approval", "instant decision"]
    replacement: "quick credit decision" 
    severity: "medium"
  no_credit_check:
    phrases: ["no credit check", "skip credit check", "credit check not required"]
    replacement: "streamlined application process"
    severity: "high"

legal_footers:
  equal_payment_generic: "Equal monthly payments required. Subject to credit approval. See terms and conditions."
  deferred_interest_generic: "If promotional balance is not paid in full by end of promotional period, interest will be charged from purchase date. Subject to credit approval."
  promotional_rate_generic: "Promotional rate applies for limited time. Standard rates apply after promotional period. Subject to credit approval."



================================================
FILE: synchrony-demo-rules-repo/rules/narrator.yml
================================================
kpis:
  approval_rate:
    formula: "approved_apps / total_apps"
    caveats: "Sampling bias; seasonality."
    thresholds:
      low: 0.60
      medium: 0.75
      high: 0.85
  promo_uptake:
    formula: "promo_txn / total_txn"
    caveats: "Category mix effects."
    thresholds:
      low: 0.15
      medium: 0.25
      high: 0.35
  revolve_rate:
    formula: "balance_revolving / total_balance"
    caveats: "Macroeconomic sensitivity."
    thresholds:
      low: 0.40
      medium: 0.55
      high: 0.70
  charge_off_rate:
    formula: "charge_offs / total_accounts"
    caveats: "Lagging indicator."
    thresholds:
      low: 0.02
      medium: 0.05
      high: 0.08
  funnel_conversion:
    formula: "completed / started"
    caveats: "Attribution leakage."
    thresholds:
      low: 0.20
      medium: 0.40
      high: 0.60
  acquisition_cost:
    formula: "marketing_spend / new_accounts"
    caveats: "Channel attribution complexity."
    thresholds:
      low: 50.00
      medium: 100.00
      high: 150.00
  portfolio_yield:
    formula: "interest_revenue / avg_balance"
    caveats: "Rate mix dependent."
    thresholds:
      low: 0.18
      medium: 0.22
      high: 0.26

insight_ranking:
  weights:
    impact: 0.6
    confidence: 0.4

action_suggestions:
  low_approval_rate:
    action: "promo_tuning"
    target_agent: "offer"
    rationale: "Adjust qualification criteria or promotional terms"
  low_promo_uptake:
    action: "launch_asset" 
    target_agent: "imagegen"
    rationale: "Create targeted promotional materials"
  high_charge_off:
    action: "portfolio_review"
    target_agent: "collections"
    rationale: "Review risk management policies"
  low_funnel_conversion:
    action: "launch_asset"
    target_agent: "imagegen"  
    rationale: "Optimize application flow visuals"



================================================
FILE: synchrony-demo-rules-repo/rules/prequalification.yml
================================================
demo_scoring:
  buckets:
    - name: "eligible"
      price_upper: 300000
      explanation: "Within typical range for demo prequalification."
    - name: "uncertain"
      price_upper: 600000
      explanation: "Borderline amount; additional info may be required."
    - name: "ineligible"
      price_upper: 999999999
      explanation: "Above demo threshold."
notes: "Deterministic hashing of user & price -> choose bucket for repeatability."



================================================
FILE: synchrony-demo-rules-repo/rules/promotions.yml
================================================
# Demo promotions for several partners (illustrative)
partners:
  - partner_id: "urbanliving"
    categories_allowed: ["furniture", "home_decor"]
    promos:
      - type: "equal_payment"
        months: 12
        min_purchase: 20000
        disclosure_key: "equal_payment_generic"
      - type: "deferred_interest"
        months: 12
        min_purchase: 20000
        disclosure_key: "deferred_interest_generic"
  - partner_id: "homearc"
    categories_allowed: ["furniture", "appliances"]
    promos:
      - type: "equal_payment"
        months: 6
        min_purchase: 10000
        disclosure_key: "equal_payment_generic"
      - type: "equal_payment"
        months: 18
        min_purchase: 40000
        disclosure_key: "equal_payment_generic"
  - partner_id: "wheelworks"
    categories_allowed: ["tires", "auto"]
    promos:
      - type: "deferred_interest"
        months: 6
        min_purchase: 5000
        disclosure_key: "deferred_interest_generic"
generic_defaults:
  equal_payment_months: [6, 12, 18]
  deferred_interest_months: [6, 12]



================================================
FILE: synchrony-demo-rules-repo/rules/routing.yml
================================================
persona_rules:
  strong_signals:
    partner: ["co-branded", "POS integration", "webhooks", "SDK", "merchant settlement", "signage", "sandbox", "developer", "API keys"]
    consumer: ["my card", "my statement", "charged", "late fee", "minimum due", "hardship", "CareCredit", "treatment", "provider"]
  weighted_keywords:
    partner:
      - ["co-branded", 0.5]
      - ["widget", 0.4]
      - ["webhook", 0.4]
      - ["campaign", 0.3]
    consumer:
      - ["charged", 0.5]
      - ["refund", 0.4]
      - ["APR", 0.3]
      - ["0% APR", 0.3]
      - ["treatment", 0.4]
platform_rules:
  carecredit: ["treatment", "provider", "dental", "derm", "clinic", "OOPP", "CareCredit"]
  digital: ["e-com", "transaction", "chargeback", "card", "merchant", "product"]
  home_auto: ["appliance", "furniture", "contractor", "tires", "home", "auto"]
  diversified_value: ["value", "discount", "mass market"]
  lifestyle: ["fashion", "lifestyle", "home decor"]
decision_thresholds:
  persona_high: 0.6
  persona_low: 0.4



================================================
FILE: synchrony-demo-rules-repo/rules/run_ledger_schema.json
================================================
{
  "type": "object",
  "required": [
    "persona",
    "platform",
    "strategy",
    "agents",
    "trust",
    "synthesis"
  ],
  "properties": {
    "persona": {
      "type": "string"
    },
    "platform": {
      "type": "string"
    },
    "strategy": {
      "type": "string"
    },
    "agents": {
      "type": "array"
    },
    "synthesis": {
      "type": "object"
    },
    "trust": {
      "type": "object"
    },
    "fallback": {
      "type": "object"
    }
  }
}



================================================
FILE: synchrony-demo-rules-repo/rules/trustshield.yml
================================================
pii_patterns:
  email: "(?i)[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}"
  phone: "(?i)(\\+?\\d[\\d\\s-]{7,}\\d)"
  address_hint: "(?i)\\d+\\s+[A-Za-z0-9\\s]+"
risk_phrases_block:
  - "gift card refund"
  - "crypto refund"
  - "send me OTP"
  - "no credit check"
  - "guaranteed approval"
risk_phrases_warn:
  - "wire urgently"
  - "zelle overpayment"
  - "account unlock fee"
brand_lookalike_patterns:
  - "(?i)synchrony-?support\\.(co|info|top)"
link_checks:
  max_redirects: 3
  min_domain_age_days: 30
responses:
  high_risk_action: "BlockAndShowSafeActions"
  medium_risk_action: "WarnAndContinue"
  low_risk_action: "Pass"


