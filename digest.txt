Directory structure:
‚îî‚îÄ‚îÄ synch-genai-poc/
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ AGENT_ARCHITECTURE.md
    ‚îú‚îÄ‚îÄ index.html
    ‚îú‚îÄ‚îÄ main.py
    ‚îú‚îÄ‚îÄ package.json
    ‚îú‚îÄ‚îÄ postcss.config.js
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ tailwind.config.js
    ‚îú‚îÄ‚îÄ tsconfig.json
    ‚îú‚îÄ‚îÄ tsconfig.node.json
    ‚îú‚îÄ‚îÄ vite.config.ts
    ‚îú‚îÄ‚îÄ app/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ router.py
    ‚îÇ   ‚îú‚îÄ‚îÄ agents/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ carecredit.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_agent.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collections.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contracts.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ devcopilot.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dispute.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ imagegen.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ narrator.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ offerpilot.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trustshield.py
    ‚îÇ   ‚îú‚îÄ‚îÄ contracts/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ merchant_agreement.md
    ‚îÇ   ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ financing_offers.json
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hardship_policies.json
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ marketplace_catalog.json
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics_schema.json
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ provider_catalog.json
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ providers.json
    ‚îÇ   ‚îú‚îÄ‚îÄ kb/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contract_ontology.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_privacy_policy.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ disputes_policy.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ promotional_terms.md
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ security_guidelines.md
    ‚îÇ   ‚îú‚îÄ‚îÄ llm/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini.py
    ‚îÇ   ‚îú‚îÄ‚îÄ openapi/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ payments.json
    ‚îÇ   ‚îú‚îÄ‚îÄ rag/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py
    ‚îÇ   ‚îú‚îÄ‚îÄ services/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pdf_processor.py
    ‚îÇ   ‚îú‚îÄ‚îÄ tools/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini_chat.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tavily_search.py
    ‚îÇ   ‚îî‚îÄ‚îÄ ui/
    ‚îÇ       ‚îú‚îÄ‚îÄ index.html
    ‚îÇ       ‚îî‚îÄ‚îÄ modern.html
    ‚îú‚îÄ‚îÄ metrics/
    ‚îÇ   ‚îú‚îÄ‚îÄ credit_metrics.csv
    ‚îÇ   ‚îú‚îÄ‚îÄ delinquency_rates.csv
    ‚îÇ   ‚îú‚îÄ‚îÄ portfolio_spend.csv
    ‚îÇ   ‚îî‚îÄ‚îÄ promo_performance.csv
    ‚îî‚îÄ‚îÄ src/
        ‚îú‚îÄ‚îÄ App.tsx
        ‚îú‚îÄ‚îÄ index.css
        ‚îú‚îÄ‚îÄ main.tsx
        ‚îú‚îÄ‚îÄ types.ts
        ‚îú‚îÄ‚îÄ components/
        ‚îÇ   ‚îú‚îÄ‚îÄ ChatMessage.tsx
        ‚îÇ   ‚îú‚îÄ‚îÄ ChatPane.tsx
        ‚îÇ   ‚îú‚îÄ‚îÄ Header.tsx
        ‚îÇ   ‚îú‚îÄ‚îÄ LeftRail.tsx
        ‚îÇ   ‚îú‚îÄ‚îÄ MarkdownRenderer.tsx
        ‚îÇ   ‚îî‚îÄ‚îÄ RightInspector.tsx
        ‚îî‚îÄ‚îÄ config/
            ‚îî‚îÄ‚îÄ agents.ts

================================================
FILE: README.md
================================================
# Synch GenAI PoC

A complete GenAI-powered financial services platform with 8 specialized AI agents, intelligent document processing, and enhanced markdown rendering.

## Quick Start

### Install Dependencies
```bash
# Install Node.js dependencies
npm install

# Install Python dependencies (if not already done)
pip install -r requirements.txt
```

### Development
```bash
# Start backend server (Terminal 1)
python main.py

# Start frontend development server (Terminal 2)
npm run dev
```

### Production
```bash
# Build frontend
npm run build

# Start production server
python main.py
```

## Features

### üß† Intelligent Fallback System
- **LLM Knowledge Fallback**: Uses the LLM's training knowledge when documents are insufficient
- **Web Search Integration**: Tavily search for current information
- **Smart Document Assessment**: AI-powered evaluation of document relevance and coverage

### üé® Enhanced UI
- **React + TypeScript**: Modern, type-safe frontend with proper markdown rendering
- **Syntax Highlighting**: Beautiful code blocks with language detection
- **Drag & Drop PDF**: Upload documents directly in chat
- **Fallback Indicators**: Visual feedback for knowledge sources used

### ü§ñ 8 Specialized AI Agents
- **Smart Chat**: AI router with intelligent fallbacks
- **OfferPilot**: Product search with financing
- **Dispute Copilot**: Credit card dispute assistance
- **Collections**: Hardship and payment plans
- **DevCopilot**: Code generation and API docs
- **CareCredit**: Medical expense analysis
- **Narrator**: Portfolio analytics
- **ImageGen**: AI image generation

## Environment Variables

Create `.env` file with:
```bash
GOOGLE_API_KEY=your_gemini_api_key
VISION_AGENT_API_KEY=your_landing_ai_key
TAVILY_API_KEY=your_tavily_key  # Optional
ALLOW_TAVILY=true  # Optional
```

## Architecture

- **Backend**: FastAPI with intelligent RAG and fallback systems
- **Frontend**: React + TypeScript with proper markdown rendering
- **AI**: Google Gemini with document assessment and knowledge fallbacks
- **PDF Processing**: Landing AI with bounding box extraction
- **Security**: PII redaction and TrustShield content filtering


================================================
FILE: AGENT_ARCHITECTURE.md
================================================
# Synch GenAI PoC - Agent Architecture Documentation

## System Overview

The Synch GenAI PoC is a comprehensive financial services chatbot platform with 8 specialized AI agents, intelligent routing, and PDF processing capabilities. The system is designed for defensive security applications with built-in PII protection and fraud detection.

## Agent Architecture Flow

```mermaid
flowchart TD
    %% User Input Layer
    User[üë§ User Input] --> UI[üñ•Ô∏è React Frontend]
    
    %% Routing Layer
    UI --> Router{üß≠ Smart Router}
    Router --> |"Gemini Classification"| GeminiClass[ü§ñ Gemini Classifier]
    GeminiClass --> |"confidence < 0.6"| KeywordFallback[üìù Keyword Analysis]
    KeywordFallback --> RouterDecision[üìä Final Route Decision]
    GeminiClass --> |"confidence >= 0.6"| RouterDecision
    
    %% Smart Chat Special Flow
    Router --> |"smart agent"| SmartChat[üß† Smart Chat Agent]
    SmartChat --> |"Route to best agent"| AutoRoute[üîÑ Auto-route to specialist]
    AutoRoute --> Agent1[Agent Selection]
    
    %% Agent Layer
    RouterDecision --> Agent1
    Agent1 --> |"offer"| OfferPilot[üè∑Ô∏è OfferPilot]
    Agent1 --> |"trust"| TrustShield[üõ°Ô∏è TrustShield]
    Agent1 --> |"dispute"| DisputeCopilot[‚öñÔ∏è Dispute Copilot]
    Agent1 --> |"collections"| Collections[üí≥ Collections Agent]
    Agent1 --> |"devcopilot"| DevCopilot[üíª DevCopilot]
    Agent1 --> |"carecredit"| CareCredit[‚ù§Ô∏è CareCredit]
    Agent1 --> |"narrator"| Narrator[üìä Portfolio Narrator]
    Agent1 --> |"imagegen"| ImageGen[üé® Image Generator]
    
    %% RAG System
    subgraph RAG["üóÑÔ∏è RAG Knowledge Base"]
        DocStore[(üìö Document Store)]
        Embedder[üî¢ Gemini Embeddings]
        Retriever[üîç Vector Retriever]
        MarkdownDocs[üìÑ Markdown Documents]
        PDFDocs[üìÑ PDF Documents]
    end
    
    %% PDF Processing Pipeline
    PDFUpload[üì§ PDF Upload] --> PDFProcessor[üîÑ LandingAI PDF Processor]
    PDFProcessor --> PDFChunks[üìë Text Chunks + Bounding Boxes]
    PDFChunks --> DocStore
    
    %% Agent Processing
    OfferPilot --> RAG
    TrustShield --> RAG
    TrustShield --> PII[üîê PII Detection/Redaction]
    DisputeCopilot --> RAG
    Collections --> RAG
    DevCopilot --> APIRef[üìñ API Reference]
    CareCredit --> RAG
    Narrator --> RAG
    ImageGen --> StableDiffusion[üé® Stable Diffusion API]
    
    %% Fallback System
    subgraph Fallbacks["üîÑ Intelligent Fallbacks"]
        LLMFallback[üß† LLM Knowledge Fallback]
        WebSearch[üåê Web Search Fallback]
        TavilyLegacy[üîç Tavily Search Legacy]
    end
    
    SmartChat --> |"insufficient docs"| Fallbacks
    
    %% Response Processing
    OfferPilot --> ResponseProc[üì§ Response Processing]
    TrustShield --> ResponseProc
    DisputeCopilot --> ResponseProc
    Collections --> ResponseProc
    DevCopilot --> ResponseProc
    CareCredit --> ResponseProc
    Narrator --> ResponseProc
    ImageGen --> ResponseProc
    
    ResponseProc --> |"with citations"| UI
    ResponseProc --> |"confidence score"| UI
    ResponseProc --> |"source tracking"| UI
    
    %% UI Components
    UI --> ChatPane[üí¨ Chat Interface]
    UI --> AgentSelector[üéõÔ∏è Agent Selector]
    UI --> PDFViewer[üìÑ PDF Viewer]
    UI --> CitationsPanel[üìù Citations Panel]
    UI --> ToolTrace[üîß Tool Trace Panel]
    
    %% Styling
    classDef userLayer fill:#e1f5fe
    classDef routingLayer fill:#f3e5f5
    classDef agentLayer fill:#e8f5e8
    classDef ragLayer fill:#fff3e0
    classDef uiLayer fill:#fce4ec
    
    class User,UI userLayer
    class Router,GeminiClass,KeywordFallback,RouterDecision,SmartChat,AutoRoute routingLayer
    class OfferPilot,TrustShield,DisputeCopilot,Collections,DevCopilot,CareCredit,Narrator,ImageGen agentLayer
    class RAG,DocStore,Embedder,Retriever,MarkdownDocs,PDFDocs ragLayer
    class ChatPane,AgentSelector,PDFViewer,CitationsPanel,ToolTrace uiLayer
```

## Agent Detailed Specifications

### üß† Smart Chat Agent
- **Purpose**: Intelligent routing hub that analyzes queries and routes to the most appropriate specialist agent
- **Key Features**:
  - Uses Gemini LLM for intent classification
  - Confidence-based routing with fallback mechanisms
  - Supports LLM knowledge and web search fallbacks when RAG documents are insufficient
  - Real-time document assessment for relevance
- **Fallback Options**: LLM Knowledge, Web Search, Legacy Tavily
- **Example Query**: *"Find a standing desk under ‚Çπ50k with 12-mo 0% APR"*

### üè∑Ô∏è OfferPilot
- **Purpose**: Product search and financing options specialist
- **Core Functions**:
  - Product discovery with budget constraints
  - Financing option analysis (APR, payment plans)
  - Promotional offer matching
  - Cross-sell opportunity identification
- **Integration**: Connected to RAG system for product knowledge
- **Example Query**: *"Show me wireless headphones under $200"*

### üõ°Ô∏è TrustShield
- **Purpose**: Real-time fraud detection and PII protection system
- **Advanced Capabilities**:
  - Multi-layer scam pattern recognition
  - PII detection and automatic redaction using Microsoft Presidio
  - Risk scoring with confidence metrics
  - Safety guidance recommendations
  - Threat evidence compilation
- **Security Features**: Built-in defensive measures, no malicious code generation
- **Example Query**: *"Someone called asking for my SSN to verify my account"*

### ‚öñÔ∏è Dispute Copilot
- **Purpose**: Credit card and transaction dispute assistance
- **Specialized Functions**:
  - Dispute classification and merit analysis
  - Evidence collection guidance
  - Chargeback process navigation
  - Documentation requirement checklists
- **Integration**: RAG-powered with dispute resolution knowledge base
- **Example Query**: *"I was charged twice for the same purchase"*

### üí≥ Collections Agent
- **Purpose**: Payment assistance and hardship support
- **Customer-Focused Features**:
  - Payment plan options analysis
  - Hardship assessment and solutions
  - Customer state tracking (balance, APR, bucket status)
  - Empathetic communication patterns
- **Data Integration**: Customer account state analysis
- **Example Query**: *"I need help with payment plan options"*

### üíª DevCopilot
- **Purpose**: Technical support and API documentation assistant
- **Developer Tools**:
  - Code generation for payment processing
  - API endpoint documentation
  - Integration guidance and troubleshooting
  - SDK usage examples
  - Multi-language support (Python, JavaScript, Java, etc.)
- **Knowledge Base**: Technical documentation and best practices
- **Example Query**: *"Generate Python code for payment processing"*

### ‚ù§Ô∏è CareCredit
- **Purpose**: Healthcare and medical expense analysis specialist
- **Healthcare Focus**:
  - Medical treatment estimate analysis
  - Dental procedure cost breakdowns
  - Healthcare financing option evaluation
  - Insurance coverage assessment
- **Specialized Knowledge**: Medical billing and healthcare financing
- **Example Query**: *"Analyze this dental treatment estimate"*

### üìä Portfolio Narrator
- **Purpose**: Business intelligence and portfolio analytics
- **Analytics Capabilities**:
  - Spending pattern analysis
  - Portfolio performance insights
  - Trend identification and explanation
  - Business metrics interpretation
- **Data Sources**: Financial data and portfolio information
- **Example Query**: *"Why did spend drop after 2025-07-31?"*

### üé® ImageGen Agent
- **Purpose**: AI-powered visual content generation
- **Creative Features**:
  - Text-to-image generation using Stable Diffusion
  - Style customization options
  - Marketing visual creation
  - Concept visualization
- **API Integration**: Stable Diffusion API
- **Example Query**: *"Create a futuristic city with flying cars and neon lights"*

## System Architecture Components

### üß≠ Intelligent Routing System
- **Primary**: Gemini-powered intent classification
- **Fallback**: Keyword-based pattern matching
- **Confidence Thresholds**: Dynamic routing based on confidence scores
- **Default Routing**: TrustShield for security when confidence is low

### üóÑÔ∏è RAG (Retrieval-Augmented Generation) System
- **Document Store**: ChromaDB for vector storage
- **Embeddings**: Google Gemini embedding model
- **Retriever**: Semantic similarity search
- **Content Types**: Markdown documents, PDF processing with bounding boxes

### üìÑ PDF Processing Pipeline
- **Processor**: LandingAI PDF processing service
- **Features**: Text extraction, bounding box detection, chunk segmentation
- **Integration**: Automatic indexing into RAG system
- **UI**: Interactive PDF viewer with clickable text chunks

### üîÑ Fallback Mechanisms
1. **Document Assessment**: LLM evaluates if retrieved documents contain sufficient information
2. **LLM Knowledge**: Falls back to pre-trained model knowledge when documents insufficient
3. **Web Search**: Real-time web search for current information
4. **Legacy Tavily**: Backup search integration

### üîê Security & Privacy Features
- **PII Detection**: Automatic detection using Microsoft Presidio
- **PII Redaction**: Real-time anonymization of sensitive data
- **Defensive Design**: All agents designed for defensive security use only
- **Fraud Detection**: Multi-pattern scam and threat detection

## API Endpoints

### Smart Chat Endpoints
- `POST /chat` - Main chat interface with fallback options
- `POST /agent/{agent_name}` - Direct agent invocation

### PDF Management
- `POST /upload/pdf` - PDF upload and processing
- `GET /pdf/{pdf_id}/page/{page_num}` - Get PDF page with annotations
- `GET /pdf/{pdf_id}/info` - Get PDF metadata and chunks

### Agent-Specific Endpoints
- `POST /agent/offerpilot` - Product search queries
- `POST /agent/dispute` - Dispute assistance
- `POST /agent/collections` - Payment assistance  
- `POST /agent/devcopilot` - Technical support
- `POST /agent/carecredit` - Healthcare analysis
- `POST /agent/narrator` - Business analytics
- `POST /agent/imagegen` - Image generation
- `POST /agent/trustshield` - Fraud detection

## Frontend Architecture

### React Components
- **ChatPane**: Main conversation interface with PDF drag-and-drop
- **LeftRail**: Agent selection sidebar with examples
- **RightInspector**: Tabbed panel for citations, tool traces, and PDF viewer
- **Header**: Settings controls with elegant toggle switches

### Key Features
- **Real-time Chat**: WebSocket-style communication with loading states
- **PDF Integration**: Drag-and-drop upload with interactive viewer
- **Agent Switching**: Seamless switching between specialized agents
- **Citation Tracking**: Source attribution for all responses
- **Tool Tracing**: Visibility into agent decision-making process

## Deployment & Configuration

### Environment Requirements
- Python 3.8+ with FastAPI
- Node.js 16+ with React/TypeScript
- Google Gemini API access
- LandingAI API for PDF processing
- Optional: Tavily API for web search

### Development Workflow
```bash
# Backend
python main.py

# Frontend
npm run dev
```

### Production Considerations
- CORS configuration for cross-origin requests
- Environment variable management
- API key security
- Rate limiting and usage monitoring

## Security & Compliance

### Defensive Security Focus
- **PII Protection**: Automatic detection and redaction
- **Fraud Prevention**: Real-time threat analysis
- **No Malicious Code**: Designed exclusively for defensive use
- **Source Tracking**: Full audit trail of information sources

### Privacy Features
- **Local Processing**: No persistent user data storage
- **Redaction**: Sensitive information automatically masked
- **Citations**: Transparent source attribution
- **User Control**: Fallback options user-configurable

This architecture provides a robust, scalable, and secure foundation for financial services AI assistance with specialized expertise across multiple domains.


================================================
FILE: index.html
================================================
<!doctype html>
<html lang="en" class="h-full">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GenAI Studio (Hackathon PoC)</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  </head>
  <body class="h-full bg-slate-50">
    <div id="root" class="h-full"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>


================================================
FILE: main.py
================================================
"""
Synch GenAI PoC - Main FastAPI Application
Complete app wiring with middleware, agent endpoints, and UI
"""

import os
import re
import logging
import time
from pathlib import Path
from typing import Optional, Dict, Any, Union

from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request, Response, UploadFile, File
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
from pydantic import BaseModel, Field
from dotenv import load_dotenv
import json

from app.rag.core import init_docstore, GeminiEmbedder, index_markdown, build_retriever, retrieve
from app.llm.gemini import chat_with_context, chat_with_context_and_fallback
from app.tools.tavily_search import web_search_into_docstore, WebDisabled
from app.router import route
from app.agents.trustshield import TrustShield
from app.agents.offerpilot import OfferPilot
from app.agents.dispute import DisputeCopilot
from app.agents.collections import CollectionsAdvisor, CustomerState
from app.agents.devcopilot import DevCopilot
from app.agents.carecredit import CareCredit
from app.agents.narrator import PortfolioIntelNarrator
from app.agents.imagegen import ImageGenAgent
from app.services.pdf_processor import LandingAIPDFProcessor, ProcessedPDF

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=getattr(logging, os.getenv("LOG_LEVEL", "INFO")),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Global components
docstore = None
embedder = None
retriever = None
agents = {}  # Agent registry
pdf_processor = None
uploaded_pdfs = {}  # Store processed PDFs

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Initialize components on startup and cleanup on shutdown"""
    global docstore, embedder, retriever, agents, pdf_processor
    
    try:
        logger.info("Initializing document store...")
        docstore = init_docstore()
        
        logger.info("Initializing Gemini embedder...")
        embedder = GeminiEmbedder()
        
        logger.info("Indexing markdown documents...")
        doc_count = index_markdown(docstore, embedder)
        logger.info(f"Indexed {doc_count} document chunks")
        
        logger.info("Building retriever...")
        retriever = build_retriever(docstore)
        
        logger.info("Initializing PDF processor...")
        pdf_processor = LandingAIPDFProcessor()
        
        logger.info("Initializing agents...")
        agents = {
            'trustshield': TrustShield(docstore=docstore, embedder=embedder, retriever=retriever),
            'offerpilot': OfferPilot(docstore=docstore, embedder=embedder, retriever=retriever),
            'dispute': DisputeCopilot(docstore=docstore, embedder=embedder, retriever=retriever),
            'collections': CollectionsAdvisor(docstore=docstore, embedder=embedder, retriever=retriever),
            'devcopilot': DevCopilot(),
            'carecredit': CareCredit(docstore=docstore, embedder=embedder, retriever=retriever),
            'narrator': PortfolioIntelNarrator(docstore=docstore, embedder=embedder, retriever=retriever),
            'imagegen': ImageGenAgent(),
        }
        
        logger.info(f"Application startup complete - {len(agents)} agents initialized")
    except Exception as e:
        logger.error(f"Failed to initialize application: {e}")
        raise
    
    yield
    
    # Cleanup on shutdown
    logger.info("Application shutdown complete")

# Initialize FastAPI app with lifespan
app = FastAPI(
    title="Synch GenAI PoC",
    description="Complete GenAI-powered financial services platform",
    version="2.0.0",
    lifespan=lifespan
)

# PII Redactor Middleware
class PIIRedactorMiddleware(BaseHTTPMiddleware):
    """Redacts PAN, SSN, CVV from request bodies"""
    
    def __init__(self, app):
        super().__init__(app)
        # PII patterns
        self.patterns = {
            'PAN': re.compile(r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b'),
            'SSN': re.compile(r'\b\d{3}-?\d{2}-?\d{4}\b'),
            'CVV': re.compile(r'\b\d{3,4}\b(?=.*(?:cvv|cvc|security|code))', re.IGNORECASE),
        }
    
    async def dispatch(self, request: Request, call_next):
        # Only process POST requests with JSON bodies
        if request.method == "POST" and request.headers.get("content-type", "").startswith("application/json"):
            body = await request.body()
            if body:
                try:
                    body_str = body.decode('utf-8')
                    original_str = body_str
                    
                    # Redact PII patterns
                    for pii_type, pattern in self.patterns.items():
                        body_str = pattern.sub(f'[REDACTED_{pii_type}]', body_str)
                    
                    # Log if redaction occurred
                    if body_str != original_str:
                        logger.warning(f"PII redaction performed on request to {request.url.path}")
                    
                    # Create new request with redacted body
                    from fastapi.requests import Request as FastAPIRequest
                    async def receive():
                        return {"type": "http.request", "body": body_str.encode('utf-8')}
                    
                    # Modify the request
                    request._body = body_str.encode('utf-8')
                    
                except Exception as e:
                    logger.error(f"Error in PII redaction: {e}")
        
        response = await call_next(request)
        return response

# TrustShield Blocking Middleware
class TrustShieldMiddleware(BaseHTTPMiddleware):
    """TrustShield security scanning and blocking"""
    
    def __init__(self, app):
        super().__init__(app)
        self.protected_endpoints = ['/chat', '/agent/', '/api/']
    
    async def dispatch(self, request: Request, call_next):
        # Check if endpoint needs protection
        needs_protection = any(request.url.path.startswith(endpoint) 
                             for endpoint in self.protected_endpoints)
        
        if needs_protection and request.method == "POST":
            # Get request body for TrustShield scan
            body = await request.body()
            if body and agents.get('trustshield'):
                try:
                    body_data = json.loads(body.decode('utf-8'))
                    
                    # Extract text to scan (look for common field names)
                    text_to_scan = ""
                    for field in ['message', 'query', 'narrative', 'question', 'estimate_text']:
                        if field in body_data:
                            text_to_scan = body_data[field]
                            break
                    
                    if text_to_scan:
                        # Run TrustShield scan
                        shield_result = agents['trustshield'].scan(text_to_scan)
                        
                        if shield_result["decision"] == "block":
                            logger.warning(f"TrustShield BLOCKED request to {request.url.path}")
                            return JSONResponse(
                                status_code=403,
                                content={
                                    "error": "Request blocked by security policy",
                                    "reason": shield_result.get('next_step', {}).get('label', 'Security violation detected'),
                                    "blocked": True
                                }
                            )
                        
                        # Replace original text with redacted version
                        for field in ['message', 'query', 'narrative', 'question', 'estimate_text']:
                            if field in body_data:
                                body_data[field] = shield_result["redacted_text"]
                        
                        # Update request body
                        new_body = json.dumps(body_data).encode('utf-8')
                        request._body = new_body
                    
                except Exception as e:
                    logger.error(f"Error in TrustShield middleware: {e}")
        
        response = await call_next(request)
        return response

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:8000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Add middleware (order matters - CORS first, then PII redaction, then TrustShield)
app.add_middleware(TrustShieldMiddleware)
app.add_middleware(PIIRedactorMiddleware)

# Startup event handler has been moved to lifespan function above

# Request/Response models
class ChatRequest(BaseModel):
    message: str
    allow_tavily: Optional[bool] = False
    allow_llm_knowledge: Optional[bool] = True
    allow_web_search: Optional[bool] = False

class ChatResponse(BaseModel):
    response: str
    agent: str
    confidence: float
    sources: list[str] = []
    used_tavily: bool = False
    fallback_used: Optional[str] = None
    document_assessment: Optional[dict] = None
    image_data: Optional[str] = None
    image_format: Optional[str] = None

class OfferRequest(BaseModel):
    query: str
    budget: Optional[float] = None

class DisputeRequest(BaseModel):
    narrative: str
    merchant: Optional[str] = None
    amount: Optional[float] = None
    uploaded_text: Optional[str] = None

class CollectionsRequest(BaseModel):
    balance: float
    apr: float
    bucket: str
    income_monthly: Optional[float] = None
    expenses_monthly: Optional[float] = None
    preferences: Optional[dict] = None

class DevCopilotRequest(BaseModel):
    service: str
    endpoint: Optional[str] = None
    lang: str = "python"
    sample: Optional[dict] = None

class CareCreditRequest(BaseModel):
    estimate_text: str
    location: Optional[str] = None
    insurance: Optional[dict] = None

class NarratorRequest(BaseModel):
    question: str

class ImageGenRequest(BaseModel):
    prompt: str
    include_text: Optional[bool] = True
    style_hints: Optional[list[str]] = None

# Serve static files from React build (only if directory exists)
if Path("dist/assets").exists():
    app.mount("/assets", StaticFiles(directory="dist/assets"), name="assets")

# UI Routes
@app.get("/", response_class=HTMLResponse)
async def root():
    """Serve the React UI"""
    try:
        # Try to serve the built React app first
        ui_path = Path("dist/index.html")
        if ui_path.exists():
            return HTMLResponse(content=ui_path.read_text(encoding='utf-8'), status_code=200)
        
        # Fallback to the old HTML version
        fallback_path = Path("app/ui/modern.html")
        if fallback_path.exists():
            return HTMLResponse(content=fallback_path.read_text(encoding='utf-8'), status_code=200)
        
        return HTMLResponse(content="<h1>UI not found</h1><p>Please run 'npm run build' to build the React app</p>", status_code=404)
    except Exception as e:
        return HTMLResponse(content=f"<h1>Error loading UI</h1><p>{str(e)}</p>", status_code=500)

@app.get("/classic", response_class=HTMLResponse)
async def classic_ui():
    """Serve the classic UI as backup"""
    return HTMLResponse(content=UI_HTML, status_code=200)

# Smart Chat Endpoint
@app.post("/chat", response_model=ChatResponse)
async def smart_chat(request: ChatRequest):
    """Smart chat with router dispatch to appropriate agent"""
    if not all([docstore, embedder, retriever]) or not agents:
        raise HTTPException(status_code=500, detail="System components not initialized")
    
    try:
        logger.info(f"Processing chat message: {request.message}")
        
        # Route the query to appropriate agent
        routing_result = route(request.message)
        routed_agent = routing_result["agent"]
        confidence = routing_result["confidence"]
        
        logger.info(f"Query routed to '{routed_agent}' agent with confidence {confidence:.3f}")
        
        # Initialize Tavily usage flag
        used_tavily = False
        
        # Dispatch to specific agent based on routing
        if routed_agent == "offerpilot" and "offerpilot" in agents:
            agent_result = agents["offerpilot"].process_query(request.message)
            response_text = f"Found {len(agent_result.items)} products. Pre-qualification: {'Eligible' if agent_result.prequal.eligible else 'Not eligible'}"
            sources = [f"Products: {len(agent_result.items)}", f"Pre-qual: {agent_result.prequal.reason}"]
            
        elif routed_agent == "dispute" and "dispute" in agents:
            agent_result = agents["dispute"].process_dispute(request.message)
            response_text = f"Dispute triage: {agent_result.triage}. Merchant resolution available."
            sources = [f"Triage: {agent_result.triage}", f"Resolution steps: {len(agent_result.merchant_resolution.checklist)}"]
            
        elif routed_agent == "collections" and "collections" in agents:
            # Need customer state for collections - create from message parsing
            customer_state = CustomerState(balance=1000.0, apr=24.99, bucket="30-60")
            agent_result = agents["collections"].process_hardship_request(customer_state)
            response_text = f"Generated {len(agent_result.plans)} hardship plans"
            sources = [f"Plans available: {len(agent_result.plans)}"]
            
        elif routed_agent == "imagegen" and "imagegen" in agents:
            from app.agents.imagegen import ImageGenRequest as AgentImageGenRequest
            image_request = AgentImageGenRequest(prompt=request.message)
            agent_result = agents["imagegen"].process_request(image_request)
            
            if agent_result.success:
                response_text = agent_result.generated_text or f"Generated image: {request.message}"
                sources = [f"Image generated successfully", f"Format: {agent_result.image_format}"]
                
                # Add image data to response (we'll handle this in UI)
                return ChatResponse(
                    response=response_text,
                    agent=routed_agent,
                    confidence=confidence,
                    sources=sources,
                    used_tavily=used_tavily,
                    image_data=agent_result.image_base64,  # Add this field
                    image_format=agent_result.image_format
                )
            else:
                response_text = f"Failed to generate image: {agent_result.error_message}"
                sources = ["Image generation failed"]
            
        else:
            # Fallback to RAG-based response with intelligent fallbacks
            retrieved_docs = retrieve(retriever, embedder, request.message, k=5)
            
            # Check for Tavily web search (legacy support)
            if (request.allow_tavily and 
                os.getenv("ALLOW_TAVILY", "false").lower() == "true" and
                (len(retrieved_docs) < 2 or 
                 (len(retrieved_docs) > 0 and all(doc.get('score', 0) < 0.7 for doc in retrieved_docs)))):
                try:
                    web_docs = web_search_into_docstore(docstore, embedder, request.message, max_results=3)
                    used_tavily = len(web_docs) > 0
                    logger.info(f"Used Tavily web search: {used_tavily}")
                    
                    # Re-retrieve documents now that we have web content in the docstore
                    if used_tavily:
                        logger.info("Re-retrieving documents including web search results...")
                        retrieved_docs = retrieve(retriever, embedder, request.message, k=5)
                        logger.info(f"Re-retrieved {len(retrieved_docs)} documents with web content")
                        
                except Exception as e:
                    logger.warning(f"Web search failed: {e}")
                    used_tavily = False
            
            # Use intelligent fallback system
            fallback_result = chat_with_context_and_fallback(
                query=request.message,
                context_documents=retrieved_docs,
                allow_llm_knowledge=request.allow_llm_knowledge,
                allow_web_search=request.allow_web_search
            )
            
            response_text = fallback_result["response"]
            fallback_used = fallback_result["fallback_used"]
            confidence = fallback_result["confidence"]
            document_assessment = fallback_result["document_assessment"]
            
            # Build sources list with assessment info
            sources = []
            if retrieved_docs:
                sources.extend([f"{doc['filename']} - Score: {doc['score']:.3f}" for doc in retrieved_docs[:3]])
            
            # Add fallback information
            if fallback_used:
                sources.append(f"üîÑ Fallback used: {fallback_used}")
                sources.append(f"üìä Document quality: {document_assessment.get('document_quality_score', 0):.2f}")
            
            # Add document assessment details
            if document_assessment:
                assessment_reason = document_assessment.get('reason', 'No assessment')
                sources.append(f"üîç Assessment: {assessment_reason}")
        
        # Store fallback info for response
        fallback_used_final = fallback_used if 'fallback_used' in locals() else None
        document_assessment_final = document_assessment if 'document_assessment' in locals() else None
        
        # Add routing info to sources
        sources.insert(0, f"üéØ Routed to: {routed_agent} ({confidence:.1%} confidence)")
        
        return ChatResponse(
            response=response_text,
            agent=routed_agent,
            confidence=confidence,
            sources=sources,
            used_tavily=used_tavily,
            fallback_used=fallback_used_final,
            document_assessment=document_assessment_final
        )
        
    except Exception as e:
        logger.error(f"Error processing chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Agent-specific endpoints for tabbed UI testing
@app.post("/agent/offerpilot")
async def agent_offerpilot(request: OfferRequest):
    """OfferPilot direct endpoint"""
    if "offerpilot" not in agents:
        raise HTTPException(status_code=500, detail="OfferPilot not initialized")
    
    try:
        result = agents["offerpilot"].process_query(request.query, request.budget)
        return result.dict()
    except Exception as e:
        logger.error(f"OfferPilot error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/dispute")
async def agent_dispute(request: DisputeRequest):
    """Dispute Copilot direct endpoint"""
    if "dispute" not in agents:
        raise HTTPException(status_code=500, detail="DisputeCopilot not initialized")
    
    try:
        result = agents["dispute"].process_dispute(
            narrative=request.narrative,
            merchant=request.merchant,
            amount=request.amount,
            uploaded_text=request.uploaded_text
        )
        return result.dict()
    except Exception as e:
        logger.error(f"DisputeCopilot error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/collections")
async def agent_collections(request: CollectionsRequest):
    """Collections Advisor direct endpoint"""
    if "collections" not in agents:
        raise HTTPException(status_code=500, detail="CollectionsAdvisor not initialized")
    
    try:
        customer_state = CustomerState(
            balance=request.balance,
            apr=request.apr,
            bucket=request.bucket,
            income_monthly=request.income_monthly,
            expenses_monthly=request.expenses_monthly,
            preferences=request.preferences
        )
        result = agents["collections"].process_hardship_request(customer_state)
        return result.dict()
    except Exception as e:
        logger.error(f"CollectionsAdvisor error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/devcopilot")
async def agent_devcopilot(request: DevCopilotRequest):
    """DevCopilot direct endpoint"""
    if "devcopilot" not in agents:
        raise HTTPException(status_code=500, detail="DevCopilot not initialized")
    
    try:
        result = agents["devcopilot"].generate_code_guide(
            service=request.service,
            endpoint=request.endpoint,
            lang=request.lang,
            sample=request.sample
        )
        return result.dict()
    except Exception as e:
        logger.error(f"DevCopilot error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/carecredit")
async def agent_carecredit(request: CareCreditRequest):
    """CareCredit direct endpoint"""
    if "carecredit" not in agents:
        raise HTTPException(status_code=500, detail="CareCredit not initialized")
    
    try:
        result = agents["carecredit"].process_estimate(
            estimate_text=request.estimate_text,
            location=request.location,
            insurance=request.insurance
        )
        return result.dict()
    except Exception as e:
        logger.error(f"CareCredit error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/narrator")
async def agent_narrator(request: NarratorRequest):
    """Portfolio Intel Narrator direct endpoint"""
    if "narrator" not in agents:
        raise HTTPException(status_code=500, detail="PortfolioIntelNarrator not initialized")
    
    try:
        result = agents["narrator"].process_question(request.question)
        return result.dict()
    except Exception as e:
        logger.error(f"PortfolioIntelNarrator error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/imagegen")
async def agent_imagegen(request: ImageGenRequest):
    """ImageGen direct endpoint"""
    if "imagegen" not in agents:
        raise HTTPException(status_code=500, detail="ImageGen not initialized")
    
    try:
        result = agents["imagegen"].process_request(request)
        return result.dict()
    except Exception as e:
        logger.error(f"ImageGen error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/trustshield")
async def agent_trustshield(request: dict):
    """TrustShield direct endpoint"""
    if "trustshield" not in agents:
        raise HTTPException(status_code=500, detail="TrustShield not initialized")
    
    try:
        text = request.get("text", "")
        result = agents["trustshield"].scan(text)
        return result
    except Exception as e:
        logger.error(f"TrustShield error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload/pdf")
async def upload_pdf(file: UploadFile = File(...)):
    """Upload and process PDF document"""
    if not pdf_processor:
        raise HTTPException(status_code=500, detail="PDF processor not initialized")
    
    # Validate file type
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Only PDF files are supported")
    
    # Limit file size (10MB)
    max_size = 10 * 1024 * 1024
    
    try:
        # Save uploaded file temporarily
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            content = await file.read()
            
            if len(content) > max_size:
                raise HTTPException(status_code=400, detail="File too large (max 10MB)")
            
            tmp_file.write(content)
            tmp_path = tmp_file.name
        
        # Process PDF
        logger.info(f"Processing uploaded PDF: {file.filename}")
        processed_pdf = pdf_processor.process_pdf(tmp_path, chunk_strategy="semantic")
        
        # Store processed PDF
        pdf_id = f"pdf_{int(time.time())}_{len(uploaded_pdfs)}"
        uploaded_pdfs[pdf_id] = processed_pdf
        
        # Add chunks to document store for RAG
        documents = []
        for chunk in processed_pdf.chunks:
            doc = chunk.to_document(file.filename)
            doc.meta["pdf_id"] = pdf_id
            documents.append(doc)
        
        # Generate embeddings and add to docstore
        if documents:
            texts = [doc.content for doc in documents]
            embeddings = embedder.embed_texts(texts)
            
            for doc, embedding in zip(documents, embeddings):
                doc.embedding = embedding
            
            docstore.write_documents(documents)
            logger.info(f"Added {len(documents)} PDF chunks to docstore")
        
        # Clean up temporary file
        os.unlink(tmp_path)
        
        return {
            "success": True,
            "pdf_id": pdf_id,
            "filename": file.filename,
            "total_pages": processed_pdf.total_pages,
            "chunks_extracted": len(processed_pdf.chunks),
            "processing_time": processed_pdf.processing_time,
            "file_size": processed_pdf.file_size
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error processing PDF upload: {e}")
        # Clean up temp file if it exists
        if 'tmp_path' in locals():
            try:
                os.unlink(tmp_path)
            except:
                pass
        raise HTTPException(status_code=500, detail=f"PDF processing failed: {str(e)}")

@app.get("/pdf/{pdf_id}/info")
async def get_pdf_info(pdf_id: str):
    """Get detailed information about a processed PDF including chunks"""
    if pdf_id not in uploaded_pdfs:
        raise HTTPException(status_code=404, detail="PDF not found")
    
    pdf = uploaded_pdfs[pdf_id]
    return {
        "pdf_id": pdf_id,
        "filename": pdf.filename,
        "total_pages": pdf.total_pages,
        "chunks": [
            {
                "chunk_id": chunk.chunk_id,
                "text": chunk.text[:100] + "..." if len(chunk.text) > 100 else chunk.text,
                "page_number": chunk.page_number,
                "bbox": chunk.bbox.to_dict(),
                "confidence": chunk.confidence
            }
            for chunk in pdf.chunks
        ],
        "processing_time": pdf.processing_time
    }

@app.get("/pdf/{pdf_id}")
async def get_pdf_summary(pdf_id: str):
    """Get summary information about a processed PDF"""
    if pdf_id not in uploaded_pdfs:
        raise HTTPException(status_code=404, detail="PDF not found")
    
    pdf = uploaded_pdfs[pdf_id]
    return {
        "pdf_id": pdf_id,
        "filename": pdf.filename,
        "total_pages": pdf.total_pages,
        "chunks": len(pdf.chunks),
        "processing_time": pdf.processing_time
    }

@app.get("/pdf/{pdf_id}/page/{page_num}")
async def get_pdf_page(pdf_id: str, page_num: int):
    """Get a specific page image with optional bounding box overlays"""
    if pdf_id not in uploaded_pdfs:
        raise HTTPException(status_code=404, detail="PDF not found")
    
    pdf = uploaded_pdfs[pdf_id]
    
    if page_num >= len(pdf.page_images) or page_num < 0:
        raise HTTPException(status_code=404, detail="Page not found")
    
    # Get chunks for this page
    page_chunks = [chunk for chunk in pdf.chunks if chunk.page_number == page_num]
    
    return {
        "pdf_id": pdf_id,
        "page_number": page_num,
        "image_base64": pdf.page_images[page_num],
        "chunks": [
            {
                "chunk_id": chunk.chunk_id,
                "text": chunk.text[:200] + "..." if len(chunk.text) > 200 else chunk.text,
                "bbox": chunk.bbox.to_dict(),
                "confidence": chunk.confidence
            }
            for chunk in page_chunks
        ]
    }

# Health endpoint
@app.get("/healthz")
async def health_check():
    """Enhanced health check with docstore size and env flags"""
    try:
        docstore_size = docstore.count_documents() if docstore else 0
        
        env_flags = {
            "ALLOW_TAVILY": os.getenv("ALLOW_TAVILY", "false").lower() == "true",
            "LOG_LEVEL": os.getenv("LOG_LEVEL", "INFO"),
            "DEBUG": os.getenv("DEBUG", "false").lower() == "true",
        }
        
        agent_status = {name: agent is not None for name, agent in agents.items()}
        
        return {
            "status": "healthy" if docstore and len(agents) > 0 else "degraded",
            "docstore_size": docstore_size,
            "agents_initialized": len(agents),
            "agent_status": agent_status,
            "env_flags": env_flags,
            "components": {
                "docstore": docstore is not None,
                "embedder": embedder is not None, 
                "retriever": retriever is not None,
            }
        }
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}

# Minimal SPA UI
UI_HTML = """
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Synch GenAI PoC</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif; background: #f8fafc; }
        .container { max-width: 1200px; margin: 0 auto; padding: 20px; }
        .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px 0; margin-bottom: 30px; border-radius: 12px; }
        .header h1 { text-align: center; font-size: 2.5rem; font-weight: 700; margin-bottom: 10px; }
        .header p { text-align: center; font-size: 1.1rem; opacity: 0.9; }
        
        .tabs { display: flex; flex-wrap: wrap; gap: 8px; margin-bottom: 30px; background: white; padding: 20px; border-radius: 12px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
        .tab { padding: 12px 20px; background: #f1f5f9; border: none; border-radius: 8px; cursor: pointer; font-weight: 500; transition: all 0.2s; color: #64748b; }
        .tab:hover { background: #e2e8f0; }
        .tab.active { background: #3b82f6; color: white; }
        
        .tab-content { display: none; background: white; padding: 30px; border-radius: 12px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
        .tab-content.active { display: block; }
        
        .form-group { margin-bottom: 20px; }
        .form-group label { display: block; font-weight: 600; margin-bottom: 8px; color: #374151; }
        .form-group input, .form-group textarea, .form-group select { width: 100%; padding: 12px 16px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 14px; transition: border-color 0.2s; }
        .form-group input:focus, .form-group textarea:focus, .form-group select:focus { outline: none; border-color: #3b82f6; }
        .form-group textarea { min-height: 100px; resize: vertical; }
        
        .btn { background: #3b82f6; color: white; border: none; padding: 14px 28px; border-radius: 8px; font-weight: 600; cursor: pointer; font-size: 14px; transition: background 0.2s; }
        .btn:hover { background: #2563eb; }
        .btn:disabled { background: #9ca3af; cursor: not-allowed; }
        
        .result { margin-top: 30px; padding: 20px; background: #f8fafc; border-radius: 8px; border-left: 4px solid #3b82f6; }
        .result-json { background: #1f2937; color: #f9fafb; padding: 20px; border-radius: 8px; font-family: 'SF Mono', Monaco, monospace; font-size: 13px; overflow-x: auto; white-space: pre; }
        
        .loading { display: none; text-align: center; padding: 20px; color: #6b7280; }
        .loading.show { display: block; }
        
        .error { background: #fef2f2; border: 1px solid #fecaca; color: #dc2626; padding: 16px; border-radius: 8px; margin-top: 20px; }
        
        .example { background: #f0f9ff; border: 1px solid #bae6fd; padding: 16px; border-radius: 8px; margin-bottom: 20px; font-size: 14px; }
        .example-title { font-weight: 600; color: #0369a1; margin-bottom: 8px; }
        
        .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-top: 20px; }
        .card { background: white; padding: 20px; border-radius: 8px; border: 1px solid #e5e7eb; }
        .card h3 { margin-bottom: 12px; color: #374151; }
        .card-content { color: #6b7280; font-size: 14px; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ü§ñ Synch GenAI PoC</h1>
            <p>Complete AI-powered financial services platform with 8 specialized agents</p>
        </div>
        
        <div class="tabs">
            <button class="tab active" onclick="showTab('chat')">üí¨ Smart Chat</button>
            <button class="tab" onclick="showTab('offerpilot')">üõçÔ∏è OfferPilot</button>
            <button class="tab" onclick="showTab('dispute')">‚öñÔ∏è Dispute Copilot</button>
            <button class="tab" onclick="showTab('collections')">üí≥ Collections</button>
            <button class="tab" onclick="showTab('devcopilot')">üë®‚Äçüíª DevCopilot</button>
            <button class="tab" onclick="showTab('carecredit')">üè• CareCredit</button>
            <button class="tab" onclick="showTab('narrator')">üìä Portfolio Intel</button>
            <button class="tab" onclick="showTab('trustshield')">üõ°Ô∏è TrustShield</button>
        </div>
        
        <!-- Smart Chat Tab -->
        <div id="chat" class="tab-content active">
            <div class="example">
                <div class="example-title">üí° Smart Chat Example:</div>
                "I want to buy a laptop under $1000 with 0% financing"
            </div>
            <div class="form-group">
                <label>Message:</label>
                <textarea id="chat-message" placeholder="Ask anything - the router will send you to the right agent..."></textarea>
            </div>
            <div class="form-group">
                <label><input type="checkbox" id="chat-tavily"> Allow web search (Tavily)</label>
            </div>
            <button class="btn" onclick="runChat()">üí¨ Send Message</button>
            <div class="loading" id="chat-loading">Processing your message...</div>
            <div id="chat-result"></div>
        </div>
        
        <!-- OfferPilot Tab -->
        <div id="offerpilot" class="tab-content">
            <div class="example">
                <div class="example-title">üõçÔ∏è OfferPilot Example:</div>
                Query: "office desk" | Budget: 600
            </div>
            <div class="form-group">
                <label>Search Query:</label>
                <input type="text" id="offer-query" placeholder="office desk" value="office desk">
            </div>
            <div class="form-group">
                <label>Budget (optional):</label>
                <input type="number" id="offer-budget" placeholder="600" value="600">
            </div>
            <button class="btn" onclick="runOfferPilot()">üõçÔ∏è Search Products</button>
            <div class="loading" id="offerpilot-loading">Searching products...</div>
            <div id="offerpilot-result"></div>
        </div>
        
        <!-- Dispute Copilot Tab -->
        <div id="dispute" class="tab-content">
            <div class="example">
                <div class="example-title">‚öñÔ∏è Dispute Example:</div>
                "I was charged twice for the same Amazon purchase on my Synchrony card"
            </div>
            <div class="form-group">
                <label>Dispute Narrative:</label>
                <textarea id="dispute-narrative" placeholder="Describe your dispute..." value="I was charged twice for the same Amazon purchase on my Synchrony card"></textarea>
            </div>
            <div class="form-group">
                <label>Merchant (optional):</label>
                <input type="text" id="dispute-merchant" placeholder="Amazon" value="Amazon">
            </div>
            <div class="form-group">
                <label>Amount (optional):</label>
                <input type="number" id="dispute-amount" placeholder="150.00" value="150.00">
            </div>
            <button class="btn" onclick="runDispute()">‚öñÔ∏è Process Dispute</button>
            <div class="loading" id="dispute-loading">Processing dispute...</div>
            <div id="dispute-result"></div>
        </div>
        
        <!-- Collections Tab -->
        <div id="collections" class="tab-content">
            <div class="example">
                <div class="example-title">üí≥ Collections Example:</div>
                Balance: 5000 | APR: 24.99% | Bucket: "90-120"
            </div>
            <div class="form-group">
                <label>Balance:</label>
                <input type="number" id="collections-balance" placeholder="5000" value="5000">
            </div>
            <div class="form-group">
                <label>APR (%):</label>
                <input type="number" id="collections-apr" placeholder="24.99" value="24.99" step="0.01">
            </div>
            <div class="form-group">
                <label>Delinquency Bucket:</label>
                <select id="collections-bucket">
                    <option value="30-60">30-60 days</option>
                    <option value="60-90">60-90 days</option>
                    <option value="90-120" selected>90-120 days</option>
                    <option value="120+">120+ days</option>
                </select>
            </div>
            <div class="form-group">
                <label>Monthly Income (optional):</label>
                <input type="number" id="collections-income" placeholder="4000">
            </div>
            <button class="btn" onclick="runCollections()">üí≥ Generate Hardship Plans</button>
            <div class="loading" id="collections-loading">Generating plans...</div>
            <div id="collections-result"></div>
        </div>
        
        <!-- DevCopilot Tab -->
        <div id="devcopilot" class="tab-content">
            <div class="example">
                <div class="example-title">üë®‚Äçüíª DevCopilot Example:</div>
                Service: "payments" | Language: "python"
            </div>
            <div class="form-group">
                <label>Service:</label>
                <input type="text" id="dev-service" placeholder="payments" value="payments">
            </div>
            <div class="form-group">
                <label>Endpoint (optional):</label>
                <input type="text" id="dev-endpoint" placeholder="/payments">
            </div>
            <div class="form-group">
                <label>Language:</label>
                <select id="dev-language">
                    <option value="python" selected>Python</option>
                    <option value="javascript">JavaScript</option>
                    <option value="java">Java</option>
                    <option value="curl">cURL</option>
                </select>
            </div>
            <button class="btn" onclick="runDevCopilot()">üë®‚Äçüíª Generate Code</button>
            <div class="loading" id="devcopilot-loading">Generating code...</div>
            <div id="devcopilot-result"></div>
        </div>
        
        <!-- CareCredit Tab -->
        <div id="carecredit" class="tab-content">
            <div class="example">
                <div class="example-title">üè• CareCredit Example:</div>
                Medical estimate with procedure codes and costs
            </div>
            <div class="form-group">
                <label>Medical Estimate:</label>
                <textarea id="care-estimate" placeholder="Paste your medical estimate..." value="Dental Estimate - City Dental Care

D0120 | Periodic oral evaluation | $85.00
D1110 | Prophylaxis - adult cleaning | $120.00
D0274 | Bitewing X-rays (4 films) | $65.00

Total: $270.00"></textarea>
            </div>
            <div class="form-group">
                <label>Location (optional):</label>
                <input type="text" id="care-location" placeholder="New York, NY" value="New York, NY">
            </div>
            <button class="btn" onclick="runCareCredit()">üè• Analyze Treatment</button>
            <div class="loading" id="carecredit-loading">Analyzing treatment...</div>
            <div id="carecredit-result"></div>
        </div>
        
        <!-- Portfolio Intel Narrator Tab -->
        <div id="narrator" class="tab-content">
            <div class="example">
                <div class="example-title">üìä Portfolio Intel Example:</div>
                "Why did spend drop after 2025-07-31?"
            </div>
            <div class="form-group">
                <label>Business Question:</label>
                <textarea id="narrator-question" placeholder="Ask about portfolio metrics..." value="Why did spend drop after 2025-07-31?"></textarea>
            </div>
            <button class="btn" onclick="runNarrator()">üìä Analyze Metrics</button>
            <div class="loading" id="narrator-loading">Analyzing portfolio data...</div>
            <div id="narrator-result"></div>
        </div>
        
        <!-- TrustShield Tab -->
        <div id="trustshield" class="tab-content">
            <div class="example">
                <div class="example-title">üõ°Ô∏è TrustShield Example:</div>
                "My SSN is 123-45-6789 and my credit card is 4111-1111-1111-1111"
            </div>
            <div class="form-group">
                <label>Text to Scan:</label>
                <textarea id="trust-text" placeholder="Enter text to scan for security issues..." value="My SSN is 123-45-6789 and my credit card is 4111-1111-1111-1111"></textarea>
            </div>
            <button class="btn" onclick="runTrustShield()">üõ°Ô∏è Security Scan</button>
            <div class="loading" id="trustshield-loading">Scanning for security issues...</div>
            <div id="trustshield-result"></div>
        </div>
    </div>

    <script>
        function showTab(tabName) {
            // Hide all tab contents
            document.querySelectorAll('.tab-content').forEach(content => {
                content.classList.remove('active');
            });
            
            // Remove active class from all tabs
            document.querySelectorAll('.tab').forEach(tab => {
                tab.classList.remove('active');
            });
            
            // Show selected tab content
            document.getElementById(tabName).classList.add('active');
            
            // Add active class to clicked tab
            event.target.classList.add('active');
        }
        
        function showLoading(agentName, show = true) {
            const loading = document.getElementById(`${agentName}-loading`);
            if (loading) {
                loading.classList.toggle('show', show);
            }
        }
        
        function showResult(agentName, result) {
            const resultDiv = document.getElementById(`${agentName}-result`);
            if (!resultDiv) return;
            
            // Create human-readable and JSON views
            const humanReadable = createHumanReadableView(result);
            const jsonView = JSON.stringify(result, null, 2);
            
            resultDiv.innerHTML = `
                <div class="result">
                    <h3>üìã Summary</h3>
                    ${humanReadable}
                    <h3 style="margin-top: 25px;">üìÑ Raw JSON Response</h3>
                    <div class="result-json">${jsonView}</div>
                </div>
            `;
        }
        
        function createHumanReadableView(result) {
            // Create cards/tiles based on result type
            if (result.items && Array.isArray(result.items)) {
                // OfferPilot results
                return `
                    <div class="grid">
                        ${result.items.map(item => `
                            <div class="card">
                                <h3>${item.title}</h3>
                                <div class="card-content">
                                    <p><strong>Price:</strong> $${item.price}</p>
                                    <p><strong>Merchant:</strong> ${item.merchant}</p>
                                    <p><strong>Offers:</strong> ${item.offers.length} financing options</p>
                                </div>
                            </div>
                        `).join('')}
                    </div>
                `;
            } else if (result.findings && Array.isArray(result.findings)) {
                // Narrator results
                return `
                    <div class="grid">
                        ${result.findings.map(finding => `
                            <div class="card">
                                <h3>${finding.title}</h3>
                                <div class="card-content">
                                    <pre>${JSON.stringify(finding.evidence, null, 2)}</pre>
                                </div>
                            </div>
                        `).join('')}
                    </div>
                `;
            } else if (result.line_items && Array.isArray(result.line_items)) {
                // CareCredit results
                return `
                    <div class="card">
                        <h3>üí∞ Treatment Costs</h3>
                        <div class="card-content">
                            ${result.line_items.map(item => `
                                <p><strong>${item.name}:</strong> $${item.subtotal} (${item.qty}x $${item.unit_cost})</p>
                            `).join('')}
                            <hr>
                            <p><strong>Total:</strong> $${result.oopp.estimated_total}</p>
                        </div>
                    </div>
                    <div class="card">
                        <h3>üè• Providers Found</h3>
                        <div class="card-content">
                            ${result.providers.map(provider => `
                                <p><strong>${provider.name}</strong><br>
                                Next appointment: ${provider.next_appt_days} days</p>
                            `).join('')}
                        </div>
                    </div>
                `;
            } else if (result.snippet && result.code) {
                // DevCopilot results
                return `
                    <div class="card">
                        <h3>üíª Generated Code</h3>
                        <div class="result-json">${result.snippet.code}</div>
                    </div>
                `;
            } else if (result.response) {
                // Chat results
                return `
                    <div class="card">
                        <h3>üí¨ Response</h3>
                        <div class="card-content">
                            <p>${result.response}</p>
                            <p><strong>Agent:</strong> ${result.agent} (${(result.confidence * 100).toFixed(1)}% confidence)</p>
                        </div>
                    </div>
                `;
            }
            
            return '<p>Response received successfully.</p>';
        }
        
        function showError(agentName, error) {
            const resultDiv = document.getElementById(`${agentName}-result`);
            if (!resultDiv) return;
            
            resultDiv.innerHTML = `<div class="error">‚ùå Error: ${error}</div>`;
        }
        
        async function apiCall(endpoint, data) {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(data)
            });
            
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }
            
            return response.json();
        }
        
        async function runChat() {
            const message = document.getElementById('chat-message').value;
            const allowTavily = document.getElementById('chat-tavily').checked;
            
            if (!message.trim()) return;
            
            showLoading('chat', true);
            try {
                const result = await apiCall('/chat', { message, allow_tavily: allowTavily });
                showResult('chat', result);
            } catch (error) {
                showError('chat', error.message);
            } finally {
                showLoading('chat', false);
            }
        }
        
        async function runOfferPilot() {
            const query = document.getElementById('offer-query').value;
            const budget = parseFloat(document.getElementById('offer-budget').value) || null;
            
            if (!query.trim()) return;
            
            showLoading('offerpilot', true);
            try {
                const result = await apiCall('/agent/offerpilot', { query, budget });
                showResult('offerpilot', result);
            } catch (error) {
                showError('offerpilot', error.message);
            } finally {
                showLoading('offerpilot', false);
            }
        }
        
        async function runDispute() {
            const narrative = document.getElementById('dispute-narrative').value;
            const merchant = document.getElementById('dispute-merchant').value || null;
            const amount = parseFloat(document.getElementById('dispute-amount').value) || null;
            
            if (!narrative.trim()) return;
            
            showLoading('dispute', true);
            try {
                const result = await apiCall('/agent/dispute', { narrative, merchant, amount });
                showResult('dispute', result);
            } catch (error) {
                showError('dispute', error.message);
            } finally {
                showLoading('dispute', false);
            }
        }
        
        async function runCollections() {
            const balance = parseFloat(document.getElementById('collections-balance').value);
            const apr = parseFloat(document.getElementById('collections-apr').value);
            const bucket = document.getElementById('collections-bucket').value;
            const income = parseFloat(document.getElementById('collections-income').value) || null;
            
            if (!balance || !apr) return;
            
            showLoading('collections', true);
            try {
                const result = await apiCall('/agent/collections', { balance, apr, bucket, income_monthly: income });
                showResult('collections', result);
            } catch (error) {
                showError('collections', error.message);
            } finally {
                showLoading('collections', false);
            }
        }
        
        async function runDevCopilot() {
            const service = document.getElementById('dev-service').value;
            const endpoint = document.getElementById('dev-endpoint').value || null;
            const lang = document.getElementById('dev-language').value;
            
            if (!service.trim()) return;
            
            showLoading('devcopilot', true);
            try {
                const result = await apiCall('/agent/devcopilot', { service, endpoint, lang });
                showResult('devcopilot', result);
            } catch (error) {
                showError('devcopilot', error.message);
            } finally {
                showLoading('devcopilot', false);
            }
        }
        
        async function runCareCredit() {
            const estimate_text = document.getElementById('care-estimate').value;
            const location = document.getElementById('care-location').value || null;
            
            if (!estimate_text.trim()) return;
            
            showLoading('carecredit', true);
            try {
                const result = await apiCall('/agent/carecredit', { estimate_text, location });
                showResult('carecredit', result);
            } catch (error) {
                showError('carecredit', error.message);
            } finally {
                showLoading('carecredit', false);
            }
        }
        
        async function runNarrator() {
            const question = document.getElementById('narrator-question').value;
            
            if (!question.trim()) return;
            
            showLoading('narrator', true);
            try {
                const result = await apiCall('/agent/narrator', { question });
                showResult('narrator', result);
            } catch (error) {
                showError('narrator', error.message);
            } finally {
                showLoading('narrator', false);
            }
        }
        
        async function runTrustShield() {
            const text = document.getElementById('trust-text').value;
            
            if (!text.trim()) return;
            
            showLoading('trustshield', true);
            try {
                const result = await apiCall('/agent/trustshield', { text });
                showResult('trustshield', result);
            } catch (error) {
                showError('trustshield', error.message);
            } finally {
                showLoading('trustshield', false);
            }
        }
    </script>
</body>
</html>
"""

if __name__ == "__main__":
    import uvicorn
    
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", 8000))
    debug = os.getenv("DEBUG", "false").lower() == "true"
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=debug,
        log_level=os.getenv("LOG_LEVEL", "info").lower()
    )


================================================
FILE: package.json
================================================
{
  "name": "synch-genai-poc",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-markdown": "^9.0.1",
    "rehype-highlight": "^7.0.0",
    "remark-gfm": "^4.0.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.66",
    "@types/react-dom": "^18.2.22",
    "@vitejs/plugin-react": "^4.2.1",
    "autoprefixer": "^10.4.19",
    "postcss": "^8.4.38",
    "tailwindcss": "^3.4.1",
    "typescript": "^5.2.2",
    "vite": "^5.2.0"
  }
}


================================================
FILE: postcss.config.js
================================================
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}


================================================
FILE: requirements.txt
================================================
# Core FastAPI dependencies
fastapi==0.116.1
uvicorn[standard]==0.32.1
pydantic==2.10.3

# AI/ML dependencies
haystack-ai==2.10.0
google-generativeai==0.8.3
tavily-python==0.5.0
sentence-transformers==3.3.1

# Data processing
numpy==2.1.3
pandas==2.2.3

# Template engine
jinja2==3.1.4

# Environment management
python-dotenv==1.0.1

# PII Detection and Security
presidio-analyzer==2.2.359
presidio-anonymizer==2.2.359
spacy==3.8.2

# PDF Processing
PyMuPDF==1.24.14



================================================
FILE: tailwind.config.js
================================================
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      fontFamily: {
        sans: ['Inter', 'system-ui', 'sans-serif'],
      },
      animation: {
        'fade-in': 'fadeIn 0.3s ease-in-out',
        'slide-up': 'slideUp 0.3s ease-out',
      },
      keyframes: {
        fadeIn: {
          '0%': { opacity: '0' },
          '100%': { opacity: '1' },
        },
        slideUp: {
          '0%': { opacity: '0', transform: 'translateY(20px)' },
          '100%': { opacity: '1', transform: 'translateY(0)' },
        }
      }
    },
  },
  plugins: [],
}


================================================
FILE: tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": false,
    "noUnusedParameters": false,
    "noFallthroughCasesInSwitch": true
  },
  "include": ["src"],
  "references": [{ "path": "./tsconfig.node.json" }]
}


================================================
FILE: tsconfig.node.json
================================================
{
  "compilerOptions": {
    "composite": true,
    "skipLibCheck": true,
    "module": "ESNext",
    "moduleResolution": "bundler",
    "allowSyntheticDefaultImports": true
  },
  "include": ["vite.config.ts"]
}


================================================
FILE: vite.config.ts
================================================
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

export default defineConfig({
  plugins: [react()],
  server: {
    port: 3000,
    proxy: {
      '/chat': 'http://localhost:8000',
      '/agent': 'http://localhost:8000',
      '/upload': 'http://localhost:8000',
      '/pdf': 'http://localhost:8000',
      '/healthz': 'http://localhost:8000',
    }
  },
  build: {
    outDir: 'dist',
  },
})


================================================
FILE: app/__init__.py
================================================
# Synch GenAI PoC Application Package



================================================
FILE: app/router.py
================================================
"""
Message routing system using Gemini classifier
"""

import logging
from typing import Dict, List
from app.llm.gemini import chat

logger = logging.getLogger(__name__)

# Supported agent types
AGENT_TYPES = [
    "offer",
    "trust", 
    "dispute",
    "collections",
    "contracts",
    "devcopilot",
    "carecredit",
    "narrator",
    "imagegen"
]

def route(message: str) -> Dict[str, any]:
    """
    Route a message to the appropriate agent using Gemini classifier
    
    Args:
        message: User message to classify
        
    Returns:
        Dictionary with agent type and confidence score
    """
    try:
        # Create classification prompt
        system_prompt = """You are a message routing classifier for a financial services platform. 
Your job is to classify user messages into one of these agent categories based on intent and content.

Agent Categories:
- offer: Product offers, promotions, deals, discounts, marketing content
- trust: Security concerns, fraud detection, suspicious activity, safety issues
- dispute: Transaction disputes, chargebacks, billing issues, payment problems
- collections: Debt collection, overdue payments, payment reminders
- contracts: Contract terms, agreements, legal documents, merchant agreements
- devcopilot: Technical support, API questions, integration help, developer tools
- carecredit: Healthcare financing, medical payments, care credit specific queries
- imagegen: Image generation, create picture, draw image, visual content requests
- narrator: General conversation, greetings, small talk, unclear intent

Respond with ONLY a JSON object in this exact format:
{"agent": "category_name", "confidence": 0.85}

The confidence should be a float between 0.0 and 1.0 representing how certain you are about the classification."""

        user_message = f"Classify this message: '{message}'"
        
        messages = [{"role": "user", "content": user_message}]
        
        # Get classification from Gemini
        response = chat(messages, system=system_prompt)
        
        # Parse JSON response
        import json
        try:
            # Handle markdown-wrapped JSON responses
            response_text = response.strip()
            if response_text.startswith('```json'):
                # Extract JSON from markdown code block
                response_text = response_text.replace('```json', '').replace('```', '').strip()
            elif response_text.startswith('```'):
                # Handle generic code blocks
                lines = response_text.split('\n')
                response_text = '\n'.join(lines[1:-1]).strip()
            
            result = json.loads(response_text)
            
            # Validate response format
            if not isinstance(result, dict) or "agent" not in result or "confidence" not in result:
                raise ValueError("Invalid response format")
            
            agent = result["agent"]
            confidence = float(result["confidence"])
            
            # Validate agent type
            if agent not in AGENT_TYPES:
                logger.warning(f"Unknown agent type '{agent}', defaulting to 'trust'")
                agent = "trust"
                confidence = 0.3
            
            # Validate confidence range
            confidence = max(0.0, min(1.0, confidence))
            
            # Apply default routing rule: if confidence < 0.5, default to "trust"
            if confidence < 0.5:
                logger.info(f"Low confidence ({confidence:.3f}) for agent '{agent}', defaulting to 'trust'")
                agent = "trust"
                confidence = 0.5
            
            logger.info(f"Routed message to '{agent}' with confidence {confidence:.3f}")
            
            return {
                "agent": agent,
                "confidence": confidence
            }
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            logger.error(f"Failed to parse classification response: {e}")
            logger.debug(f"Raw response: {response}")
            
            # Fallback classification
            return {
                "agent": "trust",
                "confidence": 0.3
            }
            
    except Exception as e:
        logger.error(f"Error in message routing: {e}")
        
        # Default fallback
        return {
            "agent": "trust", 
            "confidence": 0.3
        }

def get_agent_description(agent_type: str) -> str:
    """
    Get description of what each agent handles
    
    Args:
        agent_type: The agent type
        
    Returns:
        Description string
    """
    descriptions = {
        "offer": "Handles product offers, promotions, deals, and marketing content",
        "trust": "Manages security concerns, fraud detection, and safety issues", 
        "dispute": "Processes transaction disputes, chargebacks, and billing issues",
        "collections": "Handles debt collection and overdue payment matters",
        "contracts": "Manages contract terms, agreements, and legal documents",
        "devcopilot": "Provides technical support and developer assistance",
        "carecredit": "Handles healthcare financing and medical payment queries",
        "imagegen": "Generates images and visual content from text descriptions",
        "narrator": "Manages general conversation and unclear intents"
    }
    
    return descriptions.get(agent_type, "Unknown agent type")

def route_with_fallback_analysis(message: str) -> Dict[str, any]:
    """
    Enhanced routing with fallback keyword analysis
    
    Args:
        message: User message to classify
        
    Returns:
        Dictionary with agent type, confidence, and reasoning
    """
    # First try Gemini classification
    primary_result = route(message)
    
    # If confidence is still low, try keyword-based fallback
    if primary_result["confidence"] < 0.6:
        keyword_result = _keyword_based_routing(message)
        
        # Use keyword result if it has higher confidence
        if keyword_result["confidence"] > primary_result["confidence"]:
            logger.info(f"Using keyword-based routing over Gemini classification")
            return {
                **keyword_result,
                "method": "keyword_fallback",
                "gemini_result": primary_result
            }
    
    return {
        **primary_result,
        "method": "gemini_classification"
    }

def _keyword_based_routing(message: str) -> Dict[str, any]:
    """
    Simple keyword-based routing as fallback
    
    Args:
        message: User message
        
    Returns:
        Classification result
    """
    message_lower = message.lower()
    
    # Define keyword patterns for each agent
    patterns = {
        "trust": [
            "fraud", "scam", "suspicious", "security", "hack", "phishing", 
            "stolen", "unauthorized", "breach", "compromise", "malware",
            "gift card", "wire transfer", "refund scam", "overpay"
        ],
        "dispute": [
            "dispute", "chargeback", "wrong charge", "billing error", 
            "refund", "cancel", "unauthorized charge", "double charge"
        ],
        "collections": [
            "overdue", "payment due", "debt", "collection", "past due",
            "late payment", "outstanding balance"
        ],
        "contracts": [
            "contract", "agreement", "terms", "legal", "merchant agreement",
            "terms of service", "privacy policy"
        ],
        "devcopilot": [
            "api", "integration", "technical", "developer", "code", "sdk",
            "documentation", "endpoint", "webhook"
        ],
        "carecredit": [
            "care credit", "medical", "healthcare", "dental", "veterinary",
            "health financing"
        ],
        "offer": [
            "offer", "promotion", "deal", "discount", "sale", "special",
            "limited time", "bonus"
        ],
        "imagegen": [
            "generate image", "create picture", "draw", "make image", "visualize",
            "render", "picture of", "image of", "show me", "design"
        ]
    }
    
    # Score each agent based on keyword matches
    scores = {}
    for agent, keywords in patterns.items():
        score = sum(1 for keyword in keywords if keyword in message_lower)
        if score > 0:
            scores[agent] = score / len(keywords)  # Normalize by number of keywords
    
    if scores:
        # Get the agent with highest score
        best_agent = max(scores, key=scores.get)
        confidence = min(0.8, scores[best_agent] * 2)  # Cap at 0.8 for keyword matching
        
        return {
            "agent": best_agent,
            "confidence": confidence
        }
    
    # No keywords matched
    return {
        "agent": "narrator",
        "confidence": 0.4
    }



================================================
FILE: app/agents/__init__.py
================================================
# Agents Package



================================================
FILE: app/agents/carecredit.py
================================================
"""
CareCredit Treatment Translator
Converts medical estimates into plain-language options with provider availability and financing plans
"""

import json
import logging
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Literal
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat
from app.agents.offerpilot import OfferPilot
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Pydantic models for structured data
class InsuranceInfo(BaseModel):
    deductible_left: float
    coinsurance: float

class LineItem(BaseModel):
    name: str
    unit_cost: float
    qty: int = 1
    subtotal: float
    procedure_code: Optional[str] = None

class Provider(BaseModel):
    name: str
    address: str
    phone: str
    next_appt_days: int

class FinancingOption(BaseModel):
    offer_id: str
    months: int
    apr: float
    monthly: float
    total_cost: float

class OOPPResult(BaseModel):
    estimated_total: float
    assumptions: Dict[str, Any]

class Citation(BaseModel):
    source: str
    snippet: str

class CreditResponse(BaseModel):
    explanation: str
    line_items: List[LineItem]
    providers: List[Provider]
    financing: List[FinancingOption]
    oopp: OOPPResult
    citations: List[Citation]

@dataclass
class ParsedProcedure:
    """Represents a parsed medical/dental procedure"""
    procedure_code: Optional[str]
    name: str
    unit_cost: float
    qty: int = 1

class CareCredit:
    """
    CareCredit Treatment Translator for medical/dental estimates
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None):
        """Initialize CareCredit agent with required components"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        
        # Initialize OfferPilot for financing offers
        self.offer_pilot = OfferPilot(docstore, embedder, retriever)
        
        # Load provider data
        self._load_provider_data()
    
    def _load_provider_data(self):
        """Load healthcare provider directory"""
        try:
            providers_path = Path("app/data/providers.json")
            with open(providers_path, 'r') as f:
                data = json.load(f)
                self.providers = data["providers"]
                self.specialties = data["specialties"]
                self.procedure_mappings = data["procedure_mappings"]
            logger.info(f"Loaded {len(self.providers)} healthcare providers")
        except Exception as e:
            logger.error(f"Failed to load provider data: {e}")
            self.providers = []
            self.specialties = {}
            self.procedure_mappings = {}
    
    def process_estimate(
        self,
        estimate_text: str,
        location: Optional[str] = None,
        insurance: Optional[Dict[str, float]] = None
    ) -> CreditResponse:
        """
        Main processing pipeline for treatment estimates
        
        Args:
            estimate_text: Medical/dental estimate text
            location: Patient location for provider search
            insurance: Insurance info with deductible_left and coinsurance
            
        Returns:
            CreditResponse with explanation, providers, financing options
        """
        try:
            logger.info("Processing CareCredit treatment estimate")
            
            # Step 1: Parse estimate into line items
            parsed_items = self.estimate_parse_table(estimate_text)
            logger.info(f"Parsed {len(parsed_items)} line items from estimate")
            
            # Step 2: Calculate total cost
            total_cost = sum(item.unit_cost * item.qty for item in parsed_items)
            
            # Step 3: Identify specialty from procedures
            specialty = self._identify_specialty(parsed_items, estimate_text)
            logger.info(f"Identified specialty: {specialty}")
            
            # Step 4: Search for providers
            providers = self.providers_search({"specialty": specialty, "location": location})
            
            # Step 5: Get CareCredit financing offers
            financing_offers = self._get_carecredit_offers(total_cost)
            
            # Step 6: Calculate out-of-pocket costs
            oopp_result = self.oopp_simulate(total_cost, financing_offers[0] if financing_offers else None, insurance)
            
            # Step 7: Get terms and citations
            citations = self.terms_retrieve("CareCredit promotional financing")
            
            # Step 8: Generate plain-language explanation
            explanation = self._generate_explanation(parsed_items, providers, financing_offers, oopp_result)
            
            # Convert parsed items to LineItem models
            line_items = [
                LineItem(
                    name=item.name,
                    unit_cost=item.unit_cost,
                    qty=item.qty,
                    subtotal=item.unit_cost * item.qty,
                    procedure_code=item.procedure_code
                )
                for item in parsed_items
            ]
            
            return CreditResponse(
                explanation=explanation,
                line_items=line_items,
                providers=providers,
                financing=financing_offers,
                oopp=oopp_result,
                citations=citations
            )
            
        except Exception as e:
            logger.error(f"Error processing CareCredit estimate: {e}")
            return CreditResponse(
                explanation=f"Error processing estimate: {str(e)}",
                line_items=[],
                providers=[],
                financing=[],
                oopp=OOPPResult(estimated_total=0.0, assumptions={}),
                citations=[]
            )
    
    def estimate_parse_table(self, text: str) -> List[ParsedProcedure]:
        """
        Parse medical estimate table using Gemini with regex fallback
        
        Args:
            text: Estimate text to parse
            
        Returns:
            List of parsed procedures
        """
        try:
            # First, try Gemini-powered parsing with table hints
            system_prompt = """You are a medical billing expert. Parse the following medical/dental estimate into a structured list.

Extract each procedure/service with:
- Procedure code (if present, like D0120, 99213, etc.)
- Procedure name/description  
- Unit cost (dollar amount)
- Quantity (default to 1 if not specified)

Return as JSON array with objects containing: procedure_code, name, unit_cost, qty

Focus on actual billable procedures, ignore totals and administrative text."""

            user_message = f"Medical/dental estimate to parse:\n\n{text}"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            # Try to parse Gemini response as JSON
            try:
                parsed_json = json.loads(response.strip())
                procedures = []
                
                for item in parsed_json:
                    if isinstance(item, dict) and "name" in item and "unit_cost" in item:
                        procedures.append(ParsedProcedure(
                            procedure_code=item.get("procedure_code"),
                            name=item["name"],
                            unit_cost=float(item["unit_cost"]),
                            qty=int(item.get("qty", 1))
                        ))
                
                if procedures:
                    logger.info("Successfully parsed estimate using Gemini")
                    return procedures
                    
            except (json.JSONDecodeError, ValueError, KeyError) as e:
                logger.warning(f"Failed to parse Gemini JSON response: {e}")
            
            # Fallback to regex parsing
            logger.info("Falling back to regex parsing")
            return self._regex_parse_estimate(text)
            
        except Exception as e:
            logger.error(f"Error parsing estimate: {e}")
            return self._regex_parse_estimate(text)
    
    def _regex_parse_estimate(self, text: str) -> List[ParsedProcedure]:
        """
        Fallback regex-based estimate parsing
        
        Args:
            text: Estimate text
            
        Returns:
            List of parsed procedures
        """
        procedures = []
        
        # Common patterns for medical estimates
        patterns = [
            # Pattern 1: Code | Description | $Amount
            r'([A-Z]?\d{4,5})\s*[|\-\s]+([^|\$]+?)\s*[|\-\s]*\$?\s*(\d+(?:\.\d{2})?)',
            # Pattern 2: Description $Amount
            r'([A-Za-z][^$\n]{10,50}?)\s+\$(\d+(?:\.\d{2})?)',
            # Pattern 3: Description ... $Amount
            r'([A-Za-z][^$\n]{5,40}?)\.{2,}\$?(\d+(?:\.\d{2})?)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.MULTILINE | re.IGNORECASE)
            
            for match in matches:
                try:
                    if len(match) == 3:  # Code, description, amount
                        code, name, amount = match
                        procedures.append(ParsedProcedure(
                            procedure_code=code.strip(),
                            name=name.strip(),
                            unit_cost=float(amount),
                            qty=1
                        ))
                    elif len(match) == 2:  # Description, amount
                        name, amount = match
                        procedures.append(ParsedProcedure(
                            procedure_code=None,
                            name=name.strip(),
                            unit_cost=float(amount),
                            qty=1
                        ))
                except (ValueError, IndexError):
                    continue
        
        # Remove duplicates and clean up
        seen_names = set()
        clean_procedures = []
        for proc in procedures:
            if proc.name.lower() not in seen_names and proc.unit_cost > 0:
                seen_names.add(proc.name.lower())
                clean_procedures.append(proc)
        
        # If still no results, create generic procedure from any dollar amounts
        if not clean_procedures:
            dollar_matches = re.findall(r'\$(\d+(?:\.\d{2})?)', text)
            for amount in dollar_matches[:3]:  # Take first 3 amounts
                try:
                    cost = float(amount)
                    if cost > 10:  # Reasonable minimum
                        clean_procedures.append(ParsedProcedure(
                            procedure_code=None,
                            name=f"Medical procedure (${cost})",
                            unit_cost=cost,
                            qty=1
                        ))
                except ValueError:
                    continue
        
        return clean_procedures
    
    def providers_search(self, criteria: Dict[str, str]) -> List[Provider]:
        """
        Search providers by specialty and location
        
        Args:
            criteria: Dict with specialty and location
            
        Returns:
            List of matching providers
        """
        specialty = criteria.get("specialty", "").lower()
        location = criteria.get("location", "").lower()
        
        matching_providers = []
        
        for provider in self.providers:
            # Check specialty match
            if specialty and provider["specialty"] != specialty:
                continue
            
            # Check location match (if specified)
            if location and location not in provider["location"].lower():
                continue
            
            # Only include CareCredit accepting providers
            if provider.get("accepts_carecredit", False):
                matching_providers.append(Provider(
                    name=provider["name"],
                    address=provider["address"],
                    phone=provider["phone"],
                    next_appt_days=provider["next_appt_days"]
                ))
        
        # Sort by appointment availability
        matching_providers.sort(key=lambda p: p.next_appt_days)
        
        return matching_providers[:5]  # Return top 5
    
    def _get_carecredit_offers(self, total_cost: float) -> List[FinancingOption]:
        """
        Get CareCredit financing offers for healthcare merchants
        
        Args:
            total_cost: Total treatment cost
            
        Returns:
            List of financing options
        """
        financing_options = []
        
        try:
            # Look for healthcare-specific offers using OfferPilot
            healthcare_merchants = ["CareCredit", "Healthcare Financing", "Medical Credit"]
            
            for merchant in healthcare_merchants:
                offers = self.offer_pilot.offers_lookup(merchant, total_cost)
                
                for offer in offers:
                    # Calculate payment details
                    payment_sim = self.offer_pilot.payments_simulate(
                        total_cost, offer["months"], offer["apr"]
                    )
                    
                    financing_options.append(FinancingOption(
                        offer_id=offer["id"],
                        months=offer["months"],
                        apr=offer["apr"],
                        monthly=payment_sim["monthly"],
                        total_cost=payment_sim["total_cost"]
                    ))
            
            # Add default CareCredit options if none found
            if not financing_options:
                default_offers = [
                    {"id": "CARECREDIT_12_0", "months": 12, "apr": 0.0},
                    {"id": "CARECREDIT_24_0", "months": 24, "apr": 0.0},
                    {"id": "CARECREDIT_60_1499", "months": 60, "apr": 14.99},
                ]
                
                for offer in default_offers:
                    # Only show 0% APR for qualifying amounts
                    if offer["apr"] == 0 and total_cost < 200:
                        continue
                        
                    payment_sim = self.offer_pilot.payments_simulate(
                        total_cost, offer["months"], offer["apr"]
                    )
                    
                    financing_options.append(FinancingOption(
                        offer_id=offer["id"],
                        months=offer["months"],
                        apr=offer["apr"],
                        monthly=payment_sim["monthly"],
                        total_cost=payment_sim["total_cost"]
                    ))
            
            # Sort by APR (0% first, then ascending)
            financing_options.sort(key=lambda x: (x.apr > 0, x.apr))
            
        except Exception as e:
            logger.error(f"Error getting CareCredit offers: {e}")
        
        return financing_options
    
    def oopp_simulate(
        self, 
        total: float, 
        promo: Optional[FinancingOption], 
        insurance: Optional[Dict[str, float]]
    ) -> OOPPResult:
        """
        Simulate out-of-pocket costs with insurance and financing
        
        Args:
            total: Total procedure cost
            promo: Selected financing option
            insurance: Insurance details
            
        Returns:
            OOPP simulation result
        """
        assumptions = {}
        
        try:
            # Start with total cost
            estimated_total = total
            assumptions["original_total"] = total
            
            # Apply insurance if provided
            if insurance:
                deductible_left = insurance.get("deductible_left", 0)
                coinsurance = insurance.get("coinsurance", 0.2)  # Default 20%
                
                # Apply deductible
                after_deductible = max(0, total - deductible_left)
                deductible_used = min(total, deductible_left)
                
                # Apply coinsurance to remaining amount
                insurance_pays = after_deductible * (1 - coinsurance)
                patient_coinsurance = after_deductible * coinsurance
                
                estimated_total = deductible_used + patient_coinsurance
                
                assumptions.update({
                    "deductible_applied": deductible_used,
                    "coinsurance_rate": coinsurance,
                    "insurance_payment": insurance_pays,
                    "patient_portion": estimated_total
                })
            else:
                assumptions["insurance_status"] = "No insurance information provided"
            
            # Factor in financing if selected
            if promo:
                assumptions.update({
                    "financing_option": f"{promo.months} months at {promo.apr}% APR",
                    "monthly_payment": promo.monthly,
                    "total_with_interest": promo.total_cost
                })
                
                # For 0% APR, total cost doesn't change
                if promo.apr == 0:
                    assumptions["financing_benefit"] = "0% APR - no interest charges"
                else:
                    interest_cost = promo.total_cost - estimated_total
                    assumptions["interest_cost"] = interest_cost
            
        except Exception as e:
            logger.error(f"Error simulating OOPP: {e}")
            assumptions["error"] = str(e)
        
        return OOPPResult(
            estimated_total=round(estimated_total, 2),
            assumptions=assumptions
        )
    
    def terms_retrieve(self, query: str) -> List[Citation]:
        """
        Retrieve CareCredit terms with Tavily fallback
        
        Args:
            query: Terms query
            
        Returns:
            List of citations
        """
        citations = []
        
        try:
            # First try local knowledge base
            if self.retriever and self.embedder:
                from app.rag.core import retrieve
                results = retrieve(self.retriever, self.embedder, query, k=2)
                
                for result in results:
                    citations.append(Citation(
                        source=result.get("filename", "Terms Document"),
                        snippet=result.get("snippet", "")[:200] + "..."
                    ))
            
            # If no local results, search web with Tavily
            if not citations and self.docstore and self.embedder:
                logger.info("No local terms found, searching web for CareCredit terms")
                
                try:
                    web_docs = web_search_into_docstore(
                        self.docstore,
                        self.embedder,
                        "CareCredit promotional financing terms conditions healthcare",
                        max_results=2
                    )
                    
                    if web_docs:
                        # Re-retrieve after adding web content
                        from app.rag.core import retrieve
                        results = retrieve(self.retriever, self.embedder, query, k=2)
                        
                        for result in results:
                            citations.append(Citation(
                                source=result.get("filename", "Web Search - CareCredit"),
                                snippet=result.get("snippet", "")[:200] + "..."
                            ))
                
                except Exception as e:
                    logger.warning(f"Web search for CareCredit terms failed: {e}")
            
            # Add default citation if nothing found
            if not citations:
                citations.append(Citation(
                    source="CareCredit Terms",
                    snippet="Subject to credit approval. Minimum monthly payments required. See carecredit.com for full terms and conditions."
                ))
            
        except Exception as e:
            logger.error(f"Error retrieving terms: {e}")
        
        return citations
    
    def _identify_specialty(self, procedures: List[ParsedProcedure], text: str) -> str:
        """
        Identify medical specialty from procedures and text
        
        Args:
            procedures: Parsed procedures
            text: Original estimate text
            
        Returns:
            Medical specialty
        """
        # Check procedure codes first
        for proc in procedures:
            if proc.procedure_code:
                if proc.procedure_code in self.procedure_mappings:
                    return self.procedure_mappings[proc.procedure_code]["specialty"]
        
        # Check keywords in text and procedure names
        text_lower = text.lower()
        all_text = text_lower + " " + " ".join(proc.name.lower() for proc in procedures)
        
        specialty_scores = {}
        for specialty, keywords in self.specialties.items():
            score = sum(1 for keyword in keywords if keyword in all_text)
            if score > 0:
                specialty_scores[specialty] = score
        
        if specialty_scores:
            return max(specialty_scores.items(), key=lambda x: x[1])[0]
        
        # Default to dental (most common CareCredit usage)
        return "dental"
    
    def _generate_explanation(
        self,
        procedures: List[ParsedProcedure],
        providers: List[Provider],
        financing: List[FinancingOption],
        oopp: OOPPResult
    ) -> str:
        """
        Generate plain-language explanation of treatment options
        
        Args:
            procedures: Parsed procedures
            providers: Available providers
            financing: Financing options
            oopp: Out-of-pocket projection
            
        Returns:
            Plain-language explanation
        """
        explanation_parts = []
        
        # Treatment summary
        total_procedures = len(procedures)
        total_cost = sum(proc.unit_cost * proc.qty for proc in procedures)
        
        explanation_parts.append(
            f"Your treatment estimate includes {total_procedures} procedure{'s' if total_procedures != 1 else ''} "
            f"with a total cost of ${total_cost:,.2f}."
        )
        
        # Insurance impact
        if "insurance_payment" in oopp.assumptions:
            insurance_saves = oopp.assumptions["insurance_payment"]
            explanation_parts.append(
                f"With your insurance, you'll be responsible for approximately ${oopp.estimated_total:,.2f} "
                f"out-of-pocket (insurance covers ${insurance_saves:,.2f})."
            )
        else:
            explanation_parts.append(
                f"Without insurance information, your estimated out-of-pocket cost is ${oopp.estimated_total:,.2f}."
            )
        
        # Financing options
        if financing:
            best_offer = financing[0]  # First is best (sorted by APR)
            if best_offer.apr == 0:
                explanation_parts.append(
                    f"Great news! You may qualify for 0% APR financing with CareCredit, "
                    f"allowing you to pay just ${best_offer.monthly:.2f} per month for {best_offer.months} months."
                )
            else:
                explanation_parts.append(
                    f"CareCredit financing is available starting at {best_offer.apr}% APR, "
                    f"with payments as low as ${best_offer.monthly:.2f} per month."
                )
        
        # Provider availability
        if providers:
            next_available = min(p.next_appt_days for p in providers)
            explanation_parts.append(
                f"We found {len(providers)} CareCredit-accepting providers in your area, "
                f"with appointments available as soon as {next_available} days."
            )
        
        return " ".join(explanation_parts)

# Test cases for CareCredit scenarios  
def test_carecredit():
    """Test CareCredit with golden-path scenarios"""
    print("üß™ Testing CareCredit Treatment Translator")
    print("=" * 50)
    
    carecredit = CareCredit()
    
    test_cases = [
        {
            "name": "Dental cleaning estimate",
            "estimate_text": """
            Dental Estimate - City Dental Care
            
            D0120 | Periodic oral evaluation | $85.00
            D1110 | Prophylaxis - adult cleaning | $120.00
            D0274 | Bitewing X-rays (4 films) | $65.00
            
            Total: $270.00
            """,
            "location": "New York, NY",
            "insurance": {"deductible_left": 150.0, "coinsurance": 0.2},
            "expected_specialty": "dental",
            "expected_items": 3
        },
        {
            "name": "Dermatology procedure",
            "estimate_text": """
            Dermatology Treatment Estimate
            
            Mole removal procedure ........... $450.00
            Pathology examination ............ $125.00
            Follow-up visit .................. $85.00
            
            Estimated Total: $660.00
            """,
            "location": "Chicago, IL", 
            "insurance": None,
            "expected_specialty": "dermatology",
            "expected_items": 3
        },
        {
            "name": "Veterinary emergency",
            "estimate_text": """
            Pet Emergency Treatment
            
            Emergency exam: $150
            X-rays (2 views): $180
            Pain medication: $45
            
            Total due: $375
            """,
            "location": "Phoenix, AZ",
            "insurance": None,
            "expected_specialty": "veterinary", 
            "expected_items": 3
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            
            result = carecredit.process_estimate(
                estimate_text=case["estimate_text"],
                location=case["location"],
                insurance=case["insurance"]
            )
            
            # Validate response structure
            valid_structure = (
                isinstance(result, CreditResponse) and
                isinstance(result.line_items, list) and
                isinstance(result.providers, list) and
                isinstance(result.financing, list) and
                isinstance(result.oopp, OOPPResult) and
                isinstance(result.citations, list)
            )
            
            # Check line items parsing
            items_ok = len(result.line_items) >= case["expected_items"]
            
            # Check providers found
            providers_ok = len(result.providers) > 0
            
            # Check financing options
            financing_ok = len(result.financing) > 0
            
            # Check explanation generated
            explanation_ok = len(result.explanation) > 50
            
            # Check OOPP calculation
            oopp_ok = result.oopp.estimated_total > 0
            
            success = (valid_structure and items_ok and providers_ok and 
                      financing_ok and explanation_ok and oopp_ok)
            
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   Location: {case['location']}")
            print(f"   Line items parsed: {len(result.line_items)}")
            print(f"   Providers found: {len(result.providers)}")
            print(f"   Financing options: {len(result.financing)}")
            print(f"   Out-of-pocket estimate: ${result.oopp.estimated_total:.2f}")
            print(f"   Status: {status}")
            
            if success:
                passed += 1
            else:
                print(f"   Failure reasons:")
                if not valid_structure:
                    print(f"     - Invalid response structure")
                if not items_ok:
                    print(f"     - Insufficient line items parsed")
                if not providers_ok:
                    print(f"     - No providers found")
                if not financing_ok:
                    print(f"     - No financing options")
                if not explanation_ok:
                    print(f"     - Poor explanation generated")
                if not oopp_ok:
                    print(f"     - OOPP calculation failed")
            
            print()
            
        except Exception as e:
            print(f"   ‚ùå FAIL - Exception: {str(e)}")
            print()
    
    print(f"üìä CareCredit Test Results: {passed}/{total} tests passed")
    return passed == total

if __name__ == "__main__":
    test_carecredit()


================================================
FILE: app/agents/chat_agent.py
================================================
"""
Chat Agent for handling queries with RAG and optional Tavily fallback
"""

import os
import logging
from typing import Dict, Any, Optional

from tavily import TavilyClient

logger = logging.getLogger(__name__)

class ChatAgent:
    """
    Chat agent that processes queries using RAG pipeline with optional Tavily fallback
    """
    
    def __init__(self, rag_pipeline):
        """
        Initialize the chat agent.
        
        Args:
            rag_pipeline: The RAG pipeline instance
        """
        self.rag_pipeline = rag_pipeline
        self.tavily_client = None
        
        # Initialize Tavily client if enabled and API key is available
        if os.getenv("ALLOW_TAVILY", "false").lower() == "true":
            tavily_api_key = os.getenv("TAVILY_API_KEY")
            if tavily_api_key:
                try:
                    self.tavily_client = TavilyClient(api_key=tavily_api_key)
                    logger.info("Tavily client initialized successfully")
                except Exception as e:
                    logger.warning(f"Failed to initialize Tavily client: {e}")
            else:
                logger.warning("ALLOW_TAVILY is true but TAVILY_API_KEY not found")
    
    async def process_query(
        self, 
        query: str, 
        use_tavily: bool = False,
        confidence_threshold: float = 0.3
    ) -> Dict[str, Any]:
        """
        Process a query using RAG pipeline and optionally Tavily fallback.
        
        Args:
            query: The user's query
            use_tavily: Whether to use Tavily fallback if RAG results are poor
            confidence_threshold: Minimum confidence score for RAG results
            
        Returns:
            Dictionary containing response, sources, and metadata
        """
        try:
            logger.info(f"Processing query: {query}")
            
            # First, try RAG pipeline
            rag_result = await self.rag_pipeline.query(query)
            
            # Check if we should use Tavily fallback
            should_use_tavily = (
                use_tavily and 
                self.tavily_client and 
                self._should_fallback_to_tavily(rag_result, confidence_threshold)
            )
            
            if should_use_tavily:
                logger.info("RAG results below threshold, falling back to Tavily")
                tavily_result = await self._query_tavily(query)
                
                # Combine RAG and Tavily results
                return self._combine_results(rag_result, tavily_result)
            else:
                return {
                    **rag_result,
                    "used_tavily": False
                }
                
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            return {
                "response": f"I apologize, but I encountered an error while processing your query: {str(e)}",
                "sources": [],
                "used_tavily": False,
                "error": str(e)
            }
    
    def _should_fallback_to_tavily(self, rag_result: Dict[str, Any], threshold: float) -> bool:
        """
        Determine if we should fallback to Tavily based on RAG result quality.
        
        Args:
            rag_result: Result from RAG pipeline
            threshold: Confidence threshold
            
        Returns:
            True if should fallback to Tavily
        """
        # Check if we have few or no retrieved documents
        if rag_result.get("retrieved_documents", 0) == 0:
            return True
        
        # Check if response indicates lack of information
        response = rag_result.get("response", "").lower()
        fallback_indicators = [
            "i don't have information",
            "not available in the documents",
            "cannot find",
            "no information",
            "not mentioned in the documents"
        ]
        
        return any(indicator in response for indicator in fallback_indicators)
    
    async def _query_tavily(self, query: str) -> Dict[str, Any]:
        """
        Query Tavily for additional information.
        
        Args:
            query: The search query
            
        Returns:
            Dictionary with Tavily search results
        """
        try:
            logger.info(f"Querying Tavily for: {query}")
            
            # Search with Tavily
            search_result = self.tavily_client.search(
                query=query,
                search_depth="basic",
                max_results=3
            )
            
            # Extract relevant information
            tavily_sources = []
            tavily_content = []
            
            for result in search_result.get("results", []):
                title = result.get("title", "")
                url = result.get("url", "")
                content = result.get("content", "")
                
                if content:
                    tavily_sources.append(f"{title} - {url}")
                    tavily_content.append(content)
            
            # Create a summary response
            if tavily_content:
                combined_content = "\n\n".join(tavily_content[:2])  # Use top 2 results
                tavily_response = (
                    f"Based on web search results:\n\n{combined_content}\n\n"
                    f"Please note: This information comes from web search and may need verification."
                )
            else:
                tavily_response = "No additional information found through web search."
            
            return {
                "response": tavily_response,
                "sources": tavily_sources,
                "search_results_count": len(search_result.get("results", []))
            }
            
        except Exception as e:
            logger.error(f"Error querying Tavily: {e}")
            return {
                "response": "Unable to retrieve additional information from web search.",
                "sources": [],
                "search_results_count": 0,
                "error": str(e)
            }
    
    def _combine_results(self, rag_result: Dict[str, Any], tavily_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Combine RAG and Tavily results into a single response.
        
        Args:
            rag_result: Result from RAG pipeline
            tavily_result: Result from Tavily search
            
        Returns:
            Combined result dictionary
        """
        # Combine responses
        rag_response = rag_result.get("response", "")
        tavily_response = tavily_result.get("response", "")
        
        if rag_response and tavily_response:
            combined_response = (
                f"From knowledge base:\n{rag_response}\n\n"
                f"Additional information from web search:\n{tavily_response}"
            )
        elif tavily_response:
            combined_response = tavily_response
        else:
            combined_response = rag_response or "No information available."
        
        # Combine sources
        rag_sources = rag_result.get("sources", [])
        tavily_sources = tavily_result.get("sources", [])
        
        combined_sources = []
        if rag_sources:
            combined_sources.extend([f"KB: {source}" for source in rag_sources])
        if tavily_sources:
            combined_sources.extend([f"Web: {source}" for source in tavily_sources])
        
        return {
            "response": combined_response,
            "sources": combined_sources,
            "used_tavily": True,
            "rag_documents": rag_result.get("retrieved_documents", 0),
            "tavily_results": tavily_result.get("search_results_count", 0),
            "retrieval_method": "hybrid_with_web_fallback"
        }



================================================
FILE: app/agents/collections.py
================================================
"""
Collections & Hardship Advisor
Negotiation assistant that proposes compliant hardship plans
"""

import json
import logging
import math
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Literal
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat
from app.rag.core import retrieve
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Pydantic models for strict input/output schema enforcement
class CustomerState(BaseModel):
    balance: float
    apr: float
    bucket: Literal["current", "30", "60", "90", "120+"]
    income_monthly: Optional[float] = None
    expenses_monthly: Optional[float] = None
    preferences: Optional[dict] = None

class PaymentScheduleEntry(BaseModel):
    month: int
    payment: float
    interest: float
    principal: float
    balance: float

class HardshipPlan(BaseModel):
    type: str
    params: dict
    payment_curve: List[PaymentScheduleEntry]
    npv: float
    risk_score: float
    why: str
    disclosures: List[str]

class Citation(BaseModel):
    source: str
    snippet: str

class CollectionsResponse(BaseModel):
    plans: List[HardshipPlan]
    citations: List[Citation]

class CollectionsAdvisor:
    """
    Collections & Hardship Advisor for proposing compliant hardship plans
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None):
        """Initialize CollectionsAdvisor with RAG components for terms retrieval"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        
        # Load hardship policies
        self._load_hardship_policies()
    
    def _load_hardship_policies(self):
        """Load hardship policies from JSON file"""
        try:
            policies_path = Path("app/data/hardship_policies.json")
            with open(policies_path, 'r') as f:
                self.policies = json.load(f)
            logger.info("Loaded hardship policies successfully")
        except Exception as e:
            logger.error(f"Failed to load hardship policies: {e}")
            self.policies = {}
    
    def policy_rules_load(self) -> Dict[str, Any]:
        """Load policy rules from hardship policies"""
        return self.policies
    
    def process_hardship_request(self, customer_state: CustomerState) -> CollectionsResponse:
        """
        Main processing pipeline for hardship requests
        
        Args:
            customer_state: Customer's financial state and account information
            
        Returns:
            CollectionsResponse with recommended hardship plans and citations
        """
        try:
            logger.info(f"Processing hardship request for {customer_state.bucket} bucket, balance ${customer_state.balance:.2f}")
            
            # Step 1: Load policy rules
            policy_rules = self.policy_rules_load()
            
            # Step 2: Generate candidate plans
            candidates = self._generate_candidate_plans(customer_state, policy_rules)
            logger.info(f"Generated {len(candidates)} candidate plans")
            
            # Step 3: Simulate each plan
            simulated_plans = []
            for candidate in candidates:
                simulation = self.plan_simulate(
                    balance=customer_state.balance,
                    apr=customer_state.apr,
                    months=candidate.get("months", 12),
                    kind=candidate["type"],
                    params=candidate["params"]
                )
                
                # Step 4: Score the plan
                score_components = self._score_plan(candidate, simulation, customer_state, policy_rules)
                
                # Step 5: Generate rationale with Gemini
                rationale = self._generate_rationale(candidate, customer_state, policy_rules)
                
                # Step 6: Get mandatory disclosures
                disclosures = self._get_mandatory_disclosures(candidate["type"], policy_rules)
                
                simulated_plans.append({
                    "candidate": candidate,
                    "simulation": simulation,
                    "score": score_components["total_score"],
                    "rationale": rationale,
                    "disclosures": disclosures
                })
            
            # Step 7: Sort by score and take top 3
            simulated_plans.sort(key=lambda x: x["score"], reverse=True)
            top_plans = simulated_plans[:3]
            
            # Step 8: Get policy citations
            citations = self._get_policy_citations()
            
            # Step 9: Format response
            formatted_plans = []
            for plan_data in top_plans:
                candidate = plan_data["candidate"]
                simulation = plan_data["simulation"]
                
                formatted_plans.append(HardshipPlan(
                    type=candidate["type"],
                    params=candidate["params"],
                    payment_curve=[
                        PaymentScheduleEntry(
                            month=entry["month"],
                            payment=entry["payment"],
                            interest=entry["interest"],
                            principal=entry["principal"],
                            balance=entry["balance"]
                        ) for entry in simulation["schedule"]
                    ],
                    npv=simulation["npv"],
                    risk_score=simulation["chargeoff_risk"],
                    why=plan_data["rationale"],
                    disclosures=plan_data["disclosures"]
                ))
            
            return CollectionsResponse(
                plans=formatted_plans,
                citations=citations
            )
            
        except Exception as e:
            logger.error(f"Error processing hardship request: {e}")
            return CollectionsResponse(plans=[], citations=[])
    
    def _generate_candidate_plans(self, customer_state: CustomerState, policy_rules: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Generate candidate hardship plans based on policy rules and customer state"""
        candidates = []
        allowed_actions = policy_rules.get("allowed_actions", {})
        
        # Deferral plans
        if (allowed_actions.get("deferral", {}).get("enabled") and 
            customer_state.bucket in allowed_actions["deferral"]["eligible_buckets"]):
            
            max_months = allowed_actions["deferral"]["max_months"]
            for months in [2, 3, 6]:
                if months <= max_months:
                    candidates.append({
                        "type": "deferral",
                        "months": months,
                        "params": {"deferral_months": months}
                    })
        
        # Re-aging plans
        if (allowed_actions.get("re_aging", {}).get("enabled") and 
            customer_state.bucket in allowed_actions["re_aging"]["eligible_buckets"]):
            
            candidates.append({
                "type": "re_aging",
                "months": 12,
                "params": {"bring_current": True, "payment_history_required": 3}
            })
        
        # Settlement plans
        if (allowed_actions.get("settlement", {}).get("enabled") and 
            customer_state.bucket in allowed_actions["settlement"]["eligible_buckets"]):
            
            min_pct = allowed_actions["settlement"]["min_settlement_pct"]
            max_pct = allowed_actions["settlement"]["max_settlement_pct"]
            
            for pct in [min_pct, 0.60, 0.75, max_pct]:
                candidates.append({
                    "type": "settlement",
                    "months": 1,
                    "params": {"settlement_percentage": pct, "lump_sum": True}
                })
                
                # Split settlement options
                if not allowed_actions["settlement"]["requires_lump_sum"]:
                    candidates.append({
                        "type": "settlement",
                        "months": 6,
                        "params": {"settlement_percentage": pct, "split_months": 6}
                    })
        
        # Interest reduction plans
        if (allowed_actions.get("interest_reduction", {}).get("enabled") and 
            customer_state.bucket in allowed_actions["interest_reduction"]["eligible_buckets"]):
            
            max_cycles = allowed_actions["interest_reduction"]["max_cycles"]
            min_reduction = allowed_actions["interest_reduction"]["min_reduction_pct"]
            
            for cycles in [6, 12]:
                if cycles <= max_cycles:
                    candidates.append({
                        "type": "interest_reduction",
                        "months": cycles,
                        "params": {"reduction_percentage": min_reduction, "cycles": cycles}
                    })
        
        # Payment plan options
        if (allowed_actions.get("payment_plan", {}).get("enabled") and 
            customer_state.bucket in allowed_actions["payment_plan"]["eligible_buckets"]):
            
            min_months = allowed_actions["payment_plan"]["min_months"]
            max_months = allowed_actions["payment_plan"]["max_months"]
            
            for months in [12, 24, 36]:
                if min_months <= months <= max_months:
                    candidates.append({
                        "type": "payment_plan",
                        "months": months,
                        "params": {"term_months": months}
                    })
        
        return candidates
    
    def plan_simulate(self, balance: float, apr: float, months: int, kind: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        Simulate payment plan and calculate NPV and chargeoff risk
        
        Args:
            balance: Current balance
            apr: Annual percentage rate
            months: Plan duration in months
            kind: Plan type
            params: Plan-specific parameters
            
        Returns:
            Simulation results with schedule, NPV, and risk
        """
        monthly_rate = apr / 100 / 12
        schedule = []
        current_balance = balance
        total_payments = 0
        
        if kind == "deferral":
            deferral_months = params.get("deferral_months", 3)
            
            # Deferral period - interest only accrues
            for month in range(1, deferral_months + 1):
                interest = current_balance * monthly_rate
                current_balance += interest
                schedule.append({
                    "month": month,
                    "payment": 0.0,
                    "interest": interest,
                    "principal": 0.0,
                    "balance": current_balance
                })
            
            # Resume normal payments after deferral
            if current_balance > 0:
                remaining_months = 24  # Assume 24 month payoff after deferral
                monthly_payment = self._calculate_monthly_payment(current_balance, apr, remaining_months)
                
                for month in range(deferral_months + 1, deferral_months + remaining_months + 1):
                    interest = current_balance * monthly_rate
                    principal = monthly_payment - interest
                    current_balance = max(0, current_balance - principal)
                    total_payments += monthly_payment
                    
                    schedule.append({
                        "month": month,
                        "payment": monthly_payment,
                        "interest": interest,
                        "principal": principal,
                        "balance": current_balance
                    })
                    
                    if current_balance <= 0:
                        break
        
        elif kind == "settlement":
            settlement_pct = params.get("settlement_percentage", 0.60)
            settlement_amount = balance * settlement_pct
            split_months = params.get("split_months", 1)
            
            monthly_settlement = settlement_amount / split_months
            
            for month in range(1, split_months + 1):
                schedule.append({
                    "month": month,
                    "payment": monthly_settlement,
                    "interest": 0.0,
                    "principal": monthly_settlement,
                    "balance": max(0, settlement_amount - (monthly_settlement * month))
                })
                total_payments += monthly_settlement
        
        elif kind == "interest_reduction":
            cycles = params.get("cycles", 12)
            reduction_pct = params.get("reduction_percentage", 0.50)
            reduced_apr = apr * (1 - reduction_pct)
            reduced_monthly_rate = reduced_apr / 100 / 12
            
            monthly_payment = self._calculate_monthly_payment(balance, reduced_apr, cycles)
            
            for month in range(1, cycles + 1):
                interest = current_balance * reduced_monthly_rate
                principal = monthly_payment - interest
                current_balance = max(0, current_balance - principal)
                total_payments += monthly_payment
                
                schedule.append({
                    "month": month,
                    "payment": monthly_payment,
                    "interest": interest,
                    "principal": principal,
                    "balance": current_balance
                })
                
                if current_balance <= 0:
                    break
        
        elif kind == "payment_plan":
            term_months = params.get("term_months", 24)
            monthly_payment = self._calculate_monthly_payment(balance, apr, term_months)
            
            for month in range(1, term_months + 1):
                interest = current_balance * monthly_rate
                principal = monthly_payment - interest
                current_balance = max(0, current_balance - principal)
                total_payments += monthly_payment
                
                schedule.append({
                    "month": month,
                    "payment": monthly_payment,
                    "interest": interest,
                    "principal": principal,
                    "balance": current_balance
                })
                
                if current_balance <= 0:
                    break
        
        else:  # re_aging - bring current then normal payments
            monthly_payment = self._calculate_monthly_payment(balance, apr, 24)
            
            for month in range(1, 25):
                interest = current_balance * monthly_rate
                principal = monthly_payment - interest
                current_balance = max(0, current_balance - principal)
                total_payments += monthly_payment
                
                schedule.append({
                    "month": month,
                    "payment": monthly_payment,
                    "interest": interest,
                    "principal": principal,
                    "balance": current_balance
                })
                
                if current_balance <= 0:
                    break
        
        # Calculate NPV (simple discount at 10% annually)
        discount_rate = 0.10 / 12  # Monthly discount rate
        npv = sum(payment["payment"] / ((1 + discount_rate) ** payment["month"]) 
                 for payment in schedule)
        
        # Calculate chargeoff risk based on plan type and customer state
        chargeoff_risk = self._calculate_chargeoff_risk(kind, params, balance, apr)
        
        return {
            "schedule": schedule,
            "npv": npv,
            "chargeoff_risk": chargeoff_risk,
            "total_payments": total_payments
        }
    
    def _calculate_monthly_payment(self, balance: float, apr: float, months: int) -> float:
        """Calculate monthly payment for standard amortization"""
        if apr == 0:
            return balance / months
        
        monthly_rate = apr / 100 / 12
        return balance * (monthly_rate * (1 + monthly_rate) ** months) / ((1 + monthly_rate) ** months - 1)
    
    def _calculate_chargeoff_risk(self, plan_type: str, params: Dict[str, Any], balance: float, apr: float) -> float:
        """Calculate chargeoff risk for a plan"""
        base_risk = 0.15  # Base 15% risk
        
        # Plan type adjustments
        if plan_type == "settlement":
            base_risk *= 0.3  # Settlement reduces risk significantly
        elif plan_type == "deferral":
            base_risk *= 1.5  # Deferral increases risk
        elif plan_type == "interest_reduction":
            base_risk *= 0.7  # Interest reduction helps
        elif plan_type == "re_aging":
            base_risk *= 0.8  # Re-aging helps if customer complies
        
        # Balance size impact
        if balance > 10000:
            base_risk *= 1.2
        elif balance < 2000:
            base_risk *= 0.8
        
        # APR impact
        if apr > 25:
            base_risk *= 1.1
        
        return min(0.95, base_risk)  # Cap at 95%
    
    def _score_plan(self, candidate: Dict[str, Any], simulation: Dict[str, Any], 
                   customer_state: CustomerState, policy_rules: Dict[str, Any]) -> Dict[str, Any]:
        """Score a hardship plan based on adherence, affordability, and risk safety"""
        
        # Adherence score (0 or 1 if within policy)
        adherence = 1.0  # Assume all generated candidates are policy-compliant
        
        # Affordability score
        affordability = 1.0
        if customer_state.income_monthly and customer_state.expenses_monthly:
            disposable_income = customer_state.income_monthly - customer_state.expenses_monthly
            
            if simulation["schedule"]:
                avg_payment = sum(p["payment"] for p in simulation["schedule"]) / len(simulation["schedule"])
                if disposable_income > 0:
                    affordability = min(1.0, disposable_income / avg_payment)
                else:
                    affordability = 0.1  # Very low if no disposable income
        
        # Risk safety score
        risk_safety = 1 - simulation["chargeoff_risk"]
        
        # Combined score
        total_score = adherence * affordability * risk_safety
        
        return {
            "adherence": adherence,
            "affordability": affordability,
            "risk_safety": risk_safety,
            "total_score": total_score
        }
    
    def _generate_rationale(self, candidate: Dict[str, Any], customer_state: CustomerState, 
                           policy_rules: Dict[str, Any]) -> str:
        """Generate AI rationale for why this plan fits the customer and policy"""
        try:
            system_prompt = """You are a collections advisor explaining hardship plans. Generate a brief, professional rationale for why a specific hardship plan is appropriate for a customer's situation.

Focus on:
- Customer's financial situation and delinquency bucket
- Plan benefits and suitability
- Policy compliance
- Risk mitigation

Keep it concise (2-3 sentences) and professional."""

            plan_type = candidate["type"]
            bucket = customer_state.bucket
            balance = customer_state.balance
            
            context = f"""
Plan Type: {plan_type}
Customer Bucket: {bucket}
Balance: ${balance:.2f}
Plan Parameters: {candidate.get('params', {})}
"""
            
            if customer_state.income_monthly:
                context += f"Monthly Income: ${customer_state.income_monthly:.2f}\n"
            if customer_state.expenses_monthly:
                context += f"Monthly Expenses: ${customer_state.expenses_monthly:.2f}\n"
            
            user_message = f"Explain why this hardship plan is appropriate:\n{context}"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            return response.strip()
            
        except Exception as e:
            logger.error(f"Error generating rationale: {e}")
            return f"This {candidate['type']} plan is designed to address the customer's {customer_state.bucket} delinquency status while maintaining policy compliance."
    
    def _get_mandatory_disclosures(self, plan_type: str, policy_rules: Dict[str, Any]) -> List[str]:
        """Get mandatory disclosures for a plan type"""
        disclosures = policy_rules.get("mandatory_disclosures", {})
        return disclosures.get(plan_type, [])
    
    def _get_policy_citations(self) -> List[Citation]:
        """Get policy citations from knowledge base with Tavily fallback"""
        citations = []
        
        if not all([self.retriever, self.embedder]):
            logger.warning("RAG components not available for policy citations")
            return citations
        
        try:
            # Retrieve hardship policy documents
            results = retrieve(self.retriever, self.embedder, "hardship program policy", k=3)
            
            for result in results:
                citations.append(Citation(
                    source=result.get("filename", "Hardship Policy"),
                    snippet=result.get("snippet", "")[:300] + "..."
                ))
            
            # Tavily fallback if insufficient citations
            if len(citations) < 1:
                logger.info("Insufficient local hardship citations, searching web...")
                try:
                    web_docs = web_search_into_docstore(
                        self.docstore,
                        self.embedder,
                        "credit card hardship program deferral re-aging disclosures",
                        max_results=2
                    )
                    
                    # Re-retrieve after adding web content
                    if web_docs:
                        results = retrieve(self.retriever, self.embedder, 
                                         "hardship deferral re-aging disclosures", k=2)
                        
                        for result in results:
                            citations.append(Citation(
                                source=result.get("filename", "Web Search"),
                                snippet=result.get("snippet", "")[:300] + "..."
                            ))
                            
                except Exception as e:
                    logger.warning(f"Web search for hardship policies failed: {e}")
            
        except Exception as e:
            logger.error(f"Error retrieving policy citations: {e}")
        
        return citations

# Test cases for collections scenarios
def test_collections_advisor():
    """Test CollectionsAdvisor with golden-path scenarios"""
    print("üß™ Testing CollectionsAdvisor Golden Paths")
    print("=" * 50)
    
    advisor = CollectionsAdvisor()
    
    test_cases = [
        {
            "name": "90-day bucket with low income ‚Üí deferral wins",
            "customer_state": CustomerState(
                balance=5000.0,
                apr=24.99,
                bucket="90",
                income_monthly=2500.0,
                expenses_monthly=2200.0
            ),
            "expected_top_plan": "deferral"
        },
        {
            "name": "120+ bucket ‚Üí split settlement shown",
            "customer_state": CustomerState(
                balance=8000.0,
                apr=29.99,
                bucket="120+",
                income_monthly=3000.0,
                expenses_monthly=2800.0
            ),
            "expected_plan_type": "settlement"
        },
        {
            "name": "Current bucket with good income ‚Üí payment plan",
            "customer_state": CustomerState(
                balance=3000.0,
                apr=19.99,
                bucket="current",
                income_monthly=5000.0,
                expenses_monthly=3500.0
            ),
            "expected_plan_type": "payment_plan"
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            
            result = advisor.process_hardship_request(case["customer_state"])
            
            # Validate response structure
            valid_structure = (
                isinstance(result.plans, list) and
                len(result.plans) > 0 and
                isinstance(result.citations, list)
            )
            
            # Check if expected plan type is present
            plan_types = [plan.type for plan in result.plans]
            expected_present = (
                case.get("expected_top_plan") in plan_types or
                case.get("expected_plan_type") in plan_types
            )
            
            # Check plan completeness
            plans_complete = all(
                len(plan.payment_curve) > 0 and
                plan.npv > 0 and
                len(plan.disclosures) > 0 and
                len(plan.why) > 10
                for plan in result.plans
            )
            
            success = valid_structure and expected_present and plans_complete
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   Customer: {case['customer_state'].bucket} bucket, ${case['customer_state'].balance:.2f}")
            print(f"   Plans generated: {len(result.plans)}")
            print(f"   Plan types: {plan_types}")
            print(f"   Expected type present: {expected_present}")
            print(f"   Citations: {len(result.citations)}")
            print(f"   Status: {status}")
            print()
            
            if success:
                passed += 1
                
        except Exception as e:
            print(f"   ‚ùå ERROR: {e}")
            print()
    
    print(f"CollectionsAdvisor Test Results: {passed}/{total} passed")
    return passed == total

if __name__ == "__main__":
    # Run tests
    success = test_collections_advisor()
    print(f"\n{'üéâ All tests passed!' if success else '‚ö†Ô∏è Some tests failed.'}")



================================================
FILE: app/agents/contracts.py
================================================
"""
Merchant Onboarding & Contract Intelligence
Auto-ingest merchant agreements, extract key terms, generate operational checklists
"""

import json
import logging
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat
from app.rag.core import retrieve
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Pydantic models for strict input/output schema enforcement
class ContractSection(BaseModel):
    heading: str
    text: str
    page_span: str

class ChecklistItem(BaseModel):
    task: str
    owner: str
    due_in_days: int

class RiskFlag(BaseModel):
    severity: str  # low|med|high
    note: str

class Delta(BaseModel):
    field: str
    from_value: Any = None
    to_value: Any = None

class Citation(BaseModel):
    source: str
    snippet: str

class ContractResponse(BaseModel):
    summary: str
    extractions: Dict[str, Any]
    checklist: List[ChecklistItem]
    risk_flags: List[RiskFlag]
    deltas: List[Delta]
    citations: List[Citation]

class ContractIntelligence:
    """
    Merchant Onboarding & Contract Intelligence for automated contract analysis
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None):
        """Initialize ContractIntelligence with RAG components for terms retrieval"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        
        # Load contract ontology
        self._load_contract_ontology()
    
    def _load_contract_ontology(self):
        """Load contract ontology from knowledge base"""
        try:
            ontology_path = Path("app/kb/contract_ontology.md")
            if ontology_path.exists():
                self.ontology_doc = ontology_path.read_text()
                logger.info("Loaded contract ontology successfully")
            else:
                self.ontology_doc = ""
                logger.warning("Contract ontology not found")
        except Exception as e:
            logger.error(f"Failed to load contract ontology: {e}")
            self.ontology_doc = ""
    
    def process_contract(self, file_path: str, prev_version_path: Optional[str] = None) -> ContractResponse:
        """
        Main processing pipeline for contract analysis
        
        Args:
            file_path: Path to the contract file to analyze
            prev_version_path: Optional path to previous version for delta analysis
            
        Returns:
            ContractResponse with extractions, checklist, risk flags, and deltas
        """
        try:
            logger.info(f"Processing contract: {file_path}")
            
            # Step 1: Parse contract into sections
            sections = self.contract_parse(file_path)
            logger.info(f"Parsed {len(sections)} contract sections")
            
            # Step 2: Map sections to ontology using Gemini
            extractions = self.ontology_map(sections, self.ontology_doc)
            logger.info("Completed ontology mapping")
            
            # Step 3: Delta detection if previous version provided
            deltas = []
            if prev_version_path:
                prev_sections = self.contract_parse(prev_version_path)
                prev_extractions = self.ontology_map(prev_sections, self.ontology_doc)
                deltas = self.delta_detect(extractions, prev_extractions)
                logger.info(f"Detected {len(deltas)} deltas from previous version")
            
            # Step 4: Build operational checklist
            checklist = self._build_checklist(extractions)
            logger.info(f"Generated {len(checklist)} checklist items")
            
            # Step 5: Identify risk flags
            risk_flags = self._identify_risk_flags(extractions)
            logger.info(f"Identified {len(risk_flags)} risk flags")
            
            # Step 6: Get policy citations
            citations = self._get_contract_citations(extractions)
            
            # Step 7: Generate summary
            summary = self._generate_summary(extractions, risk_flags, deltas)
            
            return ContractResponse(
                summary=summary,
                extractions=extractions,
                checklist=checklist,
                risk_flags=risk_flags,
                deltas=deltas,
                citations=citations
            )
            
        except Exception as e:
            logger.error(f"Error processing contract: {e}")
            return ContractResponse(
                summary=f"Error processing contract: {str(e)}",
                extractions={},
                checklist=[],
                risk_flags=[],
                deltas=[],
                citations=[]
            )
    
    def contract_parse(self, path: str) -> List[ContractSection]:
        """
        Parse contract file into structured sections
        
        Args:
            path: Path to contract file (supports .md, .txt, and basic .pdf)
            
        Returns:
            List of ContractSection objects with heading, text, and page_span
        """
        try:
            file_path = Path(path)
            
            if not file_path.exists():
                logger.error(f"Contract file not found: {path}")
                return []
            
            # Read file content based on extension
            if file_path.suffix.lower() == '.pdf':
                # For PDF files, assume pre-extracted markdown version exists
                md_path = file_path.with_suffix('.md')
                if md_path.exists():
                    content = md_path.read_text(encoding='utf-8')
                    logger.info(f"Using pre-extracted markdown: {md_path}")
                else:
                    # Basic PDF text extraction (would use pdftotext in production)
                    logger.warning(f"PDF extraction not implemented, using placeholder for: {path}")
                    content = f"# Contract Document\n\nPDF content from {path} would be extracted here."
            else:
                content = file_path.read_text(encoding='utf-8')
            
            # Parse sections based on markdown headers and common contract patterns
            sections = []
            current_section = {"heading": "Preamble", "text": "", "page_span": "1"}
            
            lines = content.split('\n')
            for i, line in enumerate(lines):
                line = line.strip()
                
                # Detect section headers
                if self._is_section_header(line):
                    # Save previous section if it has content
                    if current_section["text"].strip():
                        sections.append(ContractSection(
                            heading=current_section["heading"],
                            text=current_section["text"].strip(),
                            page_span=current_section["page_span"]
                        ))
                    
                    # Start new section
                    current_section = {
                        "heading": self._clean_header(line),
                        "text": "",
                        "page_span": str((i // 50) + 1)  # Rough page estimation
                    }
                else:
                    # Add line to current section
                    if line:  # Skip empty lines
                        current_section["text"] += line + "\n"
            
            # Add final section
            if current_section["text"].strip():
                sections.append(ContractSection(
                    heading=current_section["heading"],
                    text=current_section["text"].strip(),
                    page_span=current_section["page_span"]
                ))
            
            logger.info(f"Parsed {len(sections)} sections from {path}")
            return sections
            
        except Exception as e:
            logger.error(f"Error parsing contract {path}: {e}")
            return []
    
    def _is_section_header(self, line: str) -> bool:
        """Detect if a line is a section header"""
        line = line.strip()
        
        # Markdown headers
        if line.startswith('#'):
            return True
        
        # Numbered sections
        if re.match(r'^\d+\.?\s+[A-Z]', line):
            return True
        
        # Article/Section patterns
        if re.match(r'^(ARTICLE|SECTION|SCHEDULE|APPENDIX|EXHIBIT)\s+[IVX\d]', line, re.IGNORECASE):
            return True
        
        # All caps headers (common in legal documents)
        if len(line) > 3 and line.isupper() and not re.search(r'[.!?]$', line):
            return True
        
        return False
    
    def _clean_header(self, line: str) -> str:
        """Clean and normalize section headers"""
        line = line.strip()
        
        # Remove markdown markers
        line = re.sub(r'^#+\s*', '', line)
        
        # Remove numbering
        line = re.sub(r'^\d+\.?\s*', '', line)
        
        # Remove article/section prefixes
        line = re.sub(r'^(ARTICLE|SECTION|SCHEDULE|APPENDIX|EXHIBIT)\s+[IVX\d]+\.?\s*', '', line, flags=re.IGNORECASE)
        
        return line.strip()
    
    def ontology_map(self, sections: List[ContractSection], ontology_doc: str) -> Dict[str, Any]:
        """
        Map contract sections to ontology using Gemini structured extraction
        
        Args:
            sections: Parsed contract sections
            ontology_doc: Contract ontology documentation
            
        Returns:
            Dictionary with extracted terms mapped to ontology categories
        """
        try:
            # Combine all section text for analysis
            full_text = "\n\n".join([f"## {section.heading}\n{section.text}" for section in sections])
            
            system_prompt = f"""You are a contract analysis expert. Extract key terms from the contract text according to the provided ontology.

ONTOLOGY REFERENCE:
{ontology_doc[:3000]}...

Extract information for these categories:
1. fees (setup_fees, monthly_fees, transaction_fees, volume_discounts, penalty_fees, termination_fees, payment_terms, fee_escalation)
2. sla (uptime_guarantee, response_times, resolution_times, processing_times, reporting_frequency, maintenance_windows, escalation_procedures, performance_penalties)
3. brand_usage (logo_usage_rights, trademark_usage, co_branding_requirements, marketing_approval, brand_guidelines, exclusivity_rights, attribution_requirements, usage_restrictions)
4. data_sharing (data_types_shared, data_retention_period, data_security_requirements, third_party_sharing, customer_consent_requirements, data_deletion_rights, compliance_standards, breach_notification)
5. security (security_certifications, encryption_requirements, access_controls, vulnerability_management, incident_response, audit_requirements, employee_screening, physical_security)
6. termination (termination_notice_period, termination_for_cause, termination_without_cause, data_return_obligations, transition_assistance, post_termination_restrictions, survival_clauses, termination_fees)
7. penalties (late_payment_penalties, performance_penalties, compliance_violations, data_breach_penalties, liquidated_damages, penalty_caps, cure_periods, escalating_penalties)
8. audit_rights (audit_frequency, audit_scope, audit_notice_period, audit_costs, audit_access_rights, third_party_audits, audit_remediation, audit_reporting)
9. marketing_obligations (marketing_spend_commitments, promotional_requirements, event_participation, content_creation, lead_generation, co_marketing_activities, marketing_performance_metrics, marketing_approval_process)

Return ONLY a JSON object with the extracted information. Use null for fields not found in the contract."""

            user_message = f"Extract key terms from this contract:\n\n{full_text[:8000]}"  # Limit for token constraints
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            # Parse Gemini response
            try:
                extractions = json.loads(response.strip())
                logger.info("Successfully extracted contract terms with Gemini")
                return extractions
            except json.JSONDecodeError:
                logger.warning("Gemini response not valid JSON, using fallback extraction")
                return self._fallback_extraction(sections)
                
        except Exception as e:
            logger.error(f"Error in ontology mapping: {e}")
            return self._fallback_extraction(sections)
    
    def _fallback_extraction(self, sections: List[ContractSection]) -> Dict[str, Any]:
        """Fallback extraction using regex patterns"""
        extractions = {
            "fees": {},
            "sla": {},
            "brand_usage": {},
            "data_sharing": {},
            "security": {},
            "termination": {},
            "penalties": {},
            "audit_rights": {},
            "marketing_obligations": {}
        }
        
        full_text = " ".join([section.text for section in sections])
        
        # Basic fee extraction
        fee_patterns = [
            (r'setup fee[:\s]+\$?([\d,]+)', 'setup_fees'),
            (r'monthly fee[:\s]+\$?([\d,]+)', 'monthly_fees'),
            (r'transaction fee[:\s]+(\d+\.?\d*%|\$[\d.]+)', 'transaction_fees'),
            (r'termination fee[:\s]+\$?([\d,]+)', 'termination_fees'),
            (r'net (\d+)', 'payment_terms')
        ]
        
        for pattern, field in fee_patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                extractions["fees"][field] = match.group(1)
        
        # Basic SLA extraction
        sla_patterns = [
            (r'(\d+\.?\d*)%\s+uptime', 'uptime_guarantee'),
            (r'response.*?(\d+)\s+(hours?|days?)', 'response_times'),
            (r'resolution.*?(\d+)\s+(hours?|days?)', 'resolution_times')
        ]
        
        for pattern, field in sla_patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                extractions["sla"][field] = f"{match.group(1)} {match.group(2) if len(match.groups()) > 1 else ''}"
        
        # Basic termination extraction
        termination_patterns = [
            (r'(\d+)\s+days?\s+notice', 'termination_notice_period'),
            (r'immediate termination', 'termination_for_cause')
        ]
        
        for pattern, field in termination_patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                if field == 'termination_for_cause':
                    extractions["termination"][field] = True
                else:
                    extractions["termination"][field] = match.group(1)
        
        return extractions
    
    def delta_detect(self, curr_extractions: Dict[str, Any], prev_extractions: Dict[str, Any]) -> List[Delta]:
        """
        Detect changes between current and previous contract extractions
        
        Args:
            curr_extractions: Current contract extractions
            prev_extractions: Previous contract extractions
            
        Returns:
            List of Delta objects representing changes
        """
        deltas = []
        
        try:
            # Compare each category
            for category in curr_extractions:
                if category not in prev_extractions:
                    # New category added
                    deltas.append(Delta(
                        field=category,
                        from_value=None,
                        to_value=curr_extractions[category]
                    ))
                    continue
                
                curr_cat = curr_extractions[category]
                prev_cat = prev_extractions[category]
                
                if isinstance(curr_cat, dict) and isinstance(prev_cat, dict):
                    # Compare fields within category
                    for field in curr_cat:
                        curr_val = curr_cat[field]
                        prev_val = prev_cat.get(field)
                        
                        if curr_val != prev_val:
                            deltas.append(Delta(
                                field=f"{category}.{field}",
                                from_value=prev_val,
                                to_value=curr_val
                            ))
                    
                    # Check for removed fields
                    for field in prev_cat:
                        if field not in curr_cat:
                            deltas.append(Delta(
                                field=f"{category}.{field}",
                                from_value=prev_cat[field],
                                to_value=None
                            ))
                
                elif curr_cat != prev_cat:
                    # Direct value comparison
                    deltas.append(Delta(
                        field=category,
                        from_value=prev_cat,
                        to_value=curr_cat
                    ))
            
            # Check for removed categories
            for category in prev_extractions:
                if category not in curr_extractions:
                    deltas.append(Delta(
                        field=category,
                        from_value=prev_extractions[category],
                        to_value=None
                    ))
            
            logger.info(f"Detected {len(deltas)} deltas between contract versions")
            return deltas
            
        except Exception as e:
            logger.error(f"Error in delta detection: {e}")
            return []
    
    def _build_checklist(self, extractions: Dict[str, Any]) -> List[ChecklistItem]:
        """Build operational checklist based on contract extractions"""
        checklist = []
        
        try:
            # Data sharing obligations
            if extractions.get("data_sharing", {}).get("data_types_shared"):
                checklist.append(ChecklistItem(
                    task="Implement data-share audit procedures",
                    owner="Risk",
                    due_in_days=30
                ))
                
                checklist.append(ChecklistItem(
                    task="Set up data retention and deletion processes",
                    owner="Operations",
                    due_in_days=45
                ))
            
            # Security requirements
            security = extractions.get("security", {})
            if security.get("security_certifications"):
                checklist.append(ChecklistItem(
                    task="Obtain required security certifications",
                    owner="Risk",
                    due_in_days=90
                ))
            
            if security.get("audit_requirements"):
                checklist.append(ChecklistItem(
                    task="Schedule security audit",
                    owner="Risk",
                    due_in_days=60
                ))
            
            # SLA monitoring
            sla = extractions.get("sla", {})
            if sla.get("uptime_guarantee") or sla.get("response_times"):
                checklist.append(ChecklistItem(
                    task="Set up SLA monitoring and alerting",
                    owner="Operations",
                    due_in_days=14
                ))
            
            # Brand usage compliance
            brand = extractions.get("brand_usage", {})
            if brand.get("marketing_approval"):
                checklist.append(ChecklistItem(
                    task="Establish marketing approval workflow",
                    owner="Marketing",
                    due_in_days=21
                ))
            
            if brand.get("brand_guidelines"):
                checklist.append(ChecklistItem(
                    task="Review and implement brand guidelines",
                    owner="Marketing",
                    due_in_days=14
                ))
            
            # Fee structure implementation
            fees = extractions.get("fees", {})
            if fees.get("setup_fees") or fees.get("monthly_fees"):
                checklist.append(ChecklistItem(
                    task="Configure billing system for fee structure",
                    owner="Finance",
                    due_in_days=30
                ))
            
            # Marketing obligations
            marketing = extractions.get("marketing_obligations", {})
            if marketing.get("marketing_spend_commitments"):
                checklist.append(ChecklistItem(
                    task="Plan marketing budget allocation",
                    owner="Marketing",
                    due_in_days=30
                ))
            
            if marketing.get("event_participation"):
                checklist.append(ChecklistItem(
                    task="Schedule required event participation",
                    owner="Marketing",
                    due_in_days=60
                ))
            
            # Termination procedures
            termination = extractions.get("termination", {})
            if termination.get("data_return_obligations"):
                checklist.append(ChecklistItem(
                    task="Document data return procedures",
                    owner="Legal",
                    due_in_days=45
                ))
            
            # Audit rights preparation
            audit = extractions.get("audit_rights", {})
            if audit.get("audit_frequency"):
                checklist.append(ChecklistItem(
                    task="Prepare audit documentation and procedures",
                    owner="Risk",
                    due_in_days=30
                ))
            
            logger.info(f"Generated {len(checklist)} checklist items")
            return checklist
            
        except Exception as e:
            logger.error(f"Error building checklist: {e}")
            return []
    
    def _identify_risk_flags(self, extractions: Dict[str, Any]) -> List[RiskFlag]:
        """Identify risk flags based on contract terms"""
        risk_flags = []
        
        try:
            # High risk: Uncapped penalties
            penalties = extractions.get("penalties", {})
            if penalties and not penalties.get("penalty_caps"):
                if any(penalties.get(key) for key in ["late_payment_penalties", "performance_penalties", "data_breach_penalties"]):
                    risk_flags.append(RiskFlag(
                        severity="high",
                        note="Uncapped penalties detected - unlimited liability exposure"
                    ))
            
            # High risk: Very high SLA requirements
            sla = extractions.get("sla", {})
            uptime = sla.get("uptime_guarantee", "")
            if isinstance(uptime, str) and "99.9" in uptime:
                risk_flags.append(RiskFlag(
                    severity="high",
                    note="Very high uptime SLA (>99.9%) - difficult to achieve"
                ))
            
            # Medium risk: Short termination notice
            termination = extractions.get("termination", {})
            notice_period = termination.get("termination_notice_period")
            if notice_period:
                try:
                    days = int(re.search(r'\d+', str(notice_period)).group())
                    if days < 30:
                        risk_flags.append(RiskFlag(
                            severity="high",
                            note=f"Short termination notice period ({days} days)"
                        ))
                    elif days < 90:
                        risk_flags.append(RiskFlag(
                            severity="med",
                            note=f"Moderate termination notice period ({days} days)"
                        ))
                except:
                    pass
            
            # Medium risk: Significant fees
            fees = extractions.get("fees", {})
            setup_fee = fees.get("setup_fees", "")
            if isinstance(setup_fee, str):
                try:
                    amount = int(re.sub(r'[^\d]', '', setup_fee))
                    if amount > 10000:
                        risk_flags.append(RiskFlag(
                            severity="med",
                            note=f"High setup fee (${amount:,})"
                        ))
                except:
                    pass
            
            # Medium risk: Broad audit rights
            audit = extractions.get("audit_rights", {})
            if audit.get("audit_frequency") and "annual" not in str(audit.get("audit_frequency", "")).lower():
                risk_flags.append(RiskFlag(
                    severity="med",
                    note="Frequent audit rights - operational burden"
                ))
            
            # High risk: Exclusive rights
            brand = extractions.get("brand_usage", {})
            if brand.get("exclusivity_rights"):
                risk_flags.append(RiskFlag(
                    severity="high",
                    note="Exclusive rights granted - limits future partnerships"
                ))
            
            # Medium risk: Complex data sharing
            data = extractions.get("data_sharing", {})
            if data.get("third_party_sharing") and data.get("compliance_standards"):
                risk_flags.append(RiskFlag(
                    severity="med",
                    note="Complex data sharing with compliance requirements"
                ))
            
            # Low risk: Standard terms
            if not risk_flags:
                risk_flags.append(RiskFlag(
                    severity="low",
                    note="Standard contract terms with typical risk profile"
                ))
            
            logger.info(f"Identified {len(risk_flags)} risk flags")
            return risk_flags
            
        except Exception as e:
            logger.error(f"Error identifying risk flags: {e}")
            return [RiskFlag(severity="med", note="Error in risk assessment")]
    
    def _get_contract_citations(self, extractions: Dict[str, Any]) -> List[Citation]:
        """Get contract policy citations from knowledge base with Tavily fallback"""
        citations = []
        
        if not all([self.retriever, self.embedder]):
            logger.warning("RAG components not available for contract citations")
            return citations
        
        try:
            # Create queries for key contract terms
            queries = []
            
            # Add queries based on extracted terms
            if extractions.get("audit_rights"):
                queries.append("audit rights contract terms")
            if extractions.get("sla"):
                queries.append("SLA days service level agreement")
            if extractions.get("data_sharing"):
                queries.append("data sharing reconciliation")
            
            # Default query if no specific terms
            if not queries:
                queries = ["contract terms merchant agreement"]
            
            # Retrieve relevant documents for each query
            for query in queries[:3]:  # Limit to 3 queries
                results = retrieve(self.retriever, self.embedder, query, k=2)
                
                for result in results:
                    citations.append(Citation(
                        source=result.get("filename", "Contract Policy"),
                        snippet=result.get("snippet", "")[:300] + "..."
                    ))
            
            # Tavily fallback if insufficient citations
            if len(citations) < 1:
                logger.info("Insufficient local contract citations, searching web...")
                try:
                    web_docs = web_search_into_docstore(
                        self.docstore,
                        self.embedder,
                        "contract audit rights SLA days reconciliation terms",
                        max_results=2
                    )
                    
                    # Re-retrieve after adding web content
                    if web_docs:
                        results = retrieve(self.retriever, self.embedder, 
                                         "contract terms audit SLA", k=2)
                        
                        for result in results:
                            citations.append(Citation(
                                source=result.get("filename", "Web Search"),
                                snippet=result.get("snippet", "")[:300] + "..."
                            ))
                            
                except Exception as e:
                    logger.warning(f"Web search for contract terms failed: {e}")
            
        except Exception as e:
            logger.error(f"Error retrieving contract citations: {e}")
        
        return citations
    
    def _generate_summary(self, extractions: Dict[str, Any], risk_flags: List[RiskFlag], 
                         deltas: List[Delta]) -> str:
        """Generate executive summary of contract analysis"""
        try:
            # Count non-empty categories
            populated_categories = sum(1 for cat in extractions.values() if cat)
            
            # Risk summary
            high_risks = len([r for r in risk_flags if r.severity == "high"])
            med_risks = len([r for r in risk_flags if r.severity == "med"])
            
            # Key terms summary
            key_terms = []
            
            fees = extractions.get("fees", {})
            if fees.get("setup_fees"):
                key_terms.append(f"Setup fee: {fees['setup_fees']}")
            if fees.get("monthly_fees"):
                key_terms.append(f"Monthly fee: {fees['monthly_fees']}")
            
            sla = extractions.get("sla", {})
            if sla.get("uptime_guarantee"):
                key_terms.append(f"Uptime SLA: {sla['uptime_guarantee']}")
            
            termination = extractions.get("termination", {})
            if termination.get("termination_notice_period"):
                key_terms.append(f"Termination notice: {termination['termination_notice_period']}")
            
            # Build summary
            summary_parts = [
                f"Contract analysis completed with {populated_categories} categories extracted."
            ]
            
            if key_terms:
                summary_parts.append(f"Key terms: {', '.join(key_terms[:3])}.")
            
            if high_risks > 0:
                summary_parts.append(f"‚ö†Ô∏è {high_risks} high-risk items require immediate attention.")
            elif med_risks > 0:
                summary_parts.append(f"üìã {med_risks} medium-risk items identified for review.")
            else:
                summary_parts.append("‚úÖ Standard risk profile with typical contract terms.")
            
            if deltas:
                summary_parts.append(f"üîÑ {len(deltas)} changes detected from previous version.")
            
            return " ".join(summary_parts)
            
        except Exception as e:
            logger.error(f"Error generating summary: {e}")
            return "Contract analysis completed with basic extraction."

# Test cases for contract scenarios
def test_contract_intelligence():
    """Test ContractIntelligence with golden-path scenarios"""
    print("üß™ Testing ContractIntelligence Golden Paths")
    print("=" * 50)
    
    intelligence = ContractIntelligence()
    
    test_cases = [
        {
            "name": "MD contract with audit rights ‚Üí checklist includes audit procedures",
            "file_path": "app/contracts/merchant_agreement.md",
            "expected_checklist_task": "audit",
            "expected_risk_flags": True
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            
            result = intelligence.process_contract(case["file_path"])
            
            # Validate response structure
            valid_structure = (
                hasattr(result, 'summary') and
                hasattr(result, 'extractions') and
                hasattr(result, 'checklist') and
                hasattr(result, 'risk_flags') and
                hasattr(result, 'deltas') and
                hasattr(result, 'citations')
            )
            
            # Check for expected checklist task
            checklist_ok = any(
                case["expected_checklist_task"].lower() in item.task.lower()
                for item in result.checklist
            )
            
            # Check for risk flags
            risk_flags_ok = len(result.risk_flags) > 0 if case["expected_risk_flags"] else True
            
            success = valid_structure and checklist_ok and risk_flags_ok
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   File: {case['file_path']}")
            print(f"   Extractions: {len(result.extractions)} categories")
            print(f"   Checklist: {len(result.checklist)} items")
            print(f"   Risk flags: {len(result.risk_flags)}")
            print(f"   Status: {status}")
            
            if success:
                passed += 1
            else:
                if not valid_structure:
                    print(f"   ‚ùå Invalid response structure")
                if not checklist_ok:
                    print(f"   ‚ùå Expected checklist task '{case['expected_checklist_task']}' not found")
                if not risk_flags_ok:
                    print(f"   ‚ùå Expected risk flags not found")
            
            print()
            
        except Exception as e:
            print(f"   ‚ùå FAIL - Exception: {e}")
            print()
    
    # Test delta detection with v1‚Üív2 penalty clause addition
    print("Testing Delta Detection: v1‚Üív2 penalty clause addition")
    print("-" * 50)
    
    try:
        # Create mock extractions for v1 and v2
        v1_extractions = {
            "fees": {"setup_fees": "$5000", "monthly_fees": "$1000"},
            "sla": {"uptime_guarantee": "99.5%"},
            "penalties": {}
        }
        
        v2_extractions = {
            "fees": {"setup_fees": "$5000", "monthly_fees": "$1000"},
            "sla": {"uptime_guarantee": "99.5%"},
            "penalties": {"late_payment_penalties": "5% per month", "penalty_caps": None}
        }
        
        deltas = intelligence.delta_detect(v2_extractions, v1_extractions)
        
        # Check if penalty clause delta is detected
        penalty_delta_found = any(
            "penalties" in delta.field and delta.to_value
            for delta in deltas
        )
        
        if penalty_delta_found:
            print("‚úÖ PASS - Penalty clause delta detected")
            print(f"   Deltas found: {len(deltas)}")
            for delta in deltas:
                print(f"   - {delta.field}: {delta.from_value} ‚Üí {delta.to_value}")
        else:
            print("‚ùå FAIL - Penalty clause delta not detected")
    
    except Exception as e:
        print(f"‚ùå FAIL - Delta detection test failed: {e}")
    
    print()
    print("=" * 50)
    print(f"üìä Test Results: {passed}/{total} passed")
    
    return passed == total


def main():
    """Main function for testing and demonstration"""
    print("üîç Contract Intelligence Agent")
    print("=" * 50)
    print("Analyzing merchant agreements and extracting key terms...")
    print()
    
    # Run tests
    success = test_contract_intelligence()
    
    if success:
        print("üéâ All tests passed! Contract Intelligence is working correctly.")
    else:
        print("‚ö†Ô∏è Some tests failed. Please review the implementation.")
    
    # Example usage
    print("\nüí° Example Usage:")
    print("-" * 20)
    print("from app.agents.contracts import ContractIntelligence")
    print("intelligence = ContractIntelligence(docstore, embedder, retriever)")
    print("result = intelligence.process_contract('path/to/contract.md')")
    print("print(result.summary)")
    print("for item in result.checklist:")
    print("    print(f'- {item.task} ({item.owner}, {item.due_in_days} days)')")


if __name__ == "__main__":
    main()



================================================
FILE: app/agents/devcopilot.py
================================================
"""
Developer & Partner API Copilot
Interactive guide for partner APIs with code snippets, validation, and Postman collections
"""

import json
import logging
import os
from pathlib import Path
from typing import Dict, List, Any, Optional, Literal
import jsonschema
from jsonschema import validate, ValidationError

from pydantic import BaseModel, Field

from app.llm.gemini import chat

logger = logging.getLogger(__name__)

# Pydantic models for strict input/output schema enforcement
class ValidationError(BaseModel):
    path: str
    msg: str

class ValidationResult(BaseModel):
    ok: bool
    errors: List[ValidationError] = []

class CodeSnippet(BaseModel):
    lang: str
    code: str

class PostmanInfo(BaseModel):
    filename: str

class DevCopilotResponse(BaseModel):
    endpoint: str
    snippet: CodeSnippet
    example_request: Dict[str, Any]
    validation: ValidationResult
    postman: PostmanInfo

class DevCopilot:
    """
    Developer & Partner API Copilot for interactive API integration guidance
    """
    
    def __init__(self):
        """Initialize DevCopilot with OpenAPI registry"""
        self.openapi_dir = Path("app/openapi")
        self.downloads_dir = Path("app/ui/downloads")
        self.downloads_dir.mkdir(exist_ok=True)
    
    def generate_code_guide(
        self, 
        service: str, 
        endpoint: Optional[str] = None, 
        lang: Literal["python", "javascript", "java", "curl"] = "python",
        sample: Optional[Dict[str, Any]] = None
    ) -> DevCopilotResponse:
        """
        Main processing pipeline for API code generation and guidance
        
        Args:
            service: Service name to load OpenAPI spec for
            endpoint: Specific endpoint (if None, suggests top 3)
            lang: Programming language for code snippet
            sample: Sample payload to validate
            
        Returns:
            DevCopilotResponse with code snippet, validation, and Postman collection
        """
        try:
            logger.info(f"Generating code guide for service: {service}")
            
            # Step 1: Load OpenAPI spec
            spec = self.openapi_registry(service)
            if not spec:
                return self._error_response(f"Service '{service}' not found in registry")
            
            # Step 2: Determine endpoint
            if not endpoint:
                suggested_endpoints = self._suggest_endpoints(spec, service)
                endpoint = suggested_endpoints[0] if suggested_endpoints else None
                
            if not endpoint:
                return self._error_response("No suitable endpoint found")
            
            logger.info(f"Using endpoint: {endpoint}")
            
            # Step 3: Generate code snippet
            snippet = self._generate_code_snippet(spec, endpoint, lang)
            
            # Step 4: Create example request
            example_request = self._generate_example_request(spec, endpoint)
            
            # Step 5: Validate sample payload if provided
            validation = ValidationResult(ok=True, errors=[])
            if sample:
                validation = self.payload_validate(sample, spec, endpoint)
            
            # Step 6: Generate Postman collection
            postman_info = self.postman_export(spec, endpoint)
            
            return DevCopilotResponse(
                endpoint=endpoint,
                snippet=snippet,
                example_request=example_request,
                validation=validation,
                postman=postman_info
            )
            
        except Exception as e:
            logger.error(f"Error generating code guide: {e}")
            return self._error_response(f"Error: {str(e)}")
    
    def openapi_registry(self, service: str) -> Optional[Dict[str, Any]]:
        """
        Load OpenAPI specification from registry
        
        Args:
            service: Service name
            
        Returns:
            OpenAPI spec dictionary or None if not found
        """
        try:
            spec_file = self.openapi_dir / f"{service}.json"
            if not spec_file.exists():
                logger.error(f"OpenAPI spec not found: {spec_file}")
                return None
            
            with open(spec_file, 'r') as f:
                spec = json.load(f)
            
            logger.info(f"Loaded OpenAPI spec for {service}")
            return spec
            
        except Exception as e:
            logger.error(f"Error loading OpenAPI spec for {service}: {e}")
            return None
    
    def payload_validate(
        self, 
        payload: Dict[str, Any], 
        spec: Dict[str, Any], 
        endpoint: str
    ) -> ValidationResult:
        """
        Validate payload against OpenAPI schema
        
        Args:
            payload: JSON payload to validate
            spec: OpenAPI specification
            endpoint: API endpoint path
            
        Returns:
            ValidationResult with errors if any
        """
        try:
            # Find the schema for the endpoint
            schema = self._extract_request_schema(spec, endpoint)
            if not schema:
                return ValidationResult(
                    ok=False, 
                    errors=[ValidationError(path="", msg="No schema found for endpoint")]
                )
            
            # Validate payload against schema
            try:
                validate(instance=payload, schema=schema)
                return ValidationResult(ok=True, errors=[])
            
            except jsonschema.ValidationError as e:
                errors = self._format_validation_errors([e])
                return ValidationResult(ok=False, errors=errors)
            
            except jsonschema.SchemaError as e:
                return ValidationResult(
                    ok=False,
                    errors=[ValidationError(path="schema", msg=f"Invalid schema: {str(e)}")]
                )
                
        except Exception as e:
            logger.error(f"Error validating payload: {e}")
            return ValidationResult(
                ok=False,
                errors=[ValidationError(path="", msg=f"Validation error: {str(e)}")]
            )
    
    def mock_sandbox_call(self, endpoint: str, request: Dict[str, Any]) -> Dict[str, Any]:
        """
        Mock sandbox call that echoes request with basic constraints
        
        Args:
            endpoint: API endpoint
            request: Request payload
            
        Returns:
            Mock response with status and body
        """
        try:
            # Basic mock response based on endpoint
            if "payment" in endpoint.lower():
                return {
                    "status": 201,
                    "body": {
                        "id": "pay_mock_123456",
                        "amount": request.get("amount", 100.00),
                        "currency": request.get("currency", "USD"),
                        "status": "completed",
                        "createdAt": "2024-01-01T12:00:00Z"
                    }
                }
            elif "balance" in endpoint.lower():
                return {
                    "status": 200,
                    "body": {
                        "accountId": request.get("accountId", "acc_123"),
                        "availableBalance": 1500.00,
                        "currentBalance": 2000.00,
                        "currency": "USD"
                    }
                }
            else:
                return {
                    "status": 200,
                    "body": {
                        "message": "Mock response",
                        "request": request
                    }
                }
                
        except Exception as e:
            return {
                "status": 500,
                "body": {
                    "error": f"Mock error: {str(e)}"
                }
            }
    
    def postman_export(
        self, 
        spec: Dict[str, Any], 
        focus_endpoint: Optional[str] = None
    ) -> PostmanInfo:
        """
        Export Postman collection for the API spec
        
        Args:
            spec: OpenAPI specification
            focus_endpoint: Specific endpoint to focus on
            
        Returns:
            PostmanInfo with filename
        """
        try:
            service_name = spec.get("info", {}).get("title", "API").replace(" ", "_")
            filename = f"{service_name}_collection.json"
            filepath = self.downloads_dir / filename
            
            # Create basic Postman collection
            collection = {
                "info": {
                    "name": spec.get("info", {}).get("title", "API Collection"),
                    "description": spec.get("info", {}).get("description", ""),
                    "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
                },
                "auth": {
                    "type": "apikey",
                    "apikey": [
                        {
                            "key": "key",
                            "value": "X-API-Key",
                            "type": "string"
                        },
                        {
                            "key": "value",
                            "value": "{{API_KEY}}",
                            "type": "string"
                        }
                    ]
                },
                "variable": [
                    {
                        "key": "baseUrl",
                        "value": spec.get("servers", [{}])[0].get("url", ""),
                        "type": "string"
                    }
                ],
                "item": []
            }
            
            # Add requests for each endpoint
            paths = spec.get("paths", {})
            for path, methods in paths.items():
                if focus_endpoint and path != focus_endpoint:
                    continue
                    
                for method, operation in methods.items():
                    if method.upper() in ["GET", "POST", "PUT", "DELETE", "PATCH"]:
                        request_item = self._create_postman_request(
                            path, method.upper(), operation, spec
                        )
                        collection["item"].append(request_item)
            
            # Write collection to file
            with open(filepath, 'w') as f:
                json.dump(collection, f, indent=2)
            
            logger.info(f"Exported Postman collection: {filename}")
            return PostmanInfo(filename=filename)
            
        except Exception as e:
            logger.error(f"Error exporting Postman collection: {e}")
            return PostmanInfo(filename="error_collection.json")
    
    def _suggest_endpoints(self, spec: Dict[str, Any], service: str) -> List[str]:
        """Suggest top 3 endpoints using Gemini"""
        try:
            paths = list(spec.get("paths", {}).keys())
            if len(paths) <= 3:
                return paths
            
            # Use Gemini to suggest most relevant endpoints
            system_prompt = f"""You are an API expert. Given the following API endpoints for the {service} service, suggest the top 3 most commonly used endpoints that developers would want to integrate first.

Consider endpoints that are:
1. Core functionality (create, read operations)
2. Most likely to be used in initial integration
3. Provide immediate value to developers

Return only the endpoint paths as a JSON array, nothing else."""

            user_message = f"API endpoints: {json.dumps(paths)}"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            try:
                suggested = json.loads(response.strip())
                return suggested[:3] if isinstance(suggested, list) else paths[:3]
            except:
                return paths[:3]
                
        except Exception as e:
            logger.error(f"Error suggesting endpoints: {e}")
            return list(spec.get("paths", {}).keys())[:3]
    
    def _generate_code_snippet(
        self, 
        spec: Dict[str, Any], 
        endpoint: str, 
        lang: str
    ) -> CodeSnippet:
        """Generate code snippet for the endpoint"""
        try:
            base_url = spec.get("servers", [{}])[0].get("url", "https://api.example.com")
            
            # Get endpoint details
            path_info = spec.get("paths", {}).get(endpoint, {})
            method = list(path_info.keys())[0] if path_info else "get"
            operation = path_info.get(method, {})
            
            # Generate example request body
            example_body = self._generate_example_request(spec, endpoint)
            
            if lang == "python":
                code = self._generate_python_snippet(base_url, endpoint, method, example_body)
            elif lang == "javascript":
                code = self._generate_javascript_snippet(base_url, endpoint, method, example_body)
            elif lang == "java":
                code = self._generate_java_snippet(base_url, endpoint, method, example_body)
            elif lang == "curl":
                code = self._generate_curl_snippet(base_url, endpoint, method, example_body)
            else:
                code = f"# Code snippet for {lang} not implemented yet"
            
            return CodeSnippet(lang=lang, code=code)
            
        except Exception as e:
            logger.error(f"Error generating code snippet: {e}")
            return CodeSnippet(
                lang=lang, 
                code=f"# Error generating {lang} snippet: {str(e)}"
            )
    
    def _generate_python_snippet(
        self, 
        base_url: str, 
        endpoint: str, 
        method: str, 
        example_body: Dict[str, Any]
    ) -> str:
        """Generate Python code snippet"""
        if method.upper() == "GET":
            return f'''import requests

# API Configuration
API_KEY = "your_api_key_here"
BASE_URL = "{base_url}"

# Headers
headers = {{
    "X-API-Key": API_KEY,
    "Content-Type": "application/json"
}}

# Make GET request
response = requests.get(
    f"{{BASE_URL}}{endpoint}",
    headers=headers
)

# Handle response
if response.status_code == 200:
    data = response.json()
    print("Success:", data)
else:
    print(f"Error {{response.status_code}}: {{response.text}}")
'''
        else:
            return f'''import requests
import json

# API Configuration
API_KEY = "your_api_key_here"
BASE_URL = "{base_url}"

# Headers
headers = {{
    "X-API-Key": API_KEY,
    "Content-Type": "application/json"
}}

# Request payload
payload = {json.dumps(example_body, indent=4)}

# Make {method.upper()} request
response = requests.{method.lower()}(
    f"{{BASE_URL}}{endpoint}",
    headers=headers,
    json=payload
)

# Handle response
if response.status_code in [200, 201]:
    data = response.json()
    print("Success:", data)
else:
    print(f"Error {{response.status_code}}: {{response.text}}")
'''
    
    def _generate_javascript_snippet(
        self, 
        base_url: str, 
        endpoint: str, 
        method: str, 
        example_body: Dict[str, Any]
    ) -> str:
        """Generate JavaScript code snippet"""
        if method.upper() == "GET":
            return f'''// API Configuration
const API_KEY = "your_api_key_here";
const BASE_URL = "{base_url}";

// Make GET request
fetch(`${{BASE_URL}}{endpoint}`, {{
    method: 'GET',
    headers: {{
        'X-API-Key': API_KEY,
        'Content-Type': 'application/json'
    }}
}})
.then(response => {{
    if (!response.ok) {{
        throw new Error(`HTTP error! status: ${{response.status}}`);
    }}
    return response.json();
}})
.then(data => {{
    console.log('Success:', data);
}})
.catch(error => {{
    console.error('Error:', error);
}});
'''
        else:
            return f'''// API Configuration
const API_KEY = "your_api_key_here";
const BASE_URL = "{base_url}";

// Request payload
const payload = {json.dumps(example_body, indent=2)};

// Make {method.upper()} request
fetch(`${{BASE_URL}}{endpoint}`, {{
    method: '{method.upper()}',
    headers: {{
        'X-API-Key': API_KEY,
        'Content-Type': 'application/json'
    }},
    body: JSON.stringify(payload)
}})
.then(response => {{
    if (!response.ok) {{
        throw new Error(`HTTP error! status: ${{response.status}}`);
    }}
    return response.json();
}})
.then(data => {{
    console.log('Success:', data);
}})
.catch(error => {{
    console.error('Error:', error);
}});
'''
    
    def _generate_curl_snippet(
        self, 
        base_url: str, 
        endpoint: str, 
        method: str, 
        example_body: Dict[str, Any]
    ) -> str:
        """Generate cURL code snippet"""
        if method.upper() == "GET":
            return f'''curl -X GET "{base_url}{endpoint}" \\
  -H "X-API-Key: your_api_key_here" \\
  -H "Content-Type: application/json"
'''
        else:
            return f'''curl -X {method.upper()} "{base_url}{endpoint}" \\
  -H "X-API-Key: your_api_key_here" \\
  -H "Content-Type: application/json" \\
  -d '{json.dumps(example_body)}'
'''
    
    def _generate_java_snippet(
        self, 
        base_url: str, 
        endpoint: str, 
        method: str, 
        example_body: Dict[str, Any]
    ) -> str:
        """Generate Java code snippet"""
        return f'''import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.net.URI;

public class APIClient {{
    private static final String API_KEY = "your_api_key_here";
    private static final String BASE_URL = "{base_url}";
    
    public static void main(String[] args) throws Exception {{
        HttpClient client = HttpClient.newHttpClient();
        
        HttpRequest.Builder requestBuilder = HttpRequest.newBuilder()
            .uri(URI.create(BASE_URL + "{endpoint}"))
            .header("X-API-Key", API_KEY)
            .header("Content-Type", "application/json");
            
        {"// Request body" if method.upper() != "GET" else ""}
        {"String requestBody = " + json.dumps(json.dumps(example_body)) + ";" if method.upper() != "GET" else ""}
        
        HttpRequest request = requestBuilder
            .{method.upper()}({f"HttpRequest.BodyPublishers.ofString(requestBody)" if method.upper() != "GET" else "HttpRequest.BodyPublishers.noBody()"})
            .build();
            
        HttpResponse<String> response = client.send(request, 
            HttpResponse.BodyHandlers.ofString());
            
        System.out.println("Status: " + response.statusCode());
        System.out.println("Response: " + response.body());
    }}
}}
'''
    
    def _generate_example_request(self, spec: Dict[str, Any], endpoint: str) -> Dict[str, Any]:
        """Generate example request payload"""
        try:
            path_info = spec.get("paths", {}).get(endpoint, {})
            
            # Find POST/PUT method with request body
            for method, operation in path_info.items():
                request_body = operation.get("requestBody", {})
                if request_body:
                    content = request_body.get("content", {})
                    json_content = content.get("application/json", {})
                    schema = json_content.get("schema", {})
                    
                    return self._generate_example_from_schema(schema, spec)
            
            # If no request body, return empty dict
            return {}
            
        except Exception as e:
            logger.error(f"Error generating example request: {e}")
            return {"error": "Could not generate example"}
    
    def _generate_example_from_schema(
        self, 
        schema: Dict[str, Any], 
        spec: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate example data from JSON schema"""
        try:
            # Handle $ref
            if "$ref" in schema:
                ref_path = schema["$ref"].split("/")
                ref_schema = spec
                for part in ref_path[1:]:  # Skip '#'
                    ref_schema = ref_schema.get(part, {})
                return self._generate_example_from_schema(ref_schema, spec)
            
            schema_type = schema.get("type", "object")
            
            if schema_type == "object":
                example = {}
                properties = schema.get("properties", {})
                required = schema.get("required", [])
                
                for prop_name, prop_schema in properties.items():
                    if prop_name in required or len(example) < 3:  # Include required + some optional
                        example[prop_name] = self._generate_example_value(prop_schema, spec)
                
                return example
            
            elif schema_type == "array":
                items_schema = schema.get("items", {})
                return [self._generate_example_from_schema(items_schema, spec)]
            
            else:
                return self._generate_example_value(schema, spec)
                
        except Exception as e:
            logger.error(f"Error generating example from schema: {e}")
            return {"example": "value"}
    
    def _generate_example_value(self, schema: Dict[str, Any], spec: Dict[str, Any]) -> Any:
        """Generate example value based on schema type"""
        schema_type = schema.get("type", "string")
        
        if schema_type == "string":
            if schema.get("format") == "date-time":
                return "2024-01-01T12:00:00Z"
            elif "enum" in schema:
                return schema["enum"][0]
            else:
                return "example_string"
        
        elif schema_type == "number":
            minimum = schema.get("minimum", 0)
            return max(100.0, minimum + 1)
        
        elif schema_type == "integer":
            minimum = schema.get("minimum", 0)
            return max(1, minimum + 1)
        
        elif schema_type == "boolean":
            return True
        
        elif schema_type == "object":
            return self._generate_example_from_schema(schema, spec)
        
        elif schema_type == "array":
            items_schema = schema.get("items", {})
            return [self._generate_example_value(items_schema, spec)]
        
        else:
            return "example_value"
    
    def _extract_request_schema(self, spec: Dict[str, Any], endpoint: str) -> Optional[Dict[str, Any]]:
        """Extract request schema for validation"""
        try:
            path_info = spec.get("paths", {}).get(endpoint, {})
            
            for method, operation in path_info.items():
                request_body = operation.get("requestBody", {})
                if request_body:
                    content = request_body.get("content", {})
                    json_content = content.get("application/json", {})
                    schema = json_content.get("schema", {})
                    
                    # Resolve $ref if present
                    if "$ref" in schema:
                        return self._resolve_schema_ref(schema["$ref"], spec)
                    
                    return schema
            
            return None
            
        except Exception as e:
            logger.error(f"Error extracting request schema: {e}")
            return None
    
    def _resolve_schema_ref(self, ref: str, spec: Dict[str, Any]) -> Dict[str, Any]:
        """Resolve $ref to actual schema"""
        try:
            ref_path = ref.split("/")
            schema = spec
            for part in ref_path[1:]:  # Skip '#'
                schema = schema.get(part, {})
            return schema
        except Exception as e:
            logger.error(f"Error resolving schema ref {ref}: {e}")
            return {}
    
    def _format_validation_errors(self, errors: List[jsonschema.ValidationError]) -> List[ValidationError]:
        """Format validation errors for response"""
        formatted_errors = []
        
        for error in errors:
            path = ".".join(str(p) for p in error.absolute_path) if error.absolute_path else "root"
            formatted_errors.append(ValidationError(
                path=path,
                msg=error.message
            ))
        
        return formatted_errors
    
    def _create_postman_request(
        self, 
        path: str, 
        method: str, 
        operation: Dict[str, Any], 
        spec: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Create Postman request item"""
        request_item = {
            "name": operation.get("summary", f"{method} {path}"),
            "request": {
                "method": method,
                "header": [
                    {
                        "key": "Content-Type",
                        "value": "application/json"
                    }
                ],
                "url": {
                    "raw": "{{baseUrl}}" + path,
                    "host": ["{{baseUrl}}"],
                    "path": path.strip("/").split("/")
                }
            }
        }
        
        # Add request body if present
        request_body = operation.get("requestBody", {})
        if request_body:
            example_body = self._generate_example_request(spec, path)
            request_item["request"]["body"] = {
                "mode": "raw",
                "raw": json.dumps(example_body, indent=2)
            }
        
        return request_item
    
    def _error_response(self, message: str) -> DevCopilotResponse:
        """Create error response"""
        return DevCopilotResponse(
            endpoint="",
            snippet=CodeSnippet(lang="text", code=f"Error: {message}"),
            example_request={},
            validation=ValidationResult(ok=False, errors=[ValidationError(path="", msg=message)]),
            postman=PostmanInfo(filename="error.json")
        )

# Test cases for DevCopilot scenarios
def test_devcopilot():
    """Test DevCopilot with golden-path scenarios"""
    print("üß™ Testing DevCopilot Golden Paths")
    print("=" * 50)
    
    copilot = DevCopilot()
    
    test_cases = [
        {
            "name": "Invalid payload shows precise pointer fixes",
            "service": "payments",
            "endpoint": "/payments",
            "lang": "python",
            "sample": {"amount": -10, "currency": "EUR"},  # Invalid: negative amount, wrong currency
            "expected_validation_errors": True
        },
        {
            "name": "Valid payload passes validation",
            "service": "payments", 
            "endpoint": "/payments",
            "lang": "curl",
            "sample": {"amount": 100.0, "currency": "USD", "accountId": "acc_123"},
            "expected_validation_errors": False
        },
        {
            "name": "Code snippet generation for JavaScript",
            "service": "payments",
            "endpoint": "/payments",
            "lang": "javascript",
            "sample": None,
            "expected_validation_errors": False
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            
            result = copilot.generate_code_guide(
                service=case["service"],
                endpoint=case["endpoint"],
                lang=case["lang"],
                sample=case["sample"]
            )
            
            # Validate response structure
            valid_structure = (
                hasattr(result, 'endpoint') and
                hasattr(result, 'snippet') and
                hasattr(result, 'example_request') and
                hasattr(result, 'validation') and
                hasattr(result, 'postman')
            )
            
            # Check validation expectations
            validation_ok = (
                (case["expected_validation_errors"] and not result.validation.ok) or
                (not case["expected_validation_errors"] and result.validation.ok)
            )
            
            # Check code snippet is generated
            snippet_ok = len(result.snippet.code) > 10 and case["lang"] in result.snippet.code.lower()
            
            # Check Postman file
            postman_ok = result.postman.filename.endswith(".json")
            
            success = valid_structure and validation_ok and snippet_ok and postman_ok
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   Service: {case['service']}")
            print(f"   Endpoint: {result.endpoint}")
            print(f"   Language: {result.snippet.lang}")
            print(f"   Validation OK: {result.validation.ok}")
            print(f"   Validation Errors: {len(result.validation.errors)}")
            print(f"   Postman File: {result.postman.filename}")
            print(f"   Status: {status}")
            
            if success:
                passed += 1
            else:
                print(f"   Failure reasons:")
                if not valid_structure:
                    print(f"     - Invalid response structure")
                if not validation_ok:
                    print(f"     - Validation expectation not met")
                if not snippet_ok:
                    print(f"     - Code snippet issue")
                if not postman_ok:
                    print(f"     - Postman file issue")
            
            print()
            
        except Exception as e:
            print(f"   ‚ùå FAIL - Exception: {str(e)}")
            print()
    
    print(f"üìä Results: {passed}/{total} tests passed")
    return passed == total

if __name__ == "__main__":
    test_devcopilot()



================================================
FILE: app/agents/dispute.py
================================================
"""
Dispute & Benefits Copilot
Turns messy customer narratives + receipts into compliant dispute packets
"""

import re
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat
from app.rag.core import retrieve
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Pydantic models for strict output schema enforcement
class DisputeFields(BaseModel):
    merchant: str
    date: str
    amount: float
    reason: str

class DisputePacket(BaseModel):
    summary: str
    fields: DisputeFields
    letter: str
    attachments: List[str]

class MerchantResolution(BaseModel):
    message: str
    checklist: List[str]

class Citation(BaseModel):
    source: str
    snippet: str

class DisputeResponse(BaseModel):
    triage: str
    merchant_resolution: MerchantResolution
    packet: DisputePacket
    citations: List[Citation]

class DisputeCopilot:
    """
    Dispute & Benefits Copilot for processing customer narratives into compliant dispute packets
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None):
        """Initialize DisputeCopilot with RAG components for policy retrieval"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
    
    def process_dispute(self, narrative: str, merchant: Optional[str] = None, 
                       amount: Optional[float] = None, uploaded_text: Optional[str] = None) -> DisputeResponse:
        """
        Main processing pipeline for dispute cases
        
        Args:
            narrative: Customer's description of the dispute
            merchant: Merchant name (optional)
            amount: Disputed amount (optional)
            uploaded_text: Receipt or document text (optional)
            
        Returns:
            DisputeResponse with triage, resolution, packet, and citations
        """
        try:
            logger.info(f"Processing dispute: {narrative[:100]}...")
            
            # Step 1: Triage with Gemini
            triage_result = self._triage_dispute(narrative)
            logger.info(f"Dispute triaged as: {triage_result}")
            
            # Step 2: Extract receipt information if uploaded
            receipt_data = {}
            if uploaded_text:
                receipt_data = self.receipt_extract(uploaded_text)
                logger.info(f"Extracted receipt data: {receipt_data}")
            
            # Step 3: Merge user inputs with extracted data
            merged_data = self._merge_dispute_data(
                narrative, merchant, amount, receipt_data
            )
            
            # Step 4: Retrieve merchant policy citations
            citations = self._get_policy_citations(merged_data.get("merchant"), triage_result)
            
            # Step 5: Generate merchant resolution (unless fraud)
            merchant_resolution = None
            if triage_result != "fraud":
                merchant_resolution = self._generate_merchant_resolution(
                    triage_result, merged_data, citations
                )
            else:
                merchant_resolution = MerchantResolution(
                    message="For fraudulent transactions, contact your card issuer immediately. Do not attempt merchant resolution.",
                    checklist=["Report fraud immediately", "Request account freeze", "File police report if amount > $500"]
                )
            
            # Step 6: Compose formal dispute packet
            dispute_packet = self._compose_dispute_packet(
                triage_result, merged_data, citations
            )
            
            return DisputeResponse(
                triage=triage_result,
                merchant_resolution=merchant_resolution,
                packet=dispute_packet,
                citations=citations
            )
            
        except Exception as e:
            logger.error(f"Error processing dispute: {e}")
            # Return minimal response on error
            return DisputeResponse(
                triage="billing_error",
                merchant_resolution=MerchantResolution(
                    message="Please contact customer service for assistance with your dispute.",
                    checklist=["Gather transaction documentation", "Contact customer service"]
                ),
                packet=DisputePacket(
                    summary="System error occurred during dispute processing",
                    fields=DisputeFields(
                        merchant=merchant or "Unknown",
                        date=datetime.now().strftime("%Y-%m-%d"),
                        amount=amount or 0.0,
                        reason="System error"
                    ),
                    letter="Please contact customer service for assistance.",
                    attachments=[]
                ),
                citations=[]
            )
    
    def receipt_extract(self, text: str) -> Dict[str, Any]:
        """
        Extract receipt information using Gemini + regex fallback
        
        Args:
            text: Receipt text to extract from
            
        Returns:
            Dictionary with merchant, date, amount, and items
        """
        try:
            # Use Gemini for structured extraction
            system_prompt = """You are a receipt parser. Extract structured information from receipt text.

Return ONLY a JSON object with these fields:
{
  "merchant": "merchant name or null",
  "date": "YYYY-MM-DD format or null", 
  "amount": "total amount as float or null",
  "items": ["list of purchased items or empty array"]
}

Be precise and only extract information that is clearly present."""

            user_message = f"Extract information from this receipt:\n\n{text}"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            # Parse Gemini response
            try:
                extracted = json.loads(response.strip())
                logger.info("Successfully extracted receipt data with Gemini")
                return extracted
            except json.JSONDecodeError:
                logger.warning("Gemini response not valid JSON, falling back to regex")
                return self._regex_receipt_fallback(text)
                
        except Exception as e:
            logger.error(f"Error in receipt extraction: {e}")
            return self._regex_receipt_fallback(text)
    
    def _regex_receipt_fallback(self, text: str) -> Dict[str, Any]:
        """Regex-based fallback for receipt extraction"""
        result = {
            "merchant": None,
            "date": None,
            "amount": None,
            "items": []
        }
        
        # Extract merchant (usually first line or after common patterns)
        merchant_patterns = [
            r'^([A-Z][A-Za-z\s&]+)(?:\n|\r)',  # First line capitalized
            r'(?:MERCHANT|STORE|RETAILER):\s*([^\n\r]+)',
            r'^([A-Z\s]+(?:INC|LLC|CORP|CO))',  # Corporate suffixes
        ]
        
        for pattern in merchant_patterns:
            match = re.search(pattern, text, re.MULTILINE | re.IGNORECASE)
            if match:
                result["merchant"] = match.group(1).strip()
                break
        
        # Extract date
        date_patterns = [
            r'(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})',  # MM/DD/YYYY or MM-DD-YYYY
            r'(\d{4}[/-]\d{1,2}[/-]\d{1,2})',    # YYYY/MM/DD or YYYY-MM-DD
            r'((?:JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)\s+\d{1,2},?\s+\d{4})'  # Month DD, YYYY
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    # Try to parse and standardize date
                    date_str = match.group(1)
                    # Simple conversion - in production would use dateutil
                    if '/' in date_str or '-' in date_str:
                        result["date"] = date_str
                    break
                except:
                    continue
        
        # Extract total amount
        amount_patterns = [
            r'(?:TOTAL|AMOUNT|BALANCE):\s*\$?(\d+\.?\d*)',
            r'TOTAL\s+\$?(\d+\.?\d*)',
            r'\$(\d+\.\d{2})\s*(?:TOTAL|$)',
        ]
        
        for pattern in amount_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    result["amount"] = float(match.group(1))
                    break
                except ValueError:
                    continue
        
        # Extract items (simple line-based extraction)
        lines = text.split('\n')
        items = []
        for line in lines:
            line = line.strip()
            # Look for lines that might be items (have price patterns)
            if re.search(r'\$\d+\.?\d*', line) and len(line) > 5:
                # Clean up the line
                item = re.sub(r'\s*\$\d+\.?\d*.*$', '', line).strip()
                if item and len(item) > 2:
                    items.append(item)
        
        result["items"] = items[:10]  # Limit to 10 items
        
        return result
    
    def _triage_dispute(self, narrative: str) -> str:
        """
        Triage dispute using Gemini classification
        
        Args:
            narrative: Customer dispute narrative
            
        Returns:
            Dispute type: fraud, goods_not_received, or billing_error
        """
        try:
            system_prompt = """You are a dispute triage specialist. Classify customer disputes into one of these categories:

Categories:
- fraud: Unauthorized transactions, stolen card, identity theft
- goods_not_received: Items/services paid for but not delivered or provided
- billing_error: Duplicate charges, wrong amounts, mathematical errors

Respond with ONLY a JSON object:
{"category": "category_name", "confidence": 0.85, "reasoning": "brief explanation"}

Focus on the primary issue described by the customer."""

            user_message = f"Classify this dispute: '{narrative}'"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            result = json.loads(response.strip())
            category = result.get("category", "billing_error")
            
            # Validate category
            valid_categories = ["fraud", "goods_not_received", "billing_error"]
            if category not in valid_categories:
                logger.warning(f"Invalid category '{category}', defaulting to billing_error")
                category = "billing_error"
            
            return category
            
        except Exception as e:
            logger.error(f"Error in dispute triage: {e}")
            return "billing_error"  # Safe default
    
    def _merge_dispute_data(self, narrative: str, merchant: Optional[str], 
                           amount: Optional[float], receipt_data: Dict[str, Any]) -> Dict[str, Any]:
        """Merge user inputs with extracted receipt data"""
        merged = {
            "narrative": narrative,
            "merchant": merchant or receipt_data.get("merchant"),
            "amount": amount or receipt_data.get("amount"),
            "date": receipt_data.get("date"),
            "items": receipt_data.get("items", [])
        }
        
        # Clean up merchant name
        if merged["merchant"]:
            merged["merchant"] = merged["merchant"].strip().title()
        
        return merged
    
    def _get_policy_citations(self, merchant: Optional[str], dispute_type: str) -> List[Citation]:
        """
        Retrieve merchant policy citations from knowledge base
        
        Args:
            merchant: Merchant name
            dispute_type: Type of dispute
            
        Returns:
            List of policy citations
        """
        citations = []
        
        if not all([self.retriever, self.embedder]):
            logger.warning("RAG components not available for policy citations")
            return citations
        
        try:
            # Create query for dispute policies
            if merchant:
                query = f"{merchant} dispute policy {dispute_type}"
            else:
                query = f"card dispute documentation {dispute_type} required items"
            
            # Retrieve relevant policy documents
            results = retrieve(self.retriever, self.embedder, query, k=3)
            
            for result in results:
                citations.append(Citation(
                    source=result.get("filename", "Dispute Policy"),
                    snippet=result.get("snippet", "")[:300] + "..."
                ))
            
            # If no local citations found, search web for card dispute documentation
            if not citations:
                logger.info("No local dispute policies found, searching web...")
                try:
                    web_docs = web_search_into_docstore(
                        self.docstore,
                        self.embedder,
                        "card dispute documentation duplicate charge required items",
                        max_results=2
                    )
                    
                    # Re-retrieve after adding web content
                    if web_docs:
                        results = retrieve(self.retriever, self.embedder, 
                                         f"dispute {dispute_type} documentation", k=2)
                        
                        for result in results:
                            citations.append(Citation(
                                source=result.get("filename", "Web Search"),
                                snippet=result.get("snippet", "")[:300] + "..."
                            ))
                            
                except Exception as e:
                    logger.warning(f"Web search for dispute policies failed: {e}")
            
        except Exception as e:
            logger.error(f"Error retrieving policy citations: {e}")
        
        return citations
    
    def _generate_merchant_resolution(self, dispute_type: str, data: Dict[str, Any], 
                                    citations: List[Citation]) -> MerchantResolution:
        """Generate merchant resolution draft"""
        merchant = data.get("merchant", "the merchant")
        amount = data.get("amount", 0.0)
        
        if dispute_type == "billing_error":
            message = f"""Dear {merchant} Customer Service,

I am writing to request resolution of a billing error on my account. I have identified a discrepancy in my recent transaction that requires your immediate attention.

Transaction Details:
- Date: {data.get('date', 'Not specified')}
- Amount: ${amount:.2f}
- Issue: {data.get('narrative', 'Billing discrepancy')}

I have reviewed my records and believe this charge is incorrect. Please investigate this matter and provide a correction or refund as appropriate.

I would appreciate your prompt response within 5-7 business days. Please confirm the resolution in writing.

Thank you for your attention to this matter."""

            checklist = [
                "Contact merchant customer service within 2-3 business days",
                "Provide transaction details and explanation",
                "Request written confirmation of resolution",
                "Keep records of all communication",
                "Allow 5-7 business days for merchant response",
                "Escalate to supervisor if initial contact unsuccessful"
            ]
            
        elif dispute_type == "goods_not_received":
            message = f"""Dear {merchant} Customer Service,

I am writing regarding an order that I paid for but have not received. I need your assistance in resolving this delivery issue.

Order Details:
- Date of Purchase: {data.get('date', 'Not specified')}
- Amount Paid: ${amount:.2f}
- Items: {', '.join(data.get('items', ['Not specified']))}

Despite payment being processed, I have not received the goods/services. Please investigate the status of my order and provide either:
1. Immediate shipment with tracking information, or
2. Full refund of the purchase amount

I request resolution within 10-15 business days as per standard delivery expectations.

Please confirm your resolution plan in writing."""

            checklist = [
                "Contact merchant within 30 days of expected delivery",
                "Provide order confirmation and payment proof",
                "Request tracking information if applicable",
                "Ask for delivery timeline or refund",
                "Document all communication attempts",
                "Allow 10-15 business days for resolution",
                "Request written confirmation of solution"
            ]
        
        else:  # Default case
            message = f"""Dear {merchant} Customer Service,

I need assistance resolving an issue with a recent transaction on my account.

Transaction Details:
- Date: {data.get('date', 'Not specified')}
- Amount: ${amount:.2f}
- Issue: {data.get('narrative', 'Transaction dispute')}

Please review this transaction and provide appropriate resolution.

Thank you for your prompt attention to this matter."""

            checklist = [
                "Contact merchant customer service",
                "Provide transaction documentation",
                "Explain the issue clearly",
                "Request written response",
                "Allow reasonable time for resolution"
            ]
        
        return MerchantResolution(message=message, checklist=checklist)
    
    def _compose_dispute_packet(self, dispute_type: str, data: Dict[str, Any], 
                               citations: List[Citation]) -> DisputePacket:
        """Compose formal dispute packet"""
        
        # Create summary
        merchant = data.get("merchant", "Unknown Merchant")
        amount = data.get("amount", 0.0)
        date = data.get("date", "Unknown Date")
        
        summary = f"Dispute for {dispute_type.replace('_', ' ')} involving {merchant} for ${amount:.2f} on {date}"
        
        # Create fields
        fields = DisputeFields(
            merchant=merchant,
            date=date,
            amount=amount,
            reason=data.get("narrative", "No reason provided")
        )
        
        # Generate formal dispute letter
        letter = self._generate_formal_letter(dispute_type, data, citations)
        
        # Determine required attachments
        attachments = self._get_required_attachments(dispute_type)
        
        return DisputePacket(
            summary=summary,
            fields=fields,
            letter=letter,
            attachments=attachments
        )
    
    def _generate_formal_letter(self, dispute_type: str, data: Dict[str, Any], 
                               citations: List[Citation]) -> str:
        """Generate formal dispute letter"""
        
        merchant = data.get("merchant", "Unknown Merchant")
        amount = data.get("amount", 0.0)
        date = data.get("date", "Unknown Date")
        narrative = data.get("narrative", "")
        
        current_date = datetime.now().strftime("%B %d, %Y")
        
        if dispute_type == "fraud":
            letter = f"""Date: {current_date}

To: Card Issuer Dispute Department

RE: Fraudulent Transaction Dispute

Dear Dispute Resolution Team,

I am writing to formally dispute fraudulent charges on my account. I did not authorize these transactions and believe my account has been compromised.

DISPUTED TRANSACTION DETAILS:
- Merchant: {merchant}
- Transaction Date: {date}
- Amount: ${amount:.2f}
- Description: {narrative}

FRAUD DECLARATION:
I hereby declare under penalty of perjury that:
1. I did not authorize this transaction
2. I did not participate in this transaction
3. I did not give permission for anyone else to use my account
4. I have not received any goods or services from this transaction

IMMEDIATE ACTIONS TAKEN:
- Reported fraud immediately upon discovery
- Reviewed all recent account activity
- Secured account and changed passwords

I request immediate provisional credit and permanent removal of this fraudulent charge. Please investigate this matter urgently and provide written confirmation of resolution.

Sincerely,
[Cardholder Name]
Account Number: [Account Number]"""

        elif dispute_type == "goods_not_received":
            letter = f"""Date: {current_date}

To: Card Issuer Dispute Department

RE: Goods Not Received Dispute

Dear Dispute Resolution Team,

I am formally disputing a charge for goods/services that were paid for but never received.

TRANSACTION DETAILS:
- Merchant: {merchant}
- Transaction Date: {date}
- Amount: ${amount:.2f}
- Items/Services: {', '.join(data.get('items', ['Not specified']))}

ISSUE DESCRIPTION:
{narrative}

MERCHANT CONTACT ATTEMPTS:
I have attempted to resolve this matter directly with the merchant through:
- Initial contact on [Date]
- Follow-up contact on [Date]
- No satisfactory resolution provided

SUPPORTING EVIDENCE:
- Original purchase receipt/confirmation
- Communication records with merchant
- Proof of non-delivery

I request provisional credit while this matter is investigated. The merchant has failed to deliver the goods/services as promised, and I should not be held liable for this charge.

Please investigate and provide permanent credit for this transaction.

Sincerely,
[Cardholder Name]
Account Number: [Account Number]"""

        else:  # billing_error
            letter = f"""Date: {current_date}

To: Card Issuer Dispute Department

RE: Billing Error Dispute

Dear Dispute Resolution Team,

I am writing to dispute a billing error on my account that requires correction.

TRANSACTION DETAILS:
- Merchant: {merchant}
- Transaction Date: {date}
- Disputed Amount: ${amount:.2f}
- Error Description: {narrative}

BILLING ERROR DETAILS:
This charge appears to be incorrect due to:
- Duplicate processing of the same transaction
- Incorrect amount charged
- Mathematical or computational error
- Charge for goods/services not received

MERCHANT RESOLUTION ATTEMPT:
I contacted the merchant on [Date] to resolve this billing error. [Outcome of merchant contact]

REQUESTED RESOLUTION:
Please investigate this billing error and provide appropriate correction to my account. I have supporting documentation available upon request.

I request provisional credit during the investigation period as provided under the Fair Credit Billing Act.

Sincerely,
[Cardholder Name]
Account Number: [Account Number]"""

        return letter
    
    def _get_required_attachments(self, dispute_type: str) -> List[str]:
        """Get list of required attachments for dispute type"""
        
        common_attachments = [
            "Copy of credit card statement showing the disputed charge",
            "Account holder identification",
            "Completed dispute form"
        ]
        
        if dispute_type == "fraud":
            return common_attachments + [
                "Affidavit of unauthorized use",
                "Police report (if filed)",
                "List of all unauthorized transactions",
                "Documentation of account security measures taken"
            ]
        
        elif dispute_type == "goods_not_received":
            return common_attachments + [
                "Original purchase receipt or confirmation",
                "Shipping/tracking information (if applicable)",
                "Communication records with merchant",
                "Proof of expected delivery date",
                "Evidence of non-delivery"
            ]
        
        else:  # billing_error
            return common_attachments + [
                "Original receipt showing correct amount",
                "Documentation of the billing error",
                "Calculation showing the discrepancy",
                "Correspondence with merchant (if any)"
            ]

# Test cases for dispute scenarios
def test_dispute_copilot():
    """Test DisputeCopilot with common dispute scenarios"""
    print("üß™ Testing DisputeCopilot")
    print("=" * 50)
    
    copilot = DisputeCopilot()
    
    test_cases = [
        {
            "name": "Duplicate Charge",
            "narrative": "I was charged twice for the same purchase at Best Buy. The amount of $299.99 appears twice on my statement for the same day.",
            "merchant": "Best Buy",
            "amount": 299.99,
            "uploaded_text": None,
            "expected_triage": "billing_error"
        },
        {
            "name": "Goods Not Received",
            "narrative": "I ordered a laptop from Dell on December 1st but never received it. They charged my card $899 but the item was never delivered.",
            "merchant": "Dell",
            "amount": 899.00,
            "uploaded_text": "DELL TECHNOLOGIES\nOrder Date: 12/01/2024\nLaptop Computer - $899.00\nTotal: $899.00\nExpected Delivery: 12/15/2024",
            "expected_triage": "goods_not_received"
        },
        {
            "name": "Fraudulent Transaction",
            "narrative": "I see a charge for $500 at a store I've never been to. This is definitely fraud as I was out of town that day.",
            "merchant": None,
            "amount": 500.00,
            "uploaded_text": None,
            "expected_triage": "fraud"
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            
            result = copilot.process_dispute(
                narrative=case["narrative"],
                merchant=case["merchant"],
                amount=case["amount"],
                uploaded_text=case["uploaded_text"]
            )
            
            # Validate response structure
            valid_structure = (
                hasattr(result, 'triage') and
                hasattr(result, 'merchant_resolution') and
                hasattr(result, 'packet') and
                hasattr(result, 'citations')
            )
            
            # Check triage accuracy
            triage_correct = result.triage == case["expected_triage"]
            
            # Check packet completeness
            packet_complete = (
                result.packet.fields.merchant and
                result.packet.fields.amount > 0 and
                len(result.packet.letter) > 100
            )
            
            success = valid_structure and triage_correct and packet_complete
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   Narrative: {case['narrative'][:60]}...")
            print(f"   Triage: Expected {case['expected_triage']}, Got {result.triage}")
            print(f"   Merchant Resolution: {len(result.merchant_resolution.message)} chars")
            print(f"   Dispute Letter: {len(result.packet.letter)} chars")
            print(f"   Citations: {len(result.citations)}")
            print(f"   Status: {status}")
            print()
            
            if success:
                passed += 1
                
        except Exception as e:
            print(f"   ‚ùå ERROR: {e}")
            print()
    
    print(f"DisputeCopilot Test Results: {passed}/{total} passed")
    return passed == total

if __name__ == "__main__":
    # Run tests
    success = test_dispute_copilot()
    print(f"\n{'üéâ All tests passed!' if success else '‚ö†Ô∏è Some tests failed.'}")



================================================
FILE: app/agents/imagegen.py
================================================
"""
ImageGen - AI Image Generation Agent
Creates images using Gemini's native image generation capabilities
"""

import logging
import base64
from io import BytesIO
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from PIL import Image

from google import genai
from google.genai import types
from pydantic import BaseModel

logger = logging.getLogger(__name__)

@dataclass
class GeneratedImage:
    """Generated image with metadata"""
    image_data: bytes
    format: str
    description: str
    prompt: str
    base64_data: str

class ImageGenRequest(BaseModel):
    prompt: str
    include_text: bool = True
    style_hints: Optional[List[str]] = None

class ImageGenResponse(BaseModel):
    success: bool
    prompt: str
    generated_text: Optional[str] = None
    image_base64: Optional[str] = None
    image_format: str = "PNG"
    error_message: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None

class ImageGenAgent:
    """
    AI Image Generation Agent using Gemini's native capabilities
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """Initialize ImageGen agent"""
        self.client = None
        self.model_name = "gemini-2.0-flash-preview-image-generation"
        
        try:
            import os
            api_key = api_key or os.getenv("GOOGLE_API_KEY")
            if not api_key:
                raise ValueError("Google API key is required for image generation")
            
            self.client = genai.Client(api_key=api_key)
            logger.info("ImageGen agent initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize ImageGen agent: {e}")
            raise
    
    def generate_image(self, prompt: str, include_text: bool = True, 
                      style_hints: Optional[List[str]] = None) -> ImageGenResponse:
        """
        Generate an image based on the text prompt
        
        Args:
            prompt: Text description of the image to generate
            include_text: Whether to include descriptive text with the image
            style_hints: Optional style hints to improve generation
            
        Returns:
            ImageGenResponse with generated image and metadata
        """
        try:
            logger.info(f"Generating image for prompt: {prompt[:100]}...")
            
            # Enhance prompt with style hints if provided
            enhanced_prompt = self._enhance_prompt(prompt, style_hints)
            
            # Configure generation parameters
            config = types.GenerateContentConfig(
                response_modalities=['IMAGE'] + (['TEXT'] if include_text else [])
            )
            
            # Generate content using Gemini
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=enhanced_prompt,
                config=config
            )
            
            # Process the response
            generated_text = None
            generated_image = None
            
            if response.candidates and len(response.candidates) > 0:
                candidate = response.candidates[0]
                
                for part in candidate.content.parts:
                    if part.text is not None and include_text:
                        generated_text = part.text
                    elif part.inline_data is not None:
                        # Convert image data to base64
                        image_data = part.inline_data.data
                        image_base64 = base64.b64encode(image_data).decode('utf-8')
                        
                        # Create PIL image for validation
                        image = Image.open(BytesIO(image_data))
                        
                        generated_image = GeneratedImage(
                            image_data=image_data,
                            format="PNG",
                            description=generated_text or prompt,
                            prompt=enhanced_prompt,
                            base64_data=image_base64
                        )
                        
                        logger.info(f"Successfully generated {image.size[0]}x{image.size[1]} image")
            
            if generated_image:
                return ImageGenResponse(
                    success=True,
                    prompt=enhanced_prompt,
                    generated_text=generated_text,
                    image_base64=generated_image.base64_data,
                    image_format=generated_image.format,
                    metadata={
                        "model": self.model_name,
                        "original_prompt": prompt,
                        "enhanced_prompt": enhanced_prompt,
                        "include_text": include_text,
                        "style_hints": style_hints
                    }
                )
            else:
                return ImageGenResponse(
                    success=False,
                    prompt=enhanced_prompt,
                    error_message="No image was generated in the response"
                )
                
        except Exception as e:
            logger.error(f"Error generating image: {e}")
            return ImageGenResponse(
                success=False,
                prompt=prompt,
                error_message=str(e)
            )
    
    def _enhance_prompt(self, prompt: str, style_hints: Optional[List[str]] = None) -> str:
        """
        Enhance the prompt with style hints and quality improvements
        
        Args:
            prompt: Original prompt
            style_hints: Optional style hints
            
        Returns:
            Enhanced prompt string
        """
        enhanced = prompt
        
        # Add style hints if provided
        if style_hints:
            style_text = ", ".join(style_hints)
            enhanced = f"{enhanced}, {style_text}"
        
        # Add default quality enhancers if not already present
        quality_terms = ["high quality", "detailed", "professional", "4k", "8k", "hd"]
        if not any(term in enhanced.lower() for term in quality_terms):
            enhanced = f"{enhanced}, high quality, detailed"
        
        # Add artistic style guidance if none specified
        style_terms = ["photorealistic", "digital art", "painting", "3d render", "concept art", "illustration"]
        if not any(term in enhanced.lower() for term in style_terms):
            enhanced = f"{enhanced}, digital art"
        
        return enhanced
    
    def process_request(self, request: ImageGenRequest) -> ImageGenResponse:
        """
        Process an image generation request
        
        Args:
            request: ImageGenRequest object
            
        Returns:
            ImageGenResponse with results
        """
        return self.generate_image(
            prompt=request.prompt,
            include_text=request.include_text,
            style_hints=request.style_hints
        )

# Utility functions for image handling
def save_generated_image(image_response: ImageGenResponse, 
                        filename: Optional[str] = None) -> Optional[str]:
    """
    Save a generated image to disk
    
    Args:
        image_response: ImageGenResponse with image data
        filename: Optional filename, will auto-generate if not provided
        
    Returns:
        Saved filename or None if failed
    """
    try:
        if not image_response.success or not image_response.image_base64:
            return None
        
        # Generate filename if not provided
        if not filename:
            import time
            timestamp = int(time.time())
            filename = f"generated_image_{timestamp}.{image_response.image_format.lower()}"
        
        # Decode and save image
        image_data = base64.b64decode(image_response.image_base64)
        image = Image.open(BytesIO(image_data))
        image.save(filename)
        
        logger.info(f"Saved generated image to {filename}")
        return filename
        
    except Exception as e:
        logger.error(f"Error saving image: {e}")
        return None

def get_image_data_uri(image_response: ImageGenResponse) -> Optional[str]:
    """
    Get data URI for displaying image in HTML
    
    Args:
        image_response: ImageGenResponse with image data
        
    Returns:
        Data URI string or None if failed
    """
    try:
        if not image_response.success or not image_response.image_base64:
            return None
        
        format_lower = image_response.image_format.lower()
        return f"data:image/{format_lower};base64,{image_response.image_base64}"
        
    except Exception as e:
        logger.error(f"Error creating data URI: {e}")
        return None

# Test cases for ImageGen agent
def test_imagegen():
    """Test ImageGen agent with various prompts"""
    print("üé® Testing ImageGen Agent")
    print("=" * 40)
    
    try:
        agent = ImageGenAgent()
        
        test_cases = [
            {
                "name": "Simple Object",
                "prompt": "A red apple on a wooden table",
                "expected_success": True
            },
            {
                "name": "Complex Scene", 
                "prompt": "A futuristic city with flying cars and neon lights at night",
                "style_hints": ["cyberpunk", "neon", "cinematic"],
                "expected_success": True
            },
            {
                "name": "Fantasy Character",
                "prompt": "A wizard casting a spell in an enchanted forest",
                "style_hints": ["fantasy art", "magical", "mystical"],
                "expected_success": True
            }
        ]
        
        passed = 0
        total = len(test_cases)
        
        for i, case in enumerate(test_cases, 1):
            print(f"{i}. {case['name']}")
            print(f"   Prompt: '{case['prompt']}'")
            
            try:
                result = agent.generate_image(
                    prompt=case["prompt"],
                    style_hints=case.get("style_hints")
                )
                
                success = result.success == case["expected_success"]
                
                if success and result.success:
                    print(f"   ‚úÖ PASS - Image generated successfully")
                    if result.generated_text:
                        print(f"   üìù Description: {result.generated_text[:100]}...")
                    print(f"   üñºÔ∏è Format: {result.image_format}")
                    passed += 1
                elif success:
                    print(f"   ‚úÖ PASS - Expected behavior matched")
                    passed += 1
                else:
                    print(f"   ‚ùå FAIL - {result.error_message}")
                    
            except Exception as e:
                print(f"   ‚ùå FAIL - Exception: {str(e)}")
            
            print()
        
        print(f"üìä ImageGen Results: {passed}/{total} tests passed")
        return passed == total
        
    except Exception as e:
        print(f"‚ùå Failed to initialize ImageGen agent: {e}")
        return False

if __name__ == "__main__":
    test_imagegen()


================================================
FILE: app/agents/narrator.py
================================================
"""
Portfolio Intel Narrator
Converts business questions into metrics analysis with anomaly detection and actionable insights
"""

import json
import logging
import re
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Tuple
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.llm.gemini import chat
from app.rag.core import retrieve
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Pydantic models for structured responses
class Finding(BaseModel):
    title: str
    evidence: Dict[str, Any]

class Action(BaseModel):
    hypothesis: str
    owner: str

class TablePreview(BaseModel):
    name: str
    preview_rows: int

class Citation(BaseModel):
    source: str
    snippet: str

class Anomaly(BaseModel):
    ts: str
    value: float
    z_score: float

class NarratorResponse(BaseModel):
    findings: List[Finding]
    actions: List[Action]
    tables: List[TablePreview]
    citations: List[Citation]

@dataclass
class QueryResult:
    """Results from SQL-ish query execution"""
    data: pd.DataFrame
    table_name: str
    query: str
    anomalies: List[Anomaly] = None

class SafeSQLParser:
    """
    Safe SQL-ish parser that validates queries against schema
    """
    
    def __init__(self, schema_path: str):
        """Initialize with metrics schema"""
        self.schema = self._load_schema(schema_path)
        self.allowed_ops = self.schema["allowed_operations"]
        self.table_schemas = self.schema["schemas"]
    
    def _load_schema(self, schema_path: str) -> Dict[str, Any]:
        """Load metrics schema from JSON file"""
        try:
            with open(schema_path, 'r') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Failed to load schema: {e}")
            return {"schemas": {}, "allowed_operations": {}}
    
    def parse_and_validate(self, sql_query: str) -> Dict[str, Any]:
        """
        Parse and validate SQL-ish query against schema
        
        Args:
            sql_query: SQL-ish query string
            
        Returns:
            Parsed query components or validation errors
        """
        try:
            # Normalize query
            query = sql_query.strip().upper()
            
            # Parse SELECT clause
            select_match = re.search(r'SELECT\s+(.*?)\s+FROM', query, re.IGNORECASE | re.DOTALL)
            if not select_match:
                return {"error": "Missing SELECT clause"}
            
            select_clause = select_match.group(1).strip()
            
            # Parse FROM clause
            from_match = re.search(r'FROM\s+(\w+)', query, re.IGNORECASE)
            if not from_match:
                return {"error": "Missing FROM clause"}
                
            table_name = from_match.group(1).lower()
            
            # Validate table exists
            if table_name not in self.table_schemas:
                return {"error": f"Table '{table_name}' not found in schema"}
            
            table_schema = self.table_schemas[table_name]
            
            # Parse WHERE clause (optional)
            where_clause = None
            where_match = re.search(r'WHERE\s+(.*?)(?:\s+GROUP\s+BY|\s+ORDER\s+BY|\s+LIMIT|$)', query, re.IGNORECASE | re.DOTALL)
            if where_match:
                where_clause = where_match.group(1).strip()
            
            # Parse GROUP BY clause (optional)
            group_by_clause = None
            group_match = re.search(r'GROUP\s+BY\s+(.*?)(?:\s+ORDER\s+BY|\s+LIMIT|$)', query, re.IGNORECASE | re.DOTALL)
            if group_match:
                group_by_clause = group_match.group(1).strip()
            
            # Parse ORDER BY clause (optional)
            order_by_clause = None
            order_match = re.search(r'ORDER\s+BY\s+(.*?)(?:\s+LIMIT|$)', query, re.IGNORECASE | re.DOTALL)
            if order_match:
                order_by_clause = order_match.group(1).strip()
            
            # Parse LIMIT clause (optional)
            limit_clause = None
            limit_match = re.search(r'LIMIT\s+(\d+)', query, re.IGNORECASE)
            if limit_match:
                limit_clause = int(limit_match.group(1))
                if limit_clause > self.allowed_ops["limit"]["max_rows"]:
                    return {"error": f"LIMIT exceeds maximum of {self.allowed_ops['limit']['max_rows']}"}
            
            # Validate SELECT columns and functions
            select_validation = self._validate_select_clause(select_clause, table_schema)
            if "error" in select_validation:
                return select_validation
            
            # Validate WHERE clause
            if where_clause:
                where_validation = self._validate_where_clause(where_clause, table_schema)
                if "error" in where_validation:
                    return where_validation
            
            # Validate GROUP BY
            if group_by_clause:
                group_validation = self._validate_group_by_clause(group_by_clause, table_schema)
                if "error" in group_validation:
                    return group_validation
            
            return {
                "table_name": table_name,
                "select": select_validation["columns"],
                "where": where_clause,
                "group_by": group_by_clause,
                "order_by": order_by_clause,
                "limit": limit_clause,
                "aggregations": select_validation.get("aggregations", [])
            }
            
        except Exception as e:
            logger.error(f"Error parsing SQL query: {e}")
            return {"error": f"Query parsing error: {str(e)}"}
    
    def _validate_select_clause(self, select_clause: str, table_schema: Dict) -> Dict[str, Any]:
        """Validate SELECT clause against table schema"""
        columns = []
        aggregations = []
        
        # Split by comma and analyze each part
        select_parts = [part.strip() for part in select_clause.split(',')]
        
        for part in select_parts:
            # Check for aggregation functions
            agg_match = re.match(r'(COUNT|SUM|AVG|MIN|MAX|STDDEV)\s*\(\s*(\*|\w+)\s*\)', part, re.IGNORECASE)
            if agg_match:
                func_name = agg_match.group(1).upper()
                column_name = agg_match.group(2).lower()
                
                if func_name not in self.allowed_ops["select"]["functions"]:
                    return {"error": f"Function {func_name} not allowed"}
                
                if column_name != "*" and column_name not in table_schema["columns"]:
                    return {"error": f"Column {column_name} not found in table"}
                
                aggregations.append({"function": func_name, "column": column_name})
                columns.append(f"{func_name}_{column_name}")
            else:
                # Regular column
                if part == "*":
                    columns.extend(table_schema["columns"].keys())
                else:
                    if part.lower() not in table_schema["columns"]:
                        return {"error": f"Column {part} not found in table"}
                    columns.append(part.lower())
        
        return {"columns": columns, "aggregations": aggregations}
    
    def _validate_where_clause(self, where_clause: str, table_schema: Dict) -> Dict[str, Any]:
        """Validate WHERE clause conditions"""
        # Simple validation - check for allowed operators and column existence
        allowed_operators = self.allowed_ops["where"]["operators"]
        
        # Extract column references (simplified)
        column_refs = re.findall(r'\b(\w+)\s*(?:=|!=|<|<=|>|>=|IN|LIKE|BETWEEN)', where_clause, re.IGNORECASE)
        
        for col in column_refs:
            if col.lower() not in table_schema["columns"]:
                return {"error": f"Column {col} not found in WHERE clause"}
        
        return {"valid": True}
    
    def _validate_group_by_clause(self, group_by_clause: str, table_schema: Dict) -> Dict[str, Any]:
        """Validate GROUP BY clause"""
        group_columns = [col.strip().lower() for col in group_by_clause.split(',')]
        
        if len(group_columns) > self.allowed_ops["group_by"]["max_columns"]:
            return {"error": f"GROUP BY exceeds maximum of {self.allowed_ops['group_by']['max_columns']} columns"}
        
        for col in group_columns:
            if col not in table_schema["columns"]:
                return {"error": f"GROUP BY column {col} not found in table"}
        
        return {"valid": True}

class PortfolioIntelNarrator:
    """
    Portfolio Intel Narrator for metrics analysis and anomaly detection
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None):
        """Initialize narrator with components"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        
        # Initialize SQL parser
        schema_path = "app/data/metrics_schema.json"
        self.sql_parser = SafeSQLParser(schema_path)
        self.metrics_dir = Path("metrics")
        
        # Load metric definitions
        self.metric_definitions = self.sql_parser.schema.get("metric_definitions", {})
    
    def process_question(self, question: str) -> NarratorResponse:
        """
        Main processing pipeline for business questions
        
        Args:
            question: Business question about portfolio metrics
            
        Returns:
            NarratorResponse with findings, actions, and citations
        """
        try:
            logger.info(f"Processing narrator question: {question}")
            
            # Step 1: Translate question to SQL-ish query using Gemini
            sql_query = self._translate_to_sql(question)
            logger.info(f"Generated SQL query: {sql_query}")
            
            # Step 2: Execute metrics query
            query_result = self.metrics_query(sql_query)
            if query_result is None:
                return self._error_response("Failed to execute query")
            
            # Step 3: Detect anomalies if time series data
            if self._is_time_series(query_result.data):
                anomalies = self._detect_anomalies(query_result.data)
                query_result.anomalies = anomalies
                logger.info(f"Detected {len(anomalies)} anomalies")
            
            # Step 4: Analyze findings and generate insights
            findings = self._analyze_findings(query_result, question)
            
            # Step 5: Generate action items and hypotheses
            actions = self._generate_actions(findings, question)
            
            # Step 6: Get metric definitions and terms
            citations = self.terms_retrieve("metric definitions")
            
            # Step 7: Create table previews
            tables = [TablePreview(
                name=query_result.table_name,
                preview_rows=min(len(query_result.data), 10)
            )]
            
            return NarratorResponse(
                findings=findings,
                actions=actions,
                tables=tables,
                citations=citations
            )
            
        except Exception as e:
            logger.error(f"Error processing narrator question: {e}")
            return self._error_response(str(e))
    
    def _translate_to_sql(self, question: str) -> str:
        """
        Translate business question to SQL-ish query using Gemini
        
        Args:
            question: Business question
            
        Returns:
            SQL-ish query string
        """
        try:
            # Get available tables and columns from schema
            schema_info = self._format_schema_for_llm()
            
            system_prompt = f"""You are a SQL expert for financial portfolio analysis. Convert business questions into safe SQL-ish queries.

IMPORTANT CONSTRAINTS:
- Only use SELECT statements with basic aggregations (COUNT, SUM, AVG, MIN, MAX, STDDEV)
- No JOINs, subqueries, or complex operations
- Only use tables and columns from the provided schema
- Use only these operators in WHERE: =, !=, <, <=, >, >=, IN, LIKE, BETWEEN
- Maximum 3 columns in GROUP BY
- Maximum 10,000 rows with LIMIT

AVAILABLE SCHEMA:
{schema_info}

Return ONLY the SQL query, nothing else. Example formats:
- SELECT merchant, SUM(spend_amount) FROM portfolio_spend WHERE date >= '2025-07-01' GROUP BY merchant
- SELECT date, spend_amount FROM portfolio_spend WHERE merchant = 'Amazon' ORDER BY date
- SELECT segment, AVG(delinq_30) FROM delinquency_rates WHERE month >= '2025-06-01' GROUP BY segment"""

            user_message = f"Business question: {question}"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            sql_query = response.strip()
            
            # Clean up response (remove markdown, explanations, etc.)
            sql_query = re.sub(r'```sql\n?|```\n?', '', sql_query)
            sql_query = sql_query.split('\n')[0]  # Take first line only
            
            return sql_query
            
        except Exception as e:
            logger.error(f"Error translating question to SQL: {e}")
            return "SELECT * FROM portfolio_spend LIMIT 10"  # Fallback query
    
    def _format_schema_for_llm(self) -> str:
        """Format schema information for LLM context"""
        schema_text = []
        
        for table_name, schema in self.sql_parser.table_schemas.items():
            schema_text.append(f"\nTable: {table_name}")
            schema_text.append(f"Description: {schema['description']}")
            schema_text.append("Columns:")
            for col, info in schema["columns"].items():
                schema_text.append(f"  - {col} ({info['type']}): {info['description']}")
        
        return "\n".join(schema_text)
    
    def metrics_query(self, sqlish: str) -> Optional[QueryResult]:
        """
        Execute safe SQL-ish query over metrics CSV files
        
        Args:
            sqlish: SQL-ish query string
            
        Returns:
            QueryResult with DataFrame and metadata
        """
        try:
            # Parse and validate query
            parsed = self.sql_parser.parse_and_validate(sqlish)
            if "error" in parsed:
                logger.error(f"Query validation error: {parsed['error']}")
                return None
            
            table_name = parsed["table_name"]
            
            # Load CSV file
            csv_path = self.metrics_dir / f"{table_name}.csv"
            if not csv_path.exists():
                logger.error(f"Metrics file not found: {csv_path}")
                return None
            
            df = pd.read_csv(csv_path)
            
            # Convert date columns
            table_schema = self.sql_parser.table_schemas[table_name]
            for col, info in table_schema["columns"].items():
                if info["type"] == "date" and col in df.columns:
                    df[col] = pd.to_datetime(df[col])
            
            # Apply WHERE clause
            if parsed["where"]:
                df = self._apply_where_clause(df, parsed["where"])
            
            # Apply GROUP BY and aggregations
            if parsed["group_by"] and parsed["aggregations"]:
                df = self._apply_group_by(df, parsed["group_by"], parsed["aggregations"])
            elif parsed["aggregations"]:
                # Aggregations without GROUP BY
                df = self._apply_aggregations(df, parsed["aggregations"])
            
            # Apply ORDER BY
            if parsed["order_by"]:
                df = self._apply_order_by(df, parsed["order_by"])
            
            # Apply LIMIT
            if parsed["limit"]:
                df = df.head(parsed["limit"])
            
            return QueryResult(
                data=df,
                table_name=table_name,
                query=sqlish
            )
            
        except Exception as e:
            logger.error(f"Error executing metrics query: {e}")
            return None
    
    def _apply_where_clause(self, df: pd.DataFrame, where_clause: str) -> pd.DataFrame:
        """Apply WHERE clause conditions to DataFrame"""
        try:
            # Convert SQL WHERE to pandas query (simplified)
            # This is a basic implementation - would need more robust parsing for production
            where_clause = where_clause.replace("=", "==").replace("!=", "!=")
            
            # Handle date comparisons
            where_clause = re.sub(r"'(\d{4}-\d{2}-\d{2})'", r"'\1'", where_clause)
            
            # Handle string comparisons
            where_clause = re.sub(r"(\w+)\s*==\s*'([^']+)'", r"\1 == '\2'", where_clause)
            
            return df.query(where_clause)
            
        except Exception as e:
            logger.error(f"Error applying WHERE clause: {e}")
            return df
    
    def _apply_group_by(self, df: pd.DataFrame, group_by: str, aggregations: List[Dict]) -> pd.DataFrame:
        """Apply GROUP BY with aggregations"""
        try:
            group_cols = [col.strip() for col in group_by.split(',')]
            
            # Create aggregation dictionary
            agg_dict = {}
            for agg in aggregations:
                func_name = agg["function"].lower()
                col_name = agg["column"]
                
                if col_name == "*":
                    # COUNT(*) 
                    if func_name == "count":
                        agg_dict["count"] = ("spend_amount", "count")  # Use first numeric column
                else:
                    if func_name == "count":
                        agg_dict[f"{func_name}_{col_name}"] = (col_name, "count")
                    else:
                        pandas_func = {"sum": "sum", "avg": "mean", "min": "min", "max": "max", "stddev": "std"}.get(func_name, "sum")
                        agg_dict[f"{func_name}_{col_name}"] = (col_name, pandas_func)
            
            if agg_dict:
                result = df.groupby(group_cols).agg(agg_dict).reset_index()
                # Flatten column names
                result.columns = [col[0] if col[1] == '' else f"{col[1]}_{col[0]}" if isinstance(col, tuple) else col for col in result.columns]
                return result
            else:
                return df.groupby(group_cols).size().reset_index(name='count')
                
        except Exception as e:
            logger.error(f"Error applying GROUP BY: {e}")
            return df
    
    def _apply_aggregations(self, df: pd.DataFrame, aggregations: List[Dict]) -> pd.DataFrame:
        """Apply aggregations without GROUP BY"""
        try:
            results = {}
            
            for agg in aggregations:
                func_name = agg["function"].lower()
                col_name = agg["column"]
                
                if col_name == "*":
                    if func_name == "count":
                        results[f"{func_name}_*"] = [len(df)]
                else:
                    if func_name == "count":
                        results[f"{func_name}_{col_name}"] = [df[col_name].count()]
                    elif func_name == "sum":
                        results[f"{func_name}_{col_name}"] = [df[col_name].sum()]
                    elif func_name == "avg":
                        results[f"{func_name}_{col_name}"] = [df[col_name].mean()]
                    elif func_name == "min":
                        results[f"{func_name}_{col_name}"] = [df[col_name].min()]
                    elif func_name == "max":
                        results[f"{func_name}_{col_name}"] = [df[col_name].max()]
                    elif func_name == "stddev":
                        results[f"{func_name}_{col_name}"] = [df[col_name].std()]
            
            return pd.DataFrame(results)
            
        except Exception as e:
            logger.error(f"Error applying aggregations: {e}")
            return df
    
    def _apply_order_by(self, df: pd.DataFrame, order_by: str) -> pd.DataFrame:
        """Apply ORDER BY clause"""
        try:
            order_cols = []
            ascending = []
            
            for col_spec in order_by.split(','):
                col_spec = col_spec.strip()
                if col_spec.upper().endswith(' DESC'):
                    col_name = col_spec[:-5].strip()
                    ascending.append(False)
                else:
                    col_name = col_spec.replace(' ASC', '').strip()
                    ascending.append(True)
                
                order_cols.append(col_name)
            
            return df.sort_values(by=order_cols, ascending=ascending)
            
        except Exception as e:
            logger.error(f"Error applying ORDER BY: {e}")
            return df
    
    def _is_time_series(self, df: pd.DataFrame) -> bool:
        """Check if DataFrame contains time series data"""
        date_cols = ['date', 'month', 'timestamp', 'ts']
        return any(col in df.columns for col in date_cols) and len(df) > 5
    
    def _detect_anomalies(self, df: pd.DataFrame) -> List[Anomaly]:
        """
        Detect anomalies using z-score method
        
        Args:
            df: DataFrame with time series data
            
        Returns:
            List of detected anomalies
        """
        anomalies = []
        
        try:
            # Find date column
            date_col = None
            for col in ['date', 'month', 'timestamp', 'ts']:
                if col in df.columns:
                    date_col = col
                    break
            
            if not date_col:
                return anomalies
            
            # Find numeric columns for anomaly detection
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            
            for col in numeric_cols:
                if col != date_col:
                    values = df[col].dropna()
                    if len(values) < 3:
                        continue
                    
                    # Calculate z-scores
                    mean_val = values.mean()
                    std_val = values.std()
                    
                    if std_val == 0:
                        continue
                    
                    z_scores = np.abs((values - mean_val) / std_val)
                    
                    # Find anomalies (z-score > 2.5)
                    anomaly_mask = z_scores > 2.5
                    anomaly_indices = anomaly_mask[anomaly_mask].index
                    
                    for idx in anomaly_indices:
                        anomalies.append(Anomaly(
                            ts=str(df.loc[idx, date_col]),
                            value=float(df.loc[idx, col]),
                            z_score=float(z_scores.loc[idx])
                        ))
            
        except Exception as e:
            logger.error(f"Error detecting anomalies: {e}")
        
        return anomalies
    
    def _analyze_findings(self, query_result: QueryResult, question: str) -> List[Finding]:
        """
        Analyze query results to extract key findings
        
        Args:
            query_result: Query execution results
            question: Original business question
            
        Returns:
            List of findings with evidence
        """
        findings = []
        df = query_result.data
        
        try:
            # Finding 1: Data summary
            summary_evidence = {
                "total_rows": len(df),
                "date_range": self._get_date_range(df),
                "columns_analyzed": list(df.columns),
                "table_source": query_result.table_name
            }
            
            findings.append(Finding(
                title="Data Overview",
                evidence=summary_evidence
            ))
            
            # Finding 2: Key metrics
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                metrics_evidence = {}
                for col in numeric_cols[:3]:  # Top 3 numeric columns
                    metrics_evidence[col] = {
                        "total": float(df[col].sum()) if col.endswith('_amount') or col.endswith('_count') else float(df[col].mean()),
                        "average": float(df[col].mean()),
                        "min": float(df[col].min()),
                        "max": float(df[col].max())
                    }
                
                findings.append(Finding(
                    title="Key Metrics Summary",
                    evidence=metrics_evidence
                ))
            
            # Finding 3: Anomalies if detected
            if query_result.anomalies:
                anomaly_evidence = {
                    "total_anomalies": len(query_result.anomalies),
                    "anomaly_dates": [a.ts for a in query_result.anomalies[:5]],  # Top 5
                    "max_z_score": max(a.z_score for a in query_result.anomalies)
                }
                
                findings.append(Finding(
                    title="Anomalies Detected",
                    evidence=anomaly_evidence
                ))
            
            # Finding 4: Trends analysis for spend drop questions
            if "drop" in question.lower() or "decline" in question.lower():
                trend_evidence = self._analyze_spend_trends(df, question)
                if trend_evidence:
                    findings.append(Finding(
                        title="Spend Trend Analysis",
                        evidence=trend_evidence
                    ))
            
        except Exception as e:
            logger.error(f"Error analyzing findings: {e}")
        
        return findings
    
    def _get_date_range(self, df: pd.DataFrame) -> Dict[str, str]:
        """Get date range from DataFrame"""
        try:
            date_cols = ['date', 'month', 'timestamp', 'ts']
            for col in date_cols:
                if col in df.columns:
                    min_date = df[col].min()
                    max_date = df[col].max()
                    return {
                        "start": str(min_date),
                        "end": str(max_date),
                        "column": col
                    }
        except:
            pass
        
        return {"start": "N/A", "end": "N/A", "column": "none"}
    
    def _analyze_spend_trends(self, df: pd.DataFrame, question: str) -> Dict[str, Any]:
        """Analyze spending trends for decline questions"""
        try:
            # Look for date column and spend amount
            date_col = None
            spend_col = None
            
            for col in ['date', 'month']:
                if col in df.columns:
                    date_col = col
                    break
            
            for col in ['spend_amount', 'sum_spend_amount']:
                if col in df.columns:
                    spend_col = col
                    break
            
            if not date_col or not spend_col:
                return {}
            
            # Sort by date and analyze trends
            df_sorted = df.sort_values(date_col)
            
            # Check for July 31st impact (promo expiry)
            july_31_idx = None
            for idx, row in df_sorted.iterrows():
                if '2025-07-31' in str(row[date_col]):
                    july_31_idx = idx
                    break
            
            evidence = {}
            if july_31_idx is not None:
                # Compare before and after July 31
                before_idx = max(0, july_31_idx - 2)
                after_idx = min(len(df_sorted) - 1, july_31_idx + 2)
                
                before_spend = df_sorted.iloc[before_idx][spend_col]
                after_spend = df_sorted.iloc[after_idx][spend_col]
                
                pct_change = ((after_spend - before_spend) / before_spend) * 100
                
                evidence = {
                    "july_31_impact": True,
                    "spend_before": float(before_spend),
                    "spend_after": float(after_spend), 
                    "percent_change": float(pct_change),
                    "likely_cause": "Promotional offer expiry on 2025-07-31"
                }
            
            return evidence
            
        except Exception as e:
            logger.error(f"Error analyzing spend trends: {e}")
            return {}
    
    def _generate_actions(self, findings: List[Finding], question: str) -> List[Action]:
        """
        Generate actionable hypotheses and next steps
        
        Args:
            findings: Analysis findings
            question: Original question
            
        Returns:
            List of action items with owners
        """
        actions = []
        
        try:
            # Action 1: Based on anomalies
            anomaly_findings = [f for f in findings if "anomalies" in f.title.lower()]
            if anomaly_findings:
                actions.append(Action(
                    hypothesis="Unusual spikes or drops in metrics may indicate system issues, promotional changes, or market events",
                    owner="Analytics Team"
                ))
            
            # Action 2: Based on spend drops
            if "drop" in question.lower() or "decline" in question.lower():
                actions.append(Action(
                    hypothesis="Spend decline after July 31st likely due to promotional offer expiry - consider extending or launching new promotions",
                    owner="Marketing Team"
                ))
                
                actions.append(Action(
                    hypothesis="Analyze customer retention post-promotion to understand long-term impact on portfolio health",
                    owner="Risk Management"
                ))
            
            # Action 3: Based on delinquency trends
            if "delinq" in question.lower():
                actions.append(Action(
                    hypothesis="Rising delinquency rates may require tightened underwriting or enhanced collection strategies",
                    owner="Credit Risk Team"
                ))
            
            # Action 4: General portfolio monitoring
            actions.append(Action(
                hypothesis="Implement automated monitoring for metric thresholds to catch similar patterns earlier",
                owner="Data Engineering"
            ))
            
        except Exception as e:
            logger.error(f"Error generating actions: {e}")
        
        return actions
    
    def terms_retrieve(self, query: str) -> List[Citation]:
        """
        Retrieve metric definitions and terms
        
        Args:
            query: Terms query
            
        Returns:
            List of citations
        """
        citations = []
        
        try:
            # First, add metric definitions from schema
            for metric, definition in self.metric_definitions.items():
                if metric in query.lower() or any(word in definition.lower() for word in query.split()):
                    citations.append(Citation(
                        source="Metrics Schema",
                        snippet=f"{metric}: {definition}"
                    ))
            
            # Try RAG retrieval if available
            if self.retriever and self.embedder:
                try:
                    results = retrieve(self.retriever, self.embedder, query, k=2)
                    
                    for result in results:
                        citations.append(Citation(
                            source=result.get("filename", "Knowledge Base"),
                            snippet=result.get("snippet", "")[:200] + "..."
                        ))
                except Exception as e:
                    logger.warning(f"RAG retrieval failed: {e}")
            
            # If no results, add default citation
            if not citations:
                citations.append(Citation(
                    source="Portfolio Intelligence",
                    snippet="Metrics definitions and business context for portfolio analysis and decision-making."
                ))
            
        except Exception as e:
            logger.error(f"Error retrieving terms: {e}")
        
        return citations[:5]  # Limit to 5 citations
    
    def _error_response(self, message: str) -> NarratorResponse:
        """Create error response"""
        return NarratorResponse(
            findings=[Finding(
                title="Analysis Error",
                evidence={"error": message}
            )],
            actions=[Action(
                hypothesis="Review query or data availability",
                owner="Analytics Team"
            )],
            tables=[],
            citations=[]
        )

# Test cases for Portfolio Intel Narrator
def test_narrator():
    """Test Portfolio Intel Narrator with business scenarios"""
    print("üß™ Testing Portfolio Intel Narrator")
    print("=" * 50)
    
    narrator = PortfolioIntelNarrator()
    
    test_cases = [
        {
            "name": "Spend drop analysis after July 31st",
            "question": "Why did spend drop after 2025-07-31?",
            "expected_findings": 3,
            "expected_actions": 2,
            "expected_promo_analysis": True
        },
        {
            "name": "Merchant performance comparison",
            "question": "Which merchant has the highest spend volume?",
            "expected_findings": 2,
            "expected_actions": 1,
            "expected_promo_analysis": False
        },
        {
            "name": "Delinquency trend analysis",
            "question": "How are delinquency rates trending by segment?",
            "expected_findings": 2,
            "expected_actions": 2,
            "expected_promo_analysis": False
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            print(f"{i}. {case['name']}")
            print(f"   Question: '{case['question']}'")
            
            result = narrator.process_question(case["question"])
            
            # Validate response structure
            valid_structure = (
                isinstance(result, NarratorResponse) and
                isinstance(result.findings, list) and
                isinstance(result.actions, list) and
                isinstance(result.tables, list) and
                isinstance(result.citations, list)
            )
            
            # Check findings count
            findings_ok = len(result.findings) >= case["expected_findings"]
            
            # Check actions count
            actions_ok = len(result.actions) >= case["expected_actions"]
            
            # Check for promotional analysis if expected
            promo_analysis_ok = True
            if case["expected_promo_analysis"]:
                promo_analysis_ok = any(
                    "promo" in finding.title.lower() or "july" in str(finding.evidence)
                    for finding in result.findings
                )
            
            # Check citations exist
            citations_ok = len(result.citations) > 0
            
            # Check tables exist
            tables_ok = len(result.tables) > 0
            
            success = (valid_structure and findings_ok and actions_ok and 
                      promo_analysis_ok and citations_ok and tables_ok)
            
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"   Findings generated: {len(result.findings)}")
            print(f"   Actions generated: {len(result.actions)}")
            print(f"   Tables referenced: {len(result.tables)}")
            print(f"   Citations found: {len(result.citations)}")
            if case["expected_promo_analysis"]:
                print(f"   Promotional analysis: {promo_analysis_ok}")
            print(f"   Status: {status}")
            
            if success:
                passed += 1
            else:
                print(f"   Failure reasons:")
                if not valid_structure:
                    print(f"     - Invalid response structure")
                if not findings_ok:
                    print(f"     - Insufficient findings generated")
                if not actions_ok:
                    print(f"     - Insufficient actions generated")
                if not promo_analysis_ok:
                    print(f"     - Missing promotional analysis")
                if not citations_ok:
                    print(f"     - No citations provided")
                if not tables_ok:
                    print(f"     - No tables referenced")
            
            print()
            
        except Exception as e:
            print(f"   ‚ùå FAIL - Exception: {str(e)}")
            print()
    
    print(f"üìä Portfolio Intel Narrator Results: {passed}/{total} tests passed")
    return passed == total

if __name__ == "__main__":
    test_narrator()


================================================
FILE: app/agents/offerpilot.py
================================================
"""
OfferPilot - Marketplace Discovery ‚Üí Financing ‚Üí Apply
Conversational shopping with grounded products, promo financing, and credit pre-qualification
"""

import json
import logging
import math
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass

from pydantic import BaseModel, Field

from app.rag.core import retrieve
from app.tools.tavily_search import web_search_into_docstore

logger = logging.getLogger(__name__)

# Pydantic models for strict output schema enforcement
class FinancingOffer(BaseModel):
    id: str
    months: int
    apr: float
    monthly: float
    total_cost: float
    disclaimer: str

class ProductItem(BaseModel):
    sku: str
    title: str
    price: float
    merchant: str
    offers: List[FinancingOffer]

class PrequalResult(BaseModel):
    eligible: bool
    reason: str

class Citation(BaseModel):
    source: str
    snippet: str

class OfferPilotResponse(BaseModel):
    items: List[ProductItem]
    prequal: PrequalResult
    citations: List[Citation]

@dataclass
class UserStub:
    """Mock user data for credit screening"""
    credit_score: int = 720
    income: float = 75000.0
    debt_to_income: float = 0.25
    employment_status: str = "employed"
    years_at_job: int = 3

class OfferPilot:
    """
    Marketplace discovery agent with financing options and credit pre-qualification
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None):
        """Initialize OfferPilot with RAG components for terms retrieval"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        
        # Load data files
        self._load_marketplace_data()
        self._load_financing_data()
    
    def _load_marketplace_data(self):
        """Load marketplace catalog from JSON file"""
        try:
            catalog_path = Path("app/data/marketplace_catalog.json")
            with open(catalog_path, 'r') as f:
                data = json.load(f)
                self.marketplace_products = data["products"]
                self.marketplace_metadata = data["metadata"]
            logger.info(f"Loaded {len(self.marketplace_products)} products from marketplace catalog")
        except Exception as e:
            logger.error(f"Failed to load marketplace catalog: {e}")
            self.marketplace_products = []
            self.marketplace_metadata = {}
    
    def _load_financing_data(self):
        """Load financing offers from JSON file"""
        try:
            offers_path = Path("app/data/financing_offers.json")
            with open(offers_path, 'r') as f:
                data = json.load(f)
                self.financing_offers = {offer["id"]: offer for offer in data["offers"]}
                self.merchant_offers = data["merchant_offers"]
                self.offers_metadata = data["metadata"]
            logger.info(f"Loaded {len(self.financing_offers)} financing offers")
        except Exception as e:
            logger.error(f"Failed to load financing offers: {e}")
            self.financing_offers = {}
            self.merchant_offers = {}
            self.offers_metadata = {}
    
    def process_query(self, query: str, budget: Optional[float] = None) -> OfferPilotResponse:
        """
        Main processing pipeline for OfferPilot
        
        Args:
            query: User search query
            budget: Optional budget constraint
            
        Returns:
            OfferPilotResponse with products, financing, and pre-qualification
        """
        try:
            logger.info(f"Processing OfferPilot query: {query}, budget: {budget}")
            
            # Step 1: Search marketplace
            search_results = self.marketplace_search(query, max_results=8)
            logger.info(f"Found {len(search_results)} products from marketplace search")
            
            # Step 2: Filter by budget if provided
            if budget:
                search_results = [p for p in search_results if p["price"] <= budget]
                logger.info(f"Filtered to {len(search_results)} products within budget ${budget}")
            
            # Step 3: Get financing offers for each product
            enriched_items = []
            for product in search_results[:5]:  # Top 5 products
                offers = self.offers_lookup(product["merchant"], product["price"])
                
                # Step 4: Simulate payments for each offer
                financing_offers = []
                for offer in offers:
                    payment_sim = self.payments_simulate(
                        product["price"], 
                        offer["months"], 
                        offer["apr"]
                    )
                    
                    financing_offers.append(FinancingOffer(
                        id=offer["id"],
                        months=offer["months"],
                        apr=offer["apr"],
                        monthly=payment_sim["monthly"],
                        total_cost=payment_sim["total_cost"],
                        disclaimer=offer["disclaimer"]
                    ))
                
                enriched_items.append(ProductItem(
                    sku=product["sku"],
                    title=product["title"],
                    price=product["price"],
                    merchant=product["merchant"],
                    offers=financing_offers
                ))
            
            # Step 5: Rank by relevance √ó affordability √ó promo fit
            ranked_items = self._rank_items(enriched_items, query, budget)
            
            # Step 6: Get promotional terms citations
            citations = self._get_promotional_citations(ranked_items)
            
            # Step 7: Credit pre-qualification
            user_stub = UserStub()  # Mock user data
            prequal = self.credit_quickscreen(user_stub)
            
            return OfferPilotResponse(
                items=ranked_items,
                prequal=PrequalResult(
                    eligible=prequal["eligible"],
                    reason=prequal["reason"]
                ),
                citations=citations
            )
            
        except Exception as e:
            logger.error(f"Error in OfferPilot processing: {e}")
            return OfferPilotResponse(
                items=[],
                prequal=PrequalResult(eligible=False, reason="System error occurred"),
                citations=[]
            )
    
    def marketplace_search(self, query: str, max_results: int = 8) -> List[Dict[str, Any]]:
        """
        Search marketplace catalog for products matching query
        
        Args:
            query: Search query
            max_results: Maximum number of results to return
            
        Returns:
            List of matching products
        """
        query_lower = query.lower()
        results = []
        
        for product in self.marketplace_products:
            score = 0
            
            # Title matching
            if any(word in product["title"].lower() for word in query_lower.split()):
                score += 3
            
            # Category matching
            if query_lower in product["category"].lower():
                score += 2
            
            # Features matching
            for feature in product["features"]:
                if any(word in feature.lower() for word in query_lower.split()):
                    score += 1
            
            # Description matching
            if any(word in product["description"].lower() for word in query_lower.split()):
                score += 1
            
            if score > 0:
                product_copy = product.copy()
                product_copy["relevance_score"] = score
                results.append(product_copy)
        
        # Sort by relevance score
        results.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        return results[:max_results]
    
    def offers_lookup(self, merchant: str, amount: float) -> List[Dict[str, Any]]:
        """
        Look up financing offers available for merchant and amount
        
        Args:
            merchant: Merchant name
            amount: Purchase amount
            
        Returns:
            List of applicable financing offers
        """
        applicable_offers = []
        
        # Get offers for this merchant
        merchant_offer_ids = self.merchant_offers.get(merchant, [])
        
        for offer_id in merchant_offer_ids:
            offer = self.financing_offers.get(offer_id)
            if not offer:
                continue
            
            # Check if amount qualifies for this offer
            if (amount >= offer["min_purchase"] and 
                amount <= offer["max_purchase"]):
                applicable_offers.append(offer)
        
        # Sort by APR (0% first, then ascending)
        applicable_offers.sort(key=lambda x: (x["apr"] > 0, x["apr"]))
        
        return applicable_offers
    
    def payments_simulate(self, amount: float, months: int, apr: float) -> Dict[str, Any]:
        """
        Simulate payment calculations for financing
        
        Args:
            amount: Principal amount
            months: Number of months
            apr: Annual percentage rate
            
        Returns:
            Payment simulation results
        """
        if apr == 0:
            # 0% APR - simple equal payments
            monthly = round(amount / months, 2)
            total_cost = amount
        else:
            # Standard loan calculation
            monthly_rate = apr / 100 / 12
            if monthly_rate == 0:
                monthly = round(amount / months, 2)
            else:
                monthly = round(
                    amount * (monthly_rate * (1 + monthly_rate) ** months) / 
                    ((1 + monthly_rate) ** months - 1), 2
                )
            total_cost = round(monthly * months, 2)
        
        payoff_date = datetime.now() + timedelta(days=months * 30)
        
        return {
            "monthly": monthly,
            "total_cost": total_cost,
            "payoff_date": payoff_date.strftime("%Y-%m-%d")
        }
    
    def credit_quickscreen(self, user_stub: UserStub) -> Dict[str, Any]:
        """
        Mock credit pre-qualification screening (deterministic)
        
        Args:
            user_stub: User information for screening
            
        Returns:
            Pre-qualification result
        """
        # Deterministic scoring based on user attributes
        score = 0
        reasons = []
        
        # Credit score evaluation
        if user_stub.credit_score >= 750:
            score += 40
        elif user_stub.credit_score >= 700:
            score += 30
        elif user_stub.credit_score >= 650:
            score += 20
        else:
            reasons.append("Credit score below preferred range")
        
        # Income evaluation
        if user_stub.income >= 60000:
            score += 25
        elif user_stub.income >= 40000:
            score += 15
        else:
            reasons.append("Income below minimum threshold")
        
        # Debt-to-income ratio
        if user_stub.debt_to_income <= 0.3:
            score += 20
        elif user_stub.debt_to_income <= 0.4:
            score += 10
        else:
            reasons.append("High debt-to-income ratio")
        
        # Employment stability
        if user_stub.employment_status == "employed" and user_stub.years_at_job >= 2:
            score += 15
        elif user_stub.employment_status == "employed":
            score += 10
        else:
            reasons.append("Employment history concerns")
        
        # Determine eligibility
        eligible = score >= 70
        
        if eligible:
            reason = "Pre-qualified based on credit profile"
        else:
            reason = "; ".join(reasons) if reasons else "Does not meet minimum requirements"
        
        return {
            "eligible": eligible,
            "reason": reason,
            "score": score
        }
    
    def _rank_items(self, items: List[ProductItem], query: str, budget: Optional[float]) -> List[ProductItem]:
        """
        Rank items by relevance √ó affordability √ó promo fit
        
        Args:
            items: List of product items with offers
            query: Original search query
            budget: Budget constraint
            
        Returns:
            Ranked list of items
        """
        scored_items = []
        
        for item in items:
            # Relevance score (based on title/query match)
            relevance = sum(1 for word in query.lower().split() 
                          if word in item.title.lower()) / len(query.split())
            
            # Affordability score (lower price = higher score)
            if budget:
                affordability = max(0, (budget - item.price) / budget)
            else:
                # Use relative affordability within result set
                max_price = max(i.price for i in items)
                affordability = 1 - (item.price / max_price)
            
            # Promo fit score (0% APR offers get higher score)
            promo_score = 0
            if item.offers:
                best_offer = min(item.offers, key=lambda x: x.apr)
                if best_offer.apr == 0:
                    promo_score = 1.0
                else:
                    promo_score = max(0, (25 - best_offer.apr) / 25)  # Scale from 25% APR
            
            # Combined score
            combined_score = (relevance * 0.4 + affordability * 0.3 + promo_score * 0.3)
            
            scored_items.append((item, combined_score))
        
        # Sort by combined score
        scored_items.sort(key=lambda x: x[1], reverse=True)
        
        return [item for item, score in scored_items]
    
    def _get_promotional_citations(self, items: List[ProductItem]) -> List[Citation]:
        """
        Get promotional terms citations from knowledge base
        
        Args:
            items: List of product items
            
        Returns:
            List of citations
        """
        citations = []
        
        if not all([self.retriever, self.embedder]):
            logger.warning("RAG components not available for citations")
            return citations
        
        try:
            # Create query for promotional terms
            offer_types = set()
            for item in items:
                for offer in item.offers:
                    if offer.apr == 0:
                        offer_types.add("0% APR promotional financing")
                    else:
                        offer_types.add("standard APR financing")
            
            if offer_types:
                query = f"promotional terms {' '.join(offer_types)}"
                
                # Retrieve relevant terms documents
                results = retrieve(self.retriever, self.embedder, query, k=3)
                
                for result in results:
                    citations.append(Citation(
                        source=result.get("filename", "Promotional Terms"),
                        snippet=result.get("snippet", "")[:200] + "..."
                    ))
            
            # If no local terms found, search web for Synchrony terms
            if not citations:
                logger.info("No local promotional terms found, searching web...")
                try:
                    web_docs = web_search_into_docstore(
                        self.docstore, 
                        self.embedder, 
                        "0% APR equal monthly payments Synchrony terms",
                        max_results=2
                    )
                    
                    # Re-retrieve after adding web content
                    if web_docs:
                        results = retrieve(self.retriever, self.embedder, 
                                         "promotional financing terms", k=2)
                        
                        for result in results:
                            citations.append(Citation(
                                source=result.get("filename", "Web Search"),
                                snippet=result.get("snippet", "")[:200] + "..."
                            ))
                            
                except Exception as e:
                    logger.warning(f"Web search for terms failed: {e}")
            
        except Exception as e:
            logger.error(f"Error retrieving promotional citations: {e}")
        
        return citations

# Golden-path tests
def test_offerpilot():
    """Test OfferPilot with golden-path scenarios"""
    print("üß™ Testing OfferPilot Golden Paths")
    print("=" * 50)
    
    # Initialize OfferPilot (without RAG for basic testing)
    pilot = OfferPilot()
    
    test_cases = [
        {
            "name": "Desk under $600",
            "query": "office desk",
            "budget": 600.0,
            "expected_items": 2,  # Should find both desk options
            "expected_financing": True
        },
        {
            "name": "Laptop around $1000",
            "query": "laptop computer",
            "budget": 1200.0,
            "expected_items": 3,  # Should find laptop options
            "expected_financing": True
        },
        {
            "name": "Healthcare with CareCredit",
            "query": "dental treatment",
            "budget": None,
            "expected_items": 2,  # Should find dental services
            "expected_carecredit": True
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            result = pilot.process_query(case["query"], case["budget"])
            
            # Validate response structure
            assert isinstance(result, OfferPilotResponse)
            assert isinstance(result.items, list)
            assert isinstance(result.prequal, PrequalResult)
            assert isinstance(result.citations, list)
            
            # Check item count
            items_found = len(result.items)
            items_ok = items_found > 0
            
            # Check financing offers
            has_financing = any(len(item.offers) > 0 for item in result.items)
            
            # Check for CareCredit if healthcare query
            has_carecredit = False
            if case.get("expected_carecredit"):
                has_carecredit = any(
                    any("CARECREDIT" in offer.id for offer in item.offers)
                    for item in result.items
                )
            
            # Check pre-qualification
            prequal_ok = isinstance(result.prequal.eligible, bool)
            
            # Overall success
            success = (items_ok and 
                      (has_financing if case["expected_financing"] else True) and
                      (has_carecredit if case.get("expected_carecredit") else True) and
                      prequal_ok)
            
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            
            print(f"{i}. {case['name']}")
            print(f"   Query: '{case['query']}', Budget: {case['budget']}")
            print(f"   Items found: {items_found}")
            print(f"   Has financing: {has_financing}")
            print(f"   Pre-qualified: {result.prequal.eligible}")
            if case.get("expected_carecredit"):
                print(f"   Has CareCredit: {has_carecredit}")
            print(f"   Status: {status}")
            print()
            
            if success:
                passed += 1
                
        except Exception as e:
            print(f"{i}. {case['name']}: ‚ùå ERROR - {e}")
            print()
    
    print(f"OfferPilot Test Results: {passed}/{total} passed")
    return passed == total

if __name__ == "__main__":
    # Run tests
    success = test_offerpilot()
    print(f"\n{'üéâ All tests passed!' if success else '‚ö†Ô∏è Some tests failed.'}")



================================================
FILE: app/agents/trustshield.py
================================================
"""
TrustShield - Real-time Scam & PII Defense System
Comprehensive fraud detection, PII protection, and safety guidance
"""

import re
import logging
import hashlib
import math
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

from presidio_analyzer import AnalyzerEngine
from presidio_anonymizer import AnonymizerEngine
from presidio_anonymizer.entities import OperatorConfig

from app.llm.gemini import chat
from app.rag.core import retrieve

logger = logging.getLogger(__name__)

@dataclass
class ThreatEvidence:
    """Evidence of a potential threat"""
    type: str
    evidence: str
    confidence: float
    severity: str  # low, medium, high, critical

@dataclass
class SafetyGuidance:
    """Safety guidance for users"""
    label: str
    url: str

@dataclass
class Citation:
    """Citation from knowledge base"""
    source: str
    snippet: str

class TrustShield:
    """
    Advanced threat detection and PII protection system
    """
    
    def __init__(self, docstore=None, embedder=None, retriever=None):
        """Initialize TrustShield with optional RAG components for safety guidance"""
        self.docstore = docstore
        self.embedder = embedder
        self.retriever = retriever
        
        # Initialize Presidio engines
        try:
            self.analyzer = AnalyzerEngine()
            self.anonymizer = AnonymizerEngine()
            logger.info("Presidio engines initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Presidio engines: {e}")
            self.analyzer = None
            self.anonymizer = None
        
        # Scam detection patterns
        self.scam_patterns = self._initialize_scam_patterns()
        
        # High-entropy patterns for gift cards, etc.
        self.entropy_patterns = self._initialize_entropy_patterns()
    
    def scan(self, text: str) -> Dict[str, Any]:
        """
        Comprehensive scan of text for threats, PII, and scams
        
        Args:
            text: Text to analyze
            
        Returns:
            Dictionary with decision, reasons, redacted text, next steps, and citations
        """
        try:
            logger.info(f"TrustShield scanning text: {text[:100]}...")
            
            # Initialize result structure
            result = {
                "decision": "pass",
                "reasons": [],
                "redacted_text": text,
                "next_step": None,
                "citations": []
            }
            
            # 1. PII Detection using Presidio
            pii_threats = self._detect_pii(text)
            result["reasons"].extend(pii_threats)
            
            # 2. Heuristic-based detection (regex patterns)
            heuristic_threats = self._detect_heuristic_threats(text)
            result["reasons"].extend(heuristic_threats)
            
            # 3. High-entropy detection (gift cards, etc.)
            entropy_threats = self._detect_high_entropy_patterns(text)
            result["reasons"].extend(entropy_threats)
            
            # 4. Scam phrase detection
            phrase_threats = self._detect_scam_phrases(text)
            result["reasons"].extend(phrase_threats)
            
            # 5. Gemini-based intent classification
            intent_threats = self._classify_intent_with_gemini(text)
            result["reasons"].extend(intent_threats)
            
            # 6. Determine overall decision based on threat levels
            decision, next_step = self._make_decision(result["reasons"])
            result["decision"] = decision
            result["next_step"] = next_step
            
            # 7. Get safety guidance citations if high risk
            if decision in ["block", "warn"]:
                result["citations"] = self._get_safety_citations(result["reasons"])
            
            # 8. Redact text if needed
            if decision != "block":
                result["redacted_text"] = self._redact_sensitive_content(text, result["reasons"])
            else:
                result["redacted_text"] = "[BLOCKED - High risk content detected]"
            
            logger.info(f"TrustShield decision: {decision} with {len(result['reasons'])} threats detected")
            return result
            
        except Exception as e:
            logger.error(f"Error in TrustShield scan: {e}")
            return {
                "decision": "warn",
                "reasons": [ThreatEvidence("system_error", str(e), 0.8, "medium")],
                "redacted_text": text,
                "next_step": {"label": "Contact Support", "url": "/support"},
                "citations": []
            }
    
    def _detect_pii(self, text: str) -> List[ThreatEvidence]:
        """Detect PII using Presidio analyzer"""
        threats = []
        
        if not self.analyzer:
            return threats
        
        try:
            # Analyze text for PII
            results = self.analyzer.analyze(
                text=text,
                language='en',
                entities=None  # Detect all supported entities
            )
            
            for result in results:
                # Map Presidio confidence to our threat levels
                if result.score >= 0.8:
                    severity = "high"
                elif result.score >= 0.6:
                    severity = "medium"
                else:
                    severity = "low"
                
                evidence_text = text[result.start:result.end]
                
                threats.append(ThreatEvidence(
                    type="pii_detected",
                    evidence=f"{result.entity_type}: {evidence_text}",
                    confidence=result.score,
                    severity=severity
                ))
            
        except Exception as e:
            logger.error(f"Error in PII detection: {e}")
        
        return threats
    
    def _detect_heuristic_threats(self, text: str) -> List[ThreatEvidence]:
        """Detect threats using regex patterns"""
        threats = []
        
        # Credit card patterns (Luhn algorithm validation)
        cc_matches = re.finditer(r'\b(?:\d{4}[-\s]?){3}\d{4}\b', text)
        for match in cc_matches:
            cc_number = re.sub(r'[-\s]', '', match.group())
            if self._validate_luhn(cc_number):
                threats.append(ThreatEvidence(
                    type="credit_card",
                    evidence=f"Credit card number detected: {match.group()}",
                    confidence=0.9,
                    severity="critical"
                ))
        
        # SSN patterns
        ssn_matches = re.finditer(r'\b\d{3}-?\d{2}-?\d{4}\b', text)
        for match in ssn_matches:
            threats.append(ThreatEvidence(
                type="ssn",
                evidence=f"SSN detected: {match.group()}",
                confidence=0.85,
                severity="critical"
            ))
        
        # CVV patterns (3-4 digits, context-aware)
        cvv_matches = re.finditer(r'\b(?:cvv|cvc|security code|card code)[\s:]*(\d{3,4})\b', text, re.IGNORECASE)
        for match in cvv_matches:
            threats.append(ThreatEvidence(
                type="cvv",
                evidence=f"CVV code detected: {match.group()}",
                confidence=0.9,
                severity="critical"
            ))
        
        return threats
    
    def _detect_high_entropy_patterns(self, text: str) -> List[ThreatEvidence]:
        """Detect high-entropy strings that might be gift card codes"""
        threats = []
        
        # Look for potential gift card codes (high entropy alphanumeric strings)
        potential_codes = re.findall(r'\b[A-Z0-9]{10,20}\b', text)
        
        for code in potential_codes:
            entropy = self._calculate_entropy(code)
            
            # High entropy suggests random generation (like gift card codes)
            if entropy > 3.5 and len(code) >= 12:
                # Check if it's in a suspicious context
                context_words = ["gift card", "card code", "redeem", "activation", "voucher"]
                context_found = any(word in text.lower() for word in context_words)
                
                confidence = 0.7 if context_found else 0.5
                severity = "high" if context_found else "medium"
                
                threats.append(ThreatEvidence(
                    type="gift_card_code",
                    evidence=f"Potential gift card code: {code}",
                    confidence=confidence,
                    severity=severity
                ))
        
        return threats
    
    def _detect_scam_phrases(self, text: str) -> List[ThreatEvidence]:
        """Detect common scam phrases"""
        threats = []
        text_lower = text.lower()
        
        # High-risk scam phrases
        high_risk_phrases = [
            "overpay and send gift cards",
            "refund via gift card",
            "wire money to",
            "send gift cards for refund",
            "pay with gift cards",
            "buy gift cards and send codes",
            "verification fee required",
            "advance fee required",
            "send money via western union",
            "send bitcoin for verification"
        ]
        
        # Medium-risk phrases
        medium_risk_phrases = [
            "urgent action required",
            "account will be closed",
            "verify your account immediately",
            "click here to verify",
            "suspended account",
            "unusual activity detected",
            "confirm your identity",
            "update payment information"
        ]
        
        # Check high-risk phrases
        for phrase in high_risk_phrases:
            if phrase in text_lower:
                threats.append(ThreatEvidence(
                    type="scam_phrase",
                    evidence=f"High-risk scam phrase detected: '{phrase}'",
                    confidence=0.9,
                    severity="critical"
                ))
        
        # Check medium-risk phrases
        for phrase in medium_risk_phrases:
            if phrase in text_lower:
                threats.append(ThreatEvidence(
                    type="phishing_phrase",
                    evidence=f"Phishing phrase detected: '{phrase}'",
                    confidence=0.7,
                    severity="medium"
                ))
        
        return threats
    
    def _classify_intent_with_gemini(self, text: str) -> List[ThreatEvidence]:
        """Use Gemini to classify intent for sophisticated threats"""
        threats = []
        
        try:
            system_prompt = """You are a fraud detection specialist. Analyze the following text and classify it into one of these categories:

Categories:
- refund_scam: Attempts to trick users into paying for fake refunds
- account_takeover: Attempts to gain unauthorized access to accounts  
- pii_risk: Requests for sensitive personal information
- safe: Normal, legitimate communication

Respond with ONLY a JSON object:
{"category": "category_name", "confidence": 0.85, "reasoning": "brief explanation"}

Focus on detecting sophisticated social engineering attempts."""

            user_message = f"Analyze this text: '{text}'"
            messages = [{"role": "user", "content": user_message}]
            
            response = chat(messages, system=system_prompt)
            
            import json
            # Handle markdown-wrapped JSON responses
            response_text = response.strip()
            if response_text.startswith('```json'):
                # Extract JSON from markdown code block
                response_text = response_text.replace('```json', '').replace('```', '').strip()
            elif response_text.startswith('```'):
                # Handle generic code blocks
                lines = response_text.split('\n')
                response_text = '\n'.join(lines[1:-1]).strip()
            
            result = json.loads(response_text)
            
            category = result.get("category", "safe")
            confidence = float(result.get("confidence", 0.5))
            reasoning = result.get("reasoning", "")
            
            # Map categories to threat levels
            if category == "refund_scam":
                threats.append(ThreatEvidence(
                    type="refund_scam",
                    evidence=f"Refund scam detected: {reasoning}",
                    confidence=confidence,
                    severity="critical"
                ))
            elif category == "account_takeover":
                threats.append(ThreatEvidence(
                    type="account_takeover",
                    evidence=f"Account takeover attempt: {reasoning}",
                    confidence=confidence,
                    severity="critical"
                ))
            elif category == "pii_risk":
                threats.append(ThreatEvidence(
                    type="pii_request",
                    evidence=f"Suspicious PII request: {reasoning}",
                    confidence=confidence,
                    severity="high"
                ))
            
        except Exception as e:
            logger.error(f"Error in Gemini intent classification: {e}")
        
        return threats
    
    def _make_decision(self, threats: List[ThreatEvidence]) -> Tuple[str, Optional[Dict[str, str]]]:
        """
        Make overall decision based on detected threats using weighted risk scoring
        """
        if not threats:
            return "pass", None
        
        # Calculate weighted risk score
        risk_score = self._calculate_risk_score(threats)
        
        # Count threats by severity for additional context
        critical_count = sum(1 for t in threats if t.severity == "critical")
        high_count = sum(1 for t in threats if t.severity == "high")
        medium_count = sum(1 for t in threats if t.severity == "medium")
        low_count = sum(1 for t in threats if t.severity == "low")
        
        # Get highest severity threat types for context-specific guidance
        threat_types = [t.type for t in threats]
        highest_severity_threats = [t for t in threats if t.severity == "critical"]
        if not highest_severity_threats:
            highest_severity_threats = [t for t in threats if t.severity == "high"]
        
        logger.info(f"Risk assessment: score={risk_score:.2f}, critical={critical_count}, high={high_count}, medium={medium_count}, low={low_count}")
        
        # Enhanced decision logic with risk score thresholds
        if risk_score >= 8.0 or critical_count > 0:
            # Immediate block for critical threats or very high risk
            return "block", self._get_next_step_for_threats(highest_severity_threats, "critical")
            
        elif risk_score >= 6.0 or (high_count >= 2) or (high_count >= 1 and medium_count >= 3):
            # Block for high cumulative risk
            return "block", self._get_next_step_for_threats(highest_severity_threats, "high")
            
        elif risk_score >= 4.0 or high_count >= 1 or medium_count >= 2:
            # Warning for moderate risk
            return "warn", self._get_next_step_for_threats(highest_severity_threats, "medium")
            
        elif risk_score >= 2.0 or medium_count >= 1 or low_count >= 3:
            # Pass with monitoring for low risk
            return "pass", {
                "label": "Low Risk Detected - Monitor Activity",
                "url": "/security/monitor"
            }
        else:
            # Clean pass
            return "pass", None
    
    def _calculate_risk_score(self, threats: List[ThreatEvidence]) -> float:
        """
        Calculate weighted risk score based on threat severity, confidence, and type
        """
        if not threats:
            return 0.0
        
        # Severity weights
        severity_weights = {
            "critical": 10.0,
            "high": 6.0,
            "medium": 3.0,
            "low": 1.0
        }
        
        # Threat type multipliers (some threats are inherently more dangerous)
        type_multipliers = {
            "credit_card": 1.5,
            "ssn": 1.5,
            "cvv": 1.4,
            "scam_phrase": 1.3,
            "refund_scam": 1.4,
            "account_takeover": 1.3,
            "pii_request": 1.2,
            "gift_card_code": 1.1,
            "phishing_phrase": 1.0,
            "pii_detected": 1.0,
            "system_error": 0.8
        }
        
        total_score = 0.0
        threat_count = len(threats)
        
        for threat in threats:
            # Base score from severity and confidence
            base_score = severity_weights.get(threat.severity, 1.0) * threat.confidence
            
            # Apply threat type multiplier
            type_multiplier = type_multipliers.get(threat.type, 1.0)
            threat_score = base_score * type_multiplier
            
            total_score += threat_score
        
        # Apply diminishing returns for multiple threats of same type
        unique_types = len(set(t.type for t in threats))
        diversity_factor = min(1.0, unique_types / threat_count + 0.3)
        
        # Apply escalation factor for multiple threats
        if threat_count > 1:
            escalation_factor = 1.0 + (threat_count - 1) * 0.2
            total_score *= escalation_factor
        
        # Apply diversity factor
        final_score = total_score * diversity_factor
        
        logger.debug(f"Risk calculation: base={total_score:.2f}, diversity={diversity_factor:.2f}, final={final_score:.2f}")
        
        return final_score
    
    def _get_next_step_for_threats(self, threats: List[ThreatEvidence], severity_level: str) -> Dict[str, str]:
        """
        Get context-specific next step guidance based on threat types
        """
        if not threats:
            return {"label": "Contact Support", "url": "/support"}
        
        # Categorize threats
        threat_types = set(t.type for t in threats)
        
        # PII exposure threats
        pii_threats = {"credit_card", "ssn", "cvv", "pii_detected", "pii_request"}
        if threat_types.intersection(pii_threats):
            if severity_level == "critical":
                return {
                    "label": "CRITICAL: PII Exposure Detected - Immediate Action Required",
                    "url": "/security/pii-breach"
                }
            else:
                return {
                    "label": "PII Risk Detected - Review and Secure Information",
                    "url": "/security/pii-guidance"
                }
        
        # Scam/fraud threats
        scam_threats = {"scam_phrase", "refund_scam", "account_takeover", "phishing_phrase"}
        if threat_types.intersection(scam_threats):
            if severity_level == "critical":
                return {
                    "label": "FRAUD ALERT: Scam Detected - Do Not Proceed",
                    "url": "/security/fraud-alert"
                }
            else:
                return {
                    "label": "Potential Scam Detected - Verify Before Proceeding",
                    "url": "/security/scam-guidance"
                }
        
        # Gift card/payment threats
        payment_threats = {"gift_card_code"}
        if threat_types.intersection(payment_threats):
            return {
                "label": "Suspicious Payment Method - Verify Legitimacy",
                "url": "/security/payment-verification"
            }
        
        # Default based on severity
        if severity_level == "critical":
            return {
                "label": "Critical Security Threat - Contact Support Immediately",
                "url": "/security/critical-support"
            }
        elif severity_level == "high":
            return {
                "label": "High Risk Activity - Security Review Required",
                "url": "/security/high-risk-review"
            }
        else:
            return {
                "label": "Security Warning - Proceed with Caution",
                "url": "/security/general-guidance"
            }
    
    def _get_safety_citations(self, threats: List[ThreatEvidence]) -> List[Dict[str, str]]:
        """Get safety guidance citations from knowledge base"""
        citations = []
        
        if not all([self.retriever, self.embedder]):
            return citations
        
        try:
            # Create query based on threat types
            threat_types = [t.type for t in threats]
            query = f"safety guidance for {', '.join(set(threat_types))} threats"
            
            # Retrieve relevant safety documents
            from app.rag.core import retrieve
            results = retrieve(self.retriever, self.embedder, query, k=3)
            
            for result in results:
                citations.append({
                    "source": result.get("filename", "Safety Guidelines"),
                    "snippet": result.get("snippet", "")[:200] + "..."
                })
                
        except Exception as e:
            logger.error(f"Error retrieving safety citations: {e}")
        
        return citations
    
    def _redact_sensitive_content(self, text: str, threats: List[ThreatEvidence]) -> str:
        """Redact sensitive content from text"""
        if not self.anonymizer:
            return text
        
        try:
            # Use Presidio to redact PII
            analyzer_results = self.analyzer.analyze(text=text, language='en')
            
            # Configure anonymization
            anonymized_result = self.anonymizer.anonymize(
                text=text,
                analyzer_results=analyzer_results,
                operators={
                    "CREDIT_CARD": OperatorConfig("replace", {"new_value": "[CREDIT_CARD]"}),
                    "SSN": OperatorConfig("replace", {"new_value": "[SSN]"}),
                    "PHONE_NUMBER": OperatorConfig("replace", {"new_value": "[PHONE]"}),
                    "EMAIL_ADDRESS": OperatorConfig("replace", {"new_value": "[EMAIL]"}),
                    "PERSON": OperatorConfig("replace", {"new_value": "[NAME]"}),
                    "DEFAULT": OperatorConfig("replace", {"new_value": "[REDACTED]"})
                }
            )
            
            redacted_text = anonymized_result.text
            
            # Additional redaction for gift card codes and other patterns
            redacted_text = re.sub(r'\b[A-Z0-9]{10,20}\b', '[GIFT_CARD_CODE]', redacted_text)
            
            return redacted_text
            
        except Exception as e:
            logger.error(f"Error in text redaction: {e}")
            return text
    
    def _validate_luhn(self, card_number: str) -> bool:
        """Validate credit card number using Luhn algorithm"""
        try:
            digits = [int(d) for d in card_number if d.isdigit()]
            if len(digits) < 13 or len(digits) > 19:
                return False
            
            checksum = 0
            for i, digit in enumerate(reversed(digits)):
                if i % 2 == 1:
                    digit *= 2
                    if digit > 9:
                        digit -= 9
                checksum += digit
            
            return checksum % 10 == 0
        except:
            return False
    
    def _calculate_entropy(self, string: str) -> float:
        """Calculate Shannon entropy of a string"""
        if not string:
            return 0
        
        # Count character frequencies
        char_counts = {}
        for char in string:
            char_counts[char] = char_counts.get(char, 0) + 1
        
        # Calculate entropy
        entropy = 0
        length = len(string)
        for count in char_counts.values():
            probability = count / length
            entropy -= probability * math.log2(probability)
        
        return entropy
    
    def _initialize_scam_patterns(self) -> Dict[str, List[str]]:
        """Initialize scam detection patterns"""
        return {
            "refund_scams": [
                r"overpay.*gift card",
                r"refund.*gift card",
                r"send.*gift card.*refund",
                r"buy.*gift card.*verification"
            ],
            "wire_fraud": [
                r"wire.*money.*to",
                r"western union.*transfer",
                r"send.*money.*urgent"
            ],
            "crypto_scams": [
                r"send.*bitcoin.*verification",
                r"crypto.*wallet.*verification",
                r"bitcoin.*address.*refund"
            ]
        }
    
    def _initialize_entropy_patterns(self) -> Dict[str, float]:
        """Initialize entropy thresholds for different pattern types"""
        return {
            "gift_card_codes": 3.5,
            "crypto_addresses": 4.0,
            "random_strings": 3.0
        }

# Unit tests for common scam scenarios
def test_trustshield():
    """Deterministic unit tests for TrustShield"""
    shield = TrustShield()
    
    test_cases = [
        {
            "name": "Refund Scam",
            "text": "You overpaid $500. Please buy gift cards and send the codes for your refund.",
            "expected_decision": "block",
            "expected_threats": ["scam_phrase", "refund_scam"]
        },
        {
            "name": "Credit Card Exposure",
            "text": "My card number is 4532-1234-5678-9012 and CVV is 123",
            "expected_decision": "block", 
            "expected_threats": ["credit_card", "cvv"]
        },
        {
            "name": "SSN Exposure",
            "text": "My social security number is 123-45-6789",
            "expected_decision": "block",
            "expected_threats": ["ssn"]
        },
        {
            "name": "Phishing Attempt",
            "text": "Urgent action required! Your account will be closed. Click here to verify immediately.",
            "expected_decision": "warn",
            "expected_threats": ["phishing_phrase"]
        },
        {
            "name": "Safe Message",
            "text": "Hello, I'd like to know about your payment processing fees.",
            "expected_decision": "pass",
            "expected_threats": []
        }
    ]
    
    results = []
    for case in test_cases:
        result = shield.scan(case["text"])
        
        # Check decision
        decision_correct = result["decision"] == case["expected_decision"]
        
        # Check threat types
        detected_types = [threat.type for threat in result["reasons"]]
        threats_correct = all(expected in detected_types for expected in case["expected_threats"])
        
        test_result = {
            "name": case["name"],
            "passed": decision_correct and threats_correct,
            "expected_decision": case["expected_decision"],
            "actual_decision": result["decision"],
            "expected_threats": case["expected_threats"],
            "detected_threats": detected_types
        }
        
        results.append(test_result)
        
        print(f"Test '{case['name']}': {'PASS' if test_result['passed'] else 'FAIL'}")
        if not test_result['passed']:
            print(f"  Expected: {case['expected_decision']}, Got: {result['decision']}")
            print(f"  Expected threats: {case['expected_threats']}")
            print(f"  Detected threats: {detected_types}")
    
    return results

if __name__ == "__main__":
    # Run tests
    test_results = test_trustshield()
    passed = sum(1 for r in test_results if r["passed"])
    total = len(test_results)
    print(f"\nTest Results: {passed}/{total} passed")



================================================
FILE: app/contracts/merchant_agreement.md
================================================
# Merchant Service Agreement

## Agreement Overview

This Merchant Service Agreement ("Agreement") governs the provision of payment processing and related services.

## Merchant Obligations

### Compliance Requirements
- Maintain PCI DSS compliance at all times
- Implement proper security measures for cardholder data
- Report security incidents within 24 hours
- Undergo annual security assessments

### Transaction Processing
- Process transactions only for legitimate business purposes
- Maintain accurate transaction records
- Provide clear refund and return policies
- Honor all valid chargebacks within specified timeframes

### Documentation
- Maintain detailed transaction logs for minimum 3 years
- Provide monthly reconciliation reports
- Submit compliance certificates annually
- Keep business licenses and permits current

## Service Levels

### Processing Times
- Standard transactions: 2-3 business days
- Express processing: Same day (additional fees apply)
- International transactions: 3-5 business days
- Refunds: 5-7 business days

### Availability
- System uptime: 99.9% guaranteed
- Maintenance windows: Sundays 2-4 AM EST
- Emergency maintenance: 4-hour advance notice
- Support availability: 24/7 for critical issues

## Fee Structure

### Transaction Fees
- Domestic cards: 2.9% + $0.30 per transaction
- International cards: 3.4% + $0.30 per transaction
- American Express: 3.5% + $0.30 per transaction
- Corporate cards: 3.2% + $0.30 per transaction

### Monthly Fees
- Account maintenance: $25/month
- Statement fee: $10/month
- Gateway access: $15/month
- PCI compliance fee: $20/month (waived if compliant)

### Additional Fees
- Chargeback fee: $15 per occurrence
- Retrieval request: $10 per request
- Early termination: $200 (if within first 12 months)
- Setup fee: $100 (one-time)

## Risk Management

### Transaction Monitoring
- Real-time fraud detection
- Velocity checking
- Geographic risk assessment
- Machine learning-based scoring

### Account Holds
- Suspicious activity may trigger holds
- High-risk transactions require manual review
- Rolling reserves may be applied (up to 10%)
- Release conditions clearly defined

## Termination

### Termination Rights
- Either party may terminate with 30 days notice
- Immediate termination for material breach
- Automatic termination for insolvency
- Regulatory termination as required

### Post-Termination
- Final settlement within 30 days
- Return of all confidential information
- Continued liability for processed transactions
- Data retention as per regulatory requirements

## Dispute Resolution

### Process
1. Direct negotiation (30 days)
2. Mediation (if negotiation fails)
3. Binding arbitration (final resort)
4. Governing law: Delaware

### Limitations
- Claims must be filed within 12 months
- Liability limited to fees paid in prior 12 months
- No consequential damages
- Class action waiver applies

## Contact Information

**Business Support:**
- Phone: 1-800-MERCHANT
- Email: support@merchantservices.com
- Hours: Monday-Friday 8 AM - 8 PM EST

**Technical Support:**
- Phone: 1-800-TECH-HELP
- Email: technical@merchantservices.com
- Hours: 24/7

**Compliance Department:**
- Phone: 1-800-COMPLY
- Email: compliance@merchantservices.com
- Hours: Monday-Friday 9 AM - 5 PM EST

---

*This agreement is effective as of the date of electronic acceptance or signature. Last updated: January 2025.*



================================================
FILE: app/data/financing_offers.json
================================================
{
  "offers": [
    {
      "id": "SYNC-0APR-12",
      "name": "0% APR for 12 Months",
      "type": "promotional",
      "merchant": "OfficeMax",
      "months": 12,
      "apr": 0.0,
      "min_purchase": 299.00,
      "max_purchase": 2000.00,
      "disclaimer": "0% APR for 12 months on purchases of $299 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 12 months."
    },
    {
      "id": "SYNC-0APR-18",
      "name": "0% APR for 18 Months",
      "type": "promotional",
      "merchant": "Apple Store",
      "months": 18,
      "apr": 0.0,
      "min_purchase": 500.00,
      "max_purchase": 5000.00,
      "disclaimer": "0% APR for 18 months on purchases of $500 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 18 months."
    },
    {
      "id": "SYNC-0APR-24",
      "name": "0% APR for 24 Months",
      "type": "promotional",
      "merchant": "Dell",
      "months": 24,
      "apr": 0.0,
      "min_purchase": 750.00,
      "max_purchase": 3000.00,
      "disclaimer": "0% APR for 24 months on purchases of $750 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 24 months."
    },
    {
      "id": "SYNC-STD-12",
      "name": "Standard 12 Month Plan",
      "type": "standard",
      "merchant": "IKEA",
      "months": 12,
      "apr": 19.99,
      "min_purchase": 199.00,
      "max_purchase": 10000.00,
      "disclaimer": "Standard APR of 19.99% applies. Minimum monthly payments required."
    },
    {
      "id": "SYNC-STD-24",
      "name": "Standard 24 Month Plan",
      "type": "standard",
      "merchant": "HP",
      "months": 24,
      "apr": 22.99,
      "min_purchase": 299.00,
      "max_purchase": 10000.00,
      "disclaimer": "Standard APR of 22.99% applies. Minimum monthly payments required."
    },
    {
      "id": "CARECREDIT-0APR-6",
      "name": "CareCredit 6 Months No Interest",
      "type": "healthcare",
      "merchant": "SmileCare Dental",
      "months": 6,
      "apr": 0.0,
      "min_purchase": 200.00,
      "max_purchase": 25000.00,
      "disclaimer": "No Interest if paid in full in 6 months on purchases of $200 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 6 months."
    },
    {
      "id": "CARECREDIT-0APR-12",
      "name": "CareCredit 12 Months No Interest",
      "type": "healthcare",
      "merchant": "BrightSmile Clinic",
      "months": 12,
      "apr": 0.0,
      "min_purchase": 300.00,
      "max_purchase": 25000.00,
      "disclaimer": "No Interest if paid in full in 12 months on purchases of $300 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 12 months."
    },
    {
      "id": "CARECREDIT-0APR-18",
      "name": "CareCredit 18 Months No Interest",
      "type": "veterinary",
      "merchant": "VetCare Animal Hospital",
      "months": 18,
      "apr": 0.0,
      "min_purchase": 500.00,
      "max_purchase": 25000.00,
      "disclaimer": "No Interest if paid in full in 18 months on purchases of $500 or more. Interest will be charged from the purchase date if the promotional balance is not paid in full within 18 months."
    },
    {
      "id": "CARECREDIT-STD-24",
      "name": "CareCredit Extended Payment Plan",
      "type": "healthcare",
      "merchant": "SmileCare Dental",
      "months": 24,
      "apr": 17.90,
      "min_purchase": 1000.00,
      "max_purchase": 25000.00,
      "disclaimer": "17.90% APR applies to extended payment plans. Minimum monthly payments required."
    }
  ],
  "merchant_offers": {
    "OfficeMax": ["SYNC-0APR-12", "SYNC-STD-12"],
    "IKEA": ["SYNC-STD-12"],
    "Apple Store": ["SYNC-0APR-18"],
    "Dell": ["SYNC-0APR-24"],
    "HP": ["SYNC-STD-24"],
    "SmileCare Dental": ["CARECREDIT-0APR-6", "CARECREDIT-STD-24"],
    "BrightSmile Clinic": ["CARECREDIT-0APR-12"],
    "VetCare Animal Hospital": ["CARECREDIT-0APR-18"]
  },
  "metadata": {
    "total_offers": 9,
    "offer_types": ["promotional", "standard", "healthcare", "veterinary"],
    "apr_range": {
      "min": 0.0,
      "max": 22.99
    },
    "term_range": {
      "min_months": 6,
      "max_months": 24
    },
    "last_updated": "2025-01-08T00:00:00Z"
  }
}



================================================
FILE: app/data/hardship_policies.json
================================================
{
  "policy_version": "2025.1",
  "effective_date": "2025-01-01",
  "allowed_actions": {
    "deferral": {
      "enabled": true,
      "max_months": 6,
      "min_balance": 100.0,
      "max_balance": 50000.0,
      "eligible_buckets": ["current", "30", "60", "90", "120+"],
      "required_income_verification": true,
      "max_deferrals_per_year": 2
    },
    "re_aging": {
      "enabled": true,
      "min_bucket": "60",
      "eligible_buckets": ["60", "90", "120+"],
      "min_payment_history": 3,
      "min_payment_amount_pct": 0.10,
      "max_re_aging_per_year": 1,
      "requires_hardship_documentation": true
    },
    "settlement": {
      "enabled": true,
      "min_settlement_pct": 0.40,
      "max_settlement_pct": 0.85,
      "eligible_buckets": ["90", "120+"],
      "requires_lump_sum": false,
      "split_payment_max_months": 12,
      "requires_financial_hardship": true
    },
    "interest_reduction": {
      "enabled": true,
      "min_reduction_pct": 0.25,
      "max_reduction_pct": 0.75,
      "max_cycles": 12,
      "eligible_buckets": ["current", "30", "60"],
      "requires_autopay": true,
      "min_payment_amount_pct": 0.02
    },
    "payment_plan": {
      "enabled": true,
      "min_months": 6,
      "max_months": 60,
      "min_monthly_payment": 25.0,
      "eligible_buckets": ["current", "30", "60", "90", "120+"],
      "requires_income_verification": true
    }
  },
  "risk_parameters": {
    "chargeoff_risk_factors": {
      "bucket_multipliers": {
        "current": 0.02,
        "30": 0.08,
        "60": 0.20,
        "90": 0.45,
        "120+": 0.75
      },
      "income_ratio_impact": {
        "high_ratio": 0.1,
        "medium_ratio": 0.3,
        "low_ratio": 0.7
      },
      "balance_size_impact": {
        "small": 0.1,
        "medium": 0.2,
        "large": 0.4
      }
    },
    "affordability_thresholds": {
      "comfortable": 0.3,
      "manageable": 0.5,
      "stretched": 0.8
    }
  },
  "mandatory_disclosures": {
    "deferral": [
      "Interest will continue to accrue during the deferral period",
      "Your account will remain past due during deferral",
      "Credit reporting may continue during deferral period",
      "This is a temporary hardship accommodation",
      "You must resume regular payments after the deferral period"
    ],
    "re_aging": [
      "Re-aging will bring your account current",
      "You must make consecutive on-time payments to maintain current status",
      "Re-aging is limited to once per 12-month period",
      "Failure to maintain payments may result in immediate acceleration",
      "This accommodation may be reported to credit bureaus"
    ],
    "settlement": [
      "Settlement amount is less than the full balance owed",
      "Forgiven debt may be reported as taxable income",
      "Settlement will be reported to credit bureaus as 'settled for less than full amount'",
      "This will have a negative impact on your credit score",
      "Payment must be received by the agreed deadline"
    ],
    "interest_reduction": [
      "Reduced interest rate is temporary and subject to terms",
      "Rate will return to standard APR after the promotional period",
      "You must maintain automatic payments to qualify",
      "Missing payments will result in immediate rate restoration",
      "This is a hardship accommodation and may be reported"
    ],
    "payment_plan": [
      "You must make all scheduled payments on time",
      "Missing payments may result in plan termination",
      "Interest continues to accrue at your current APR",
      "Plan terms are subject to credit review and approval",
      "Additional fees may apply for plan setup"
    ]
  },
  "compliance_requirements": {
    "udaap_safe": true,
    "cfpb_compliant": true,
    "state_regulations": {
      "california": {
        "additional_disclosures": ["California residents have additional rights under state law"],
        "cooling_off_period": 3
      },
      "new_york": {
        "additional_disclosures": ["New York residents may contact the state attorney general"],
        "mandatory_review_period": 5
      }
    },
    "documentation_required": {
      "income_verification": ["pay stubs", "tax returns", "bank statements"],
      "hardship_documentation": ["medical bills", "unemployment notice", "divorce decree"],
      "identity_verification": ["government ID", "SSN verification"]
    }
  },
  "escalation_triggers": {
    "supervisor_review": {
      "settlement_above_pct": 0.70,
      "deferral_months_above": 4,
      "multiple_hardships_per_year": 2
    },
    "legal_review": {
      "settlement_below_pct": 0.50,
      "disputed_debt": true,
      "bankruptcy_indication": true
    },
    "executive_approval": {
      "balance_above": 25000.0,
      "settlement_below_pct": 0.45,
      "regulatory_complaint": true
    }
  }
}



================================================
FILE: app/data/marketplace_catalog.json
================================================
{
  "products": [
    {
      "sku": "DESK-001",
      "title": "Executive Standing Desk with Drawers",
      "merchant": "OfficeMax",
      "price": 549.99,
      "category": "furniture",
      "features": ["height adjustable", "3 drawers", "cable management", "oak finish"],
      "description": "Premium standing desk perfect for home office"
    },
    {
      "sku": "DESK-002", 
      "title": "Compact Writing Desk",
      "merchant": "IKEA",
      "price": 299.99,
      "category": "furniture",
      "features": ["compact design", "2 drawers", "white finish", "easy assembly"],
      "description": "Simple and functional desk for small spaces"
    },
    {
      "sku": "LAPTOP-001",
      "title": "MacBook Air M2 13-inch",
      "merchant": "Apple Store",
      "price": 1199.99,
      "category": "electronics",
      "features": ["M2 chip", "8GB RAM", "256GB SSD", "13.6-inch display"],
      "description": "Latest MacBook Air with M2 processor"
    },
    {
      "sku": "LAPTOP-002",
      "title": "Dell XPS 13 Laptop",
      "merchant": "Dell",
      "price": 999.99,
      "category": "electronics", 
      "features": ["Intel i7", "16GB RAM", "512GB SSD", "13.4-inch 4K display"],
      "description": "Premium ultrabook with stunning display"
    },
    {
      "sku": "LAPTOP-003",
      "title": "HP Pavilion 15 Laptop",
      "merchant": "HP",
      "price": 699.99,
      "category": "electronics",
      "features": ["AMD Ryzen 5", "8GB RAM", "256GB SSD", "15.6-inch display"],
      "description": "Reliable laptop for everyday computing"
    },
    {
      "sku": "DENTAL-001",
      "title": "Dental Crown Treatment",
      "merchant": "SmileCare Dental",
      "price": 1200.00,
      "category": "healthcare",
      "features": ["porcelain crown", "same-day service", "5-year warranty"],
      "description": "High-quality dental crown restoration"
    },
    {
      "sku": "DENTAL-002",
      "title": "Teeth Whitening Treatment",
      "merchant": "BrightSmile Clinic",
      "price": 450.00,
      "category": "healthcare",
      "features": ["professional whitening", "1-hour treatment", "guaranteed results"],
      "description": "Professional teeth whitening service"
    },
    {
      "sku": "VET-001",
      "title": "Pet Surgery - ACL Repair",
      "merchant": "VetCare Animal Hospital",
      "price": 2500.00,
      "category": "veterinary",
      "features": ["orthopedic surgery", "post-op care", "rehabilitation included"],
      "description": "ACL repair surgery for dogs"
    },
    {
      "sku": "PHONE-001",
      "title": "iPhone 15 Pro",
      "merchant": "Apple Store",
      "price": 999.99,
      "category": "electronics",
      "features": ["A17 Pro chip", "128GB storage", "titanium design", "48MP camera"],
      "description": "Latest iPhone with titanium design"
    },
    {
      "sku": "TABLET-001",
      "title": "iPad Air 5th Gen",
      "merchant": "Apple Store", 
      "price": 599.99,
      "category": "electronics",
      "features": ["M1 chip", "64GB storage", "10.9-inch display", "Apple Pencil compatible"],
      "description": "Powerful tablet for creativity and productivity"
    }
  ],
  "metadata": {
    "total_products": 10,
    "categories": ["furniture", "electronics", "healthcare", "veterinary"],
    "merchants": ["OfficeMax", "IKEA", "Apple Store", "Dell", "HP", "SmileCare Dental", "BrightSmile Clinic", "VetCare Animal Hospital"],
    "price_range": {
      "min": 299.99,
      "max": 2500.00
    },
    "last_updated": "2025-01-08T00:00:00Z"
  }
}



================================================
FILE: app/data/metrics_schema.json
================================================
{
  "schemas": {
    "portfolio_spend": {
      "table_name": "portfolio_spend",
      "description": "Daily portfolio spending metrics by merchant and promo type",
      "columns": {
        "date": {"type": "date", "description": "Transaction date"},
        "merchant": {"type": "string", "description": "Merchant name"},
        "promo_type": {"type": "string", "description": "Promotional offer type"},
        "spend_amount": {"type": "float", "description": "Total spend amount in USD"},
        "transaction_count": {"type": "integer", "description": "Number of transactions"},
        "avg_ticket": {"type": "float", "description": "Average transaction amount"},
        "new_customers": {"type": "integer", "description": "New customer count"}
      },
      "primary_key": ["date", "merchant", "promo_type"],
      "time_column": "date"
    },
    "delinquency_rates": {
      "table_name": "delinquency_rates", 
      "description": "Monthly delinquency rates by customer segment and vintage",
      "columns": {
        "month": {"type": "date", "description": "Month-end date"},
        "segment": {"type": "string", "description": "Customer credit segment"},
        "vintage": {"type": "string", "description": "Account vintage (origination quarter)"},
        "total_accounts": {"type": "integer", "description": "Total active accounts"},
        "delinq_30": {"type": "float", "description": "30+ days delinquency rate"},
        "delinq_60": {"type": "float", "description": "60+ days delinquency rate"},
        "delinq_90": {"type": "float", "description": "90+ days delinquency rate"},
        "charge_off_rate": {"type": "float", "description": "Charge-off rate"}
      },
      "primary_key": ["month", "segment", "vintage"],
      "time_column": "month"
    },
    "promo_performance": {
      "table_name": "promo_performance",
      "description": "Promotional campaign performance metrics",
      "columns": {
        "date": {"type": "date", "description": "Campaign date"},
        "promo_id": {"type": "string", "description": "Promotion identifier"},
        "promo_name": {"type": "string", "description": "Promotion name"},
        "start_date": {"type": "date", "description": "Promotion start date"},
        "end_date": {"type": "date", "description": "Promotion end date"},
        "applications": {"type": "integer", "description": "Credit applications"},
        "approvals": {"type": "integer", "description": "Credit approvals"},
        "approval_rate": {"type": "float", "description": "Approval rate percentage"},
        "activation_rate": {"type": "float", "description": "Card activation rate"},
        "spend_per_approval": {"type": "float", "description": "Average spend per approval"}
      },
      "primary_key": ["date", "promo_id"],
      "time_column": "date"
    },
    "credit_metrics": {
      "table_name": "credit_metrics",
      "description": "Credit portfolio health metrics",
      "columns": {
        "date": {"type": "date", "description": "Metric date"},
        "product": {"type": "string", "description": "Credit product type"},
        "outstanding_balance": {"type": "float", "description": "Total outstanding balance"},
        "utilization_rate": {"type": "float", "description": "Credit utilization rate"},
        "payment_rate": {"type": "float", "description": "Payment rate"},
        "net_charge_offs": {"type": "float", "description": "Net charge-offs"},
        "provision_expense": {"type": "float", "description": "Provision expense"},
        "yield": {"type": "float", "description": "Portfolio yield percentage"}
      },
      "primary_key": ["date", "product"],
      "time_column": "date"
    }
  },
  "allowed_operations": {
    "select": {
      "functions": ["COUNT", "SUM", "AVG", "MIN", "MAX", "STDDEV"],
      "aggregations": true,
      "joins": false
    },
    "where": {
      "operators": ["=", "!=", "<", "<=", ">", ">=", "IN", "LIKE", "BETWEEN"],
      "functions": ["DATE", "MONTH", "YEAR", "QUARTER"]
    },
    "group_by": {
      "allowed": true,
      "max_columns": 3
    },
    "order_by": {
      "allowed": true,
      "max_columns": 2
    },
    "limit": {
      "allowed": true,
      "max_rows": 10000
    }
  },
  "metric_definitions": {
    "spend_amount": "Total dollar amount spent by customers using credit products",
    "delinq_30": "Percentage of accounts 30+ days past due on payments", 
    "approval_rate": "Percentage of credit applications that are approved",
    "utilization_rate": "Average credit utilization across active accounts",
    "charge_off_rate": "Percentage of accounts charged off as uncollectible",
    "payment_rate": "Percentage of minimum payment made on time",
    "portfolio_yield": "Annual percentage yield earned on outstanding balances",
    "provision_expense": "Expected credit loss provisions for future charge-offs"
  }
}


================================================
FILE: app/data/provider_catalog.json
================================================
{
  "providers": [
    {
      "id": "prov_001",
      "name": "GlobalPay Solutions",
      "type": "payment_processor",
      "status": "active",
      "supported_regions": ["US", "CA", "EU", "UK"],
      "supported_currencies": ["USD", "CAD", "EUR", "GBP"],
      "features": {
        "real_time_processing": true,
        "fraud_detection": true,
        "recurring_billing": true,
        "mobile_payments": true,
        "cryptocurrency": false
      },
      "pricing": {
        "setup_fee": 100,
        "monthly_fee": 25,
        "transaction_rate": 2.9,
        "international_rate": 3.4
      },
      "integration": {
        "api_version": "v2.1",
        "webhook_support": true,
        "sdk_available": ["javascript", "python", "php", "java"],
        "documentation_url": "https://docs.globalpay.com"
      },
      "compliance": {
        "pci_dss": "Level 1",
        "gdpr_compliant": true,
        "sox_compliant": true,
        "certifications": ["ISO 27001", "SOC 2 Type II"]
      },
      "contact": {
        "support_email": "support@globalpay.com",
        "support_phone": "+1-800-555-0123",
        "account_manager": "Sarah Johnson",
        "technical_contact": "tech@globalpay.com"
      }
    },
    {
      "id": "prov_002",
      "name": "SecureTransact Inc",
      "type": "payment_gateway",
      "status": "active",
      "supported_regions": ["US", "CA", "MX"],
      "supported_currencies": ["USD", "CAD", "MXN"],
      "features": {
        "real_time_processing": true,
        "fraud_detection": true,
        "recurring_billing": false,
        "mobile_payments": true,
        "cryptocurrency": true
      },
      "pricing": {
        "setup_fee": 200,
        "monthly_fee": 35,
        "transaction_rate": 2.7,
        "international_rate": 3.2
      },
      "integration": {
        "api_version": "v3.0",
        "webhook_support": true,
        "sdk_available": ["javascript", "python", "ruby"],
        "documentation_url": "https://api.securetransact.com"
      },
      "compliance": {
        "pci_dss": "Level 1",
        "gdpr_compliant": false,
        "sox_compliant": true,
        "certifications": ["ISO 27001"]
      },
      "contact": {
        "support_email": "help@securetransact.com",
        "support_phone": "+1-888-555-0456",
        "account_manager": "Mike Chen",
        "technical_contact": "developers@securetransact.com"
      }
    },
    {
      "id": "prov_003",
      "name": "EuroPayments Ltd",
      "type": "payment_processor",
      "status": "active",
      "supported_regions": ["EU", "UK", "CH", "NO"],
      "supported_currencies": ["EUR", "GBP", "CHF", "NOK", "SEK", "DKK"],
      "features": {
        "real_time_processing": true,
        "fraud_detection": true,
        "recurring_billing": true,
        "mobile_payments": true,
        "cryptocurrency": false
      },
      "pricing": {
        "setup_fee": 150,
        "monthly_fee": 30,
        "transaction_rate": 2.5,
        "international_rate": 3.0
      },
      "integration": {
        "api_version": "v2.3",
        "webhook_support": true,
        "sdk_available": ["javascript", "python", "php", "java", "dotnet"],
        "documentation_url": "https://developers.europayments.com"
      },
      "compliance": {
        "pci_dss": "Level 1",
        "gdpr_compliant": true,
        "sox_compliant": false,
        "certifications": ["ISO 27001", "SOC 2 Type II", "PSD2"]
      },
      "contact": {
        "support_email": "support@europayments.com",
        "support_phone": "+44-20-7123-4567",
        "account_manager": "Emma Thompson",
        "technical_contact": "api-support@europayments.com"
      }
    }
  ],
  "metadata": {
    "total_providers": 3,
    "active_providers": 3,
    "last_updated": "2025-01-08T00:00:00Z",
    "version": "1.2.0",
    "supported_regions_total": ["US", "CA", "EU", "UK", "MX", "CH", "NO"],
    "supported_currencies_total": ["USD", "CAD", "EUR", "GBP", "MXN", "CHF", "NOK", "SEK", "DKK"]
  }
}



================================================
FILE: app/data/providers.json
================================================
{
  "providers": [
    {
      "id": "dent_001",
      "name": "City Dental Care",
      "specialty": "dental",
      "address": "123 Main St, New York, NY 10001",
      "phone": "(212) 555-0123",
      "next_appt_days": 7,
      "location": "New York, NY",
      "accepts_carecredit": true,
      "rating": 4.8
    },
    {
      "id": "dent_002", 
      "name": "Smile Bright Dentistry",
      "specialty": "dental",
      "address": "456 Oak Ave, Los Angeles, CA 90210",
      "phone": "(323) 555-0456",
      "next_appt_days": 14,
      "location": "Los Angeles, CA",
      "accepts_carecredit": true,
      "rating": 4.6
    },
    {
      "id": "derm_001",
      "name": "Advanced Dermatology Center",
      "specialty": "dermatology",
      "address": "789 Elm St, Chicago, IL 60601",
      "phone": "(312) 555-0789",
      "next_appt_days": 21,
      "location": "Chicago, IL",
      "accepts_carecredit": true,
      "rating": 4.9
    },
    {
      "id": "orth_001",
      "name": "Orthopedic Specialists",
      "specialty": "orthopedic",
      "address": "321 Pine St, Houston, TX 77001",
      "phone": "(713) 555-0321",
      "next_appt_days": 10,
      "location": "Houston, TX",
      "accepts_carecredit": true,
      "rating": 4.7
    },
    {
      "id": "vet_001",
      "name": "Pet Care Veterinary Hospital",
      "specialty": "veterinary",
      "address": "654 Birch Rd, Phoenix, AZ 85001",
      "phone": "(602) 555-0654",
      "next_appt_days": 3,
      "location": "Phoenix, AZ",
      "accepts_carecredit": true,
      "rating": 4.8
    },
    {
      "id": "opht_001",
      "name": "Vision Care Center",
      "specialty": "ophthalmology",
      "address": "987 Cedar St, Philadelphia, PA 19101",
      "phone": "(215) 555-0987",
      "next_appt_days": 28,
      "location": "Philadelphia, PA",
      "accepts_carecredit": true,
      "rating": 4.5
    },
    {
      "id": "dent_003",
      "name": "Downtown Dental Group",
      "specialty": "dental",
      "address": "147 Broadway, New York, NY 10002", 
      "phone": "(212) 555-0147",
      "next_appt_days": 5,
      "location": "New York, NY",
      "accepts_carecredit": true,
      "rating": 4.7
    },
    {
      "id": "derm_002",
      "name": "Skin Health Associates",
      "specialty": "dermatology",
      "address": "258 Sunset Blvd, Los Angeles, CA 90211",
      "phone": "(323) 555-0258",
      "next_appt_days": 35,
      "location": "Los Angeles, CA",
      "accepts_carecredit": true,
      "rating": 4.4
    }
  ],
  "specialties": {
    "dental": ["teeth", "tooth", "dental", "dentist", "cavity", "crown", "root canal", "cleaning", "whitening"],
    "dermatology": ["skin", "dermatology", "dermatologist", "acne", "mole", "rash", "cosmetic", "botox"],
    "orthopedic": ["bone", "joint", "orthopedic", "knee", "hip", "shoulder", "fracture", "surgery"],
    "veterinary": ["pet", "dog", "cat", "veterinary", "vet", "animal"],
    "ophthalmology": ["eye", "vision", "glasses", "contacts", "laser", "cataract", "glaucoma"]
  },
  "procedure_mappings": {
    "D0120": {"name": "Periodic oral evaluation", "specialty": "dental"},
    "D0150": {"name": "Comprehensive oral evaluation", "specialty": "dental"},
    "D1110": {"name": "Prophylaxis - adult", "specialty": "dental"},
    "D2140": {"name": "Amalgam - one surface", "specialty": "dental"},
    "D2750": {"name": "Crown - porcelain fused to metal", "specialty": "dental"},
    "D3310": {"name": "Endodontic therapy, anterior tooth", "specialty": "dental"},
    "11200": {"name": "Removal of skin tags", "specialty": "dermatology"},
    "17000": {"name": "Destruction of benign lesions", "specialty": "dermatology"},
    "29881": {"name": "Arthroscopy, knee, surgical", "specialty": "orthopedic"},
    "27447": {"name": "Total knee arthroplasty", "specialty": "orthopedic"}
  }
}


================================================
FILE: app/kb/contract_ontology.md
================================================
# Contract Ontology - Key Terms Extraction Guide

## Overview

This document defines the standard ontology for extracting key terms from merchant agreements, partnership contracts, and vendor agreements. It serves as a reference for automated contract analysis and obligation mapping.

## Core Extraction Categories

### 1. Fees Structure

**Definition**: All monetary obligations, charges, and payment terms

**Key Fields to Extract:**
- `setup_fees`: One-time implementation or onboarding costs
- `monthly_fees`: Recurring monthly charges
- `transaction_fees`: Per-transaction charges (fixed or percentage)
- `volume_discounts`: Tiered pricing based on transaction volume
- `penalty_fees`: Charges for non-compliance or violations
- `termination_fees`: Costs associated with contract termination
- `payment_terms`: When payments are due (net 30, etc.)
- `fee_escalation`: Annual increases or adjustment mechanisms

**Example Patterns:**
- "Setup fee of $5,000 due within 30 days"
- "Monthly service fee: $2,500"
- "Transaction fee: 2.5% + $0.30 per transaction"
- "Volume discount: >$1M monthly = 2.0% rate"

### 2. Service Level Agreements (SLAs)

**Definition**: Performance commitments and operational requirements

**Key Fields to Extract:**
- `uptime_guarantee`: System availability commitments (99.9%)
- `response_times`: Support response requirements
- `resolution_times`: Issue resolution commitments
- `processing_times`: Transaction or request processing speeds
- `reporting_frequency`: How often reports are provided
- `maintenance_windows`: Scheduled downtime allowances
- `escalation_procedures`: How issues are escalated
- `performance_penalties`: Consequences for SLA breaches

**Example Patterns:**
- "99.5% uptime guarantee"
- "Support response within 4 business hours"
- "Critical issues resolved within 24 hours"
- "Transaction processing within 2 seconds"

### 3. Brand Usage Rights

**Definition**: Intellectual property usage, marketing rights, and brand guidelines

**Key Fields to Extract:**
- `logo_usage_rights`: Permission to use company logos
- `trademark_usage`: Rights to use trademarks and service marks
- `co_branding_requirements`: Joint branding obligations
- `marketing_approval`: Requirement for marketing material approval
- `brand_guidelines`: Standards for brand representation
- `exclusivity_rights`: Exclusive usage or territory rights
- `attribution_requirements`: How to credit the brand
- `usage_restrictions`: Limitations on brand usage

**Example Patterns:**
- "Merchant may use Company logo in approved marketing materials"
- "All marketing materials require prior written approval"
- "Exclusive rights within the healthcare vertical"
- "Logo usage must comply with brand guidelines v2.1"

### 4. Data Sharing & Privacy

**Definition**: Data handling, sharing, and privacy obligations

**Key Fields to Extract:**
- `data_types_shared`: Categories of data being exchanged
- `data_retention_period`: How long data is kept
- `data_security_requirements`: Security standards and controls
- `third_party_sharing`: Rights to share data with third parties
- `customer_consent_requirements`: Consent obligations
- `data_deletion_rights`: Right to delete or return data
- `compliance_standards`: GDPR, CCPA, PCI-DSS requirements
- `breach_notification`: Data breach notification procedures

**Example Patterns:**
- "Customer transaction data retained for 7 years"
- "PCI-DSS Level 1 compliance required"
- "Data may be shared with approved payment processors"
- "Breach notification within 72 hours"

### 5. Security Requirements

**Definition**: Cybersecurity, physical security, and operational security obligations

**Key Fields to Extract:**
- `security_certifications`: Required certifications (SOC 2, ISO 27001)
- `encryption_requirements`: Data encryption standards
- `access_controls`: User access and authentication requirements
- `vulnerability_management`: Security testing and patching
- `incident_response`: Security incident procedures
- `audit_requirements`: Security audit obligations
- `employee_screening`: Background check requirements
- `physical_security`: Facility security requirements

**Example Patterns:**
- "SOC 2 Type II certification required annually"
- "AES-256 encryption for data at rest"
- "Multi-factor authentication for all admin access"
- "Quarterly vulnerability assessments required"

### 6. Termination Clauses

**Definition**: Contract termination conditions, procedures, and consequences

**Key Fields to Extract:**
- `termination_notice_period`: Required notice before termination
- `termination_for_cause`: Conditions allowing immediate termination
- `termination_without_cause`: General termination rights
- `data_return_obligations`: Requirements to return or delete data
- `transition_assistance`: Support during transition period
- `post_termination_restrictions`: Ongoing obligations after termination
- `survival_clauses`: Terms that survive contract termination
- `termination_fees`: Costs associated with early termination

**Example Patterns:**
- "90 days written notice required for termination"
- "Immediate termination for material breach"
- "All customer data returned within 30 days"
- "Early termination fee: 6 months of monthly fees"

### 7. Penalties & Compliance

**Definition**: Consequences for non-compliance and violation remedies

**Key Fields to Extract:**
- `late_payment_penalties`: Charges for overdue payments
- `performance_penalties`: Consequences for SLA breaches
- `compliance_violations`: Penalties for regulatory non-compliance
- `data_breach_penalties`: Consequences for security incidents
- `liquidated_damages`: Pre-agreed damage amounts
- `penalty_caps`: Maximum penalty amounts
- `cure_periods`: Time allowed to remedy violations
- `escalating_penalties`: Increasing penalties for repeated violations

**Example Patterns:**
- "Late payment penalty: 1.5% per month"
- "SLA breach penalty: $1,000 per hour of downtime"
- "Data breach penalty: up to $100,000"
- "30-day cure period for material breaches"

### 8. Audit Rights

**Definition**: Rights to inspect, audit, and verify compliance

**Key Fields to Extract:**
- `audit_frequency`: How often audits may be conducted
- `audit_scope`: What can be audited
- `audit_notice_period`: Advance notice required for audits
- `audit_costs`: Who pays for audit expenses
- `audit_access_rights`: What records and systems can be accessed
- `third_party_audits`: Rights to use external auditors
- `audit_remediation`: Requirements to address audit findings
- `audit_reporting`: Audit report sharing requirements

**Example Patterns:**
- "Annual compliance audits permitted with 30 days notice"
- "Audit costs borne by requesting party unless violations found"
- "Access to all relevant records and systems"
- "Third-party auditors subject to confidentiality agreements"

### 9. Marketing Obligations

**Definition**: Marketing, promotion, and business development commitments

**Key Fields to Extract:**
- `marketing_spend_commitments`: Required marketing investments
- `promotional_requirements`: Mandatory promotional activities
- `event_participation`: Trade show or conference obligations
- `content_creation`: Requirements to create marketing content
- `lead_generation`: Lead generation and sharing obligations
- `co_marketing_activities`: Joint marketing initiatives
- `marketing_performance_metrics`: Success measurement criteria
- `marketing_approval_process`: Review and approval procedures

**Example Patterns:**
- "Minimum $50,000 annual marketing spend required"
- "Participation in 2 major industry conferences annually"
- "Monthly case study or success story required"
- "Joint webinar quarterly"

## Extraction Guidelines

### Document Structure Recognition

**Section Identification Patterns:**
- Headers: "FEES", "SERVICE LEVELS", "TERMINATION", "DATA PRIVACY"
- Numbered sections: "3. Payment Terms", "7. Intellectual Property"
- Article references: "Article IV - Confidentiality"
- Appendix references: "Schedule A - Fee Structure"

### Risk Flag Triggers

**High Risk Indicators:**
- Uncapped penalties or unlimited liability
- SLA requirements >99.9% uptime
- Termination notice <30 days
- Exclusive rights or exclusivity clauses
- Personal guarantees or joint liability

**Medium Risk Indicators:**
- SLA requirements 95-99% uptime
- Termination notice 30-90 days
- Significant setup or termination fees
- Complex fee structures with multiple tiers
- Broad audit rights or frequent audits

**Low Risk Indicators:**
- Standard industry terms
- Reasonable notice periods (90+ days)
- Capped penalties and liability
- Clear termination procedures
- Standard data protection requirements

### Owner Assignment Heuristics

**Legal Team:**
- Contract amendments and modifications
- Intellectual property and trademark issues
- Liability and indemnification matters
- Regulatory compliance requirements

**Risk Team:**
- Data privacy and security requirements
- Audit rights and compliance monitoring
- Risk assessment and mitigation
- Insurance and liability coverage

**Finance Team:**
- Fee structures and payment terms
- Revenue recognition implications
- Cost analysis and budgeting
- Financial reporting requirements

**Operations Team:**
- SLA monitoring and performance
- System integration and technical requirements
- Day-to-day contract administration
- Vendor relationship management

**Marketing Team:**
- Brand usage and co-marketing
- Marketing obligations and commitments
- Promotional requirements
- Content creation and approval

## Common Contract Patterns

### Payment Terms Variations
- "Net 30" = Payment due 30 days after invoice
- "2/10 Net 30" = 2% discount if paid within 10 days, otherwise net 30
- "Monthly in advance" = Payment due at start of service period
- "Quarterly in arrears" = Payment due at end of quarter

### SLA Measurement Methods
- "Calendar time" = 24/7 including weekends and holidays
- "Business hours" = Typically 8 AM - 6 PM, Monday-Friday
- "Scheduled maintenance excluded" = Planned downtime doesn't count
- "Force majeure excluded" = Natural disasters and external factors excluded

### Termination Notice Calculations
- "Business days" = Excludes weekends and holidays
- "Calendar days" = Includes all days
- "Written notice" = Formal documentation required
- "Email acceptable" = Electronic delivery permitted

This ontology serves as the foundation for automated contract analysis, ensuring consistent extraction of key terms and proper risk assessment across all merchant agreements and partnership contracts.



================================================
FILE: app/kb/data_privacy_policy.md
================================================
# Data Privacy Policy

## Overview

This document outlines our comprehensive data privacy policy and practices for handling user information.

## Data Collection

We collect the following types of data:

### Personal Information
- Name and contact details
- Email addresses
- Phone numbers
- Billing addresses

### Usage Data
- Website interaction patterns
- Feature usage statistics
- Performance metrics
- Error logs

## Data Usage

We use collected data for:

1. **Service Provision**: To deliver our core services and features
2. **Communication**: To send important updates and notifications
3. **Improvement**: To enhance user experience and system performance
4. **Compliance**: To meet legal and regulatory requirements

## User Rights

Users have the following rights regarding their data:

- **Access**: Request copies of personal data
- **Rectification**: Correct inaccurate information
- **Erasure**: Request deletion of personal data
- **Portability**: Receive data in a structured format
- **Objection**: Object to certain data processing activities

## Data Security

We implement robust security measures including:

- Encryption of data in transit and at rest
- Regular security audits and assessments
- Access controls and authentication
- Employee training on data protection

## Data Retention

- Personal data is retained for the minimum period necessary
- Account data is deleted within 30 days of account closure
- Usage logs are retained for 12 months for security purposes
- Backup data is automatically purged after 2 years

## Third-Party Sharing

We do not sell personal data to third parties. Limited sharing occurs only for:

- Payment processing (with PCI-compliant processors)
- Legal compliance (when required by law)
- Service providers (under strict data processing agreements)

## Contact Information

For privacy-related inquiries, contact our Data Protection Officer at:
- Email: privacy@company.com
- Phone: +1-555-0123
- Address: 123 Privacy Lane, Data City, DC 12345

Last updated: January 2025



================================================
FILE: app/kb/disputes_policy.md
================================================
# Card Dispute and Chargeback Policy

## Overview

This document outlines the policies and procedures for handling credit card disputes, chargebacks, and billing error resolution for Synchrony and CareCredit accounts.

## Types of Disputes

### 1. Billing Errors
**Definition**: Incorrect charges, duplicate transactions, or mathematical errors on statements.

**Common Examples:**
- Duplicate charges for the same transaction
- Charges for incorrect amounts
- Charges for items not purchased
- Mathematical or computational errors
- Failure to credit payments or returns

**Resolution Process:**
1. Contact merchant first for direct resolution
2. If unresolved, file formal dispute within 60 days
3. Provide transaction details and supporting documentation
4. Temporary credit may be issued during investigation

**Required Documentation:**
- Original receipt or transaction record
- Proof of attempted merchant contact
- Bank or credit card statement showing the charge
- Any correspondence with the merchant

### 2. Goods Not Received
**Definition**: Items or services paid for but never delivered or provided.

**Qualifying Conditions:**
- Payment was made but goods/services not received
- Delivery was significantly delayed beyond agreed timeframe
- Services were not performed as contracted

**Resolution Steps:**
1. **Merchant Contact**: Contact merchant within 30 days of expected delivery
2. **Documentation**: Gather proof of purchase and delivery expectations
3. **Dispute Filing**: File dispute if merchant doesn't resolve within 15 business days
4. **Investigation**: Card issuer investigates and may issue provisional credit

**Required Evidence:**
- Purchase receipt or confirmation
- Shipping/tracking information (if applicable)
- Communication records with merchant
- Proof of non-delivery (e.g., delivery confirmation showing different address)

### 3. Fraudulent Transactions
**Definition**: Unauthorized charges made without cardholder's knowledge or consent.

**Immediate Actions:**
1. **Report Immediately**: Contact card issuer within 2 business days
2. **Freeze Account**: Request immediate account freeze if necessary
3. **File Police Report**: For fraud amounts over $500
4. **Monitor Statements**: Review all recent transactions

**Zero Liability Protection:**
- Cardholders are not liable for unauthorized transactions
- Maximum liability is $50 for reported fraud
- No liability if reported within 2 business days

**Investigation Process:**
- Immediate provisional credit for disputed amount
- 10 business day investigation period
- Permanent credit if fraud is confirmed
- New card issued if account is compromised

## Dispute Filing Requirements

### Timeline Requirements
- **Billing Errors**: Must be reported within 60 days of statement date
- **Goods Not Received**: File within 120 days of expected delivery
- **Fraudulent Charges**: Report immediately, no later than 60 days

### Required Information
**For All Disputes:**
- Account number and cardholder name
- Transaction date and amount
- Merchant name and location
- Description of the dispute
- Steps taken to resolve with merchant

**Additional for Billing Errors:**
- Copy of receipt showing correct amount
- Bank statement showing incorrect charge
- Calculation showing the error

**Additional for Goods Not Received:**
- Purchase confirmation or receipt
- Expected delivery date
- Tracking information (if available)
- Proof of merchant contact attempts

**Additional for Fraud:**
- Affidavit of unauthorized use
- Police report number (if filed)
- List of all unauthorized transactions

## Merchant Resolution Process

### First Contact Requirements
Before filing a formal dispute, cardholders should:

1. **Contact Merchant Directly**
   - Call customer service number on receipt
   - Email customer support if available
   - Visit physical location if applicable

2. **Document the Contact**
   - Date and time of contact
   - Name of representative spoken to
   - Summary of conversation
   - Any reference numbers provided

3. **Allow Resolution Time**
   - Give merchant 5-10 business days to respond
   - For billing errors: 2-3 business days
   - For non-delivery: 10-15 business days

4. **Escalate if Necessary**
   - Request supervisor or manager
   - Ask for written confirmation of resolution
   - Get timeline for refund or correction

### Merchant Cooperation
**Merchants are expected to:**
- Respond to customer inquiries within 2 business days
- Provide clear explanation of charges
- Process legitimate refunds within 5-7 business days
- Maintain transaction records for dispute resolution

## Formal Dispute Process

### Step 1: Initial Filing
- Complete dispute form with all required information
- Submit supporting documentation
- Receive confirmation and reference number
- Account receives provisional credit (if applicable)

### Step 2: Investigation
- Card issuer reviews all documentation
- May contact merchant for response
- Additional information may be requested
- Investigation typically takes 30-45 days

### Step 3: Resolution
- **Dispute Upheld**: Permanent credit issued, case closed
- **Dispute Denied**: Provisional credit reversed, detailed explanation provided
- **Partial Resolution**: Partial credit based on investigation findings

### Step 4: Appeal Process
If dispute is denied:
- Request detailed explanation
- Provide additional evidence if available
- File appeal within 30 days
- Consider arbitration for amounts over $500

## Documentation Best Practices

### Receipt Management
- Keep all receipts for at least 2 years
- Store digital copies in secure location
- Include receipts for returns and exchanges
- Photograph receipts immediately after purchase

### Communication Records
- Save all emails with merchants
- Document phone calls with date, time, and summary
- Keep screenshots of online transactions
- Maintain shipping and tracking information

### Financial Records
- Review statements monthly
- Report discrepancies immediately
- Keep statements for at least 3 years
- Monitor credit reports for unauthorized accounts

## Special Considerations

### Promotional Financing Disputes
For 0% APR promotional financing:
- Disputes may affect promotional terms
- Interest may accrue during investigation
- Resolution may require promotional rate restoration
- Document promotional offer terms carefully

### Healthcare and Veterinary Services
For CareCredit disputes:
- Medical necessity may be factor in resolution
- Insurance coordination may complicate disputes
- Provider licensing and credentials relevant
- Treatment outcomes may affect dispute validity

### Recurring Charges
For subscription or recurring services:
- Cancellation must be properly documented
- Terms of service cancellation policy applies
- Advance notice requirements must be met
- Partial month charges may be valid

## Contact Information

### Customer Service
- **Synchrony Customer Service**: 1-866-396-8254
- **CareCredit Customer Service**: 1-800-677-0718
- **Dispute Department**: 1-800-DISPUTE (1-800-347-7883)

### Online Resources
- **Account Management**: mysynchrony.com
- **CareCredit Portal**: carecredit.com
- **Dispute Forms**: Available in online account portal
- **Document Upload**: Secure portal for evidence submission

### Regulatory Contacts
- **Consumer Financial Protection Bureau**: consumerfinance.gov
- **Federal Trade Commission**: ftc.gov/complaint
- **State Attorney General**: Contact local office
- **Better Business Bureau**: bbb.org

---

*This policy is subject to change. Cardholders should review current terms and conditions for the most up-to-date dispute procedures. Last updated: January 2025*



================================================
FILE: app/kb/promotional_terms.md
================================================
# Promotional Financing Terms and Conditions

## Synchrony Promotional Financing

### 0% APR Equal Monthly Payments

**Eligibility Requirements:**
- Subject to credit approval
- Minimum purchase amounts vary by merchant and promotion
- Valid government-issued photo ID required
- Must be 18 years or older

**How It Works:**
- 0% APR for the promotional period when you make equal monthly payments
- No interest charges if promotional balance is paid in full by the end of the promotional period
- If promotional balance is not paid in full, interest will be charged from the purchase date

**Payment Terms:**
- Equal monthly payments required during promotional period
- Payments must be made on time to maintain promotional rate
- Late payments may result in loss of promotional rate
- Minimum payment due if less than promotional payment amount

**Important Disclosures:**
- Standard APR applies after promotional period ends
- Interest will be charged from purchase date if promotional balance not paid in full
- Account must remain in good standing to maintain promotional terms
- Subject to credit limit and account terms

### Standard APR Financing

**Interest Rates:**
- APR varies based on creditworthiness
- Rates typically range from 17.90% to 29.99%
- Rate determined at time of credit approval

**Payment Options:**
- Minimum monthly payments based on balance
- Pay more than minimum to reduce interest charges
- No prepayment penalties

## CareCredit Healthcare Financing

### No Interest Promotional Plans

**Available Terms:**
- 6 months no interest on purchases of $200+
- 12 months no interest on purchases of $300+
- 18 months no interest on purchases of $500+
- 24 months no interest on purchases of $1,000+

**Eligible Services:**
- Dental procedures and treatments
- Vision care and LASIK surgery
- Veterinary care for pets
- Cosmetic and dermatology procedures
- Hearing aids and audiology services

**How No Interest Works:**
- No interest if paid in full within promotional period
- Interest will be charged from purchase date if promotional balance not paid in full
- Minimum monthly payments required during promotional period

### Extended Payment Plans

**Long-term Financing:**
- 24, 36, 48, or 60 month payment plans available
- Fixed APR typically 17.90% for qualified applicants
- Predictable monthly payments
- Available for purchases of $1,000 or more

**Benefits:**
- Lower monthly payments compared to no interest plans
- Interest charges spread over longer term
- Helps manage larger healthcare expenses

## Application Process

### Online Application
1. **Quick Pre-qualification:** Soft credit check, no impact to credit score
2. **Instant Decision:** Most applications approved within seconds
3. **Use Immediately:** Start using your account right away

### In-Store Application
1. **Apply at Point of Sale:** Complete application with merchant
2. **Instant Approval:** Get decision immediately
3. **Complete Purchase:** Use financing for same-day purchase

### Required Information
- Full legal name and date of birth
- Social Security number
- Current address and phone number
- Employment information and income
- Valid government-issued photo ID

## Account Management

### Online Account Access
- View statements and payment history
- Make payments online or by phone
- Set up automatic payments
- Update account information
- Access promotional offers

### Payment Options
- Online payments from bank account
- Phone payments available 24/7
- Mail payments to processing center
- Automatic payment setup available

### Customer Service
- 24/7 customer service available
- Dedicated healthcare financing specialists
- Account management support
- Dispute resolution assistance

## Important Notices

### Credit Impact
- Credit applications may impact credit score
- Payment history reported to credit bureaus
- Responsible use can help build credit history

### Fees and Penalties
- Late payment fees may apply
- Returned payment fees for insufficient funds
- No annual fees on most accounts
- No prepayment penalties

### Promotional Rate Protection
- Make all payments on time to maintain promotional rate
- Pay at least the minimum promotional payment amount
- Account must remain in good standing
- Contact customer service if experiencing payment difficulties

## Merchant-Specific Terms

### Electronics and Technology
- Apple Store: 0% APR for 18 months on purchases $500+
- Dell: 0% APR for 24 months on purchases $750+
- HP: Standard APR financing available

### Furniture and Home
- OfficeMax: 0% APR for 12 months on purchases $299+
- IKEA: Standard APR financing available

### Healthcare Providers
- Dental practices: CareCredit 6-12 month no interest plans
- Veterinary clinics: CareCredit 18 month no interest plans
- Vision centers: CareCredit promotional financing available

---

*Terms and conditions subject to change. All financing subject to credit approval. See merchant or visit website for current terms and complete details.*

**Last Updated:** January 2025



================================================
FILE: app/kb/security_guidelines.md
================================================
# Security Guidelines and Threat Response

## Overview

This document provides comprehensive security guidelines for identifying and responding to various threats, scams, and security incidents.

## PII Protection Guidelines

### Credit Card Information
- **Never share** complete credit card numbers in unsecured communications
- **Immediately report** any suspected credit card data exposure
- **Use secure channels** for payment processing only
- **Verify legitimacy** of any payment requests

### Social Security Numbers (SSN)
- **Critical sensitivity**: SSNs should never be shared via chat, email, or phone
- **Identity theft risk**: Exposure can lead to serious financial fraud
- **Immediate action**: Report any SSN exposure to security team immediately
- **Verification required**: Always verify identity before discussing SSN-related matters

### Personal Identifiable Information (PII)
- **Minimize collection**: Only collect PII that is absolutely necessary
- **Secure storage**: All PII must be encrypted and access-controlled
- **Limited sharing**: PII should only be shared on a need-to-know basis
- **Regular audits**: Conduct regular reviews of PII handling practices

## Scam Detection and Prevention

### Refund Scams
**Common patterns:**
- Claims of overpayment requiring gift card refunds
- Requests to purchase gift cards for verification
- Urgent demands for immediate payment via unconventional methods

**Response protocol:**
1. **Stop all communication** immediately
2. **Do not provide** any payment information
3. **Verify independently** through official channels
4. **Report the incident** to security team

### Gift Card Fraud
**Warning signs:**
- Requests for gift card codes as payment
- Claims that gift cards are required for refunds
- High-pressure tactics demanding immediate gift card purchases

**Prevention measures:**
- **Educate users** that legitimate businesses don't request gift card payments
- **Verify all requests** through independent communication channels
- **Report suspicious activity** immediately

### Wire Transfer Fraud
**Red flags:**
- Urgent requests for wire transfers
- Instructions to send money to unfamiliar recipients
- Claims of emergency situations requiring immediate wire transfers

**Safety measures:**
- **Verify recipient identity** through multiple channels
- **Confirm legitimacy** of transfer requests independently
- **Use secure, traceable** transfer methods when legitimate

## Phishing and Social Engineering

### Common Phishing Tactics
- **Urgent action required** messages
- **Account suspension** threats
- **Immediate verification** demands
- **Suspicious links** and attachments

### Protection strategies:**
- **Verify sender identity** through independent channels
- **Check URLs carefully** before clicking
- **Never provide credentials** via email or chat
- **Report suspicious messages** to security team

## Account Security

### Account Takeover Prevention
**Warning signs:**
- Unexpected password reset requests
- Unfamiliar login notifications
- Changes to account information without user action
- Suspicious account activity

**Response actions:**
1. **Change passwords** immediately
2. **Enable two-factor authentication**
3. **Review account activity** for unauthorized changes
4. **Contact security team** for investigation

### Multi-Factor Authentication (MFA)
- **Enable MFA** on all critical accounts
- **Use authenticator apps** rather than SMS when possible
- **Keep backup codes** in a secure location
- **Regularly review** MFA settings

## Incident Response Procedures

### Immediate Response (0-15 minutes)
1. **Contain the threat** - Stop ongoing malicious activity
2. **Assess the scope** - Determine what information may be compromised
3. **Notify security team** - Alert appropriate personnel immediately
4. **Document the incident** - Record all relevant details

### Short-term Response (15 minutes - 4 hours)
1. **Investigate thoroughly** - Gather all available evidence
2. **Implement safeguards** - Prevent further damage
3. **Notify affected parties** - Inform users if their data is involved
4. **Coordinate response** - Work with relevant teams and authorities

### Long-term Response (4+ hours)
1. **Complete investigation** - Determine root cause and full impact
2. **Implement improvements** - Update security measures to prevent recurrence
3. **Monitor for recurrence** - Watch for similar threats
4. **Update procedures** - Revise security protocols based on lessons learned

## Contact Information

### Security Team
- **Emergency hotline**: 1-800-SECURITY (24/7)
- **Email**: security@company.com
- **Incident reporting**: incidents@company.com

### Law Enforcement
- **FBI Internet Crime Complaint Center**: ic3.gov
- **Local police**: 911 (for immediate threats)
- **FTC Fraud Reporting**: reportfraud.ftc.gov

## Training and Awareness

### Regular Training Topics
- **Phishing recognition** - Monthly awareness sessions
- **Social engineering tactics** - Quarterly workshops
- **Incident response** - Annual drills and simulations
- **New threat briefings** - As needed based on emerging threats

### Resources
- **Security awareness portal**: security.company.com
- **Threat intelligence updates**: Weekly security bulletins
- **Best practices guide**: Available on company intranet
- **Reporting tools**: Integrated into all communication platforms

## Compliance and Regulatory Requirements

### Data Protection Regulations
- **GDPR compliance** for European users
- **CCPA compliance** for California residents
- **PCI DSS standards** for payment processing
- **SOX requirements** for financial reporting

### Audit and Monitoring
- **Continuous monitoring** of security events
- **Regular compliance audits** by third-party assessors
- **Penetration testing** conducted quarterly
- **Vulnerability assessments** performed monthly

---

*This document is updated regularly to reflect the latest security threats and best practices. Last updated: January 2025*



================================================
FILE: app/llm/__init__.py
================================================
# LLM Package



================================================
FILE: app/llm/gemini.py
================================================
"""
Gemini chat model integration for LLM functionality
"""

import os
import logging
from typing import List, Dict, Any, Optional

from google import genai

logger = logging.getLogger(__name__)

def chat(messages: List[Dict[str, str]], system: Optional[str] = None) -> str:
    """
    Generate chat response using Gemini chat model
    
    Args:
        messages: List of message dictionaries with 'role' and 'content' keys
                 Roles should be 'user' or 'assistant'
        system: Optional system prompt to prepend to the conversation
        
    Returns:
        Generated response string
        
    Raises:
        ValueError: If API key is not configured
        Exception: For API errors or other failures
    """
    # Get configuration
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GOOGLE_API_KEY environment variable is required")
    
    model_name = os.getenv("GEMINI_CHAT_MODEL", "gemini-2.5-flash")
    
    # Initialize the modern Gemini client
    client = genai.Client(api_key=api_key)
    
    try:
        # Build the prompt
        prompt_parts = []
        
        # Add system prompt if provided
        if system:
            prompt_parts.append(f"System: {system}\n")
        
        # Add conversation messages
        for message in messages:
            role = message.get("role", "user")
            content = message.get("content", "")
            
            if role == "user":
                prompt_parts.append(f"User: {content}")
            elif role == "assistant":
                prompt_parts.append(f"Assistant: {content}")
            else:
                # Handle unknown roles as user messages
                prompt_parts.append(f"User: {content}")
        
        # Add final assistant prompt
        prompt_parts.append("Assistant:")
        
        # Combine into single prompt
        full_prompt = "\n\n".join(prompt_parts)
        
        logger.debug(f"Sending prompt to Gemini model {model_name}")
        
        # Generate response using modern API
        response = client.models.generate_content(
            model=model_name,
            contents=full_prompt
        )
        
        if not response.text:
            logger.warning("Empty response from Gemini API")
            return "I apologize, but I couldn't generate a response. Please try again."
        
        logger.debug(f"Received response from Gemini: {len(response.text)} characters")
        return response.text.strip()
        
    except Exception as e:
        logger.error(f"Error generating chat response with Gemini: {e}")
        return f"I apologize, but I encountered an error while processing your request: {str(e)}"

def chat_with_context(
    query: str,
    context_documents: List[Dict[str, Any]],
    system_prompt: Optional[str] = None
) -> str:
    """
    Generate chat response with retrieved document context
    
    Args:
        query: User's query
        context_documents: List of retrieved documents with 'snippet' and 'source' keys
        system_prompt: Optional system prompt
        
    Returns:
        Generated response string
    """
    # Default system prompt for RAG
    default_system = (
        "You are a helpful assistant that answers questions based on provided documents. "
        "Use only the information from the documents to answer questions. "
        "If the information is not available in the documents, say so clearly. "
        "Provide specific references to the source documents when possible."
    )
    
    system = system_prompt or default_system
    
    # Build context from documents
    context_parts = []
    for i, doc in enumerate(context_documents, 1):
        snippet = doc.get("snippet", "")
        source = doc.get("source", "unknown")
        filename = doc.get("filename", "unknown")
        doc_type = doc.get("type", "unknown")
        
        context_parts.append(
            f"Document {i}:\n"
            f"Source: {filename} ({doc_type})\n"
            f"Content: {snippet}\n"
        )
    
    context_text = "\n".join(context_parts)
    
    # Create user message with context
    user_message = f"""
Based on the following documents, please answer this question: {query}

Documents:
{context_text}

Question: {query}

Please provide a comprehensive answer based on the information in the documents above.
"""
    
    messages = [{"role": "user", "content": user_message}]
    
    return chat(messages, system=system)

def summarize_text(text: str, max_length: int = 500) -> str:
    """
    Summarize text using Gemini
    
    Args:
        text: Text to summarize
        max_length: Maximum length of summary in words
        
    Returns:
        Summarized text
    """
    system_prompt = (
        f"You are a helpful assistant that creates concise summaries. "
        f"Summarize the following text in no more than {max_length} words. "
        f"Focus on the key points and maintain accuracy."
    )
    
    messages = [{"role": "user", "content": f"Please summarize this text:\n\n{text}"}]
    
    return chat(messages, system=system_prompt)

def extract_key_points(text: str, num_points: int = 5) -> List[str]:
    """
    Extract key points from text using Gemini
    
    Args:
        text: Text to analyze
        num_points: Number of key points to extract
        
    Returns:
        List of key points as strings
    """
    system_prompt = (
        "You are a helpful assistant that extracts key points from text. "
        f"Extract the {num_points} most important points from the following text. "
        "Return each point as a separate line starting with a bullet point (‚Ä¢)."
    )
    
    messages = [{"role": "user", "content": f"Extract key points from this text:\n\n{text}"}]
    
    response = chat(messages, system=system_prompt)
    
    # Parse bullet points
    lines = response.split('\n')
    key_points = []
    
    for line in lines:
        line = line.strip()
        if line.startswith('‚Ä¢') or line.startswith('-') or line.startswith('*'):
            # Remove bullet point and clean up
            point = line[1:].strip()
            if point:
                key_points.append(point)
    
    return key_points[:num_points]  # Ensure we don't exceed requested number

def classify_query(query: str, categories: List[str]) -> str:
    """
    Classify a query into one of the provided categories
    
    Args:
        query: Query to classify
        categories: List of possible categories
        
    Returns:
        Best matching category
    """
    categories_text = ", ".join(categories)
    
    system_prompt = (
        "You are a helpful assistant that classifies user queries. "
        f"Classify the following query into one of these categories: {categories_text}. "
        "Return only the category name, nothing else."
    )
    
    messages = [{"role": "user", "content": f"Classify this query: {query}"}]
    
    response = chat(messages, system=system_prompt).strip()
    
    # Find best match from categories
    response_lower = response.lower()
    for category in categories:
        if category.lower() in response_lower:
            return category
    
    # Return first category as fallback
    return categories[0] if categories else "general"

def chat_with_context_and_fallback(
    query: str,
    context_documents: List[Dict[str, Any]],
    allow_llm_knowledge: bool = True,
    allow_web_search: bool = False,
    system_prompt: Optional[str] = None
) -> Dict[str, Any]:
    """
    Generate chat response with fallback options when documents are insufficient
    
    Args:
        query: User's query
        context_documents: List of retrieved documents with 'snippet' and 'source' keys
        allow_llm_knowledge: Whether to fallback to LLM's own knowledge if documents insufficient
        allow_web_search: Whether to use web search if documents insufficient
        system_prompt: Optional system prompt
        
    Returns:
        Dictionary with response, fallback_used, and confidence
    """
    # Check document quality/relevance intelligently
    doc_quality = assess_document_quality(query, context_documents)
    
    fallback_used = None
    confidence = doc_quality["confidence"]
    
    if doc_quality["sufficient"]:
        # Use regular RAG response
        response = chat_with_context(query, context_documents, system_prompt)
    else:
        # Documents are insufficient - use fallback
        if allow_llm_knowledge:
            response = chat_with_llm_knowledge(query, context_documents, system_prompt)
            fallback_used = "llm_knowledge"
            confidence = max(0.6, confidence)  # Boost confidence for LLM knowledge fallback
        elif allow_web_search:
            try:
                # Import here to avoid circular dependency
                from app.tools.tavily_search import web_search_into_docstore
                
                # Perform web search (this should be done in the main endpoint, but for now we'll indicate it)
                response = chat_with_web_search_fallback(query, context_documents, system_prompt)
                fallback_used = "web_search"
                confidence = 0.7  # Higher confidence for web search results
            except ImportError:
                response = f"Based on the documents provided, there is insufficient information to answer '{query}'. Web search functionality is not available."
                fallback_used = "web_search_unavailable"
                confidence = 0.3
        else:
            response = f"Based on the documents provided, there is insufficient information to answer '{query}'. Consider enabling fallback options (LLM knowledge or web search) to access additional information sources."
            fallback_used = "none"
            confidence = 0.2
    
    return {
        "response": response,
        "fallback_used": fallback_used,
        "confidence": confidence,
        "document_assessment": doc_quality
    }

def assess_document_quality(query: str, context_documents: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Intelligently assess whether retrieved documents are sufficient to answer the query
    
    Args:
        query: User's query
        context_documents: Retrieved documents
        
    Returns:
        Dictionary with assessment results
    """
    if not context_documents:
        return {
            "sufficient": False,
            "confidence": 0.0,
            "reason": "No documents found",
            "document_quality_score": 0.0,
            "semantic_relevance": 0.0,
            "coverage_score": 0.0
        }
    
    # Use LLM to assess document relevance and coverage
    assessment_prompt = f"""
Analyze whether these documents contain sufficient information to answer the user's question comprehensively.

Question: {query}

Documents:
{_format_docs_for_assessment(context_documents)}

Rate the documents on a scale of 0-10 for:
1. Semantic Relevance: How well do the documents relate to the question?
2. Information Coverage: How completely do they address what the user is asking?
3. Answer Sufficiency: Can the question be fully answered using only these documents?

Respond in this exact JSON format:
{{
    "semantic_relevance": <0-10>,
    "coverage_score": <0-10>, 
    "answer_sufficiency": <0-10>,
    "sufficient": <true/false>,
    "reasoning": "<brief explanation>"
}}
"""
    
    try:
        # Get LLM assessment
        messages = [{"role": "user", "content": assessment_prompt}]
        assessment_response = chat(messages, system="You are an expert at evaluating document relevance. Provide only valid JSON responses.")
        
        logger.debug(f"Raw Gemini assessment response: {assessment_response[:200]}...")
        
        # Parse JSON response with robust handling
        import json
        
        # Handle markdown-wrapped JSON responses
        response_text = assessment_response.strip()
        if response_text.startswith('```json'):
            # Extract JSON from markdown code block
            response_text = response_text.replace('```json', '').replace('```', '').strip()
        elif response_text.startswith('```'):
            # Handle generic code blocks
            lines = response_text.split('\n')
            response_text = '\n'.join(lines[1:-1]).strip()
        
        # Check if response is empty or contains fallback message
        if not response_text or "I apologize, but I couldn't generate a response" in response_text:
            logger.error("Empty or fallback response from Gemini API for document assessment")
            raise ValueError("Empty or fallback response from Gemini API")
        
        logger.debug(f"Cleaned response text: {response_text[:200]}...")
        assessment = json.loads(response_text)
        
        # Validate assessment structure
        required_fields = ['semantic_relevance', 'coverage_score', 'answer_sufficiency', 'sufficient']
        missing_fields = [field for field in required_fields if field not in assessment]
        if missing_fields:
            logger.warning(f"Missing fields in assessment: {missing_fields}")
            # Set default values for missing fields
            for field in missing_fields:
                if field == 'sufficient':
                    assessment[field] = False
                else:
                    assessment[field] = 0
        
        # Calculate overall quality score
        quality_score = (
            assessment.get("semantic_relevance", 0) * 0.4 +
            assessment.get("coverage_score", 0) * 0.4 +
            assessment.get("answer_sufficiency", 0) * 0.2
        ) / 10.0
        
        # Determine sufficiency with intelligent thresholds
        sufficient = assessment.get("sufficient", False) and quality_score >= 0.6
        
        return {
            "sufficient": sufficient,
            "confidence": quality_score,
            "reason": assessment.get("reasoning", "Assessment completed"),
            "document_quality_score": quality_score,
            "semantic_relevance": assessment.get("semantic_relevance", 0) / 10.0,
            "coverage_score": assessment.get("coverage_score", 0) / 10.0,
            "answer_sufficiency": assessment.get("answer_sufficiency", 0) / 10.0
        }
        
    except json.JSONDecodeError as e:
        logger.warning(f"Failed to parse Gemini JSON response for assessment, falling back to heuristics. Response was: '{assessment_response[:100]}...' Error: {e}")
        
        # Fallback to enhanced heuristic assessment
    except Exception as e:
        logger.warning(f"Failed to get intelligent assessment, falling back to heuristics: {e}")
        
        # Fallback to enhanced heuristic assessment
        scores = [doc.get("score", 0.0) for doc in context_documents]
        avg_score = sum(scores) / len(scores) if scores else 0.0
        
        # Enhanced heuristics
        keyword_matches = _count_keyword_matches(query, context_documents)
        length_score = min(1.0, sum(len(doc.get("snippet", "")) for doc in context_documents) / 1000)
        diversity_score = _calculate_document_diversity(context_documents)
        
        quality_score = (avg_score * 0.4) + (keyword_matches * 0.3) + (length_score * 0.2) + (diversity_score * 0.1)
        sufficient = quality_score >= 0.5 and len(context_documents) >= 1
        
        return {
            "sufficient": sufficient,
            "confidence": quality_score,
            "reason": f"Heuristic assessment - relevance: {avg_score:.2f}, keywords: {keyword_matches:.2f}, content: {length_score:.2f}",
            "document_quality_score": quality_score,
            "semantic_relevance": avg_score,
            "coverage_score": keyword_matches,
            "answer_sufficiency": length_score
        }

def chat_with_llm_knowledge(
    query: str,
    context_documents: List[Dict[str, Any]],
    system_prompt: Optional[str] = None
) -> str:
    """
    Generate chat response using LLM's own knowledge with document context as supporting info
    
    Args:
        query: User's query
        context_documents: Retrieved documents (used as supporting context)
        system_prompt: Optional system prompt
        
    Returns:
        Generated response string
    """
    # Enhanced system prompt that allows LLM knowledge
    enhanced_system = (
        "You are a helpful assistant with extensive knowledge. "
        "Answer the user's question using your knowledge and training. "
        "If relevant documents are provided, use them as supporting evidence, but you may "
        "also draw from your general knowledge to provide a comprehensive answer. "
        "Clearly distinguish between information from documents and your general knowledge. "
        "If the documents have limited relevance, focus more on your training knowledge."
    )
    
    system = system_prompt or enhanced_system
    
    # Build supporting context from documents if available
    if context_documents:
        context_parts = []
        for i, doc in enumerate(context_documents[:3], 1):  # Limit to top 3
            snippet = doc.get("snippet", "")[:400]  # Limit length
            filename = doc.get("filename", "unknown")
            score = doc.get("score", 0.0)
            
            context_parts.append(f"Supporting Document {i} ({filename}, relevance: {score:.2f}):\n{snippet}")
        
        context_text = "\n\n".join(context_parts)
        
        user_message = f"""
Question: {query}

Supporting documents (may have limited relevance):
{context_text}

Please answer the question comprehensively using your knowledge. You may reference the supporting documents if relevant, but feel free to provide additional context and information from your training to give a complete answer. If the documents don't fully address the question, supplement with your general knowledge.
"""
    else:
        user_message = f"Question: {query}\n\nPlease provide a comprehensive answer using your knowledge and training."
    
    messages = [{"role": "user", "content": user_message}]
    
    return chat(messages, system=system)

def _format_docs_for_assessment(context_documents: List[Dict[str, Any]]) -> str:
    """Format documents for LLM assessment"""
    formatted = []
    for i, doc in enumerate(context_documents[:5], 1):  # Limit to top 5 docs
        snippet = doc.get("snippet", "")[:300]  # Limit snippet length
        filename = doc.get("filename", "unknown")
        score = doc.get("score", 0.0)
        
        formatted.append(f"Doc {i} ({filename}, score: {score:.2f}):\n{snippet}")
    
    return "\n\n".join(formatted)

def _count_keyword_matches(query: str, context_documents: List[Dict[str, Any]]) -> float:
    """Count keyword matches between query and documents"""
    import re
    
    # Extract keywords from query (simple approach)
    query_words = set(re.findall(r'\b\w+\b', query.lower()))
    query_words = {w for w in query_words if len(w) > 2}  # Filter short words
    
    if len(query_words) == 0:
        return 0.0
    
    total_matches = 0
    for doc in context_documents:
        snippet = doc.get("snippet", "").lower()
        doc_words = set(re.findall(r'\b\w+\b', snippet))
        matches = len(query_words.intersection(doc_words))
        total_matches += matches
    
    # Normalize by query length and document count
    return min(1.0, total_matches / (len(query_words) * len(context_documents)))

def _calculate_document_diversity(context_documents: List[Dict[str, Any]]) -> float:
    """Calculate diversity score based on different document sources"""
    if len(context_documents) <= 1:
        return 0.5
    
    sources = set()
    for doc in context_documents:
        filename = doc.get("filename", "unknown")
        doc_type = doc.get("type", "unknown")
        sources.add(f"{filename}_{doc_type}")
    
    # More diverse sources = higher score
    diversity = len(sources) / len(context_documents)
    return min(1.0, diversity * 2)  # Scale up the impact

def chat_with_web_search_fallback(
    query: str,
    context_documents: List[Dict[str, Any]],
    system_prompt: Optional[str] = None
) -> str:
    """
    Generate chat response indicating web search would be performed
    (Actual web search should be handled in the main endpoint)
    
    Args:
        query: User's query
        context_documents: Retrieved documents (used as supporting context)
        system_prompt: Optional system prompt
        
    Returns:
        Generated response string
    """
    # Enhanced system prompt that acknowledges web search capability
    enhanced_system = (
        "You are a helpful assistant with access to both document knowledge and web search. "
        "The provided documents have limited relevance to the user's question, so you should "
        "indicate that web search would provide more current and comprehensive information. "
        "Acknowledge what limited information is available in the documents, then suggest "
        "that web search would be performed to get more complete answers."
    )
    
    system = system_prompt or enhanced_system
    
    # Build context information
    if context_documents:
        doc_info = f"Available documents ({len(context_documents)} found) have limited relevance to your question."
    else:
        doc_info = "No relevant documents were found in the knowledge base."
    
    user_message = f"""
Question: {query}

{doc_info}

Since the document knowledge is insufficient to fully answer your question, a web search would typically be performed here to find more current and comprehensive information. This would help provide you with up-to-date answers that go beyond the available document knowledge base.
    
Please provide a response acknowledging the limitation and indicating what a web search could help find.
"""
    
    messages = [{"role": "user", "content": user_message}]
    
    return chat(messages, system=system)



================================================
FILE: app/openapi/payments.json
================================================
{
  "openapi": "3.0.0",
  "info": {
    "title": "Synchrony Payments API",
    "version": "1.0.0",
    "description": "Partner API for processing payments and managing transactions"
  },
  "servers": [
    {
      "url": "https://api.synchrony.com/v1",
      "description": "Production server"
    },
    {
      "url": "https://sandbox-api.synchrony.com/v1",
      "description": "Sandbox server"
    }
  ],
  "security": [
    {
      "ApiKeyAuth": []
    }
  ],
  "paths": {
    "/payments": {
      "post": {
        "summary": "Create a payment",
        "description": "Process a new payment transaction",
        "operationId": "createPayment",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/PaymentRequest"
              }
            }
          }
        },
        "responses": {
          "201": {
            "description": "Payment created successfully",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/PaymentResponse"
                }
              }
            }
          },
          "400": {
            "description": "Invalid request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/payments/{paymentId}": {
      "get": {
        "summary": "Get payment details",
        "description": "Retrieve details of a specific payment",
        "operationId": "getPayment",
        "parameters": [
          {
            "name": "paymentId",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Payment details",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/PaymentResponse"
                }
              }
            }
          }
        }
      }
    },
    "/accounts/{accountId}/balance": {
      "get": {
        "summary": "Get account balance",
        "description": "Retrieve current balance for an account",
        "operationId": "getAccountBalance",
        "parameters": [
          {
            "name": "accountId",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Account balance",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/BalanceResponse"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "securitySchemes": {
      "ApiKeyAuth": {
        "type": "apiKey",
        "in": "header",
        "name": "X-API-Key"
      }
    },
    "schemas": {
      "PaymentRequest": {
        "type": "object",
        "required": ["amount", "currency", "accountId"],
        "properties": {
          "amount": {
            "type": "number",
            "minimum": 0.01,
            "description": "Payment amount"
          },
          "currency": {
            "type": "string",
            "enum": ["USD"],
            "description": "Currency code"
          },
          "accountId": {
            "type": "string",
            "description": "Account identifier"
          },
          "description": {
            "type": "string",
            "maxLength": 255,
            "description": "Payment description"
          },
          "metadata": {
            "type": "object",
            "description": "Additional metadata"
          }
        }
      },
      "PaymentResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Payment ID"
          },
          "amount": {
            "type": "number",
            "description": "Payment amount"
          },
          "currency": {
            "type": "string",
            "description": "Currency code"
          },
          "status": {
            "type": "string",
            "enum": ["pending", "completed", "failed"],
            "description": "Payment status"
          },
          "createdAt": {
            "type": "string",
            "format": "date-time",
            "description": "Creation timestamp"
          }
        }
      },
      "BalanceResponse": {
        "type": "object",
        "properties": {
          "accountId": {
            "type": "string",
            "description": "Account identifier"
          },
          "availableBalance": {
            "type": "number",
            "description": "Available balance"
          },
          "currentBalance": {
            "type": "number",
            "description": "Current balance"
          },
          "currency": {
            "type": "string",
            "description": "Currency code"
          }
        }
      },
      "Error": {
        "type": "object",
        "properties": {
          "error": {
            "type": "string",
            "description": "Error message"
          },
          "code": {
            "type": "string",
            "description": "Error code"
          }
        }
      }
    }
  }
}



================================================
FILE: app/rag/__init__.py
================================================
# RAG Pipeline Package



================================================
FILE: app/rag/core.py
================================================
"""
Core RAG functionality with Gemini embeddings and Haystack integration
"""

import os
import logging
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import re

from google import genai
from haystack import Document
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever

logger = logging.getLogger(__name__)

class WebDisabled(Exception):
    """Raised when web search is disabled but requested"""
    pass

def init_docstore() -> InMemoryDocumentStore:
    """Initialize Haystack InMemoryDocumentStore"""
    return InMemoryDocumentStore()

class GeminiEmbedder:
    """Gemini embeddings API wrapper with batching and retry logic"""
    
    def __init__(self, model: str = None, api_key: str = None):
        self.model = model or os.getenv("GEMINI_EMBED_MODEL", "models/text-embedding-004")
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")
        
        if not self.api_key:
            raise ValueError("Google API key is required")
        
        self.client = genai.Client(api_key=self.api_key)
        logger.info(f"Initialized GeminiEmbedder with model: {self.model}")
    
    def embed_texts(self, texts: List[str], batch_size: int = 10, max_retries: int = 3) -> List[List[float]]:
        """
        Embed a list of texts using Gemini embeddings API
        
        Args:
            texts: List of text strings to embed
            batch_size: Number of texts to process in each batch
            max_retries: Maximum number of retry attempts
            
        Returns:
            List of embedding vectors, same length as input texts
        """
        if not texts:
            return []
        
        all_embeddings = []
        
        # Process in batches
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_embeddings = self._embed_batch_with_retry(batch, max_retries)
            all_embeddings.extend(batch_embeddings)
        
        logger.info(f"Generated embeddings for {len(texts)} texts")
        return all_embeddings
    
    def _embed_batch_with_retry(self, batch: List[str], max_retries: int) -> List[List[float]]:
        """Embed a batch of texts with retry logic"""
        for attempt in range(max_retries + 1):
            try:
                # Use modern Gemini embeddings API
                result = self.client.models.embed_content(
                    model=self.model,
                    contents=batch
                )
                
                # Extract embeddings from response
                if hasattr(result, 'embeddings'):
                    embeddings = []
                    for embedding in result.embeddings:
                        if hasattr(embedding, 'values'):
                            embeddings.append(embedding.values)
                        else:
                            embeddings.append(embedding)
                    return embeddings
                else:
                    # Fallback - return zero vectors
                    return [[0.0] * 768 for _ in batch]
                
            except Exception as e:
                if attempt < max_retries:
                    wait_time = 2 ** attempt  # Exponential backoff
                    logger.warning(f"Embedding attempt {attempt + 1} failed: {e}. Retrying in {wait_time}s...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"Failed to generate embeddings after {max_retries + 1} attempts: {e}")
                    # Return zero vectors as fallback
                    return [[0.0] * 768 for _ in batch]  # Default dimension
    
    def embed_query(self, query: str) -> List[float]:
        """Embed a single query text"""
        try:
            result = self.client.models.embed_content(
                model=self.model,
                contents=query
            )
            
            if hasattr(result, 'embeddings') and result.embeddings:
                # Get first embedding for single query
                embedding = result.embeddings[0]
                if hasattr(embedding, 'values'):
                    return embedding.values
                else:
                    return embedding
            else:
                # Fallback
                return [0.0] * 768
                
        except Exception as e:
            logger.error(f"Failed to embed query: {e}")
            return [0.0] * 768  # Default dimension fallback

def _count_tokens(text: str) -> int:
    """Rough token count estimation (1 token ‚âà 4 characters)"""
    return len(text) // 4

def _split_text_into_chunks(text: str, max_tokens: int = 1500, overlap_tokens: int = 150) -> List[Dict[str, Any]]:
    """
    Split text into chunks with token limits and overlap
    
    Args:
        text: Text to split
        max_tokens: Maximum tokens per chunk
        overlap_tokens: Overlap between chunks
        
    Returns:
        List of chunk dictionaries with text and line span info
    """
    lines = text.split('\n')
    chunks = []
    current_chunk = []
    current_tokens = 0
    start_line = 0
    
    for i, line in enumerate(lines):
        line_tokens = _count_tokens(line)
        
        # If adding this line would exceed max tokens, finalize current chunk
        if current_tokens + line_tokens > max_tokens and current_chunk:
            chunk_text = '\n'.join(current_chunk)
            chunks.append({
                'text': chunk_text,
                'start_line': start_line,
                'end_line': i - 1,
                'token_count': current_tokens
            })
            
            # Start new chunk with overlap
            overlap_lines = []
            overlap_tokens = 0
            
            # Add lines from the end of current chunk for overlap
            for j in range(len(current_chunk) - 1, -1, -1):
                line_overlap_tokens = _count_tokens(current_chunk[j])
                if overlap_tokens + line_overlap_tokens <= overlap_tokens:
                    overlap_lines.insert(0, current_chunk[j])
                    overlap_tokens += line_overlap_tokens
                else:
                    break
            
            current_chunk = overlap_lines + [line]
            current_tokens = overlap_tokens + line_tokens
            start_line = max(0, i - len(overlap_lines))
        else:
            current_chunk.append(line)
            current_tokens += line_tokens
            if not current_chunk or len(current_chunk) == 1:
                start_line = i
    
    # Add final chunk if it exists
    if current_chunk:
        chunk_text = '\n'.join(current_chunk)
        chunks.append({
            'text': chunk_text,
            'start_line': start_line,
            'end_line': len(lines) - 1,
            'token_count': current_tokens
        })
    
    return chunks

def index_markdown(docstore: InMemoryDocumentStore, embedder: GeminiEmbedder, base_dir: str = "app") -> int:
    """
    Index markdown files from /kb and /contracts directories
    
    Args:
        docstore: Haystack document store
        embedder: Gemini embedder instance
        base_dir: Base directory path
        
    Returns:
        Number of documents indexed
    """
    base_path = Path(base_dir)
    kb_path = base_path / "kb"
    contracts_path = base_path / "contracts"
    
    documents = []
    
    # Process both directories
    for dir_path in [kb_path, contracts_path]:
        if not dir_path.exists():
            logger.warning(f"Directory not found: {dir_path}")
            continue
            
        for md_file in dir_path.glob("*.md"):
            try:
                content = md_file.read_text(encoding="utf-8")
                file_type = "policy" if dir_path.name == "kb" else "contract"
                
                # Split into chunks
                chunks = _split_text_into_chunks(content)
                
                for i, chunk in enumerate(chunks):
                    doc_id = f"{md_file.stem}_chunk_{i}"
                    
                    doc = Document(
                        content=chunk['text'],
                        meta={
                            "source": str(md_file),
                            "filename": md_file.name,
                            "type": file_type,
                            "chunk_id": i,
                            "start_line": chunk['start_line'],
                            "end_line": chunk['end_line'],
                            "token_count": chunk['token_count']
                        }
                    )
                    documents.append(doc)
                    
            except Exception as e:
                logger.error(f"Error processing {md_file}: {e}")
    
    if not documents:
        logger.warning("No documents found to index")
        return 0
    
    # Generate embeddings for all documents
    logger.info(f"Generating embeddings for {len(documents)} document chunks...")
    texts = [doc.content for doc in documents]
    embeddings = embedder.embed_texts(texts)
    
    # Add embeddings to documents
    for doc, embedding in zip(documents, embeddings):
        doc.embedding = embedding
    
    # Write to document store
    docstore.write_documents(documents)
    
    logger.info(f"Successfully indexed {len(documents)} document chunks")
    return len(documents)

def build_retriever(docstore: InMemoryDocumentStore) -> InMemoryEmbeddingRetriever:
    """Build Haystack InMemoryEmbeddingRetriever"""
    return InMemoryEmbeddingRetriever(document_store=docstore)

def retrieve(retriever: InMemoryEmbeddingRetriever, embedder: GeminiEmbedder, query: str, k: int = 5) -> List[Dict[str, Any]]:
    """
    Retrieve relevant documents for a query
    
    Args:
        retriever: Haystack embedding retriever
        embedder: Gemini embedder for query embedding
        query: Search query
        k: Number of results to return
        
    Returns:
        List of dictionaries with source, snippet, and score
    """
    try:
        # Embed the query
        query_embedding = embedder.embed_query(query)
        
        # Retrieve documents
        result = retriever.run(query_embedding=query_embedding, top_k=k)
        documents = result.get("documents", [])
        
        # Format results
        formatted_results = []
        for doc in documents:
            formatted_results.append({
                "source": doc.meta.get("source", "unknown"),
                "snippet": doc.content,
                "score": getattr(doc, 'score', 0.0),
                "filename": doc.meta.get("filename", "unknown"),
                "type": doc.meta.get("type", "unknown"),
                "chunk_id": doc.meta.get("chunk_id", 0),
                "line_span": f"{doc.meta.get('start_line', 0)}-{doc.meta.get('end_line', 0)}"
            })
        
        logger.info(f"Retrieved {len(formatted_results)} documents for query: {query}")
        return formatted_results
        
    except Exception as e:
        logger.error(f"Error during retrieval: {e}")
        return []



================================================
FILE: app/rag/pipeline.py
================================================
"""
Hybrid RAG Pipeline Implementation using Haystack 2.x and Gemini API
"""

import os
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional

import google.generativeai as genai
from haystack import Pipeline, Document
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.retrievers.in_memory import InMemoryBM25Retriever, InMemoryEmbeddingRetriever
from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder
from haystack.components.writers import DocumentWriter
from haystack.components.preprocessors.document_splitter import DocumentSplitter
from haystack.components.joiners import DocumentJoiner
from haystack.components.rankers import TransformersSimilarityRanker
from haystack.components.builders.chat_prompt_builder import ChatPromptBuilder
from haystack.dataclasses import ChatMessage

from app.tools.gemini_chat import GeminiChatGenerator

logger = logging.getLogger(__name__)

class RAGPipeline:
    """Hybrid RAG Pipeline using Haystack 2.x with BM25 + Embedding retrieval and Gemini chat"""
    
    def __init__(self):
        self.document_store = None
        self.indexing_pipeline = None
        self.retrieval_pipeline = None
        self.rag_pipeline = None
        self.chat_generator = None
        
        # Initialize Gemini API
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY environment variable is required")
        
        genai.configure(api_key=api_key)
        
    async def initialize(self):
        """Initialize the hybrid RAG pipeline components"""
        try:
            logger.info("Initializing document store...")
            self.document_store = InMemoryDocumentStore()
            
            logger.info("Building indexing pipeline...")
            self._build_indexing_pipeline()
            
            logger.info("Loading knowledge base documents...")
            await self._load_knowledge_base()
            
            logger.info("Building hybrid retrieval pipeline...")
            self._build_retrieval_pipeline()
            
            logger.info("Building RAG pipeline...")
            self._build_rag_pipeline()
            
            logger.info("Hybrid RAG pipeline initialization complete")
            
        except Exception as e:
            logger.error(f"Failed to initialize RAG pipeline: {e}")
            raise
    
    def _build_indexing_pipeline(self):
        """Build the document indexing pipeline"""
        # Document splitter for chunking
        document_splitter = DocumentSplitter(
            split_by="word", 
            split_length=512, 
            split_overlap=32
        )
        
        # Document embedder using sentence transformers
        document_embedder = SentenceTransformersDocumentEmbedder(
            model="sentence-transformers/all-MiniLM-L6-v2"  # Lightweight model for PoC
        )
        
        # Document writer
        document_writer = DocumentWriter(self.document_store)
        
        # Build indexing pipeline
        self.indexing_pipeline = Pipeline()
        self.indexing_pipeline.add_component("document_splitter", document_splitter)
        self.indexing_pipeline.add_component("document_embedder", document_embedder)
        self.indexing_pipeline.add_component("document_writer", document_writer)
        
        # Connect components
        self.indexing_pipeline.connect("document_splitter", "document_embedder")
        self.indexing_pipeline.connect("document_embedder", "document_writer")
    
    def _build_retrieval_pipeline(self):
        """Build the hybrid retrieval pipeline"""
        # Text embedder for query embedding
        text_embedder = SentenceTransformersTextEmbedder(
            model="sentence-transformers/all-MiniLM-L6-v2"  # Same model as document embedder
        )
        
        # Retrievers
        embedding_retriever = InMemoryEmbeddingRetriever(self.document_store)
        bm25_retriever = InMemoryBM25Retriever(self.document_store)
        
        # Document joiner to combine results
        document_joiner = DocumentJoiner()
        
        # Ranker to score and rank combined results
        ranker = TransformersSimilarityRanker(
            model="cross-encoder/ms-marco-MiniLM-L-6-v2"  # Lightweight cross-encoder
        )
        
        # Build retrieval pipeline
        self.retrieval_pipeline = Pipeline()
        self.retrieval_pipeline.add_component("text_embedder", text_embedder)
        self.retrieval_pipeline.add_component("embedding_retriever", embedding_retriever)
        self.retrieval_pipeline.add_component("bm25_retriever", bm25_retriever)
        self.retrieval_pipeline.add_component("document_joiner", document_joiner)
        self.retrieval_pipeline.add_component("ranker", ranker)
        
        # Connect components
        self.retrieval_pipeline.connect("text_embedder", "embedding_retriever")
        self.retrieval_pipeline.connect("bm25_retriever", "document_joiner")
        self.retrieval_pipeline.connect("embedding_retriever", "document_joiner")
        self.retrieval_pipeline.connect("document_joiner", "ranker")
    
    def _build_rag_pipeline(self):
        """Build the complete RAG pipeline with chat generation"""
        # Initialize Gemini chat generator
        self.chat_generator = GeminiChatGenerator(
            model=os.getenv("GEMINI_CHAT_MODEL", "gemini-2.5-flash")
        )
        
        # Define the prompt template
        prompt_template = [
            ChatMessage.from_system(
                "You are a helpful assistant that answers questions based on the provided documents. "
                "Use only the information from the documents to answer questions. "
                "If the information is not available in the documents, say so clearly. "
                "Provide specific references to the source documents when possible."
            ),
            ChatMessage.from_user(
                "Given these documents, answer the question.\n\n"
                "Documents:\n{% for doc in documents %}{{ doc.content }}\n"
                "Source: {{ doc.meta.get('filename', 'Unknown') }} ({{ doc.meta.get('type', 'unknown') }})\n"
                "---\n{% endfor %}\n"
                "Question: {{question}}\n\n"
                "Answer:"
            )
        ]
        
        # Create prompt builder
        prompt_builder = ChatPromptBuilder(
            template=prompt_template,
            required_variables={"question", "documents"}
        )
        
        # Build RAG pipeline
        self.rag_pipeline = Pipeline()
        
        # Add retrieval components
        self.rag_pipeline.add_component("text_embedder", SentenceTransformersTextEmbedder(
            model="sentence-transformers/all-MiniLM-L6-v2"
        ))
        self.rag_pipeline.add_component("embedding_retriever", InMemoryEmbeddingRetriever(self.document_store))
        self.rag_pipeline.add_component("bm25_retriever", InMemoryBM25Retriever(self.document_store))
        self.rag_pipeline.add_component("document_joiner", DocumentJoiner())
        self.rag_pipeline.add_component("ranker", TransformersSimilarityRanker(
            model="cross-encoder/ms-marco-MiniLM-L-6-v2"
        ))
        
        # Add generation components
        self.rag_pipeline.add_component("prompt_builder", prompt_builder)
        self.rag_pipeline.add_component("llm", self.chat_generator)
        
        # Connect retrieval components
        self.rag_pipeline.connect("text_embedder", "embedding_retriever")
        self.rag_pipeline.connect("bm25_retriever", "document_joiner")
        self.rag_pipeline.connect("embedding_retriever", "document_joiner")
        self.rag_pipeline.connect("document_joiner", "ranker")
        
        # Connect to generation
        self.rag_pipeline.connect("ranker", "prompt_builder.documents")
        self.rag_pipeline.connect("prompt_builder", "llm.messages")
    
    async def _load_knowledge_base(self):
        """Load documents from the knowledge base directories"""
        documents = []
        
        # Load from kb directory (markdown policies/terms)
        kb_path = Path("app/kb")
        if kb_path.exists():
            for file_path in kb_path.glob("*.md"):
                content = file_path.read_text(encoding="utf-8")
                doc = Document(
                    content=content,
                    meta={
                        "source": str(file_path),
                        "type": "policy",
                        "filename": file_path.name
                    }
                )
                documents.append(doc)
        
        # Load from contracts directory
        contracts_path = Path("app/contracts")
        if contracts_path.exists():
            for file_path in contracts_path.glob("*.md"):
                content = file_path.read_text(encoding="utf-8")
                doc = Document(
                    content=content,
                    meta={
                        "source": str(file_path),
                        "type": "contract",
                        "filename": file_path.name
                    }
                )
                documents.append(doc)
        
        # Load from data directory (JSON/CSV stubs)
        data_path = Path("app/data")
        if data_path.exists():
            for file_path in data_path.glob("*.json"):
                content = file_path.read_text(encoding="utf-8")
                doc = Document(
                    content=f"Data file: {file_path.name}\n\n{content}",
                    meta={
                        "source": str(file_path),
                        "type": "data",
                        "filename": file_path.name
                    }
                )
                documents.append(doc)
        
        if not documents:
            # Add some sample documents for testing
            logger.warning("No documents found in knowledge base, adding sample documents")
            documents = [
                Document(
                    content="This is a sample policy document about data privacy and user rights. "
                    "Users have the right to access, modify, and delete their personal data. "
                    "We collect minimal data necessary for service provision.",
                    meta={"source": "sample", "type": "policy", "filename": "sample_policy.md"}
                ),
                Document(
                    content="This is a sample contract document outlining merchant terms and conditions. "
                    "Merchants must comply with payment processing standards and maintain accurate records. "
                    "Commission rates vary based on transaction volume.",
                    meta={"source": "sample", "type": "contract", "filename": "sample_contract.md"}
                ),
                Document(
                    content="Sample data: {'providers': ['Provider A', 'Provider B'], 'offers': ['Offer 1', 'Offer 2'], "
                    "'metrics': {'total_transactions': 1000, 'success_rate': 0.95}}",
                    meta={"source": "sample", "type": "data", "filename": "sample_data.json"}
                )
            ]
        
        logger.info(f"Indexing {len(documents)} documents...")
        
        # Run indexing pipeline
        self.indexing_pipeline.run({"document_splitter": {"documents": documents}})
        
        logger.info(f"Successfully indexed {self.document_store.count_documents()} document chunks")
    
    async def query(self, question: str, top_k: int = 5) -> Dict[str, Any]:
        """Query the hybrid RAG pipeline"""
        if not self.rag_pipeline:
            raise RuntimeError("RAG pipeline not initialized")
        
        try:
            logger.info(f"Processing query: {question}")
            
            # Run the RAG pipeline
            results = self.rag_pipeline.run({
                "text_embedder": {"text": question},
                "bm25_retriever": {"query": question, "top_k": top_k},
                "embedding_retriever": {"top_k": top_k},
                "ranker": {"query": question, "top_k": top_k},
                "prompt_builder": {"question": question}
            })
            
            # Extract response and sources
            response = results["llm"]["replies"][0].content if results["llm"]["replies"] else "No response generated"
            
            # Get source information from ranked documents
            ranked_docs = results.get("ranker", {}).get("documents", [])
            sources = [
                f"{doc.meta.get('filename', 'Unknown')} ({doc.meta.get('type', 'unknown')}) - Score: {doc.score:.3f}"
                for doc in ranked_docs[:3]  # Top 3 sources
            ]
            
            return {
                "response": response,
                "sources": sources,
                "retrieved_documents": len(ranked_docs),
                "retrieval_method": "hybrid"
            }
            
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            raise
    
    def get_document_count(self) -> int:
        """Get the number of documents in the document store"""
        if not self.document_store:
            return 0
        return self.document_store.count_documents()



================================================
FILE: app/services/pdf_processor.py
================================================
"""
PDF Processing Service with Landing AI Document Extraction
Processes uploaded PDFs and extracts structured content with bounding boxes
"""

import os
import logging
import base64
import tempfile
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path
import json
import time

import requests
from PIL import Image
import fitz  # PyMuPDF
from haystack import Document

try:
    from agentic_doc.parse import parse
    AGENTIC_DOC_AVAILABLE = True
except ImportError:
    AGENTIC_DOC_AVAILABLE = False
    logging.warning("agentic_doc not available - falling back to REST API")

logger = logging.getLogger(__name__)

@dataclass
class BoundingBox:
    """Bounding box coordinates"""
    x: float
    y: float
    width: float
    height: float
    page: int
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "x": self.x,
            "y": self.y,
            "width": self.width,
            "height": self.height,
            "page": self.page
        }

@dataclass
class PDFChunk:
    """Extracted PDF chunk with location and content"""
    text: str
    bbox: BoundingBox
    page_number: int
    chunk_id: str
    confidence: float = 1.0
    metadata: Optional[Dict[str, Any]] = None
    
    def to_document(self, pdf_name: str) -> Document:
        """Convert to Haystack document"""
        return Document(
            content=self.text,
            meta={
                "source": pdf_name,
                "type": "pdf",
                "chunk_id": self.chunk_id,
                "page_number": self.page_number,
                "bbox": self.bbox.to_dict(),
                "confidence": self.confidence,
                "metadata": self.metadata or {}
            }
        )

@dataclass
class ProcessedPDF:
    """Complete processed PDF with chunks and page images"""
    filename: str
    chunks: List[PDFChunk]
    page_images: List[str]  # Base64 encoded page images
    total_pages: int
    file_size: int
    processing_time: float
    
class LandingAIPDFProcessor:
    """
    PDF processor using Landing AI's Document Extraction API
    """
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("VISION_AGENT_API_KEY")
        if not self.api_key:
            logger.warning("Vision Agent API key not found - using fallback processing")
        
        self.base_url = "https://predict.app.landing.ai/inference/v1"
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}" if self.api_key else ""
        }
    
    def process_pdf(self, pdf_path: str, chunk_strategy: str = "semantic") -> ProcessedPDF:
        """
        Process PDF using Landing AI or fallback method
        
        Args:
            pdf_path: Path to PDF file
            chunk_strategy: Strategy for chunking ("semantic", "page", "paragraph")
            
        Returns:
            ProcessedPDF with extracted chunks and metadata
        """
        start_time = time.time()
        pdf_name = Path(pdf_path).name
        
        try:
            # Try Landing AI SDK first if available and API key is set
            if AGENTIC_DOC_AVAILABLE and self.api_key:
                logger.info(f"Processing {pdf_name} with Landing AI SDK...")
                result = self._process_with_agentic_doc(pdf_path, chunk_strategy)
            elif self.api_key:
                logger.info(f"Processing {pdf_name} with Landing AI REST API...")
                result = self._process_with_landing_ai(pdf_path, chunk_strategy)
            else:
                logger.info(f"Processing {pdf_name} with fallback method...")
                result = self._process_with_fallback(pdf_path, chunk_strategy)
            
            processing_time = time.time() - start_time
            result.processing_time = processing_time
            
            logger.info(f"Successfully processed {pdf_name}: {len(result.chunks)} chunks, "
                       f"{result.total_pages} pages in {processing_time:.2f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"Error processing PDF {pdf_name}: {e}")
            # Fallback to basic processing
            return self._process_with_fallback(pdf_path, chunk_strategy)
    
    def _process_with_agentic_doc(self, pdf_path: str, chunk_strategy: str) -> ProcessedPDF:
        """Process PDF using Landing AI agentic_doc SDK"""
        
        # Set API key as environment variable for the SDK
        if self.api_key:
            os.environ["VISION_AGENT_API_KEY"] = self.api_key
        
        # First, extract page images for visualization
        page_images = self._extract_page_images(pdf_path)
        
        try:
            # Parse PDF using agentic_doc
            logger.info(f"Calling agentic_doc.parse on {pdf_path}")
            result = parse(pdf_path)
            
            if not result:
                raise Exception("No results from agentic_doc.parse")
            
            # Get the first document result
            doc_result = result[0]
            
            # Extract chunks from the result
            chunks = []
            if hasattr(doc_result, 'chunks') and doc_result.chunks:
                # Open PDF once for all coordinate conversions
                pdf_doc = fitz.open(pdf_path)
                scale_factor = 2  # We render images at 2x scale
                
                try:
                    for i, chunk_data in enumerate(doc_result.chunks):
                        # Get text from chunk
                        text = chunk_data.text if hasattr(chunk_data, 'text') else str(chunk_data)
                        
                        # Extract grounding information for bounding boxes
                        if hasattr(chunk_data, 'grounding') and chunk_data.grounding:
                            ground = chunk_data.grounding[0]  # Take first grounding
                            page_num = ground.page
                            box = ground.box
                            
                            # Get page dimensions for coordinate conversion
                            if page_num < pdf_doc.page_count:
                                page = pdf_doc[page_num]
                                page_rect = page.rect
                                
                                # Convert normalized coordinates to pixel coordinates
                                # Landing AI format: l, t, r, b (normalized 0-1)
                                l = box.l
                                t = box.t
                                r = box.r
                                b = box.b
                                
                                # Convert to absolute coordinates with scaling
                                x = l * page_rect.width * scale_factor
                                y = t * page_rect.height * scale_factor
                                width = (r - l) * page_rect.width * scale_factor
                                height = (b - t) * page_rect.height * scale_factor
                                
                                bbox = BoundingBox(
                                    x=x,
                                    y=y,
                                    width=width,
                                    height=height,
                                    page=page_num
                                )
                            else:
                                # Invalid page number - use first page
                                page = pdf_doc[0]
                                page_rect = page.rect
                                bbox = BoundingBox(
                                    x=0, y=0,
                                    width=page_rect.width * scale_factor,
                                    height=page_rect.height * scale_factor,
                                    page=0
                                )
                                page_num = 0
                        else:
                            # No grounding info - use whole first page
                            page = pdf_doc[0]
                            page_rect = page.rect
                            bbox = BoundingBox(
                                x=0, y=0,
                                width=page_rect.width * scale_factor,
                                height=page_rect.height * scale_factor,
                                page=0
                            )
                            page_num = 0
                        
                        # Create chunk with proper confidence handling
                        confidence = 1.0
                        if hasattr(chunk_data, 'confidence') and chunk_data.confidence is not None:
                            confidence = float(chunk_data.confidence)
                        
                        chunk = PDFChunk(
                            text=text,
                            bbox=bbox,
                            page_number=page_num,
                            chunk_id=f"chunk_{i}",
                            confidence=confidence,
                            metadata={}
                        )
                        chunks.append(chunk)
                
                finally:
                    pdf_doc.close()
            
            # Get total pages from the PDF
            doc = fitz.open(pdf_path)
            total_pages = doc.page_count
            doc.close()
            
            return ProcessedPDF(
                filename=Path(pdf_path).name,
                chunks=chunks,
                page_images=page_images,
                total_pages=total_pages,
                file_size=os.path.getsize(pdf_path),
                processing_time=0  # Will be set by caller
            )
            
        except Exception as e:
            logger.error(f"agentic_doc processing failed: {e}")
            raise

    def _process_with_landing_ai(self, pdf_path: str, chunk_strategy: str) -> ProcessedPDF:
        """Process PDF using Landing AI API"""
        
        # First, extract page images for visualization
        page_images = self._extract_page_images(pdf_path)
        
        # Encode PDF for API
        with open(pdf_path, 'rb') as f:
            pdf_base64 = base64.b64encode(f.read()).decode('utf-8')
        
        # Landing AI Document Extraction API call
        payload = {
            "file_content": pdf_base64,
            "file_type": "pdf",
            "extraction_config": {
                "chunk_strategy": chunk_strategy,
                "include_bboxes": True,
                "include_confidence": True,
                "page_images": True
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/documents/extract",
                headers=self.headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                data = response.json()
                return self._parse_landing_ai_response(data, page_images, pdf_path)
            else:
                logger.error(f"Landing AI API error: {response.status_code} - {response.text}")
                raise Exception(f"API returned {response.status_code}")
                
        except Exception as e:
            logger.error(f"Landing AI processing failed: {e}")
            raise
    
    def _process_with_fallback(self, pdf_path: str, chunk_strategy: str) -> ProcessedPDF:
        """Fallback processing using PyMuPDF"""
        
        doc = fitz.open(pdf_path)
        chunks = []
        page_images = []
        
        try:
            # Extract page images
            for page_num in range(doc.page_count):
                page = doc[page_num]
                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x scale for better quality
                img_data = pix.tobytes("png")
                img_base64 = base64.b64encode(img_data).decode('utf-8')
                page_images.append(img_base64)
            
            # Extract text chunks based on strategy
            if chunk_strategy == "page":
                chunks = self._chunk_by_page(doc)
            elif chunk_strategy == "paragraph":
                chunks = self._chunk_by_paragraph(doc)
            else:  # semantic (default)
                chunks = self._chunk_semantically(doc)
            
            return ProcessedPDF(
                filename=Path(pdf_path).name,
                chunks=chunks,
                page_images=page_images,
                total_pages=doc.page_count,
                file_size=os.path.getsize(pdf_path),
                processing_time=0  # Will be set by caller
            )
            
        finally:
            doc.close()
    
    def _extract_page_images(self, pdf_path: str) -> List[str]:
        """Extract page images as base64 strings"""
        doc = fitz.open(pdf_path)
        images = []
        
        try:
            for page_num in range(doc.page_count):
                page = doc[page_num]
                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
                img_data = pix.tobytes("png")
                img_base64 = base64.b64encode(img_data).decode('utf-8')
                images.append(img_base64)
        finally:
            doc.close()
            
        return images
    
    def _parse_landing_ai_response(self, data: Dict[str, Any], 
                                  page_images: List[str], pdf_path: str) -> ProcessedPDF:
        """Parse Landing AI API response into ProcessedPDF"""
        
        chunks = []
        extracted_chunks = data.get("chunks", [])
        
        # Get page dimensions for coordinate conversion
        doc = fitz.open(pdf_path)
        
        try:
            for i, chunk_data in enumerate(extracted_chunks):
                # Landing AI uses normalized coordinates in 'grounding' field
                grounding = chunk_data.get("grounding", [])
                if not grounding:
                    continue
                
                ground = grounding[0]  # Take first grounding
                page_num = ground.get("page", 0)
                box = ground.get("box", {})
                
                # Get page dimensions (PDF uses 2x scale for images)
                page = doc[page_num]
                page_rect = page.rect
                scale_factor = 2  # We render images at 2x scale
                
                # Convert normalized coordinates to pixel coordinates
                # Landing AI format: l, t, r, b (normalized 0-1)
                l = box.get("l", 0)  # Left
                t = box.get("t", 0)  # Top
                r = box.get("r", 0)  # Right  
                b = box.get("b", 0)  # Bottom
                
                # Convert to absolute coordinates with scaling
                x = l * page_rect.width * scale_factor
                y = t * page_rect.height * scale_factor
                width = (r - l) * page_rect.width * scale_factor
                height = (b - t) * page_rect.height * scale_factor
                
                bbox = BoundingBox(
                    x=x,
                    y=y,
                    width=width,
                    height=height,
                    page=page_num
                )
                
                chunk = PDFChunk(
                    text=chunk_data.get("text", ""),
                    bbox=bbox,
                    page_number=page_num,
                    chunk_id=f"chunk_{i}",
                    confidence=chunk_data.get("confidence", 1.0),
                    metadata=chunk_data.get("metadata", {})
                )
                chunks.append(chunk)
        
        finally:
            doc.close()
        
        return ProcessedPDF(
            filename=Path(pdf_path).name,
            chunks=chunks,
            page_images=page_images,
            total_pages=data.get("total_pages", len(page_images)),
            file_size=os.path.getsize(pdf_path),
            processing_time=0
        )
    
    def _chunk_by_page(self, doc: fitz.Document) -> List[PDFChunk]:
        """Chunk PDF by page"""
        chunks = []
        
        for page_num in range(doc.page_count):
            page = doc[page_num]
            text = page.get_text()
            
            if text.strip():
                # Get page dimensions for bounding box
                rect = page.rect
                bbox = BoundingBox(
                    x=0, y=0,
                    width=rect.width,
                    height=rect.height,
                    page=page_num
                )
                
                chunk = PDFChunk(
                    text=text.strip(),
                    bbox=bbox,
                    page_number=page_num,
                    chunk_id=f"page_{page_num}",
                    confidence=1.0
                )
                chunks.append(chunk)
        
        return chunks
    
    def _chunk_by_paragraph(self, doc: fitz.Document) -> List[PDFChunk]:
        """Chunk PDF by paragraphs using text blocks"""
        chunks = []
        chunk_id = 0
        
        for page_num in range(doc.page_count):
            page = doc[page_num]
            blocks = page.get_text("dict")["blocks"]
            
            for block in blocks:
                if "lines" in block:  # Text block
                    text_parts = []
                    
                    for line in block["lines"]:
                        for span in line["spans"]:
                            text_parts.append(span["text"])
                    
                    text = "".join(text_parts).strip()
                    if text and len(text) > 20:  # Minimum length filter
                        
                        # Create bounding box from block (apply 2x scale to match image rendering)
                        scale_factor = 2
                        bbox = BoundingBox(
                            x=block["bbox"][0] * scale_factor,
                            y=block["bbox"][1] * scale_factor,
                            width=(block["bbox"][2] - block["bbox"][0]) * scale_factor,
                            height=(block["bbox"][3] - block["bbox"][1]) * scale_factor,
                            page=page_num
                        )
                        
                        chunk = PDFChunk(
                            text=text,
                            bbox=bbox,
                            page_number=page_num,
                            chunk_id=f"para_{chunk_id}",
                            confidence=0.9
                        )
                        chunks.append(chunk)
                        chunk_id += 1
        
        return chunks
    
    def _chunk_semantically(self, doc: fitz.Document) -> List[PDFChunk]:
        """Semantic chunking - group related paragraphs"""
        # For now, use paragraph chunking with larger minimum sizes
        paragraphs = self._chunk_by_paragraph(doc)
        
        # Merge small adjacent paragraphs
        merged_chunks = []
        current_chunk = None
        
        for para in paragraphs:
            if current_chunk is None:
                current_chunk = para
            elif (len(current_chunk.text) < 300 and 
                  para.page_number == current_chunk.page_number):
                # Merge with previous chunk
                current_chunk.text += "\n\n" + para.text
                # Expand bounding box
                current_chunk.bbox.width = max(
                    current_chunk.bbox.x + current_chunk.bbox.width,
                    para.bbox.x + para.bbox.width
                ) - current_chunk.bbox.x
                current_chunk.bbox.height = max(
                    current_chunk.bbox.y + current_chunk.bbox.height,
                    para.bbox.y + para.bbox.height
                ) - current_chunk.bbox.y
            else:
                merged_chunks.append(current_chunk)
                current_chunk = para
        
        if current_chunk:
            merged_chunks.append(current_chunk)
        
        return merged_chunks

def save_processed_pdf(processed_pdf: ProcessedPDF, 
                      output_dir: str = "processed_pdfs") -> str:
    """Save processed PDF data to disk for caching"""
    
    os.makedirs(output_dir, exist_ok=True)
    
    # Create filename from original
    base_name = Path(processed_pdf.filename).stem
    output_file = Path(output_dir) / f"{base_name}_processed.json"
    
    # Convert to serializable format
    data = {
        "filename": processed_pdf.filename,
        "chunks": [
            {
                "text": chunk.text,
                "bbox": chunk.bbox.to_dict(),
                "page_number": chunk.page_number,
                "chunk_id": chunk.chunk_id,
                "confidence": chunk.confidence,
                "metadata": chunk.metadata
            }
            for chunk in processed_pdf.chunks
        ],
        "page_images": processed_pdf.page_images,
        "total_pages": processed_pdf.total_pages,
        "file_size": processed_pdf.file_size,
        "processing_time": processed_pdf.processing_time
    }
    
    with open(output_file, 'w') as f:
        json.dump(data, f, indent=2)
    
    logger.info(f"Saved processed PDF to {output_file}")
    return str(output_file)

# Test function
def test_pdf_processor():
    """Test PDF processing with sample file"""
    print("üîç Testing PDF Processor")
    print("=" * 40)
    
    processor = LandingAIPDFProcessor()
    
    # Create a simple test PDF if none exists
    test_file = "test_document.pdf"
    
    try:
        result = processor.process_pdf(test_file, chunk_strategy="semantic")
        
        print(f"‚úÖ Processed: {result.filename}")
        print(f"   Pages: {result.total_pages}")
        print(f"   Chunks: {len(result.chunks)}")
        print(f"   Processing time: {result.processing_time:.2f}s")
        
        for i, chunk in enumerate(result.chunks[:3]):
            print(f"   Chunk {i}: {chunk.text[:50]}...")
            print(f"     Page: {chunk.page_number}, BBox: {chunk.bbox.to_dict()}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        return False

if __name__ == "__main__":
    test_pdf_processor()


================================================
FILE: app/tools/__init__.py
================================================
# Tools Package



================================================
FILE: app/tools/gemini_chat.py
================================================
"""
Gemini Chat Generator for Haystack 2.x
"""

import os
import logging
from typing import List, Dict, Any, Optional

import google.generativeai as genai
from haystack import component, default_from_dict, default_to_dict
from haystack.dataclasses import ChatMessage, ChatRole

logger = logging.getLogger(__name__)

@component
class GeminiChatGenerator:
    """
    A component for generating chat responses using Google's Gemini API.
    
    This component integrates with Haystack 2.x pipelines and provides
    chat completion functionality using Gemini models.
    """
    
    def __init__(
        self,
        model: str = "gemini-2.5-flash",
        api_key: Optional[str] = None,
        generation_config: Optional[Dict[str, Any]] = None,
        safety_settings: Optional[List[Dict[str, Any]]] = None
    ):
        """
        Initialize the Gemini Chat Generator.
        
        Args:
            model: The Gemini model to use
            api_key: Google API key (if not provided, uses GOOGLE_API_KEY env var)
            generation_config: Generation configuration parameters
            safety_settings: Safety settings for content filtering
        """
        self.model_name = model
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")
        
        if not self.api_key:
            raise ValueError("Google API key is required")
        
        # Configure Gemini API
        genai.configure(api_key=self.api_key)
        
        # Initialize the model
        self.model = genai.GenerativeModel(
            model_name=self.model_name,
            generation_config=generation_config,
            safety_settings=safety_settings
        )
        
        logger.info(f"Initialized Gemini Chat Generator with model: {self.model_name}")
    
    def to_dict(self) -> Dict[str, Any]:
        """Serialize component to dictionary."""
        return default_to_dict(
            self,
            model=self.model_name,
            api_key=self.api_key,
        )
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "GeminiChatGenerator":
        """Deserialize component from dictionary."""
        return default_from_dict(cls, data)
    
    def _convert_messages_to_gemini_format(self, messages: List[ChatMessage]) -> List[Dict[str, str]]:
        """Convert Haystack ChatMessage format to Gemini format."""
        gemini_messages = []
        
        for message in messages:
            # Map Haystack roles to Gemini roles
            if message.role == ChatRole.SYSTEM:
                # Gemini doesn't have a system role, so we'll prepend system messages to user messages
                gemini_messages.append({
                    "role": "user",
                    "parts": [{"text": f"System: {message.content}"}]
                })
            elif message.role == ChatRole.USER:
                gemini_messages.append({
                    "role": "user",
                    "parts": [{"text": message.content}]
                })
            elif message.role == ChatRole.ASSISTANT:
                gemini_messages.append({
                    "role": "model",
                    "parts": [{"text": message.content}]
                })
        
        return gemini_messages
    
    @component.output_types(replies=List[ChatMessage])
    def run(self, messages: List[ChatMessage]) -> Dict[str, Any]:
        """
        Generate a chat response using Gemini.
        
        Args:
            messages: List of ChatMessage objects representing the conversation
            
        Returns:
            Dictionary with 'replies' key containing generated ChatMessage responses
        """
        try:
            logger.info(f"Generating response with {len(messages)} input messages")
            
            # Convert messages to Gemini format
            gemini_messages = self._convert_messages_to_gemini_format(messages)
            
            # For Gemini, we need to handle the conversation differently
            # We'll combine all messages into a single prompt for simplicity
            combined_prompt = ""
            for msg in messages:
                if msg.role == ChatRole.SYSTEM:
                    combined_prompt += f"System: {msg.content}\n\n"
                elif msg.role == ChatRole.USER:
                    combined_prompt += f"User: {msg.content}\n\n"
                elif msg.role == ChatRole.ASSISTANT:
                    combined_prompt += f"Assistant: {msg.content}\n\n"
            
            # Generate response
            response = self.model.generate_content(combined_prompt)
            
            if not response.text:
                logger.warning("Empty response from Gemini API")
                return {"replies": []}
            
            # Create ChatMessage response
            reply = ChatMessage.from_assistant(response.text)
            
            logger.info("Successfully generated response")
            return {"replies": [reply]}
            
        except Exception as e:
            logger.error(f"Error generating response with Gemini: {e}")
            # Return empty response on error
            return {"replies": []}



================================================
FILE: app/tools/tavily_search.py
================================================
"""
Tavily web search integration with document store indexing
"""

import os
import logging
from typing import List, Dict, Any, Optional
import time

from tavily import TavilyClient
from haystack import Document
from haystack.document_stores.in_memory import InMemoryDocumentStore

from app.rag.core import GeminiEmbedder, WebDisabled
from app.llm.gemini import chat

logger = logging.getLogger(__name__)

def web_search_into_docstore(
    docstore: InMemoryDocumentStore,
    embedder: GeminiEmbedder,
    query: str,
    max_results: int = 5
) -> List[Document]:
    """
    Perform web search with Tavily and add results to document store
    
    Args:
        docstore: Haystack document store to add results to
        embedder: Gemini embedder for generating embeddings
        query: Search query
        max_results: Maximum number of search results to process
        
    Returns:
        List of newly added Document objects
        
    Raises:
        WebDisabled: If ALLOW_TAVILY is not set to true
    """
    # Check if Tavily is enabled
    if os.getenv("ALLOW_TAVILY", "false").lower() != "true":
        raise WebDisabled("Web search is disabled. Set ALLOW_TAVILY=true to enable.")
    
    # Get Tavily API key
    tavily_api_key = os.getenv("TAVILY_API_KEY")
    if not tavily_api_key:
        raise ValueError("TAVILY_API_KEY environment variable is required when ALLOW_TAVILY=true")
    
    try:
        # Initialize Tavily client
        client = TavilyClient(api_key=tavily_api_key)
        
        # Perform search
        logger.info(f"Performing web search for: {query}")
        search_result = client.search(
            query=query,
            search_depth="basic",
            max_results=max_results,
            include_answer=True,
            include_raw_content=True
        )
        
        # Process search results
        documents = []
        results = search_result.get("results", [])
        
        if not results:
            logger.warning(f"No web search results found for query: {query}")
            return documents
        
        # Process each search result
        for i, result in enumerate(results):
            try:
                title = result.get("title", "")
                url = result.get("url", "")
                content = result.get("content", "")
                raw_content = result.get("raw_content", "")
                
                # Use raw content if available, otherwise use content
                full_content = raw_content if raw_content else content
                
                if not full_content:
                    logger.warning(f"No content found for URL: {url}")
                    continue
                
                # Summarize content using Gemini
                summary = _summarize_web_content(title, full_content, url, query)
                
                # Create document
                doc = Document(
                    content=summary,
                    meta={
                        "source": "web_search",
                        "source_url": url,
                        "title": title,
                        "type": "web_result",
                        "search_query": query,
                        "result_index": i,
                        "original_content_length": len(full_content),
                        "timestamp": time.time()
                    }
                )
                
                documents.append(doc)
                
            except Exception as e:
                logger.error(f"Error processing search result {i}: {e}")
                continue
        
        if not documents:
            logger.warning("No valid documents created from web search results")
            return documents
        
        # Generate embeddings for all documents
        logger.info(f"Generating embeddings for {len(documents)} web search results...")
        texts = [doc.content for doc in documents]
        embeddings = embedder.embed_texts(texts)
        
        # Add embeddings to documents
        for doc, embedding in zip(documents, embeddings):
            doc.embedding = embedding
        
        # Write documents to store
        docstore.write_documents(documents)
        
        logger.info(f"Successfully added {len(documents)} web search results to document store")
        return documents
        
    except WebDisabled:
        raise
    except Exception as e:
        logger.error(f"Error during web search: {e}")
        return []

def _summarize_web_content(title: str, content: str, url: str, query: str) -> str:
    """
    Summarize web content using Gemini chat model
    
    Args:
        title: Page title
        content: Page content
        url: Page URL
        query: Original search query
        
    Returns:
        Summarized content
    """
    try:
        # Truncate content if too long (keep first 3000 characters)
        truncated_content = content[:3000] if len(content) > 3000 else content
        
        # Create summarization prompt
        system_prompt = (
            "You are a helpful assistant that summarizes web content. "
            "Create a concise but informative summary that captures the key information "
            "relevant to the user's search query. Focus on factual content and maintain accuracy."
        )
        
        user_message = f"""
Please summarize the following web content in relation to the search query: "{query}"

Title: {title}
URL: {url}
Content: {truncated_content}

Provide a clear, factual summary that highlights information most relevant to the search query.
Keep the summary concise but comprehensive (2-3 paragraphs maximum).
"""
        
        messages = [
            {"role": "user", "content": user_message}
        ]
        
        # Get summary from Gemini
        summary = chat(messages, system=system_prompt)
        
        # Add source attribution
        attributed_summary = f"{summary}\n\nSource: {title} ({url})"
        
        return attributed_summary
        
    except Exception as e:
        logger.error(f"Error summarizing content from {url}: {e}")
        # Return truncated original content as fallback
        fallback_content = content[:1000] if len(content) > 1000 else content
        return f"Content from {title} ({url}):\n\n{fallback_content}"

def search_and_get_results(query: str, max_results: int = 5) -> List[Dict[str, Any]]:
    """
    Perform web search and return formatted results without adding to docstore
    
    Args:
        query: Search query
        max_results: Maximum number of results
        
    Returns:
        List of formatted search results
        
    Raises:
        WebDisabled: If ALLOW_TAVILY is not set to true
    """
    # Check if Tavily is enabled
    if os.getenv("ALLOW_TAVILY", "false").lower() != "true":
        raise WebDisabled("Web search is disabled. Set ALLOW_TAVILY=true to enable.")
    
    # Get Tavily API key
    tavily_api_key = os.getenv("TAVILY_API_KEY")
    if not tavily_api_key:
        raise ValueError("TAVILY_API_KEY environment variable is required when ALLOW_TAVILY=true")
    
    try:
        # Initialize Tavily client
        client = TavilyClient(api_key=tavily_api_key)
        
        # Perform search
        logger.info(f"Performing web search for: {query}")
        search_result = client.search(
            query=query,
            search_depth="basic",
            max_results=max_results,
            include_answer=True
        )
        
        # Format results
        formatted_results = []
        results = search_result.get("results", [])
        
        for result in results:
            formatted_results.append({
                "title": result.get("title", ""),
                "url": result.get("url", ""),
                "content": result.get("content", ""),
                "score": result.get("score", 0.0)
            })
        
        # Include answer if available
        answer = search_result.get("answer")
        if answer:
            formatted_results.insert(0, {
                "title": "Direct Answer",
                "url": "tavily://answer",
                "content": answer,
                "score": 1.0
            })
        
        logger.info(f"Retrieved {len(formatted_results)} web search results")
        return formatted_results
        
    except WebDisabled:
        raise
    except Exception as e:
        logger.error(f"Error during web search: {e}")
        return []



================================================
FILE: app/ui/index.html
================================================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Synch GenAI PoC</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #4f46e5 0%, #7c3aed 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            font-weight: 700;
        }

        .header p {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .chat-container {
            height: 500px;
            overflow-y: auto;
            padding: 20px;
            background: #f8fafc;
        }

        .message {
            margin-bottom: 20px;
            padding: 15px;
            border-radius: 12px;
            max-width: 80%;
            word-wrap: break-word;
        }

        .message.user {
            background: #4f46e5;
            color: white;
            margin-left: auto;
            text-align: right;
        }

        .message.assistant {
            background: white;
            border: 1px solid #e2e8f0;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        }

        .message.error {
            background: #fee2e2;
            border: 1px solid #fecaca;
            color: #dc2626;
        }

        .sources {
            margin-top: 10px;
            padding-top: 10px;
            border-top: 1px solid #e2e8f0;
            font-size: 0.9rem;
            color: #64748b;
        }

        .sources h4 {
            margin-bottom: 5px;
            color: #374151;
        }

        .sources ul {
            list-style: none;
            padding-left: 0;
        }

        .sources li {
            margin-bottom: 3px;
            padding-left: 15px;
            position: relative;
        }

        .sources li:before {
            content: "‚Ä¢";
            color: #4f46e5;
            position: absolute;
            left: 0;
        }

        .input-container {
            padding: 20px;
            background: white;
            border-top: 1px solid #e2e8f0;
        }

        .input-row {
            display: flex;
            gap: 10px;
            margin-bottom: 10px;
        }

        .query-input {
            flex: 1;
            padding: 12px 16px;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            font-size: 1rem;
            transition: border-color 0.2s;
        }

        .query-input:focus {
            outline: none;
            border-color: #4f46e5;
        }

        .send-button {
            padding: 12px 24px;
            background: #4f46e5;
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            cursor: pointer;
            transition: background-color 0.2s;
        }

        .send-button:hover:not(:disabled) {
            background: #4338ca;
        }

        .send-button:disabled {
            background: #9ca3af;
            cursor: not-allowed;
        }

        .options {
            display: flex;
            align-items: center;
            gap: 15px;
            font-size: 0.9rem;
            color: #64748b;
        }

        .checkbox-container {
            display: flex;
            align-items: center;
            gap: 5px;
        }

        .checkbox-container input[type="checkbox"] {
            margin: 0;
        }

        .status {
            padding: 10px 20px;
            background: #f1f5f9;
            border-top: 1px solid #e2e8f0;
            font-size: 0.9rem;
            color: #64748b;
            text-align: center;
        }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #4f46e5;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-right: 10px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .welcome-message {
            text-align: center;
            color: #64748b;
            font-style: italic;
            margin: 50px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Synch GenAI PoC</h1>
            <p>Intelligent Knowledge Base Assistant</p>
        </div>

        <div class="chat-container" id="chatContainer">
            <div class="welcome-message">
                Welcome! Ask me anything about our policies, contracts, or data. I'll search our knowledge base and provide accurate answers.
            </div>
        </div>

        <div class="input-container">
            <div class="input-row">
                <input 
                    type="text" 
                    id="queryInput" 
                    class="query-input" 
                    placeholder="Ask a question about policies, contracts, or data..."
                    onkeypress="handleKeyPress(event)"
                >
                <button id="sendButton" class="send-button" onclick="sendQuery()">
                    Send
                </button>
            </div>
            <div class="options">
                <div class="checkbox-container">
                    <input type="checkbox" id="tavilyCheckbox">
                    <label for="tavilyCheckbox">Enable web search fallback</label>
                </div>
            </div>
        </div>

        <div class="status" id="status">
            Ready to answer your questions
        </div>
    </div>

    <script>
        let isLoading = false;

        function handleKeyPress(event) {
            if (event.key === 'Enter' && !isLoading) {
                sendQuery();
            }
        }

        async function sendQuery() {
            const queryInput = document.getElementById('queryInput');
            const sendButton = document.getElementById('sendButton');
            const chatContainer = document.getElementById('chatContainer');
            const status = document.getElementById('status');
            const tavilyCheckbox = document.getElementById('tavilyCheckbox');

            const query = queryInput.value.trim();
            if (!query || isLoading) return;

            // Clear welcome message if it exists
            const welcomeMessage = chatContainer.querySelector('.welcome-message');
            if (welcomeMessage) {
                welcomeMessage.remove();
            }

            // Add user message
            addMessage('user', query);

            // Clear input and disable button
            queryInput.value = '';
            isLoading = true;
            sendButton.disabled = true;
            sendButton.innerHTML = '<div class="loading"></div>Thinking...';
            status.innerHTML = '<div class="loading"></div>Processing your query...';

            try {
                const response = await fetch('/api/query', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        query: query,
                        use_tavily: tavilyCheckbox.checked
                    })
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }

                const data = await response.json();
                addMessage('assistant', data.response, data.sources, data.used_tavily);
                
                // Update status
                const method = data.retrieval_method || 'hybrid';
                const docCount = data.retrieved_documents || 0;
                status.textContent = `Retrieved ${docCount} documents using ${method} retrieval${data.used_tavily ? ' with web search' : ''}`;

            } catch (error) {
                console.error('Error:', error);
                addMessage('error', `Sorry, I encountered an error: ${error.message}`);
                status.textContent = 'Error occurred while processing query';
            } finally {
                isLoading = false;
                sendButton.disabled = false;
                sendButton.textContent = 'Send';
                queryInput.focus();
            }
        }

        function addMessage(type, content, sources = [], usedTavily = false) {
            const chatContainer = document.getElementById('chatContainer');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;

            let messageHTML = `<div>${content}</div>`;

            if (sources && sources.length > 0) {
                messageHTML += `
                    <div class="sources">
                        <h4>Sources${usedTavily ? ' (Knowledge Base + Web)' : ' (Knowledge Base)'}:</h4>
                        <ul>
                            ${sources.map(source => `<li>${source}</li>`).join('')}
                        </ul>
                    </div>
                `;
            }

            messageDiv.innerHTML = messageHTML;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        // Check health on page load
        async function checkHealth() {
            try {
                const response = await fetch('/api/health');
                const data = await response.json();
                
                if (data.status === 'healthy') {
                    document.getElementById('status').textContent = 
                        `System ready - ${data.rag_initialized ? 'RAG initialized' : 'RAG not ready'}`;
                } else {
                    document.getElementById('status').textContent = 'System not ready';
                }
            } catch (error) {
                document.getElementById('status').textContent = 'Unable to connect to server';
            }
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            checkHealth();
            document.getElementById('queryInput').focus();
        });
    </script>
</body>
</html>



================================================
FILE: app/ui/modern.html
================================================
<!DOCTYPE html>
<html lang="en" class="h-full">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GenAI Studio (Hackathon PoC)</title>
    <script src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        'teal': {
                            500: '#14b8a6',
                            600: '#0d9488',
                        },
                        'slate': {
                            50: '#f8fafc',
                            100: '#f1f5f9',
                            200: '#e2e8f0',
                            300: '#cbd5e1',
                            400: '#94a3b8',
                            500: '#64748b',
                            600: '#475569',
                            700: '#334155',
                            800: '#1e293b',
                            900: '#0f172a',
                        }
                    }
                }
            }
        }
    </script>
    <style>
        .chat-message {
            animation: slideInUp 0.3s ease-out;
        }
        @keyframes slideInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        .tool-chip {
            transition: all 0.2s ease;
        }
        .tool-chip:hover {
            transform: translateY(-1px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        .redacted-text {
            background: linear-gradient(90deg, #94a3b8 25%, transparent 25%);
            background-size: 8px 1px;
            background-repeat: repeat-x;
            background-position: 0 50%;
            color: transparent;
        }
        .redacted-text:hover::after {
            content: " (Redacted)";
            color: #64748b;
            font-size: 0.75rem;
            background: #1e293b;
            padding: 2px 6px;
            border-radius: 4px;
            margin-left: 4px;
        }
        
        /* Enhanced markdown styles */
        .markdown-content {
            line-height: 1.6;
        }
        
        .markdown-content pre {
            margin: 1rem 0;
            position: relative;
        }
        
        .markdown-content code {
            font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace;
        }
        
        .markdown-content pre code {
            color: #e6ffed !important;
            background: transparent !important;
            padding: 0 !important;
            border-radius: 0 !important;
        }
        
        /* Override highlight.js theme for better visibility */
        .hljs {
            background: #1e293b !important;
            color: #e2e8f0 !important;
        }
        
        .hljs-keyword { color: #f59e0b !important; }
        .hljs-string { color: #10b981 !important; }
        .hljs-comment { color: #6b7280 !important; }
        .hljs-function { color: #3b82f6 !important; }
        .hljs-variable { color: #8b5cf6 !important; }
        .hljs-number { color: #f472b6 !important; }
        .hljs-built_in { color: #06b6d4 !important; }
    </style>
</head>
<body class="h-full bg-slate-50">
    <div id="root" class="h-full"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef } = React;
        const ReactMarkdown = window.ReactMarkdown;
        
        // Custom components for react-markdown
        const markdownComponents = {
            code: ({ node, inline, className, children, ...props }) => {
                const match = /language-(\w+)/.exec(className || '');
                const language = match ? match[1] : '';
                
                return !inline ? (
                    <div className="my-4">
                        {language && (
                            <div className="bg-slate-100 px-3 py-1 text-xs font-mono text-slate-600 border-t border-l border-r border-slate-300 rounded-t">
                                {language}
                            </div>
                        )}
                        <pre className={`bg-slate-900 text-green-400 p-4 rounded${language ? '-b' : ''} overflow-x-auto`}>
                            <code className={className} {...props}>
                                {children}
                            </code>
                        </pre>
                    </div>
                ) : (
                    <code className="bg-slate-100 text-slate-800 px-1.5 py-0.5 rounded text-sm font-mono" {...props}>
                        {children}
                    </code>
                );
            },
            h1: ({ children }) => <h1 className="text-2xl font-bold text-slate-800 mt-8 mb-4">{children}</h1>,
            h2: ({ children }) => <h2 className="text-xl font-bold text-slate-800 mt-6 mb-3">{children}</h2>,
            h3: ({ children }) => <h3 className="text-lg font-semibold text-slate-800 mt-4 mb-2">{children}</h3>,
            p: ({ children }) => <p className="mb-3 leading-relaxed">{children}</p>,
            ul: ({ children }) => <ul className="list-disc list-inside mb-3 space-y-1">{children}</ul>,
            ol: ({ children }) => <ol className="list-decimal list-inside mb-3 space-y-1">{children}</ol>,
            li: ({ children }) => <li className="ml-2">{children}</li>,
            strong: ({ children }) => <strong className="font-semibold text-slate-800">{children}</strong>,
            em: ({ children }) => <em className="italic">{children}</em>,
            blockquote: ({ children }) => (
                <blockquote className="border-l-4 border-slate-300 pl-4 italic text-slate-600 mb-3">
                    {children}
                </blockquote>
            )
        };

        // Agent configurations
        const AGENTS = {
            'smart': {
                name: 'Smart Chat',
                icon: 'fa-brain',
                color: 'text-teal-600',
                example: 'Find a standing desk under ‚Çπ50k with 12-mo 0% APR',
                tooltip: 'AI router - finds the best agent for your query'
            },
            'offerpilot': {
                name: 'OfferPilot',
                icon: 'fa-tags',
                color: 'text-blue-600',
                example: 'Show me laptops under ‚Çπ80k with financing options',
                tooltip: 'Product search with financing pre-qualification'
            },
            'trustshield': {
                name: 'TrustShield',
                icon: 'fa-shield-halved',
                color: 'text-red-600',
                example: 'I got an email asking for gift cards as refund',
                tooltip: 'Fraud detection and PII protection system'
            },
            'dispute': {
                name: 'Dispute',
                icon: 'fa-gavel',
                color: 'text-amber-600',
                example: 'Charged twice for ‚Çπ12,499 at Amazon on Dec 15th',
                tooltip: 'Transaction dispute resolution assistant'
            },
            'collections': {
                name: 'Collections',
                icon: 'fa-handshake',
                color: 'text-green-600',
                example: 'I have ‚Çπ25k balance at 24% APR, need payment options',
                tooltip: 'Hardship and payment plan assistance'
            },
            'contracts': {
                name: 'Contracts',
                icon: 'fa-file-contract',
                color: 'text-purple-600',
                example: 'Review my merchant agreement for key obligations',
                tooltip: 'Contract analysis and obligation tracking'
            },
            'devcopilot': {
                name: 'DevCopilot',
                icon: 'fa-code',
                color: 'text-indigo-600',
                example: 'Generate Python code for payments API integration',
                tooltip: 'Developer tools and API integration help'
            },
            'carecredit': {
                name: 'CareCredit',
                icon: 'fa-heart-pulse',
                color: 'text-pink-600',
                example: 'Dental procedure costs ‚Çπ45k, what are my options?',
                tooltip: 'Healthcare financing and payment plans'
            },
            'narrator': {
                name: 'Narrator',
                icon: 'fa-chart-line',
                color: 'text-orange-600',
                example: 'Why did spend drop after 2025-07-31?',
                tooltip: 'Portfolio analytics and business insights'
            },
            'imagegen': {
                name: 'ImageGen',
                icon: 'fa-image',
                color: 'text-violet-600',
                example: 'Create a futuristic city with flying cars and neon lights',
                tooltip: 'AI-powered image generation from text descriptions'
            }
        };

        // Main App Component
        function App() {
            const [selectedAgent, setSelectedAgent] = useState('smart');
            const [allowTavily, setAllowTavily] = useState(false);
            const [allowLlmKnowledge, setAllowLlmKnowledge] = useState(true);
            const [allowWebSearch, setAllowWebSearch] = useState(false);
            const [messages, setMessages] = useState([]);
            const [inputText, setInputText] = useState('');
            const [isLoading, setIsLoading] = useState(false);
            const [rightPanel, setRightPanel] = useState('citations');
            const [citations, setCitations] = useState([]);
            const [toolTrace, setToolTrace] = useState([]);
            const [uploadedPdfs, setUploadedPdfs] = useState([]);
            const [selectedPdfChunk, setSelectedPdfChunk] = useState(null);
            const messagesEndRef = useRef(null);

            // Auto-scroll to bottom when messages change
            useEffect(() => {
                messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
            }, [messages]);
            
            // Highlight code blocks after messages update
            useEffect(() => {
                if (window.hljs) {
                    setTimeout(() => window.hljs.highlightAll(), 100);
                }
            }, [messages]);

            const sendMessage = async () => {
                if (!inputText.trim()) return;

                const userMessage = {
                    id: Date.now(),
                    type: 'user',
                    content: inputText,
                    timestamp: new Date()
                };

                setMessages(prev => [...prev, userMessage]);
                setIsLoading(true);

                try {
                    const endpoint = selectedAgent === 'smart' ? '/chat' : `/agent/${selectedAgent}`;
                    const payload = selectedAgent === 'smart' 
                        ? { 
                            message: inputText, 
                            allow_tavily: allowTavily,
                            allow_llm_knowledge: allowLlmKnowledge,
                            allow_web_search: allowWebSearch
                        }
                        : selectedAgent === 'imagegen'
                        ? { prompt: inputText, include_text: true, style_hints: [] }
                        : { query: inputText };

                    const response = await fetch(endpoint, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    const data = await response.json();
                    
                    const assistantMessage = {
                        id: Date.now() + 1,
                        type: 'assistant',
                        content: data.response || data,
                        agent: data.agent || selectedAgent,
                        confidence: data.confidence || 1.0,
                        sources: data.sources || [],
                        used_tavily: data.used_tavily || false,
                        timestamp: new Date(),
                        latency: Math.random() * 2000 + 500, // Mock latency
                        image_data: data.image_data,
                        image_format: data.image_format
                    };

                    setMessages(prev => [...prev, assistantMessage]);
                    setCitations(data.sources || []);
                    setToolTrace(prev => [...prev, {
                        tool: selectedAgent,
                        args: payload,
                        result: data,
                        timestamp: new Date()
                    }]);

                } catch (error) {
                    console.error('Error sending message:', error);
                    setMessages(prev => [...prev, {
                        id: Date.now() + 1,
                        type: 'error',
                        content: 'Sorry, there was an error processing your request.',
                        timestamp: new Date()
                    }]);
                }

                setInputText('');
                setIsLoading(false);
            };

            const useExample = (agentKey) => {
                setInputText(AGENTS[agentKey].example);
                setSelectedAgent(agentKey);
            };

            const clearChat = () => {
                setMessages([]);
                setCitations([]);
                setToolTrace([]);
            };

            const uploadPdf = async (file) => {
                const formData = new FormData();
                formData.append('file', file);
                
                try {
                    const response = await fetch('/upload/pdf', {
                        method: 'POST',
                        body: formData
                    });
                    
                    if (!response.ok) {
                        const errorText = await response.text();
                        console.error(`Upload failed with status ${response.status}:`, errorText);
                        throw new Error(`Upload failed: ${response.status} - ${errorText}`);
                    }
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        setUploadedPdfs(prev => [...prev, result]);
                        
                        // Get first page thumbnail for display
                        let thumbnailImage = null;
                        try {
                            const pageResponse = await fetch(`/pdf/${result.pdf_id}/page/0`);
                            if (pageResponse.ok) {
                                const pageData = await pageResponse.json();
                                thumbnailImage = pageData.image_base64;
                            }
                        } catch (error) {
                            console.error('Failed to fetch PDF thumbnail:', error);
                        }
                        
                        // Add upload notification to chat with PDF data
                        const uploadMessage = {
                            id: Date.now(),
                            type: 'pdf_upload',
                            content: `üìÑ Uploaded and processed: ${result.filename} (${result.chunks_extracted} chunks from ${result.total_pages} pages)`,
                            timestamp: new Date(),
                            pdfData: result,
                            thumbnail: thumbnailImage
                        };
                        setMessages(prev => [...prev, uploadMessage]);
                        
                        return result;
                    } else {
                        throw new Error('Upload failed');
                    }
                } catch (error) {
                    console.error('PDF upload error:', error);
                    
                    const errorMessage = {
                        id: Date.now(),
                        type: 'error',
                        content: `Failed to upload PDF: ${error.message}`,
                        timestamp: new Date()
                    };
                    setMessages(prev => [...prev, errorMessage]);
                    
                    throw error;
                }
            };

            const exportJSON = () => {
                const lastMessage = messages[messages.length - 1];
                if (lastMessage && lastMessage.type === 'assistant') {
                    const blob = new Blob([JSON.stringify(lastMessage, null, 2)], 
                        { type: 'application/json' });
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = `genai-response-${Date.now()}.json`;
                    a.click();
                }
            };

            return (
                <div className="h-screen flex flex-col bg-slate-50">
                    {/* Header */}
                    <Header 
                        allowTavily={allowTavily}
                        setAllowTavily={setAllowTavily}
                        allowLlmKnowledge={allowLlmKnowledge}
                        setAllowLlmKnowledge={setAllowLlmKnowledge}
                        allowWebSearch={allowWebSearch}
                        setAllowWebSearch={setAllowWebSearch}
                        onClear={clearChat}
                        onExport={exportJSON}
                    />

                    {/* Main Content */}
                    <div className="flex-1 flex overflow-hidden">
                        {/* Left Rail */}
                        <LeftRail 
                            selectedAgent={selectedAgent}
                            onSelectAgent={setSelectedAgent}
                            onUseExample={useExample}
                        />

                        {/* Chat Pane */}
                        <ChatPane
                            messages={messages}
                            isLoading={isLoading}
                            inputText={inputText}
                            setInputText={setInputText}
                            selectedAgent={selectedAgent}
                            allowTavily={allowTavily}
                            setAllowTavily={setAllowTavily}
                            onSendMessage={sendMessage}
                            messagesEndRef={messagesEndRef}
                            uploadedPdfs={uploadedPdfs}
                            setUploadedPdfs={setUploadedPdfs}
                            uploadPdf={uploadPdf}
                        />

                        {/* Right Inspector */}
                        <RightInspector
                            activePanel={rightPanel}
                            setActivePanel={setRightPanel}
                            citations={citations}
                            toolTrace={toolTrace}
                            uploadedPdfs={uploadedPdfs}
                            selectedPdfChunk={selectedPdfChunk}
                            setSelectedPdfChunk={setSelectedPdfChunk}
                        />
                    </div>
                </div>
            );
        }

        // Header Component
        function Header({ allowTavily, setAllowTavily, allowLlmKnowledge, setAllowLlmKnowledge, allowWebSearch, setAllowWebSearch, onClear, onExport }) {
            return (
                <header className="bg-white border-b border-slate-200 px-6 py-3">
                    <div className="flex items-center justify-between">
                        <div className="flex items-center space-x-4">
                            <h1 className="text-xl font-semibold text-slate-800">
                                GenAI Studio <span className="text-sm font-normal text-slate-500">(Hackathon PoC)</span>
                            </h1>
                            <div className="flex items-center space-x-3">
                                <span className="px-2 py-1 text-xs bg-slate-100 text-slate-600 rounded-md">
                                    Local ‚Ä¢ No DB
                                </span>
                                <div className="space-y-2">
                                    <label className="flex items-center space-x-2 text-sm">
                                        <input
                                            type="checkbox"
                                            checked={allowTavily}
                                            onChange={(e) => setAllowTavily(e.target.checked)}
                                            className="rounded text-teal-600 focus:ring-teal-500"
                                        />
                                        <span className="text-slate-600">Allow Tavily (legacy)</span>
                                    </label>
                                    <label className="flex items-center space-x-2 text-sm">
                                        <input
                                            type="checkbox"
                                            checked={allowLlmKnowledge}
                                            onChange={(e) => setAllowLlmKnowledge(e.target.checked)}
                                            className="rounded text-blue-600 focus:ring-blue-500"
                                        />
                                        <span className="text-slate-600">LLM Knowledge Fallback</span>
                                    </label>
                                    <label className="flex items-center space-x-2 text-sm">
                                        <input
                                            type="checkbox"
                                            checked={allowWebSearch}
                                            onChange={(e) => setAllowWebSearch(e.target.checked)}
                                            className="rounded text-purple-600 focus:ring-purple-500"
                                        />
                                        <span className="text-slate-600">Web Search Fallback</span>
                                    </label>
                                </div>
                            </div>
                        </div>

                        <div className="flex items-center space-x-3">
                            <span className="px-2 py-1 text-xs bg-green-100 text-green-600 rounded-md">
                                PII Redaction ON
                            </span>
                            <button
                                onClick={onClear}
                                className="px-3 py-1 text-sm text-slate-600 hover:text-slate-800"
                            >
                                Clear
                            </button>
                            <button
                                onClick={onExport}
                                className="px-3 py-1 text-sm text-slate-600 hover:text-slate-800"
                            >
                                Export JSON
                            </button>
                            <span className="px-2 py-1 text-xs bg-amber-100 text-amber-700 rounded-md">
                                Demo ‚Äî not legal/credit advice
                            </span>
                        </div>
                    </div>
                </header>
            );
        }

        // Left Rail Component
        function LeftRail({ selectedAgent, onSelectAgent, onUseExample }) {
            return (
                <div className="w-64 bg-white border-r border-slate-200 flex flex-col">
                    <div className="p-4 border-b border-slate-200">
                        <h2 className="font-medium text-slate-800 mb-3">Agents</h2>
                    </div>
                    <div className="flex-1 overflow-y-auto">
                        {Object.entries(AGENTS).map(([key, agent]) => (
                            <AgentItem
                                key={key}
                                agentKey={key}
                                agent={agent}
                                isSelected={selectedAgent === key}
                                onSelect={() => onSelectAgent(key)}
                                onUseExample={() => onUseExample(key)}
                            />
                        ))}
                    </div>
                </div>
            );
        }

        // Agent Item Component
        function AgentItem({ agentKey, agent, isSelected, onSelect, onUseExample }) {
            return (
                <div 
                    className={`p-3 border-b border-slate-100 cursor-pointer hover:bg-slate-50 transition-colors ${
                        isSelected ? 'bg-teal-50 border-r-2 border-teal-500' : ''
                    }`}
                    onClick={onSelect}
                >
                    <div className="flex items-center justify-between">
                        <div className="flex items-center space-x-3">
                            <i className={`fas ${agent.icon} ${agent.color}`}></i>
                            <div>
                                <div className="font-medium text-sm text-slate-800">
                                    {agent.name}
                                </div>
                                <div className="text-xs text-slate-500 mt-1">
                                    {agent.tooltip}
                                </div>
                            </div>
                        </div>
                        <button
                            onClick={(e) => {
                                e.stopPropagation();
                                onUseExample();
                            }}
                            className="text-xs text-teal-600 hover:text-teal-700 p-1"
                            title="Try Example"
                        >
                            <i className="fas fa-play"></i>
                        </button>
                    </div>
                </div>
            );
        }

        // Chat Pane Component
        function ChatPane({ messages, isLoading, inputText, setInputText, selectedAgent, allowTavily, setAllowTavily, onSendMessage, messagesEndRef, uploadedPdfs, setUploadedPdfs, uploadPdf }) {
            const [isDragOver, setIsDragOver] = useState(false);
            
            const handleKeyPress = (e) => {
                if (e.key === 'Enter') {
                    if (e.shiftKey || e.ctrlKey) {
                        // Allow new line on Shift+Enter or Ctrl+Enter
                        return;
                    } else {
                        // Send message on plain Enter
                        e.preventDefault();
                        if (inputText.trim()) {
                            onSendMessage();
                        }
                    }
                }
            };

            const handleDragOver = (e) => {
                e.preventDefault();
                e.stopPropagation();
                setIsDragOver(true);
            };

            const handleDragLeave = (e) => {
                e.preventDefault();
                e.stopPropagation();
                setIsDragOver(false);
            };

            const handleDrop = async (e) => {
                e.preventDefault();
                e.stopPropagation();
                setIsDragOver(false);

                const files = Array.from(e.dataTransfer.files);
                console.log('Dropped files:', files.map(f => ({ name: f.name, type: f.type, size: f.size })));
                
                const pdfFiles = files.filter(file => 
                    file.type === 'application/pdf' || file.name.toLowerCase().endsWith('.pdf')
                );

                if (pdfFiles.length === 0) {
                    alert('Please drop PDF files only.');
                    return;
                }

                console.log('Processing PDF files:', pdfFiles.map(f => f.name));

                // Upload each PDF file
                for (const file of pdfFiles) {
                    try {
                        console.log(`Uploading PDF: ${file.name}`);
                        await uploadPdf(file);
                        console.log(`Successfully uploaded: ${file.name}`);
                    } catch (error) {
                        console.error(`Error uploading PDF ${file.name}:`, error);
                    }
                }
            };

            return (
                <div 
                    className="flex-1 flex flex-col bg-white relative"
                    onDragOver={handleDragOver}
                    onDragLeave={handleDragLeave}
                    onDrop={handleDrop}
                >
                    {/* Chat Header */}
                    <div className="p-4 border-b border-slate-200">
                        <div className="flex items-center justify-between">
                            <div className="flex items-center space-x-2">
                                <i className={`fas ${AGENTS[selectedAgent].icon} ${AGENTS[selectedAgent].color}`}></i>
                                <span className="font-medium text-slate-800">{AGENTS[selectedAgent].name}</span>
                                {selectedAgent !== 'smart' && (
                                    <span className="px-2 py-1 text-xs bg-slate-100 text-slate-600 rounded">
                                        Direct Mode
                                    </span>
                                )}
                            </div>
                            <div className="text-sm text-slate-500">
                                {messages.length} messages
                            </div>
                        </div>
                    </div>

                    {/* Messages */}
                    <div className="flex-1 overflow-y-auto p-4 space-y-4">
                        {messages.length === 0 && (
                            <div className="text-center py-12">
                                <i className={`fas ${AGENTS[selectedAgent].icon} text-4xl ${AGENTS[selectedAgent].color} mb-4`}></i>
                                <h3 className="text-lg font-medium text-slate-800 mb-2">
                                    {AGENTS[selectedAgent].name}
                                </h3>
                                <p className="text-slate-600 mb-4">
                                    {AGENTS[selectedAgent].tooltip}
                                </p>
                                <div className="text-sm text-slate-500">
                                    Try: "{AGENTS[selectedAgent].example}"
                                </div>
                            </div>
                        )}
                        
                        {messages.map((message) => (
                            <ChatMessage key={message.id} message={message} />
                        ))}
                        
                        {isLoading && (
                            <div className="flex justify-center py-4">
                                <div className="flex items-center space-x-2 text-slate-500">
                                    <div className="animate-spin h-4 w-4 border-2 border-teal-500 border-t-transparent rounded-full"></div>
                                    <span>Thinking...</span>
                                </div>
                            </div>
                        )}
                        <div ref={messagesEndRef} />
                    </div>

                    {/* Drag & Drop Overlay */}
                    {isDragOver && (
                        <div className="absolute inset-0 bg-teal-500 bg-opacity-10 border-2 border-dashed border-teal-500 flex items-center justify-center z-50">
                            <div className="bg-white p-6 rounded-lg shadow-lg text-center">
                                <i className="fas fa-file-pdf text-4xl text-teal-600 mb-2"></i>
                                <p className="text-lg font-medium text-slate-800 mb-1">Drop PDF files here</p>
                                <p className="text-sm text-slate-600">Upload documents to analyze and chat about</p>
                            </div>
                        </div>
                    )}

                    {/* Composer */}
                    <div className="border-t border-slate-200 p-4">
                        {/* PDF Upload Area */}
                        {uploadedPdfs.length > 0 && (
                            <div className="mb-3 p-2 bg-slate-50 rounded border border-slate-200">
                                <div className="text-xs text-slate-600 mb-2">üìÑ Attached PDFs:</div>
                                <div className="flex flex-wrap gap-2">
                                    {uploadedPdfs.map((pdf, index) => (
                                        <div key={index} className="flex items-center space-x-2 bg-white px-2 py-1 rounded border text-xs">
                                            <i className="fas fa-file-pdf text-red-600"></i>
                                            <span>{pdf.filename}</span>
                                            <span className="text-slate-500">({pdf.chunks_extracted} chunks)</span>
                                            <button
                                                onClick={() => setUploadedPdfs(prev => prev.filter((_, i) => i !== index))}
                                                className="text-slate-400 hover:text-red-600 ml-1"
                                            >
                                                <i className="fas fa-times"></i>
                                            </button>
                                        </div>
                                    ))}
                                </div>
                            </div>
                        )}

                        {/* Input Container */}
                        <div className="relative bg-white border border-slate-300 rounded-lg focus-within:border-teal-500 focus-within:ring-1 focus-within:ring-teal-500">
                            <div className="flex items-end">
                                {/* Plus Button */}
                                <div className="flex-shrink-0 p-2">
                                    <label className="cursor-pointer text-slate-500 hover:text-slate-700 transition-colors">
                                        <input
                                            type="file"
                                            accept=".pdf"
                                            className="hidden"
                                            onChange={async (e) => {
                                                const file = e.target.files[0];
                                                if (file) {
                                                    try {
                                                        await uploadPdf(file);
                                                    } catch (error) {
                                                        // Error already handled in uploadPdf
                                                    }
                                                    e.target.value = ''; // Reset input
                                                }
                                            }}
                                        />
                                        <div className="w-6 h-6 rounded-full border border-slate-300 flex items-center justify-center hover:bg-slate-50 transition-colors">
                                            <i className="fas fa-plus text-xs"></i>
                                        </div>
                                    </label>
                                </div>

                                {/* Text Input */}
                                <div className="flex-1 min-h-[44px]">
                                    <textarea
                                        value={inputText}
                                        onChange={(e) => setInputText(e.target.value)}
                                        onKeyPress={handleKeyPress}
                                        placeholder={selectedAgent === 'smart' 
                                            ? 'Ask about your documents, shop + finance, dispute, contracts...'
                                            : `Ask ${AGENTS[selectedAgent].name}...`
                                        }
                                        className="w-full px-2 py-2 border-0 bg-transparent resize-none focus:outline-none"
                                        rows={Math.min(inputText.split('\n').length, 4)}
                                        disabled={isLoading}
                                    />
                                </div>

                                {/* Send Button */}
                                <div className="flex-shrink-0 p-2">
                                    <button
                                        onClick={onSendMessage}
                                        disabled={isLoading || !inputText.trim()}
                                        className={`w-8 h-8 rounded-full flex items-center justify-center transition-all ${
                                            inputText.trim() && !isLoading
                                                ? 'bg-teal-600 text-white hover:bg-teal-700'
                                                : 'bg-slate-100 text-slate-400'
                                        }`}
                                    >
                                        <i className="fas fa-paper-plane text-sm"></i>
                                    </button>
                                </div>
                            </div>
                        </div>

                        {/* Footer Info */}
                        <div className="flex items-center justify-between mt-2">
                            <div className="flex items-center space-x-4">
                                {selectedAgent === 'smart' && (
                                    <label className="flex items-center space-x-1 text-xs text-slate-500">
                                        <input
                                            type="checkbox"
                                            checked={allowTavily}
                                            onChange={(e) => setAllowTavily(e.target.checked)}
                                            className="rounded"
                                        />
                                        <span>Use Tavily</span>
                                    </label>
                                )}
                            </div>
                            <div className="text-xs text-slate-400">
                                {inputText.length} chars ‚Ä¢ Enter to send ‚Ä¢ Shift+Enter for new line
                            </div>
                        </div>
                    </div>
                </div>
            );
        }

        // Chat Message Component
        function ChatMessage({ message }) {
            if (message.type === 'user') {
                return (
                    <div className="flex justify-end">
                        <div className="bg-teal-600 text-white px-4 py-2 rounded-lg max-w-md">
                            {message.content}
                        </div>
                    </div>
                );
            }

            if (message.type === 'error') {
                return (
                    <div className="flex">
                        <div className="bg-red-100 text-red-700 px-4 py-2 rounded-lg max-w-md">
                            <i className="fas fa-exclamation-triangle mr-2"></i>
                            {message.content}
                        </div>
                    </div>
                );
            }

            if (message.type === 'pdf_upload') {
                return (
                    <div className="flex">
                        <div className="bg-blue-50 border border-blue-200 px-4 py-3 rounded-lg max-w-md">
                            <div className="flex items-start space-x-3">
                                {message.thumbnail && (
                                    <div className="flex-shrink-0">
                                        <img 
                                            src={`data:image/png;base64,${message.thumbnail}`} 
                                            alt="PDF Thumbnail"
                                            className="w-16 h-20 object-cover rounded border border-slate-200 shadow-sm"
                                        />
                                    </div>
                                )}
                                <div className="flex-1">
                                    <div className="flex items-center space-x-2 mb-1">
                                        <i className="fas fa-file-pdf text-red-600"></i>
                                        <span className="font-medium text-sm text-slate-800">
                                            {message.pdfData?.filename}
                                        </span>
                                    </div>
                                    <div className="text-xs text-slate-600 space-y-1">
                                        <div>üìÑ {message.pdfData?.total_pages} pages</div>
                                        <div>üß© {message.pdfData?.chunks_extracted} chunks extracted</div>
                                        <div>‚ö° Processed in {message.pdfData?.processing_time?.toFixed(2)}s</div>
                                    </div>
                                    <div className="text-xs text-slate-500 mt-2">
                                        Ready for questions about this document
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                );
            }

            return (
                <div className="chat-message">
                    <div className="flex items-start space-x-3">
                        <div className={`w-8 h-8 rounded-full bg-slate-100 flex items-center justify-center`}>
                            <i className={`fas ${AGENTS[message.agent]?.icon || 'fa-robot'} text-slate-600`}></i>
                        </div>
                        <div className="flex-1">
                            {/* Message Header */}
                            <div className="flex items-center space-x-2 mb-2">
                                <span className="font-medium text-sm text-slate-800">
                                    {AGENTS[message.agent]?.name || message.agent}
                                </span>
                                <span className="text-xs text-slate-500">
                                    {message.timestamp.toLocaleTimeString()}
                                </span>
                                {message.latency && (
                                    <span className="text-xs text-slate-400">
                                        {Math.round(message.latency)}ms
                                    </span>
                                )}
                                {message.confidence && (
                                    <span className={`text-xs px-1 py-0.5 rounded ${
                                        message.confidence > 0.8 ? 'bg-green-100 text-green-600' :
                                        message.confidence > 0.6 ? 'bg-yellow-100 text-yellow-600' :
                                        'bg-red-100 text-red-600'
                                    }`}>
                                        {Math.round(message.confidence * 100)}%
                                    </span>
                                )}
                                {message.used_tavily && (
                                    <span className="text-xs bg-blue-100 text-blue-600 px-2 py-0.5 rounded">
                                        <i className="fas fa-globe mr-1"></i>
                                        Web Enhanced
                                    </span>
                                )}
                            </div>

                            {/* Message Content */}
                            <div className="prose prose-sm max-w-none text-slate-700">
                                {typeof message.content === 'string' ? (
                                    <ReactMarkdown 
                                        components={markdownComponents}
                                        className="markdown-content"
                                    >
                                        {message.content.replace(/\[REDACTED[^\]]*\]/g, '‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà')}
                                    </ReactMarkdown>
                                ) : (
                                    <pre className="text-sm bg-slate-50 p-3 rounded border overflow-x-auto">
                                        {JSON.stringify(message.content, null, 2)}
                                    </pre>
                                )}
                            </div>

                            {/* Generated Image Display */}
                            {message.image_data && (
                                <div className="mt-4">
                                    <div className="border border-slate-200 rounded-lg overflow-hidden bg-slate-50">
                                        <div className="p-3 bg-slate-100 border-b border-slate-200">
                                            <div className="flex items-center justify-between text-sm">
                                                <div className="flex items-center space-x-2">
                                                    <i className="fas fa-image text-violet-600"></i>
                                                    <span className="font-medium text-slate-800">Generated Image</span>
                                                    <span className="px-2 py-1 text-xs bg-violet-100 text-violet-700 rounded">
                                                        {message.image_format || 'PNG'}
                                                    </span>
                                                </div>
                                                <button
                                                    onClick={() => {
                                                        const link = document.createElement('a');
                                                        link.download = `generated-image-${Date.now()}.${(message.image_format || 'PNG').toLowerCase()}`;
                                                        link.href = `data:image/${(message.image_format || 'png').toLowerCase()};base64,${message.image_data}`;
                                                        link.click();
                                                    }}
                                                    className="text-slate-500 hover:text-slate-700"
                                                    title="Download Image"
                                                >
                                                    <i className="fas fa-download"></i>
                                                </button>
                                            </div>
                                        </div>
                                        <div className="p-4">
                                            <img
                                                src={`data:image/${(message.image_format || 'png').toLowerCase()};base64,${message.image_data}`}
                                                alt="Generated image"
                                                className="max-w-full h-auto rounded border border-slate-200 shadow-sm hover:shadow-md transition-shadow cursor-pointer"
                                                style={{ maxHeight: '400px', objectFit: 'contain' }}
                                                onClick={() => {
                                                    // Open full-size image in new window
                                                    const newWindow = window.open();
                                                    newWindow.document.write(`
                                                        <html>
                                                            <head><title>Generated Image</title></head>
                                                            <body style="margin:0; background:#000; display:flex; justify-content:center; align-items:center; min-height:100vh;">
                                                                <img src="data:image/${(message.image_format || 'png').toLowerCase()};base64,${message.image_data}" style="max-width:100%; max-height:100%; object-fit:contain;" />
                                                            </body>
                                                        </html>
                                                    `);
                                                }}
                                            />
                                        </div>
                                    </div>
                                </div>
                            )}

                            {/* Sources */}
                            {message.sources && message.sources.length > 0 && (
                                <div className="mt-3 flex flex-wrap gap-1">
                                    {message.sources.slice(0, 5).map((source, index) => (
                                        <button
                                            key={index}
                                            className="tool-chip text-xs bg-slate-100 hover:bg-slate-200 text-slate-600 px-2 py-1 rounded-md"
                                            title={source}
                                        >
                                            <i className="fas fa-quote-left mr-1"></i>
                                            ({index + 1})
                                        </button>
                                    ))}
                                </div>
                            )}
                            
                            {/* Fallback Information */}
                            {message.fallback_used && (
                                <div className="mt-2 px-3 py-2 bg-blue-50 border border-blue-200 rounded-lg">
                                    <div className="flex items-center space-x-2 text-sm">
                                        <i className="fas fa-route text-blue-600"></i>
                                        <span className="font-medium text-blue-800">
                                            Fallback Used: {message.fallback_used.replace('_', ' ')}
                                        </span>
                                    </div>
                                    {message.document_assessment && (
                                        <div className="mt-1 text-xs text-blue-700">
                                            <div>Quality Score: {(message.document_assessment.document_quality_score * 100).toFixed(0)}%</div>
                                            <div>Assessment: {message.document_assessment.reason}</div>
                                        </div>
                                    )}
                                </div>
                            )}
                        </div>
                    </div>
                </div>
            );
        }

        // Right Inspector Component
        function RightInspector({ activePanel, setActivePanel, citations, toolTrace, uploadedPdfs, selectedPdfChunk, setSelectedPdfChunk }) {
            return (
                <div className="w-80 bg-white border-l border-slate-200 flex flex-col">
                    {/* Panel Tabs */}
                    <div className="border-b border-slate-200">
                        <div className="flex">
                            {[
                                { id: 'citations', label: 'Citations', icon: 'fa-quote-left' },
                                { id: 'trace', label: 'Tool Trace', icon: 'fa-code' },
                                { id: 'docs', label: 'Doc Viewer', icon: 'fa-file-text' }
                            ].map(tab => (
                                <button
                                    key={tab.id}
                                    onClick={() => setActivePanel(tab.id)}
                                    className={`flex-1 px-3 py-2 text-sm font-medium border-b-2 ${
                                        activePanel === tab.id
                                            ? 'border-teal-500 text-teal-600'
                                            : 'border-transparent text-slate-500 hover:text-slate-700'
                                    }`}
                                >
                                    <i className={`fas ${tab.icon} mr-1`}></i>
                                    {tab.label}
                                </button>
                            ))}
                        </div>
                    </div>

                    {/* Panel Content */}
                    <div className="flex-1 overflow-y-auto p-4">
                        {activePanel === 'citations' && (
                            <CitationsPanel 
                                citations={citations} 
                                onPdfChunkClick={(filename, chunkId) => {
                                    // Switch to docs panel
                                    setActivePanel('docs');
                                    setSelectedPdfChunk(chunkId);
                                    
                                    // Find and auto-select the PDF by filename
                                    const matchingPdf = uploadedPdfs.find(pdf => 
                                        pdf.filename === filename
                                    );
                                    
                                    if (matchingPdf) {
                                        // This will be handled by the DocViewerPanel
                                        console.log(`Navigating to PDF: ${filename}, Chunk: ${chunkId}`);
                                    }
                                }}
                            />
                        )}
                        {activePanel === 'trace' && (
                            <ToolTracePanel toolTrace={toolTrace} />
                        )}
                        {activePanel === 'docs' && (
                            <DocViewerPanel 
                                uploadedPdfs={uploadedPdfs}
                                selectedPdfChunk={selectedPdfChunk}
                                setSelectedPdfChunk={setSelectedPdfChunk}
                            />
                        )}
                    </div>
                </div>
            );
        }

        // Citations Panel
        function CitationsPanel({ citations, onPdfChunkClick }) {
            if (citations.length === 0) {
                return (
                    <div className="text-center py-8 text-slate-500">
                        <i className="fas fa-quote-left text-2xl mb-2"></i>
                        <p>No citations yet</p>
                        <p className="text-xs mt-1">Sources will appear here</p>
                    </div>
                );
            }

            return (
                <div className="space-y-3">
                    {citations.map((citation, index) => {
                        // Parse different citation formats
                        let sourceName = citation;
                        let score = null;
                        let type = 'source';
                        let icon = 'fa-file-text';
                        
                        // Handle routing info (first citation)
                        if (citation.includes('üéØ Routed to:')) {
                            const match = citation.match(/üéØ Routed to: (\w+) \((\d+\.?\d*)% confidence\)/);
                            if (match) {
                                sourceName = `Routed to ${match[1]}`;
                                score = `${match[2]}% confidence`;
                                type = 'routing';
                                icon = 'fa-route';
                            }
                        }
                        // Handle score-based citations
                        else if (citation.includes(' - Score:')) {
                            const parts = citation.split(' - Score:');
                            sourceName = parts[0].trim();
                            score = `Score: ${parts[1].trim()}`;
                            type = 'document';
                            icon = 'fa-file-text';
                        }
                        // Handle PDF citations with chunk IDs
                        else if (citation.includes('.pdf') || citation.includes('pdf_') || citation.includes('chunk_')) {
                            type = 'pdf';
                            icon = 'fa-file-pdf';
                            
                            // Try to extract PDF filename and chunk ID
                            const pdfMatch = citation.match(/([^\/]+\.pdf)/);
                            const chunkMatch = citation.match(/(chunk_\w+|para_\d+|page_\d+)/);
                            
                            if (pdfMatch) {
                                sourceName = pdfMatch[1];
                                if (chunkMatch) {
                                    score = `Chunk: ${chunkMatch[1]}`;
                                    // Store chunk info for click handler
                                    citation.chunkId = chunkMatch[1];
                                    citation.filename = pdfMatch[1];
                                }
                            }
                        }
                        // Handle other citation formats
                        else if (citation.includes('.md')) {
                            type = 'document';
                            icon = 'fa-file-text';
                        }
                        else if (citation.includes('Web Enhanced') || citation.includes('Tavily')) {
                            type = 'web';
                            icon = 'fa-globe';
                        }
                        
                        return (
                            <div key={index} className={`border rounded-md p-3 ${
                                type === 'routing' ? 'border-teal-200 bg-teal-50' :
                                type === 'web' ? 'border-blue-200 bg-blue-50' :
                                type === 'pdf' ? 'border-red-200 bg-red-50' :
                                'border-slate-200'
                            }`}>
                                <div className="flex items-start justify-between mb-2">
                                    <div className="flex items-start space-x-2">
                                        <i className={`fas ${icon} text-sm mt-0.5 ${
                                            type === 'routing' ? 'text-teal-600' :
                                            type === 'web' ? 'text-blue-600' :
                                            type === 'pdf' ? 'text-red-600' :
                                            'text-slate-600'
                                        }`}></i>
                                        <div>
                                            <div className="text-sm font-medium text-slate-800">
                                                {sourceName}
                                            </div>
                                            {score && (
                                                <div className={`text-xs mt-1 ${
                                                    type === 'routing' ? 'text-teal-600' :
                                                    type === 'web' ? 'text-blue-600' :
                                                    type === 'pdf' ? 'text-red-600' :
                                                    'text-slate-500'
                                                }`}>
                                                    {score}
                                                </div>
                                            )}
                                        </div>
                                    </div>
                                    <span className={`text-xs px-2 py-1 rounded ${
                                        type === 'routing' ? 'bg-teal-100 text-teal-700' :
                                        type === 'web' ? 'bg-blue-100 text-blue-700' :
                                        'bg-slate-100 text-slate-600'
                                    }`}>
                                        ({index + 1})
                                    </span>
                                </div>
                                {type === 'document' && (
                                    <button className="text-xs text-slate-600 hover:text-slate-800">
                                        <i className="fas fa-eye mr-1"></i>
                                        View source
                                    </button>
                                )}
                                {type === 'pdf' && citation.chunkId && (
                                    <button 
                                        onClick={() => {
                                            // Switch to docs panel
                                            onPdfChunkClick(citation.filename, citation.chunkId);
                                        }}
                                        className="text-xs text-red-600 hover:text-red-800 transition-colors"
                                    >
                                        <i className="fas fa-external-link-alt mr-1"></i>
                                        View in PDF
                                    </button>
                                )}
                                {type === 'web' && (
                                    <div className="text-xs text-blue-600">
                                        <i className="fas fa-external-link-alt mr-1"></i>
                                        External source
                                    </div>
                                )}
                            </div>
                        );
                    })}
                </div>
            );
        }

        // Tool Trace Panel
        function ToolTracePanel({ toolTrace }) {
            if (toolTrace.length === 0) {
                return (
                    <div className="text-center py-8 text-slate-500">
                        <i className="fas fa-code text-2xl mb-2"></i>
                        <p>No trace yet</p>
                        <p className="text-xs mt-1">Tool calls will appear here</p>
                    </div>
                );
            }

            return (
                <div className="space-y-3">
                    {toolTrace.map((trace, index) => (
                        <div key={index} className="border border-slate-200 rounded-md">
                            <div className="p-3 border-b border-slate-100">
                                <div className="flex items-center justify-between">
                                    <span className="font-medium text-sm text-slate-800">
                                        {trace.tool}
                                    </span>
                                    <span className="text-xs text-slate-500">
                                        {trace.timestamp.toLocaleTimeString()}
                                    </span>
                                </div>
                            </div>
                            <div className="p-3">
                                <details className="text-xs">
                                    <summary className="cursor-pointer text-slate-600 mb-2">
                                        View details
                                    </summary>
                                    <pre className="bg-slate-50 p-2 rounded text-slate-700 overflow-x-auto">
                                        {JSON.stringify(trace.result, null, 2).slice(0, 500)}...
                                    </pre>
                                </details>
                            </div>
                        </div>
                    ))}
                </div>
            );
        }

        // Doc Viewer Panel  
        function DocViewerPanel({ uploadedPdfs, selectedPdfChunk, setSelectedPdfChunk }) {
            const [selectedPdf, setSelectedPdf] = useState(null);
            const [currentPage, setCurrentPage] = useState(0);
            const [pageData, setPageData] = useState(null);
            const [loading, setLoading] = useState(false);
            const [imgLoaded, setImgLoaded] = useState(null);
            const imgRef = useRef(null);
            
            useEffect(() => {
                if (selectedPdf && currentPage !== null) {
                    loadPageData();
                }
            }, [selectedPdf, currentPage]);
            
            // Auto-select PDF when chunk is selected from citations
            useEffect(() => {
                if (selectedPdfChunk && uploadedPdfs.length > 0 && !selectedPdf) {
                    // Find which PDF contains this chunk
                    const findPdfWithChunk = async () => {
                        for (const pdf of uploadedPdfs) {
                            try {
                                const response = await fetch(`/pdf/${pdf.pdf_id}/info`);
                                const pdfInfo = await response.json();
                                
                                // Check if this PDF has the selected chunk
                                const hasChunk = pdfInfo.chunks && pdfInfo.chunks.some(chunk => 
                                    chunk.chunk_id === selectedPdfChunk
                                );
                                
                                if (hasChunk) {
                                    setSelectedPdf(pdf);
                                    
                                    // Find the page containing this chunk
                                    const matchingChunk = pdfInfo.chunks.find(chunk => 
                                        chunk.chunk_id === selectedPdfChunk
                                    );
                                    
                                    if (matchingChunk) {
                                        setCurrentPage(matchingChunk.page_number || 0);
                                    }
                                    break;
                                }
                            } catch (error) {
                                console.error(`Error checking PDF ${pdf.filename}:`, error);
                            }
                        }
                    };
                    
                    findPdfWithChunk();
                }
            }, [selectedPdfChunk, uploadedPdfs]);
            
            const loadPageData = async () => {
                if (!selectedPdf) return;
                
                setLoading(true);
                try {
                    const response = await fetch(`/pdf/${selectedPdf.pdf_id}/page/${currentPage}`);
                    const data = await response.json();
                    setPageData(data);
                } catch (error) {
                    console.error('Error loading page data:', error);
                } finally {
                    setLoading(false);
                }
            };

            if (uploadedPdfs.length === 0) {
                return (
                    <div className="text-center py-8 text-slate-500">
                        <i className="fas fa-file-pdf text-2xl mb-2"></i>
                        <p>No PDFs uploaded</p>
                        <p className="text-xs mt-1">Upload a PDF to view it here</p>
                    </div>
                );
            }

            if (!selectedPdf) {
                return (
                    <div>
                        <h3 className="font-medium text-slate-800 mb-3">Uploaded PDFs</h3>
                        <div className="space-y-2">
                            {uploadedPdfs.map((pdf, index) => (
                                <button
                                    key={index}
                                    onClick={() => {
                                        setSelectedPdf(pdf);
                                        setCurrentPage(0);
                                    }}
                                    className="w-full p-3 text-left bg-slate-50 hover:bg-slate-100 rounded border border-slate-200"
                                >
                                    <div className="flex items-center space-x-2">
                                        <i className="fas fa-file-pdf text-red-600"></i>
                                        <div className="flex-1 min-w-0">
                                            <div className="font-medium text-sm text-slate-800 truncate">
                                                {pdf.filename}
                                            </div>
                                            <div className="text-xs text-slate-500">
                                                {pdf.total_pages} pages ‚Ä¢ {pdf.chunks_extracted} chunks
                                            </div>
                                        </div>
                                    </div>
                                </button>
                            ))}
                        </div>
                    </div>
                );
            }

            return (
                <div>
                    {/* PDF Header */}
                    <div className="border-b border-slate-200 pb-3 mb-3">
                        <div className="flex items-center justify-between">
                            <button 
                                onClick={() => setSelectedPdf(null)}
                                className="text-slate-500 hover:text-slate-700"
                            >
                                <i className="fas fa-arrow-left"></i>
                            </button>
                            <div className="text-sm font-medium text-slate-800 truncate">
                                {selectedPdf.filename}
                            </div>
                            <div className="text-xs text-slate-500">
                                {currentPage + 1}/{selectedPdf.total_pages}
                            </div>
                        </div>
                    </div>

                    {/* Page Navigation */}
                    <div className="flex items-center justify-center space-x-2 mb-3">
                        <button
                            onClick={() => setCurrentPage(Math.max(0, currentPage - 1))}
                            disabled={currentPage === 0}
                            className="px-2 py-1 text-xs bg-slate-100 hover:bg-slate-200 disabled:opacity-50 rounded"
                        >
                            <i className="fas fa-chevron-left"></i>
                        </button>
                        <span className="text-xs text-slate-600">
                            Page {currentPage + 1}
                        </span>
                        <button
                            onClick={() => setCurrentPage(Math.min(selectedPdf.total_pages - 1, currentPage + 1))}
                            disabled={currentPage >= selectedPdf.total_pages - 1}
                            className="px-2 py-1 text-xs bg-slate-100 hover:bg-slate-200 disabled:opacity-50 rounded"
                        >
                            <i className="fas fa-chevron-right"></i>
                        </button>
                    </div>

                    {/* PDF Page Viewer */}
                    <div className="relative">
                        {loading ? (
                            <div className="flex items-center justify-center py-8">
                                <div className="animate-spin h-6 w-6 border-2 border-teal-500 border-t-transparent rounded-full"></div>
                            </div>
                        ) : pageData ? (
                            <div className="relative border border-slate-200 rounded overflow-hidden">
                                <img
                                    ref={imgRef}
                                    src={`data:image/png;base64,${pageData.image_base64}`}
                                    alt={`Page ${currentPage + 1}`}
                                    className="w-full h-auto"
                                    onLoad={() => {
                                        // Force re-render of bounding boxes when image loads
                                        setImgLoaded(Date.now());
                                    }}
                                />
                                
                                {/* Bounding Box Overlays */}
                                {imgLoaded && pageData.chunks.map((chunk, index) => {
                                    // Calculate scale factor based on actual image display size
                                    const imgElement = imgRef.current;
                                    if (!imgElement) return null;
                                    
                                    // Get the natural (original) dimensions of the rendered image
                                    const naturalWidth = imgElement.naturalWidth;
                                    const naturalHeight = imgElement.naturalHeight;
                                    
                                    // Get the displayed dimensions
                                    const displayWidth = imgElement.offsetWidth;
                                    const displayHeight = imgElement.offsetHeight;
                                    
                                    // Our coordinates are based on the natural image size
                                    // We need to scale them to the displayed size
                                    const scaleX = displayWidth / naturalWidth;
                                    const scaleY = displayHeight / naturalHeight;
                                    
                                    return (
                                        <div
                                            key={chunk.chunk_id}
                                            className={`absolute border-2 cursor-pointer transition-all ${
                                                selectedPdfChunk === chunk.chunk_id 
                                                    ? 'border-teal-500 bg-teal-500 bg-opacity-20' 
                                                    : 'border-blue-500 bg-blue-500 bg-opacity-10 hover:bg-opacity-20'
                                            }`}
                                            style={{
                                                left: `${chunk.bbox.x * scaleX}px`,
                                                top: `${chunk.bbox.y * scaleY}px`, 
                                                width: `${chunk.bbox.width * scaleX}px`,
                                                height: `${chunk.bbox.height * scaleY}px`
                                            }}
                                            onClick={() => setSelectedPdfChunk(
                                                selectedPdfChunk === chunk.chunk_id ? null : chunk.chunk_id
                                            )}
                                            title={chunk.text}
                                        >
                                            <div className="absolute -top-5 -left-0.5 bg-blue-500 text-white text-xs px-1 rounded">
                                                {index + 1}
                                            </div>
                                        </div>
                                    );
                                })}
                            </div>
                        ) : null}
                    </div>

                    {/* Chunk Details */}
                    {selectedPdfChunk && pageData && (
                        <div className="mt-3 p-3 bg-slate-50 rounded border border-slate-200">
                            <h4 className="text-sm font-medium text-slate-800 mb-2">Selected Chunk</h4>
                            {(() => {
                                const chunk = pageData.chunks.find(c => c.chunk_id === selectedPdfChunk);
                                return chunk ? (
                                    <div>
                                        <div className="text-xs text-slate-600 mb-1">
                                            ID: {chunk.chunk_id} ‚Ä¢ Confidence: {(chunk.confidence * 100).toFixed(1)}%
                                        </div>
                                        <div className="text-sm text-slate-700 max-h-32 overflow-y-auto">
                                            {chunk.text}
                                        </div>
                                    </div>
                                ) : null;
                            })()}
                        </div>
                    )}
                </div>
            );
        }

        // Render the app
        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>


================================================
FILE: metrics/credit_metrics.csv
================================================
date,product,outstanding_balance,utilization_rate,payment_rate,net_charge_offs,provision_expense,yield
2025-01-31,CareCredit,2500000000.00,0.65,0.88,15000000.00,18000000.00,0.142
2025-01-31,Synchrony_Store_Card,4200000000.00,0.72,0.85,28000000.00,32000000.00,0.168
2025-01-31,PayPal_Credit,1800000000.00,0.58,0.90,8500000.00,10500000.00,0.135
2025-02-28,CareCredit,2520000000.00,0.66,0.87,15500000.00,18500000.00,0.144
2025-02-28,Synchrony_Store_Card,4250000000.00,0.73,0.84,29000000.00,33000000.00,0.170
2025-02-28,PayPal_Credit,1820000000.00,0.59,0.89,8800000.00,10800000.00,0.137
2025-03-31,CareCredit,2540000000.00,0.64,0.89,14800000.00,17800000.00,0.141
2025-03-31,Synchrony_Store_Card,4300000000.00,0.71,0.86,27500000.00,31500000.00,0.166
2025-03-31,PayPal_Credit,1840000000.00,0.57,0.91,8200000.00,10200000.00,0.133
2025-04-30,CareCredit,2580000000.00,0.67,0.86,16200000.00,19200000.00,0.146
2025-04-30,Synchrony_Store_Card,4380000000.00,0.74,0.83,30500000.00,34500000.00,0.172
2025-04-30,PayPal_Credit,1870000000.00,0.60,0.88,9100000.00,11100000.00,0.139
2025-05-31,CareCredit,2600000000.00,0.65,0.88,15800000.00,18800000.00,0.143
2025-05-31,Synchrony_Store_Card,4420000000.00,0.72,0.85,29800000.00,33800000.00,0.169
2025-05-31,PayPal_Credit,1890000000.00,0.58,0.90,8900000.00,10900000.00,0.136
2025-06-30,CareCredit,2650000000.00,0.68,0.85,16800000.00,19800000.00,0.148
2025-06-30,Synchrony_Store_Card,4480000000.00,0.75,0.82,31200000.00,35200000.00,0.174
2025-06-30,PayPal_Credit,1920000000.00,0.61,0.87,9400000.00,11400000.00,0.141
2025-07-31,CareCredit,2680000000.00,0.66,0.87,16200000.00,19200000.00,0.145
2025-07-31,Synchrony_Store_Card,4520000000.00,0.73,0.84,30800000.00,34800000.00,0.171
2025-07-31,PayPal_Credit,1950000000.00,0.59,0.89,9200000.00,11200000.00,0.138


================================================
FILE: metrics/delinquency_rates.csv
================================================
month,segment,vintage,total_accounts,delinq_30,delinq_60,delinq_90,charge_off_rate
2025-01-31,PRIME,2024Q1,45000,0.025,0.012,0.008,0.003
2025-01-31,PRIME,2024Q2,52000,0.022,0.010,0.007,0.002
2025-01-31,NEAR_PRIME,2024Q1,38000,0.045,0.025,0.018,0.008
2025-01-31,NEAR_PRIME,2024Q2,41000,0.042,0.023,0.016,0.007
2025-01-31,SUBPRIME,2024Q1,28000,0.085,0.055,0.042,0.025
2025-01-31,SUBPRIME,2024Q2,31000,0.082,0.052,0.039,0.023
2025-02-28,PRIME,2024Q1,44800,0.028,0.014,0.009,0.004
2025-02-28,PRIME,2024Q2,51800,0.024,0.012,0.008,0.003
2025-02-28,NEAR_PRIME,2024Q1,37900,0.048,0.027,0.020,0.009
2025-02-28,NEAR_PRIME,2024Q2,40800,0.045,0.025,0.018,0.008
2025-02-28,SUBPRIME,2024Q1,27800,0.088,0.058,0.045,0.027
2025-02-28,SUBPRIME,2024Q2,30900,0.085,0.055,0.042,0.025
2025-03-31,PRIME,2024Q1,44600,0.026,0.013,0.008,0.003
2025-03-31,PRIME,2024Q2,51600,0.023,0.011,0.007,0.002
2025-03-31,NEAR_PRIME,2024Q1,37750,0.046,0.026,0.019,0.008
2025-03-31,NEAR_PRIME,2024Q2,40650,0.043,0.024,0.017,0.007
2025-03-31,SUBPRIME,2024Q1,27650,0.086,0.056,0.043,0.026
2025-03-31,SUBPRIME,2024Q2,30750,0.083,0.053,0.040,0.024
2025-04-30,PRIME,2024Q1,44400,0.029,0.015,0.010,0.005
2025-04-30,PRIME,2024Q2,51400,0.026,0.013,0.009,0.004
2025-04-30,NEAR_PRIME,2024Q1,37600,0.049,0.028,0.021,0.010
2025-04-30,NEAR_PRIME,2024Q2,40500,0.046,0.026,0.019,0.009
2025-04-30,SUBPRIME,2024Q1,27500,0.089,0.059,0.046,0.028
2025-04-30,SUBPRIME,2024Q2,30600,0.086,0.056,0.043,0.026
2025-05-31,PRIME,2024Q1,44200,0.027,0.014,0.009,0.004
2025-05-31,PRIME,2024Q2,51200,0.024,0.012,0.008,0.003
2025-05-31,NEAR_PRIME,2024Q1,37450,0.047,0.027,0.020,0.009
2025-05-31,NEAR_PRIME,2024Q2,40350,0.044,0.025,0.018,0.008
2025-05-31,SUBPRIME,2024Q1,27350,0.087,0.057,0.044,0.027
2025-05-31,SUBPRIME,2024Q2,30450,0.084,0.054,0.041,0.025
2025-06-30,PRIME,2024Q1,44000,0.030,0.016,0.011,0.006
2025-06-30,PRIME,2024Q2,51000,0.027,0.014,0.010,0.005
2025-06-30,NEAR_PRIME,2024Q1,37300,0.050,0.029,0.022,0.011
2025-06-30,NEAR_PRIME,2024Q2,40200,0.047,0.027,0.020,0.010
2025-06-30,SUBPRIME,2024Q1,27200,0.090,0.060,0.047,0.029
2025-06-30,SUBPRIME,2024Q2,30300,0.087,0.057,0.044,0.027
2025-07-31,PRIME,2024Q1,43800,0.025,0.012,0.008,0.003
2025-07-31,PRIME,2024Q2,50800,0.022,0.010,0.007,0.002
2025-07-31,NEAR_PRIME,2024Q1,37150,0.044,0.024,0.017,0.007
2025-07-31,NEAR_PRIME,2024Q2,40050,0.041,0.022,0.015,0.006
2025-07-31,SUBPRIME,2024Q1,27050,0.084,0.053,0.040,0.024
2025-07-31,SUBPRIME,2024Q2,30150,0.081,0.050,0.037,0.022


================================================
FILE: metrics/portfolio_spend.csv
================================================
date,merchant,promo_type,spend_amount,transaction_count,avg_ticket,new_customers
2025-07-01,HomeDepot,0_APR_12_MONTH,2450000.50,1200,2041.67,85
2025-07-01,HomeDepot,STANDARD,890000.25,890,1000.00,45
2025-07-01,Amazon,0_APR_6_MONTH,3200000.75,2400,1333.33,120
2025-07-01,Amazon,STANDARD,1800000.00,1800,1000.00,90
2025-07-01,BestBuy,0_APR_18_MONTH,1850000.00,925,2000.00,78
2025-07-02,HomeDepot,0_APR_12_MONTH,2380000.00,1190,2000.00,82
2025-07-02,HomeDepot,STANDARD,920000.00,920,1000.00,48
2025-07-02,Amazon,0_APR_6_MONTH,3150000.00,2300,1369.57,118
2025-07-02,Amazon,STANDARD,1750000.00,1750,1000.00,88
2025-07-02,BestBuy,0_APR_18_MONTH,1900000.00,950,2000.00,80
2025-07-15,HomeDepot,0_APR_12_MONTH,2600000.00,1300,2000.00,95
2025-07-15,HomeDepot,STANDARD,950000.00,950,1000.00,52
2025-07-15,Amazon,0_APR_6_MONTH,3400000.00,2550,1333.33,135
2025-07-15,Amazon,STANDARD,1900000.00,1900,1000.00,95
2025-07-15,BestBuy,0_APR_18_MONTH,2100000.00,1050,2000.00,88
2025-07-30,HomeDepot,0_APR_12_MONTH,2800000.00,1400,2000.00,105
2025-07-30,HomeDepot,STANDARD,980000.00,980,1000.00,55
2025-07-30,Amazon,0_APR_6_MONTH,3600000.00,2700,1333.33,145
2025-07-30,Amazon,STANDARD,2000000.00,2000,1000.00,100
2025-07-30,BestBuy,0_APR_18_MONTH,2200000.00,1100,2000.00,92
2025-07-31,HomeDepot,0_APR_12_MONTH,2750000.00,1375,2000.00,102
2025-07-31,HomeDepot,STANDARD,975000.00,975,1000.00,54
2025-07-31,Amazon,0_APR_6_MONTH,3550000.00,2665,1332.08,142
2025-07-31,Amazon,STANDARD,1950000.00,1950,1000.00,98
2025-07-31,BestBuy,0_APR_18_MONTH,2150000.00,1075,2000.00,90
2025-08-01,HomeDepot,0_APR_12_MONTH,1200000.00,600,2000.00,45
2025-08-01,HomeDepot,STANDARD,880000.00,880,1000.00,42
2025-08-01,Amazon,0_APR_6_MONTH,1500000.00,1125,1333.33,68
2025-08-01,Amazon,STANDARD,1650000.00,1650,1000.00,85
2025-08-01,BestBuy,0_APR_18_MONTH,1850000.00,925,2000.00,78
2025-08-02,HomeDepot,0_APR_12_MONTH,1180000.00,590,2000.00,44
2025-08-02,HomeDepot,STANDARD,860000.00,860,1000.00,41
2025-08-02,Amazon,0_APR_6_MONTH,1480000.00,1110,1333.33,67
2025-08-02,Amazon,STANDARD,1620000.00,1620,1000.00,83
2025-08-02,BestBuy,0_APR_18_MONTH,1800000.00,900,2000.00,76
2025-08-05,HomeDepot,0_APR_12_MONTH,1150000.00,575,2000.00,43
2025-08-05,HomeDepot,STANDARD,840000.00,840,1000.00,40
2025-08-05,Amazon,0_APR_6_MONTH,1450000.00,1087,1333.95,65
2025-08-05,Amazon,STANDARD,1580000.00,1580,1000.00,81
2025-08-05,BestBuy,0_APR_18_MONTH,1750000.00,875,2000.00,74


================================================
FILE: metrics/promo_performance.csv
================================================
date,promo_id,promo_name,start_date,end_date,applications,approvals,approval_rate,activation_rate,spend_per_approval
2025-07-01,PROMO_HD_001,HomeDepot Summer Sale,2025-06-15,2025-07-31,1500,1200,0.80,0.85,2250.50
2025-07-01,PROMO_AMZ_001,Amazon Prime Day,2025-07-10,2025-07-20,2800,2240,0.80,0.90,1850.25
2025-07-01,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,950,760,0.80,0.88,2150.75
2025-07-02,PROMO_HD_001,HomeDepot Summer Sale,2025-06-15,2025-07-31,1480,1184,0.80,0.86,2200.00
2025-07-02,PROMO_AMZ_001,Amazon Prime Day,2025-07-10,2025-07-20,2750,2200,0.80,0.91,1825.50
2025-07-02,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,970,776,0.80,0.87,2175.25
2025-07-15,PROMO_HD_001,HomeDepot Summer Sale,2025-06-15,2025-07-31,1650,1320,0.80,0.87,2300.75
2025-07-15,PROMO_AMZ_001,Amazon Prime Day,2025-07-10,2025-07-20,3200,2560,0.80,0.92,1950.00
2025-07-15,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1100,880,0.80,0.89,2225.50
2025-07-30,PROMO_HD_001,HomeDepot Summer Sale,2025-06-15,2025-07-31,1750,1400,0.80,0.88,2400.25
2025-07-30,PROMO_AMZ_001,Amazon Prime Day,2025-07-10,2025-07-20,3400,2720,0.80,0.93,2050.75
2025-07-30,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1150,920,0.80,0.90,2275.00
2025-07-31,PROMO_HD_001,HomeDepot Summer Sale,2025-06-15,2025-07-31,1800,1440,0.80,0.89,2450.50
2025-07-31,PROMO_AMZ_001,Amazon Prime Day,2025-07-10,2025-07-20,3500,2800,0.80,0.94,2100.25
2025-07-31,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1200,960,0.80,0.91,2300.75
2025-08-01,PROMO_HD_002,HomeDepot Fall Prep,2025-08-01,2025-08-31,800,640,0.80,0.75,1850.00
2025-08-01,PROMO_AMZ_002,Amazon Back to School,2025-08-01,2025-08-15,1200,960,0.80,0.82,1650.25
2025-08-01,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1180,944,0.80,0.89,2275.50
2025-08-02,PROMO_HD_002,HomeDepot Fall Prep,2025-08-01,2025-08-31,820,656,0.80,0.76,1875.25
2025-08-02,PROMO_AMZ_002,Amazon Back to School,2025-08-01,2025-08-15,1180,944,0.80,0.83,1675.00
2025-08-02,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1160,928,0.80,0.88,2250.75
2025-08-05,PROMO_HD_002,HomeDepot Fall Prep,2025-08-01,2025-08-31,850,680,0.80,0.77,1900.50
2025-08-05,PROMO_AMZ_002,Amazon Back to School,2025-08-01,2025-08-15,1150,920,0.80,0.84,1700.75
2025-08-05,PROMO_BB_001,BestBuy Back to School,2025-07-01,2025-08-31,1140,912,0.80,0.87,2225.25


================================================
FILE: src/App.tsx
================================================
import React, { useState, useEffect, useRef } from 'react';
import { Message, ChatRequest, ChatResponse, UploadedPdf } from './types';
import { AGENTS } from './config/agents';
import Header from './components/Header';
import LeftRail from './components/LeftRail';
import ChatPane from './components/ChatPane';
import RightInspector from './components/RightInspector';

function App() {
  const [selectedAgent, setSelectedAgent] = useState('smart');
  const [allowTavily, setAllowTavily] = useState(false);
  const [allowLlmKnowledge, setAllowLlmKnowledge] = useState(true);
  const [allowWebSearch, setAllowWebSearch] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputText, setInputText] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [rightPanel, setRightPanel] = useState('citations');
  const [citations, setCitations] = useState<string[]>([]);
  const [toolTrace, setToolTrace] = useState<any[]>([]);
  const [uploadedPdfs, setUploadedPdfs] = useState<UploadedPdf[]>([]);
  const [selectedPdfChunk, setSelectedPdfChunk] = useState(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // Auto-scroll to bottom when messages change
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  const sendMessage = async () => {
    if (!inputText.trim()) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: inputText,
      agent: 'user',
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setInputText('');
    setIsLoading(true);

    try {
      const endpoint = selectedAgent === 'smart' ? '/chat' : `/agent/${selectedAgent}`;
      const payload: ChatRequest | any = selectedAgent === 'smart' 
        ? { 
            message: inputText, 
            allow_tavily: allowTavily,
            allow_llm_knowledge: allowLlmKnowledge,
            allow_web_search: allowWebSearch
          }
        : selectedAgent === 'imagegen'
        ? { prompt: inputText, include_text: true, style_hints: [] }
        : { query: inputText };

      const response = await fetch(endpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload)
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const result: ChatResponse = await response.json();
      
      const aiMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: result.response,
        agent: result.agent,
        confidence: result.confidence,
        sources: result.sources,
        used_tavily: result.used_tavily,
        fallback_used: result.fallback_used,
        document_assessment: result.document_assessment,
        image_data: result.image_data,
        image_format: result.image_format,
        timestamp: new Date()
      };

      setMessages(prev => [...prev, aiMessage]);
      setCitations(result.sources || []);
    } catch (error) {
      console.error('Error sending message:', error);
      const errorMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: `Error: ${error instanceof Error ? error.message : 'Unknown error occurred'}`,
        agent: 'system',
        timestamp: new Date()
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  const uploadPdf = async (file: File) => {
    const formData = new FormData();
    formData.append('file', file);

    try {
      const response = await fetch('/upload/pdf', {
        method: 'POST',
        body: formData
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`Upload failed with status ${response.status}:`, errorText);
        throw new Error(`Upload failed: ${response.status} - ${errorText}`);
      }

      const result = await response.json();
      
      // Add PDF upload message
      const pdfMessage: Message = {
        id: Date.now().toString(),
        role: 'user',
        content: `Uploaded PDF: ${file.name}`,
        agent: 'user',
        timestamp: new Date(),
        pdfData: {
          filename: result.filename,
          total_pages: result.total_pages,
          chunks_extracted: result.chunks_extracted,
          processing_time: result.processing_time,
          file_size: result.file_size
        }
      };

      setMessages(prev => [...prev, pdfMessage]);
      setUploadedPdfs(prev => [...prev, {
        pdf_id: result.pdf_id,
        filename: result.filename,
        total_pages: result.total_pages,
        chunks: result.chunks_extracted,
        processing_time: result.processing_time
      }]);
    } catch (error) {
      console.error('PDF upload error:', error);
    }
  };

  const handleSelectAgent = (agent: string) => {
    setSelectedAgent(agent);
  };

  const handleUseExample = (agent: string) => {
    setSelectedAgent(agent);
    setInputText(AGENTS[agent]?.example || '');
  };

  const clearChat = () => {
    setMessages([]);
    setCitations([]);
    setToolTrace([]);
  };

  const exportJSON = () => {
    const lastMessage = messages[messages.length - 1];
    if (lastMessage && lastMessage.role === 'assistant') {
      const blob = new Blob([JSON.stringify(lastMessage, null, 2)], { type: 'application/json' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `genai-response-${Date.now()}.json`;
      a.click();
      URL.revokeObjectURL(url);
    }
  };

  return (
    <div className="h-screen flex flex-col bg-slate-50">
      {/* Header */}
      <Header 
        allowTavily={allowTavily}
        setAllowTavily={setAllowTavily}
        allowLlmKnowledge={allowLlmKnowledge}
        setAllowLlmKnowledge={setAllowLlmKnowledge}
        allowWebSearch={allowWebSearch}
        setAllowWebSearch={setAllowWebSearch}
        onClear={clearChat}
        onExport={exportJSON}
      />

      {/* Main Content */}
      <div className="flex-1 flex overflow-hidden">
        {/* Left Rail */}
        <LeftRail 
          selectedAgent={selectedAgent}
          onSelectAgent={handleSelectAgent}
          onUseExample={handleUseExample}
        />

        {/* Chat Pane */}
        <ChatPane 
          messages={messages}
          isLoading={isLoading}
          inputText={inputText}
          setInputText={setInputText}
          selectedAgent={selectedAgent}
          onSendMessage={sendMessage}
          messagesEndRef={messagesEndRef}
          uploadPdf={uploadPdf}
        />

        {/* Right Inspector */}
        <RightInspector 
          activePanel={rightPanel}
          setActivePanel={setRightPanel}
          citations={citations}
          toolTrace={toolTrace}
          uploadedPdfs={uploadedPdfs}
          selectedPdfChunk={selectedPdfChunk}
          setSelectedPdfChunk={setSelectedPdfChunk}
        />
      </div>
    </div>
  );
}

export default App;


================================================
FILE: src/index.css
================================================
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  html, body {
    @apply h-full;
  }
}

@layer components {
  .tool-chip {
    @apply transition-all duration-200 ease-in-out;
  }
  
  .tool-chip:hover {
    @apply transform -translate-y-1 shadow-md;
  }
  
  .redacted-text {
    @apply bg-slate-800 text-slate-800 px-2 py-1 rounded select-none;
    background-image: repeating-linear-gradient(45deg, transparent, transparent 2px, rgba(255,255,255,.1) 2px, rgba(255,255,255,.1) 4px);
    background-repeat: repeat-x;
    background-position: 0 50%;
    color: transparent;
  }
  
  .redacted-text:hover::after {
    content: " (Redacted)";
    @apply text-slate-400 text-xs bg-slate-700 px-1.5 py-0.5 rounded ml-1;
  }
  
  .markdown-content {
    @apply leading-relaxed;
  }
  
  .markdown-content pre {
    @apply my-4 relative;
  }
  
  .markdown-content code {
    @apply font-mono;
  }
  
  .markdown-content pre code {
    @apply text-slate-100 bg-transparent p-0 rounded-none;
  }
}

/* Syntax highlighting overrides */
.hljs {
  @apply bg-slate-900 text-slate-100 !important;
}

.hljs-keyword { @apply text-amber-400 !important; }
.hljs-string { @apply text-emerald-400 !important; }
.hljs-comment { @apply text-slate-500 !important; }
.hljs-function { @apply text-blue-400 !important; }
.hljs-variable { @apply text-purple-400 !important; }
.hljs-number { @apply text-pink-400 !important; }
.hljs-built_in { @apply text-cyan-400 !important; }


================================================
FILE: src/main.tsx
================================================
import React from 'react'
import ReactDOM from 'react-dom/client'
import App from './App.tsx'
import './index.css'

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>,
)


================================================
FILE: src/types.ts
================================================
export interface Agent {
  name: string;
  icon: string;
  color: string;
  example: string;
  tooltip: string;
}

export interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  agent: string;
  confidence?: number;
  sources?: string[];
  used_tavily?: boolean;
  fallback_used?: string | null;
  document_assessment?: DocumentAssessment | null;
  image_data?: string | null;
  image_format?: string | null;
  timestamp: Date;
  pdfData?: PdfData;
}

export interface DocumentAssessment {
  sufficient: boolean;
  confidence: number;
  reason: string;
  document_quality_score: number;
  semantic_relevance: number;
  coverage_score: number;
  answer_sufficiency: number;
}

export interface PdfData {
  filename: string;
  total_pages: number;
  chunks_extracted: number;
  processing_time: number;
  file_size: number;
}

export interface ChatRequest {
  message: string;
  allow_tavily?: boolean;
  allow_llm_knowledge?: boolean;
  allow_web_search?: boolean;
}

export interface ChatResponse {
  response: string;
  agent: string;
  confidence: number;
  sources: string[];
  used_tavily: boolean;
  fallback_used?: string | null;
  document_assessment?: DocumentAssessment | null;
  image_data?: string | null;
  image_format?: string | null;
}

export interface UploadedPdf {
  pdf_id: string;
  filename: string;
  total_pages: number;
  chunks: number;
  processing_time: number;
}


================================================
FILE: src/components/ChatMessage.tsx
================================================
import React from 'react';
import { Message } from '../types';
import { AGENTS } from '../config/agents';
import MarkdownRenderer from './MarkdownRenderer';

interface ChatMessageProps {
  message: Message;
}

const ChatMessage: React.FC<ChatMessageProps> = ({ message }) => {
  if (message.role === 'user') {
    return (
      <div className="chat-message animate-fade-in">
        <div className="flex items-start space-x-3 justify-end">
          <div className="max-w-3xl">
            <div className="bg-teal-600 text-white px-4 py-2 rounded-2xl rounded-tr-sm">
              <p className="text-sm leading-relaxed whitespace-pre-wrap">{message.content}</p>
            </div>
            {message.pdfData && (
              <div className="mt-2 p-3 bg-red-50 border border-red-200 rounded-lg max-w-sm">
                <div className="flex items-center space-x-2">
                  <div className="w-8 h-8 bg-red-100 rounded flex items-center justify-center flex-shrink-0">
                    <i className="fas fa-file-pdf text-red-600"></i>
                  </div>
                  <div className="flex-1">
                    <div className="flex items-center space-x-2 mb-1">
                      <i className="fas fa-file-pdf text-red-600"></i>
                      <span className="font-medium text-sm text-slate-800">
                        {message.pdfData.filename}
                      </span>
                    </div>
                    <div className="text-xs text-slate-600 space-y-1">
                      <div>üìÑ {message.pdfData.total_pages} pages</div>
                      <div>üß© {message.pdfData.chunks_extracted} chunks extracted</div>
                      <div>‚ö° Processed in {message.pdfData.processing_time?.toFixed(2)}s</div>
                    </div>
                    <div className="text-xs text-slate-500 mt-2">
                      Ready for questions about this document
                    </div>
                  </div>
                </div>
              </div>
            )}
          </div>
          <div className="w-8 h-8 rounded-full bg-teal-600 flex items-center justify-center text-white flex-shrink-0">
            <i className="fas fa-user text-sm"></i>
          </div>
        </div>
      </div>
    );
  }

  return (
    <div className="chat-message animate-fade-in">
      <div className="flex items-start space-x-3">
        <div className="w-8 h-8 rounded-full bg-slate-100 flex items-center justify-center">
          <i className={`fas ${AGENTS[message.agent]?.icon || 'fa-robot'} text-slate-600`}></i>
        </div>
        <div className="flex-1 max-w-4xl">
          {/* Message Header */}
          <div className="flex items-center space-x-2 mb-2">
            <span className="font-medium text-slate-700">
              {AGENTS[message.agent]?.name || 'AI Assistant'}
            </span>
            {message.confidence !== undefined && (
              <span className="px-2 py-0.5 text-xs bg-slate-100 text-slate-600 rounded-full">
                {(message.confidence * 100).toFixed(0)}%
              </span>
            )}
          </div>

          {/* Message Content */}
          <MarkdownRenderer content={message.content} />

          {/* Image Display */}
          {message.image_data && (
            <div className="mt-4 max-w-lg">
              <div className="border border-slate-200 rounded-lg overflow-hidden">
                <div className="bg-slate-50 px-3 py-2 border-b border-slate-200">
                  <span className="text-sm text-slate-600 flex items-center">
                    <i className="fas fa-image mr-2"></i>
                    Generated Image ({message.image_format})
                  </span>
                </div>
                <div className="p-4">
                  <img
                    src={`data:image/${message.image_format};base64,${message.image_data}`}
                    alt="Generated content"
                    className="max-w-full h-auto rounded"
                  />
                </div>
              </div>
            </div>
          )}

          {/* Sources */}
          {message.sources && message.sources.length > 0 && (
            <div className="mt-3 flex flex-wrap gap-1">
              {message.sources.slice(0, 5).map((source, index) => (
                <button
                  key={index}
                  className="tool-chip text-xs bg-slate-100 hover:bg-slate-200 text-slate-600 px-2 py-1 rounded-md"
                  title={source}
                >
                  <i className="fas fa-quote-left mr-1"></i>
                  ({index + 1})
                </button>
              ))}
            </div>
          )}
          
          {/* Fallback Information */}
          {message.fallback_used && (
            <div className="mt-2 px-3 py-2 bg-blue-50 border border-blue-200 rounded-lg">
              <div className="flex items-center space-x-2 text-sm">
                <i className="fas fa-route text-blue-600"></i>
                <span className="font-medium text-blue-800">
                  Fallback Used: {message.fallback_used.replace('_', ' ')}
                </span>
              </div>
              {message.document_assessment && (
                <div className="mt-1 text-xs text-blue-700">
                  <div>Quality Score: {(message.document_assessment.document_quality_score * 100).toFixed(0)}%</div>
                  <div>Assessment: {message.document_assessment.reason}</div>
                </div>
              )}
            </div>
          )}
        </div>
      </div>
    </div>
  );
};

export default ChatMessage;


================================================
FILE: src/components/ChatPane.tsx
================================================
import React, { useState, useRef } from 'react';
import { Message } from '../types';
import { AGENTS } from '../config/agents';
import ChatMessage from './ChatMessage';

interface ChatPaneProps {
  messages: Message[];
  isLoading: boolean;
  inputText: string;
  setInputText: (text: string) => void;
  selectedAgent: string;
  onSendMessage: () => void;
  messagesEndRef: React.RefObject<HTMLDivElement>;
  uploadPdf: (file: File) => void;
}

const ChatPane: React.FC<ChatPaneProps> = ({
  messages,
  isLoading,
  inputText,
  setInputText,
  selectedAgent,
  onSendMessage,
  messagesEndRef,
  uploadPdf
}) => {
  const [isDragOver, setIsDragOver] = useState(false);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter') {
      if (e.shiftKey || e.ctrlKey) {
        // Allow new line on Shift+Enter or Ctrl+Enter
        return;
      } else {
        // Send message on plain Enter
        e.preventDefault();
        if (inputText.trim()) {
          onSendMessage();
        }
      }
    }
  };

  const handleDragOver = (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragOver(true);
  };

  const handleDragLeave = (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragOver(false);
  };

  const handleDrop = async (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragOver(false);

    const files = Array.from(e.dataTransfer.files);
    console.log('Dropped files:', files.map(f => ({ name: f.name, type: f.type, size: f.size })));
    
    const pdfFiles = files.filter(file => 
      file.type === 'application/pdf' || file.name.toLowerCase().endsWith('.pdf')
    );

    if (pdfFiles.length === 0) {
      alert('Please drop PDF files only.');
      return;
    }

    // Upload each PDF file
    for (const file of pdfFiles) {
      try {
        console.log(`Uploading PDF: ${file.name}`);
        await uploadPdf(file);
        console.log(`Successfully uploaded: ${file.name}`);
      } catch (error) {
        console.error(`Error uploading PDF ${file.name}:`, error);
      }
    }
  };

  const handleFileUpload = () => {
    fileInputRef.current?.click();
  };

  const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file && file.type === 'application/pdf') {
      uploadPdf(file);
    }
  };

  return (
    <div 
      className="flex-1 flex flex-col bg-white relative"
      onDragOver={handleDragOver}
      onDragLeave={handleDragLeave}
      onDrop={handleDrop}
    >
      {/* Drag overlay */}
      {isDragOver && (
        <div className="absolute inset-0 bg-teal-50 border-2 border-dashed border-teal-300 flex items-center justify-center z-10">
          <div className="text-center">
            <i className="fas fa-file-pdf text-4xl text-teal-600 mb-4"></i>
            <p className="text-teal-800 font-medium">Drop PDF files here</p>
          </div>
        </div>
      )}

      {/* Chat Header */}
      <div className="bg-white border-b border-slate-200 px-6 py-3 flex items-center justify-between">
        <div className="flex items-center space-x-3">
          <div className="flex items-center space-x-2">
            <i className={`fas ${AGENTS[selectedAgent]?.icon || 'fa-robot'} ${AGENTS[selectedAgent]?.color || 'text-slate-600'}`}></i>
            <span className="font-medium text-slate-800">{AGENTS[selectedAgent]?.name || 'AI Assistant'}</span>
          </div>
          <span className="px-2 py-1 text-xs bg-slate-100 text-slate-600 rounded-md">
            {messages.length} messages
          </span>
        </div>
        <div className="flex items-center space-x-2 text-sm text-slate-500">
          <i className="fas fa-circle text-green-500"></i>
          <span>Online</span>
        </div>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-6 space-y-6">
        {messages.length === 0 ? (
          <div className="text-center py-12">
            <div className="w-16 h-16 bg-slate-100 rounded-full flex items-center justify-center mx-auto mb-4">
              <i className={`fas ${AGENTS[selectedAgent]?.icon || 'fa-robot'} ${AGENTS[selectedAgent]?.color || 'text-slate-400'} text-2xl`}></i>
            </div>
            <h3 className="text-lg font-medium text-slate-800 mb-2">
              Chat with {AGENTS[selectedAgent]?.name || 'AI Assistant'}
            </h3>
            <p className="text-slate-600 max-w-md mx-auto mb-4">
              {AGENTS[selectedAgent]?.tooltip || 'Start a conversation by typing your message below.'}
            </p>
            <div className="text-sm text-slate-500">
              <p>Try: "{AGENTS[selectedAgent]?.example || 'Hello, how can you help me?'}"</p>
            </div>
          </div>
        ) : (
          messages.map((message) => (
            <ChatMessage key={message.id} message={message} />
          ))
        )}
        
        {isLoading && (
          <div className="flex items-center space-x-3 animate-fade-in">
            <div className="w-8 h-8 rounded-full bg-slate-100 flex items-center justify-center">
              <i className={`fas ${AGENTS[selectedAgent]?.icon || 'fa-robot'} text-slate-600`}></i>
            </div>
            <div className="flex space-x-1">
              <div className="w-2 h-2 bg-slate-400 rounded-full animate-bounce"></div>
              <div className="w-2 h-2 bg-slate-400 rounded-full animate-bounce" style={{animationDelay: '0.1s'}}></div>
              <div className="w-2 h-2 bg-slate-400 rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
            </div>
          </div>
        )}
        <div ref={messagesEndRef} />
      </div>

      {/* Input */}
      <div className="bg-white border-t border-slate-200 p-4">
        <div className="flex items-end space-x-3">
          <button
            onClick={handleFileUpload}
            className="p-2 text-slate-600 hover:text-slate-800 hover:bg-slate-100 rounded-lg transition-colors"
            title="Upload PDF"
          >
            <i className="fas fa-plus text-lg"></i>
          </button>
          
          <div className="flex-1">
            <textarea
              value={inputText}
              onChange={(e) => setInputText(e.target.value)}
              onKeyDown={handleKeyPress}
              placeholder={`Ask to ${AGENTS[selectedAgent]?.name || 'AI Assistant'}...`}
              className="w-full px-4 py-3 border border-slate-300 rounded-lg resize-none focus:outline-none focus:ring-2 focus:ring-teal-500 focus:border-transparent"
              rows={1}
              disabled={isLoading}
            />
          </div>
          
          <button
            onClick={onSendMessage}
            disabled={!inputText.trim() || isLoading}
            className="px-4 py-3 bg-teal-600 text-white rounded-lg hover:bg-teal-700 disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
          >
            <i className="fas fa-paper-plane"></i>
          </button>
        </div>
        <div className="mt-2 flex items-center justify-between text-xs text-slate-500">
          <span>Use Tavily ‚Ä¢ Shift+Enter for new line</span>
          <span>0 chars ‚Ä¢ Shift+Enter to send</span>
        </div>
      </div>

      {/* Hidden file input */}
      <input
        ref={fileInputRef}
        type="file"
        accept=".pdf"
        onChange={handleFileChange}
        className="hidden"
      />
    </div>
  );
};

export default ChatPane;


================================================
FILE: src/components/Header.tsx
================================================
import React from 'react';

interface HeaderProps {
  allowTavily: boolean;
  setAllowTavily: (value: boolean) => void;
  allowLlmKnowledge: boolean;
  setAllowLlmKnowledge: (value: boolean) => void;
  allowWebSearch: boolean;
  setAllowWebSearch: (value: boolean) => void;
  onClear: () => void;
  onExport: () => void;
}

const Header: React.FC<HeaderProps> = ({
  allowTavily,
  setAllowTavily,
  allowLlmKnowledge,
  setAllowLlmKnowledge,
  allowWebSearch,
  setAllowWebSearch,
  onClear,
  onExport
}) => {
  return (
    <header className="bg-white border-b border-slate-200 px-6 py-3">
      <div className="flex items-center justify-between">
        <div className="flex items-center space-x-6">
          <h1 className="text-xl font-semibold text-slate-800">
            GenAI Studio <span className="text-sm font-normal text-slate-500">(Hackathon PoC)</span>
          </h1>
          <div className="flex items-center space-x-4">
            <span className="px-2 py-1 text-xs bg-slate-100 text-slate-600 rounded-md">
              Local ‚Ä¢ No DB
            </span>
            
            {/* Elegant Toggle Switches */}
            <div className="flex items-center space-x-6 ml-4">
              {/* Tavily Toggle */}
              <div className="flex items-center space-x-2">
                <label className="relative inline-flex items-center cursor-pointer">
                  <input
                    type="checkbox"
                    checked={allowTavily}
                    onChange={(e) => setAllowTavily(e.target.checked)}
                    className="sr-only peer"
                  />
                  <div className="w-9 h-5 bg-slate-200 peer-focus:outline-none peer-focus:ring-2 peer-focus:ring-teal-300 rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:rounded-full after:h-4 after:w-4 after:transition-all peer-checked:bg-teal-500"></div>
                </label>
                <span className="text-xs text-slate-600 font-medium">
                  Tavily <span className="text-slate-400">(legacy)</span>
                </span>
              </div>

              {/* LLM Knowledge Toggle */}
              <div className="flex items-center space-x-2">
                <label className="relative inline-flex items-center cursor-pointer">
                  <input
                    type="checkbox"
                    checked={allowLlmKnowledge}
                    onChange={(e) => setAllowLlmKnowledge(e.target.checked)}
                    className="sr-only peer"
                  />
                  <div className="w-9 h-5 bg-slate-200 peer-focus:outline-none peer-focus:ring-2 peer-focus:ring-blue-300 rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:rounded-full after:h-4 after:w-4 after:transition-all peer-checked:bg-blue-500"></div>
                </label>
                <span className="text-xs text-slate-600 font-medium flex items-center space-x-1">
                  <i className="fas fa-brain text-blue-500"></i>
                  <span>LLM Knowledge</span>
                </span>
              </div>

              {/* Web Search Toggle */}
              <div className="flex items-center space-x-2">
                <label className="relative inline-flex items-center cursor-pointer">
                  <input
                    type="checkbox"
                    checked={allowWebSearch}
                    onChange={(e) => setAllowWebSearch(e.target.checked)}
                    className="sr-only peer"
                  />
                  <div className="w-9 h-5 bg-slate-200 peer-focus:outline-none peer-focus:ring-2 peer-focus:ring-purple-300 rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:rounded-full after:h-4 after:w-4 after:transition-all peer-checked:bg-purple-500"></div>
                </label>
                <span className="text-xs text-slate-600 font-medium flex items-center space-x-1">
                  <i className="fas fa-search text-purple-500"></i>
                  <span>Web Search</span>
                </span>
              </div>
            </div>
          </div>
        </div>

        <div className="flex items-center space-x-3">
          <span className="px-2 py-1 text-xs bg-green-100 text-green-600 rounded-md">
            PII Redaction ON
          </span>
          <button
            onClick={onClear}
            className="px-3 py-1 text-sm text-slate-600 hover:text-slate-800"
          >
            Clear
          </button>
          <button
            onClick={onExport}
            className="px-3 py-1 text-sm text-slate-600 hover:text-slate-800"
          >
            Export
          </button>
        </div>
      </div>
    </header>
  );
};

export default Header;


================================================
FILE: src/components/LeftRail.tsx
================================================
import React from 'react';
import { AGENTS } from '../config/agents';

interface LeftRailProps {
  selectedAgent: string;
  onSelectAgent: (agent: string) => void;
  onUseExample: (agent: string) => void;
}

interface AgentItemProps {
  agentKey: string;
  agent: any;
  isSelected: boolean;
  onSelect: () => void;
  onUseExample: () => void;
}

function AgentItem({ agentKey, agent, isSelected, onSelect, onUseExample }: AgentItemProps) {
  return (
    <div 
      className={`p-3 border-b border-slate-100 cursor-pointer hover:bg-slate-50 transition-colors ${
        isSelected ? 'bg-teal-50 border-r-2 border-teal-500' : ''
      }`}
      onClick={onSelect}
    >
      <div className="flex items-center justify-between">
        <div className="flex items-center space-x-3">
          <i className={`fas ${agent.icon} ${agent.color}`}></i>
          <div>
            <div className="font-medium text-sm text-slate-800">
              {agent.name}
            </div>
            <div className="text-xs text-slate-500 mt-1">
              {agent.tooltip}
            </div>
          </div>
        </div>
        <button
          onClick={(e) => {
            e.stopPropagation();
            onUseExample();
          }}
          className="text-xs text-teal-600 hover:text-teal-700 p-1"
          title="Try Example"
        >
          <i className="fas fa-play"></i>
        </button>
      </div>
    </div>
  );
}

const LeftRail: React.FC<LeftRailProps> = ({ selectedAgent, onSelectAgent, onUseExample }) => {
  return (
    <div className="w-64 bg-white border-r border-slate-200 flex flex-col">
      <div className="p-4 border-b border-slate-200">
        <h2 className="font-medium text-slate-800 mb-3">Agents</h2>
      </div>
      <div className="flex-1 overflow-y-auto">
        {Object.entries(AGENTS).map(([key, agent]) => (
          <AgentItem
            key={key}
            agentKey={key}
            agent={agent}
            isSelected={selectedAgent === key}
            onSelect={() => onSelectAgent(key)}
            onUseExample={() => onUseExample(key)}
          />
        ))}
      </div>
    </div>
  );
};

export default LeftRail;


================================================
FILE: src/components/MarkdownRenderer.tsx
================================================
import React from 'react';
import ReactMarkdown from 'react-markdown';
import rehypeHighlight from 'rehype-highlight';
import remarkGfm from 'remark-gfm';
import 'highlight.js/styles/github-dark.css';

interface MarkdownRendererProps {
  content: string;
  className?: string;
}

const MarkdownRenderer: React.FC<MarkdownRendererProps> = ({ content, className = '' }) => {
  // Process content to handle redacted text
  const processedContent = content.replace(/\[REDACTED[^\]]*\]/g, '‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà');

  const components = {
    code: ({ node, inline, className, children, ...props }: any) => {
      const match = /language-(\w+)/.exec(className || '');
      const language = match ? match[1] : '';
      
      return !inline ? (
        <div className="my-4">
          {language && (
            <div className="bg-slate-100 px-3 py-1 text-xs font-mono text-slate-600 border-t border-l border-r border-slate-300 rounded-t">
              {language}
            </div>
          )}
          <pre className={`bg-slate-900 text-slate-100 p-4 rounded${language ? '-b' : ''} overflow-x-auto`}>
            <code className={className} {...props}>
              {children}
            </code>
          </pre>
        </div>
      ) : (
        <code className="bg-slate-100 text-slate-800 px-1.5 py-0.5 rounded text-sm font-mono" {...props}>
          {children}
        </code>
      );
    },
    h1: ({ children }: any) => <h1 className="text-2xl font-bold text-slate-800 mt-8 mb-4">{children}</h1>,
    h2: ({ children }: any) => <h2 className="text-xl font-bold text-slate-800 mt-6 mb-3">{children}</h2>,
    h3: ({ children }: any) => <h3 className="text-lg font-semibold text-slate-800 mt-4 mb-2">{children}</h3>,
    p: ({ children }: any) => <p className="mb-3 leading-relaxed">{children}</p>,
    ul: ({ children }: any) => <ul className="list-disc list-inside mb-3 space-y-1">{children}</ul>,
    ol: ({ children }: any) => <ol className="list-decimal list-inside mb-3 space-y-1">{children}</ol>,
    li: ({ children }: any) => <li className="ml-2">{children}</li>,
    strong: ({ children }: any) => <strong className="font-semibold text-slate-800">{children}</strong>,
    em: ({ children }: any) => <em className="italic">{children}</em>,
    blockquote: ({ children }: any) => (
      <blockquote className="border-l-4 border-slate-300 pl-4 italic text-slate-600 mb-3">
        {children}
      </blockquote>
    ),
    table: ({ children }: any) => (
      <div className="overflow-x-auto mb-4">
        <table className="min-w-full border border-slate-300">{children}</table>
      </div>
    ),
    th: ({ children }: any) => (
      <th className="border border-slate-300 bg-slate-100 px-4 py-2 text-left font-semibold">{children}</th>
    ),
    td: ({ children }: any) => (
      <td className="border border-slate-300 px-4 py-2">{children}</td>
    )
  };

  return (
    <div className={`prose prose-sm max-w-none text-slate-700 markdown-content ${className}`}>
      <ReactMarkdown
        components={components}
        rehypePlugins={[rehypeHighlight]}
        remarkPlugins={[remarkGfm]}
      >
        {processedContent}
      </ReactMarkdown>
    </div>
  );
};

export default MarkdownRenderer;


================================================
FILE: src/components/RightInspector.tsx
================================================
import React, { useState, useEffect, useRef } from 'react';
import { UploadedPdf } from '../types';

interface RightInspectorProps {
  activePanel: string;
  setActivePanel: (panel: string) => void;
  citations: string[];
  toolTrace: any[];
  uploadedPdfs: UploadedPdf[];
  selectedPdfChunk: any;
  setSelectedPdfChunk: (chunk: any) => void;
}

const RightInspector: React.FC<RightInspectorProps> = ({
  activePanel,
  setActivePanel,
  citations,
  toolTrace,
  uploadedPdfs,
  selectedPdfChunk,
  setSelectedPdfChunk
}) => {
  return (
    <div className="w-80 bg-white border-l border-slate-200 flex flex-col">
      {/* Tabs */}
      <div className="border-b border-slate-200">
        <div className="flex">
          <button
            onClick={() => setActivePanel('citations')}
            className={`flex-1 px-4 py-3 text-sm font-medium border-b-2 ${
              activePanel === 'citations'
                ? 'text-teal-600 border-teal-500'
                : 'text-slate-500 border-transparent hover:text-slate-700 hover:border-slate-300'
            }`}
          >
            <i className="fas fa-quote-left mr-2"></i>
            Citations
          </button>
          <button
            onClick={() => setActivePanel('tools')}
            className={`flex-1 px-4 py-3 text-sm font-medium border-b-2 ${
              activePanel === 'tools'
                ? 'text-teal-600 border-teal-500'
                : 'text-slate-500 border-transparent hover:text-slate-700 hover:border-slate-300'
            }`}
          >
            <i className="fas fa-cog mr-2"></i>
            Tool Trace
          </button>
          <button
            onClick={() => setActivePanel('pdfs')}
            className={`flex-1 px-4 py-3 text-sm font-medium border-b-2 relative ${
              activePanel === 'pdfs'
                ? 'text-teal-600 border-teal-500'
                : 'text-slate-500 border-transparent hover:text-slate-700 hover:border-slate-300'
            }`}
          >
            <i className="fas fa-file-pdf mr-2"></i>
            Doc Viewer
            {uploadedPdfs.length > 0 && (
              <span className="absolute -top-1 -right-1 w-5 h-5 bg-red-500 text-white text-xs rounded-full flex items-center justify-center">
                {uploadedPdfs.length}
              </span>
            )}
          </button>
        </div>
      </div>

      {/* Content */}
      <div className="flex-1 overflow-y-auto">
        {activePanel === 'citations' && (
          <div className="p-4">
            <h3 className="font-medium text-slate-800 mb-4">Sources & Citations</h3>
            {citations.length > 0 ? (
              <div className="space-y-3">
                {citations.map((citation, index) => (
                  <div key={index} className="p-3 bg-slate-50 rounded-lg border border-slate-200">
                    <div className="flex items-start space-x-2">
                      <span className="flex-shrink-0 w-5 h-5 bg-teal-100 text-teal-700 rounded text-xs font-medium flex items-center justify-center">
                        {index + 1}
                      </span>
                      <div className="text-sm text-slate-700 leading-relaxed">
                        {citation}
                      </div>
                    </div>
                  </div>
                ))}
              </div>
            ) : (
              <div className="text-center py-8">
                <i className="fas fa-quote-left text-3xl text-slate-300 mb-3"></i>
                <p className="text-slate-500 text-sm">No citations yet</p>
                <p className="text-xs text-slate-400 mt-1">Citations will appear here when you chat with agents</p>
              </div>
            )}
          </div>
        )}

        {activePanel === 'tools' && (
          <div className="p-4">
            <h3 className="font-medium text-slate-800 mb-4">Tool Trace</h3>
            {toolTrace.length > 0 ? (
              <div className="space-y-3">
                {toolTrace.map((trace, index) => (
                  <div key={index} className="p-3 bg-slate-50 rounded-lg border border-slate-200">
                    <div className="text-sm font-medium text-slate-800 mb-2">
                      {trace.tool_name}
                    </div>
                    <div className="text-xs text-slate-600">
                      Status: {trace.status}
                    </div>
                  </div>
                ))}
              </div>
            ) : (
              <div className="text-center py-8">
                <i className="fas fa-cog text-3xl text-slate-300 mb-3"></i>
                <p className="text-slate-500 text-sm">No tool traces yet</p>
                <p className="text-xs text-slate-400 mt-1">Tool execution logs will appear here</p>
              </div>
            )}
          </div>
        )}

        {activePanel === 'pdfs' && (
          <DocViewerPanel 
            uploadedPdfs={uploadedPdfs}
            selectedPdfChunk={selectedPdfChunk}
            setSelectedPdfChunk={setSelectedPdfChunk}
          />
        )}
      </div>
    </div>
  );
};

// Doc Viewer Panel Component
function DocViewerPanel({ uploadedPdfs, selectedPdfChunk, setSelectedPdfChunk }: {
  uploadedPdfs: UploadedPdf[];
  selectedPdfChunk: any;
  setSelectedPdfChunk: (chunk: any) => void;
}) {
  const [selectedPdf, setSelectedPdf] = useState<UploadedPdf | null>(null);
  const [currentPage, setCurrentPage] = useState(0);
  const [pageData, setPageData] = useState<any>(null);
  const [loading, setLoading] = useState(false);
  const [imgLoaded, setImgLoaded] = useState<boolean | null>(null);
  const imgRef = useRef<HTMLImageElement>(null);

  useEffect(() => {
    if (selectedPdf && currentPage !== null) {
      loadPageData();
    }
  }, [selectedPdf, currentPage]);

  // Auto-select PDF when chunk is selected from citations
  useEffect(() => {
    if (selectedPdfChunk && uploadedPdfs.length > 0 && !selectedPdf) {
      // Find which PDF contains this chunk
      const findPdfWithChunk = async () => {
        for (const pdf of uploadedPdfs) {
          try {
            const response = await fetch(`/pdf/${pdf.pdf_id}/info`);
            const pdfInfo = await response.json();
            
            // Check if this PDF has the selected chunk
            const hasChunk = pdfInfo.chunks && pdfInfo.chunks.some((chunk: any) => 
              chunk.chunk_id === selectedPdfChunk
            );
            
            if (hasChunk) {
              setSelectedPdf(pdf);
              
              // Find the page containing this chunk
              const matchingChunk = pdfInfo.chunks.find((chunk: any) => 
                chunk.chunk_id === selectedPdfChunk
              );
              
              if (matchingChunk) {
                setCurrentPage(matchingChunk.page_number || 0);
              }
              break;
            }
          } catch (error) {
            console.error(`Error checking PDF ${pdf.filename}:`, error);
          }
        }
      };
      
      findPdfWithChunk();
    }
  }, [selectedPdfChunk, uploadedPdfs, selectedPdf]);

  const loadPageData = async () => {
    if (!selectedPdf) return;
    
    setLoading(true);
    try {
      const response = await fetch(`/pdf/${selectedPdf.pdf_id}/page/${currentPage}`);
      const data = await response.json();
      setPageData(data);
    } catch (error) {
      console.error('Error loading page data:', error);
      setPageData(null);
    }
    setLoading(false);
  };

  const handlePdfSelect = (pdf: UploadedPdf) => {
    setSelectedPdf(pdf);
    setCurrentPage(0);
    setPageData(null);
  };

  const nextPage = () => {
    if (selectedPdf && currentPage < selectedPdf.total_pages - 1) {
      setCurrentPage(currentPage + 1);
    }
  };

  const prevPage = () => {
    if (currentPage > 0) {
      setCurrentPage(currentPage - 1);
    }
  };

  return (
    <div className="p-4">
      <h3 className="font-medium text-slate-800 mb-4">Document Viewer</h3>
      
      {uploadedPdfs.length === 0 ? (
        <div className="text-center py-8">
          <i className="fas fa-file-pdf text-3xl text-slate-300 mb-3"></i>
          <p className="text-slate-500 text-sm">No PDFs uploaded</p>
          <p className="text-xs text-slate-400 mt-1">Drag & drop PDF files to analyze them</p>
        </div>
      ) : !selectedPdf ? (
        <div className="space-y-3">
          {uploadedPdfs.map((pdf) => (
            <div 
              key={pdf.pdf_id} 
              className="p-3 bg-slate-50 rounded-lg border border-slate-200 cursor-pointer hover:bg-slate-100"
              onClick={() => handlePdfSelect(pdf)}
            >
              <div className="flex items-center space-x-3">
                <i className="fas fa-file-pdf text-red-500 text-lg"></i>
                <div className="flex-1">
                  <div className="font-medium text-sm text-slate-800 truncate">
                    {pdf.filename}
                  </div>
                  <div className="text-xs text-slate-600 space-y-1 mt-1">
                    <div>üìÑ {pdf.total_pages} pages</div>
                    <div>üß© {pdf.chunks} chunks</div>
                    <div>‚ö° {pdf.processing_time.toFixed(2)}s</div>
                  </div>
                </div>
              </div>
            </div>
          ))}
        </div>
      ) : (
        <div className="space-y-4">
          {/* PDF Header */}
          <div className="flex items-center justify-between">
            <button
              onClick={() => setSelectedPdf(null)}
              className="text-teal-600 hover:text-teal-700 text-sm flex items-center space-x-1"
            >
              <i className="fas fa-arrow-left"></i>
              <span>Back to list</span>
            </button>
            <div className="text-xs text-slate-600">
              {selectedPdf.filename}
            </div>
          </div>

          {/* Page Navigation */}
          <div className="flex items-center justify-between py-2 border-t border-b border-slate-200">
            <button
              onClick={prevPage}
              disabled={currentPage === 0}
              className="p-1 text-slate-600 hover:text-slate-800 disabled:opacity-30 disabled:cursor-not-allowed"
            >
              <i className="fas fa-chevron-left"></i>
            </button>
            <span className="text-sm text-slate-600">
              Page {currentPage + 1} of {selectedPdf.total_pages}
            </span>
            <button
              onClick={nextPage}
              disabled={currentPage >= selectedPdf.total_pages - 1}
              className="p-1 text-slate-600 hover:text-slate-800 disabled:opacity-30 disabled:cursor-not-allowed"
            >
              <i className="fas fa-chevron-right"></i>
            </button>
          </div>

          {/* PDF Page Viewer */}
          <div className="relative">
            {loading ? (
              <div className="flex items-center justify-center py-8">
                <div className="animate-spin h-6 w-6 border-2 border-teal-500 border-t-transparent rounded-full"></div>
              </div>
            ) : pageData ? (
              <div className="relative border border-slate-200 rounded overflow-hidden">
                <img
                  ref={imgRef}
                  src={`data:image/png;base64,${pageData.image_base64}`}
                  alt={`Page ${currentPage + 1}`}
                  className="w-full h-auto"
                  onLoad={() => setImgLoaded(true)}
                  onError={() => setImgLoaded(false)}
                />
                
                {/* Chunk overlays */}
                {imgLoaded && pageData.chunks && imgRef.current && (() => {
                  const img = imgRef.current;
                  const scaleX = img.offsetWidth / img.naturalWidth;
                  const scaleY = img.offsetHeight / img.naturalHeight;
                  
                  return pageData.chunks.map((chunk: any, index: number) => {
                    if (!chunk.bbox) return null;
                    
                    return (
                      <div
                        key={chunk.chunk_id}
                        className={`absolute border-2 cursor-pointer transition-all ${
                          selectedPdfChunk === chunk.chunk_id 
                            ? 'border-teal-500 bg-teal-500 bg-opacity-20' 
                            : 'border-blue-500 bg-blue-500 bg-opacity-10 hover:bg-opacity-20'
                        }`}
                        style={{
                          left: `${chunk.bbox.x * scaleX}px`,
                          top: `${chunk.bbox.y * scaleY}px`, 
                          width: `${chunk.bbox.width * scaleX}px`,
                          height: `${chunk.bbox.height * scaleY}px`
                        }}
                        onClick={() => setSelectedPdfChunk(
                          selectedPdfChunk === chunk.chunk_id ? null : chunk.chunk_id
                        )}
                        title={chunk.text}
                      >
                        <div className="absolute -top-5 -left-0.5 bg-blue-500 text-white text-xs px-1 rounded">
                          {index + 1}
                        </div>
                      </div>
                    );
                  });
                })()}
              </div>
            ) : (
              <div className="flex items-center justify-center py-8 text-slate-500">
                <i className="fas fa-exclamation-triangle mr-2"></i>
                Failed to load page
              </div>
            )}
          </div>

          {/* Chunk Details */}
          {selectedPdfChunk && pageData && (
            <div className="mt-3 p-3 bg-slate-50 rounded border border-slate-200">
              <h4 className="text-sm font-medium text-slate-800 mb-2">Selected Chunk</h4>
              {(() => {
                const chunk = pageData.chunks.find((c: any) => c.chunk_id === selectedPdfChunk);
                return chunk ? (
                  <div>
                    <div className="text-xs text-slate-600 mb-1">
                      ID: {chunk.chunk_id} ‚Ä¢ Confidence: {(chunk.confidence * 100).toFixed(1)}%
                    </div>
                    <div className="text-sm text-slate-700 max-h-32 overflow-y-auto">
                      {chunk.text}
                    </div>
                  </div>
                ) : null;
              })()}
            </div>
          )}
        </div>
      )}
    </div>
  );
}

export default RightInspector;


================================================
FILE: src/config/agents.ts
================================================
import { Agent } from '../types';

export const AGENTS: Record<string, Agent> = {
  smart: {
    name: 'Smart Chat',
    icon: 'fa-brain',
    color: 'text-teal-600',
    example: 'Find a standing desk under ‚Çπ50k with 12-mo 0% APR',
    tooltip: 'AI router - finds the best agent for your query'
  },
  offerpilot: {
    name: 'OfferPilot',
    icon: 'fa-tags',
    color: 'text-blue-600',
    example: 'Show me wireless headphones under $200',
    tooltip: 'Product search with financing options'
  },
  dispute: {
    name: 'Dispute Copilot',
    icon: 'fa-balance-scale',
    color: 'text-red-600',
    example: 'I was charged twice for the same purchase',
    tooltip: 'Credit card dispute assistance'
  },
  collections: {
    name: 'Collections',
    icon: 'fa-credit-card',
    color: 'text-indigo-600',
    example: 'I need help with payment plan options',
    tooltip: 'Hardship and payment assistance'
  },
  devcopilot: {
    name: 'DevCopilot',
    icon: 'fa-code',
    color: 'text-green-600',
    example: 'Generate Python code for payment processing',
    tooltip: 'Code generation and API documentation'
  },
  carecredit: {
    name: 'CareCredit',
    icon: 'fa-heartbeat',
    color: 'text-pink-600',
    example: 'Analyze this dental treatment estimate',
    tooltip: 'Medical/dental expense analysis'
  },
  narrator: {
    name: 'Narrator',
    icon: 'fa-chart-line',
    color: 'text-orange-600',
    example: 'Why did spend drop after 2025-07-31?',
    tooltip: 'Portfolio analytics and business insights'
  },
  imagegen: {
    name: 'ImageGen',
    icon: 'fa-image',
    color: 'text-violet-600',
    example: 'Create a futuristic city with flying cars and neon lights',
    tooltip: 'AI-powered image generation from text descriptions'
  }
};

